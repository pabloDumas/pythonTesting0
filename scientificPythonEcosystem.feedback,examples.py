this document is organized by 1. feedback and 2. examples (code)
    1. feedback's for [primarily] the scientific Python ecosystem (numpy, pandas, etc.) and other [mostly] Python docs (if anyone has time to make the updates, go you! if not, np but hopefully this helps someone out!)
    2. examples (code) again for [primarily] the scientific Python ecosystem (numpy, pandas, etc.) and [mostly] Python modules (this is for you webscrapers out there and you end users, that like seeing every combination of a docs e.g. function params; #comments like this usually state unexpected behavior or just something nifty!)
most run on Windows 10, python 3.10, numpy 1.23, pandas 1.5.2

Feedback
(done)  prepended means that these are the results of running the above source code
check that all are numpy (there are some python ones in here as well; check by url)

https://numpy.org/doc/stable/user/basics.rec.html#numpy.lib.recfunctions.find_duplicates
	need source code update to work with
		normal arrays that have more than one structured-field name (seems to only work for masked arrays..)
			a1=numpy.array([(11,11),(12,12),(13,13)],dtype=numpy.dtype({'names':['float0','int50'],'formats':['f4','i4']}))
			print(numpy.lib.recfunctions.find_duplicates(a1))
			(done) 'numpy.ndarray' object has no attribute 'filled'
https://numpy.org/doc/stable/user/basics.rec.html#numpy.lib.recfunctions.flatten_descr
	need source code update to work with titles,offsets,itemsize
		dtype0=numpy.dtype({'titles':['title0',None],'names':['name0','name1'],'formats':['U9','>f4'],'offsets':[0,12],'itemsize':36})
		print(numpy.lib.recfunctions.flatten_descr(dtype0))
		(done) too many values to unpack (expected 2)

https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.wald.html
	for whatever reason, when mean0=1 and scale0=20 in below code, numpy (incorrect) doesn't reflect scipy.stats equivalent (correct)
		for mean0 in [0.1,1,10]:
			for scale0 in [.01,1,20]:
				matplotlib.pyplot.hist(numpy.random.default_rng(8).wald(mean0,scale0,size=n0),bins=bins0,density=True)
				matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.wald.pdf(numpy.linspace(startX0,endX0,n0),scale=scale0),linewidth=2,color='wheat',label='wald')
				matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.invgauss.pdf(numpy.linspace(startX0,endX0,n0),mean0,scale=scale0)-.02,linewidth=2,color='green',label='invgauss')

https://numpy.org/doc/stable/user/basics.io.genfromtxt.html
	'numpy.lib.npyio.recfromtxt' > 'filling_values' doesn't
		1. allow 'None' as dictinonary key (e.g. fillValue applying to all columns)
		2. work (e.g. the passed in column:value combo doesn't actually change the output at all)
			s0=io.StringIO('comment0n0,n1,n2\nv0,v1,v2\n3,,m0')
			try:
				print(numpy.lib.npyio.recfromtxt(s0,comments='comment0',missing_values={1:'',None:'m0'},filling_values={1:'column1mv',None:'iAmNone0'},names=True,usecols=(-2,-1),delimiter=','))
			except Exception as e:
				print(e)
			(done) list indices must be integers or slices, not NoneType



numpy.org/doc/stable/reference/generated/numpy.frompyfunc.html
	'''identityobject, optional'''; not optional, it's actually just not supported (either through arg or kwarg passing..)
	'''The value to use for the identity attribute of the resulting object. '''; resulting object doesn't have identity attribute..




https://numpy.org/doc/stable/reference/generated/numpy.record.pprint.html
	if the array doesn't have structured dtype (i.e. dtype=[('int0','i4'),('int1','i4'),('str0','U4')]) then pprint() call tries to find the original ndarray class and you get errors like ''''numpy.ndarray' object has no attribute 'pprint'''' and ''''numpy.str_' object has no attribute 'pprint''''

https://numpy.org/doc/stable/reference/generated/numpy.ma.MaskedArray.torecords.html
	not an alias of numpy.ma.MaskedArray.toflex but same functionality

https://numpy.org/doc/stable/reference/maskedarray.baseclass.html
	setting numpy.ma.masked_print_options, then making masked array with mask, then printing same masked array  doesn't seem to use set 'numpy.ma.masked_print_options' value but rather just the default '--'..
		



https://numpy.org/doc/stable/user/basics.dispatch.html
	code coming after '''For this example we will only handle the method __call__''' >> is the code right (specifically '''if N is not None:''' with '''N = None''' won't N always be None.. code below also works
	
code0
import numbers
class dA0:
    def __init__(self,n,v,d):
        self.n=n
        self.v=v
        self.d=d
    def __repr__(self):
        return f'{self.__class__.__name__},n={self.n},v={self.v},d={self.d}'
    def __array__(self):
        return self.v*numpy.eye(self.n,dtype=self.d)
    def __array_ufunc__(self,ufunc,method,*a,**kwa):
        if method=='__call__':
            n0=None
            s0=[]
            for a0 in a:
                if isinstance(a0,numbers.Number):
                    s0.append(a0)
                elif isinstance(a0,self.__class__):
                    s0.append(a0.v)
                    if a0.n is not None:
                        if a0.n != self.n:
                            raise TypeError('inconsistentSizes')
                        else:
                            n0=a0.n
                else:
                    return NotImplemented
            return self.__class__(n0,ufunc(*s0,**kwa),numpy.float_)
        else:
            return NotImplemented

dA0i=dA0(4,2,numpy.float_)
print(dA0i)
print(numpy.array(dA0i))
print(numpy.asarray(dA0i))
print(numpy.add(dA0i,2.))
print(numpy.array(numpy.multiply(dA0i,100.)))


results0
dA0,n=4,v=2,d=<class 'numpy.float64'>
[[2. 0. 0. 0.]
 [0. 2. 0. 0.]
 [0. 0. 2. 0.]
 [0. 0. 0. 2.]]
[[2. 0. 0. 0.]
 [0. 2. 0. 0.]
 [0. 0. 2. 0.]
 [0. 0. 0. 2.]]
dA0,n=4,v=4.0,d=<class 'numpy.float64'>
[[200.   0.   0.   0.]
 [  0. 200.   0.   0.]
 [  0.   0. 200.   0.]
 [  0.   0.   0. 200.]]
		





https://numpy.org/doc/stable/reference/generated/numpy.ma.fix_invalid.html
	fill_value doesn't seem to do anything
		a0=numpy.arange(11).view(numpy.recarray).astype(numpy.float_)
		m0=numpy.arange(11)
		m0[:2]=1
		m0[2:]=0
		print(numpy.ma.fix_invalid(a0,mask=m0,copy=True,fill_value=676.))
		[-- -- -- 3.0 -- 5.0 -- 7.0 -- 9.0 10.0]



https://numpy.org/doc/stable/reference/generated/numpy.ma.default_fill_value.html
	default for numpy.str_,numpy.unicode_ is ''  and  for numpy.string_,numpy.bytes_ is b''
		only actual written out string (e.g. 'abc') is default 'N/A'

https://numpy.org/doc/stable/reference/maskedarray.baseclass.html#numpy.ma.masked
	can we add support for datetime
		'''Could not convert object to NumPy datetime'''


https://numpy.org/doc/stable/reference/generated/numpy.polynomial.polynomial.polypow.html
	'''maxpowerinteger, optional''' says '''Default is 16''' but no error when maxpower=17; what is true default?
		p2=numpy.polynomial.Polynomial([0,1])
		p2=p2.coef
		print(numpy.polynomial.polynomial.polypow(p2,17,maxpower=None))


https://numpy.org/doc/1.24/reference/generated/numpy.polynomial.polynomial.polyint.html
	carray_like ''1-D array of polynomial coefficients, ordered from low to high.''' but accepts 2-d (and more?); need to update to accepts [at least] 2-d


https://numpy.org/doc/stable/reference/generated/numpy.polynomial.polynomial.polyvander3d.html
	'''where 0 <= i <= l, 0 <= j <= m, and 0 <= j <= n. ''' needs to be '''where 0 <= i <= l, 0 <= j <= m, and 0 <= k <= n. ''' since:
		1. above '''If l, m, n are the given degrees in x, y, z''' where n corresponds to z (in the equation, k corresponds to 3rd dimension z)
		2. if you even try it (run it in numpy) and assign j something higher than n (again, which corresponds to z), it works (which, per the first, erroneous statement, it should not..)
		
		
https://numpy.org/doc/stable/reference/routines.polynomials.package.html#module-numpy.polynomial
	'''Poly.nickname â€“ String used in printing''' doesn't exist in either the class or an instance of the class; needs to be removed
	
https://numpy.org/doc/stable/reference/routines.polynomials.classes.html
	'''It is intended that all polynomial instances are immutable, therefore augmented operations (+=, -=, etc.) and any other functionality that would violate the immutablity of a polynomial instance are intentionally unimplemented.'''  but +=, etc. works (doesn't return NotImplemented); I get that there might be some behind-the-scenes copy and instantiation to make it appear like these immutable types are mutable but we need to state that += ARE POSSIBLE because of this

https://numpy.org/doc/stable/reference/generated/numpy.polynomial.chebyshev.chebpts1.html
	'''The Chebyshev points of the first kind are the points cos(x), where x = [pi*(k + .5)/npts for k in range(npts)].''' needs to be '''The Chebyshev points of the first kind are the points -cos(x), where x = [pi*(k + .5)/npts for k in range(npts)].''' (or similar to what we have in https://numpy.org/doc/stable/reference/generated/numpy.polynomial.chebyshev.chebpts2.html where we tack on '''sorted in ascending order''')   to make the formula and the result of this function align

https://numpy.org/doc/stable/reference/generated/numpy.polynomial.chebyshev.chebpts2.html
	doesn't correspond to roots of the Chebyshev second kind polynomial (per https://en.wikipedia.org/wiki/Chebyshev_polynomials, this is '''Similarly, the roots of Un are {\displaystyle x_{k}=\cos \left({\frac {k}{n+1}}\pi \right),\quad k=1,\ldots ,n.}x_{k}=\cos \left({\frac {k}{n+1}}\pi \right),\quad k=1,\ldots ,n.''')
		what's the value of this other than just a shortcut for '''cos(x), where x = [pi*k/(npts - 1) for k in range(npts)] sorted in ascending order'''  (it would be nice if numpy.polynomial.chebyshev.chebpts2 were 2nd kind roots just like numpy.polynomial.chebyshev.chebpts1 are 1st kind roots)


https://en.wikipedia.org/wiki/Chebyshev_polynomials
	numpy.polynomial.Chebyshev([1,0,-8,0,8]).roots()  doesn't match  Wikipedia's roots formula results (which is the same as numpy.polynomial.chebyshev.chebpts1(4) results)  for  Chebyshev first kind fourth degree polynomial; which one is right (numpy.polynomial.Chebyshev([1,0,-8,0,8]).roots() or Wikipedia)?
		numpy
			1.0 + 0.0 T_1(x) - 8.0 T_2(x) + 0.0 T_3(x) + 8.0 T_4(x)
			[-0.98921858 -0.52100538  0.52100538  0.98921858]
			[-0.92387953 -0.38268343  0.38268343  0.92387953]
		Wikipedia
			Roots and extrema
			one can show that the roots of Tn are
			{\displaystyle x_{k}=\cos \left({\frac {\pi (k+1/2)}{n}}\right),\quad k=0,\ldots ,n-1.}{\displaystyle x_{k}=\cos \left({\frac {\pi (k+1/2)}{n}}\right),\quad k=0,\ldots ,n-1.}

https://numpy.org/doc/stable/reference/generated/numpy.busday_offset.html#numpy.busday_offset
	needs to handle 'None's well but currently doesn't (e.g. if you specify 'holidays=None' as 1 of the kwargs, you get the below error (same thing for the others..); other Numpy objects are quite good at doing so, especially if you want to iterate through a list of kwarg values, one of which is None and you don't want an error!)
		C:\Users\pdumas\Documents\Code>py C:\Users\pdumas\Documents\Code\numpy0.py
		Traceback (most recent call last):
		  File "C:\Users\pdumas\Documents\Code\numpy0.py", line 7967, in <module>
			print(roll0,numpy.busday_offset(d0,0,roll=roll0,weekmask='1111100',holidays=None,busdaycal=None,out=None),sep='     ',end='\n')
		  File "<__array_function__ internals>", line 200, in busday_offset
		ValueError: holidays must be a provided as a one-dimensional array

		C:\Users\pdumas\Documents\Code>py C:\Users\pdumas\Documents\Code\numpy0.py
		Traceback (most recent call last):
		  File "C:\Users\pdumas\Documents\Code\numpy0.py", line 7967, in <module>
			print(roll0,numpy.busday_offset(d0,0,roll=roll0,weekmask='1111100',holidays=[],busdaycal=None,out=None),sep='     ',end='\n')
		  File "<__array_function__ internals>", line 200, in busday_offset
		TypeError: busday_offset() argument 6 must be numpy.busdaycalendar, not None

		C:\Users\pdumas\Documents\Code>py C:\Users\pdumas\Documents\Code\numpy0.py
		Traceback (most recent call last):
		  File "C:\Users\pdumas\Documents\Code\numpy0.py", line 7967, in <module>
			print(roll0,numpy.busday_offset(d0,0,roll=roll0,weekmask='1111100',holidays=[],out=None),sep='     ',end='\n')
		  File "<__array_function__ internals>", line 200, in busday_offset
		ValueError: busday_offset: must provide a NumPy array for 'out'
	
		this comment also applies to
			https://numpy.org/doc/stable/reference/generated/numpy.is_busday.html
			https://numpy.org/doc/stable/reference/generated/numpy.busday_count.html

https://numpy.org/doc/stable/reference/generated/numpy.busdaycalendar.html
	need to mention that holidays will only be filled if they're on valid [business] days (e.g. if you have Monday as the only valid business day and make a Tuesday a holiday, busdaycalendar0.holidays will be [] (NOT [<whatever date you chose as the Tuesday holiday>])

https://numpy.org/doc/stable/reference/generated/numpy.datetime_data.html
	need to explain what's going on in background that makes these (below code) not align (one would expect they would..)
		d0=numpy.dtype('datetime64[2D]')
		print(d0)
		ad0=numpy.arange('2023-01-06','2023-02-28',2,dtype='datetime64[D]')
		print(ad0)
		ad1=numpy.arange('2023-01-06','2023-02-28',dtype=d0)
		print(ad1)
		print(ad0==ad1)

https://numpy.org/doc/stable/reference/generated/numpy.datetime_as_string.html
	need to mention that:
		timezone='UTC' and timezone='local' only show effect if a TIME (not on just a DATE)
		to use pytz timezones, one needs casting='unsafe' (wish I knew that beforehand!)
		'None' and 'auto' are no different ?






https://docs.python.org/3/library/filecmp.html
	'left_list', 'left_only', etc. don't appear in attributes (yet we're sure there are files in only left for 'left_only') but they appear in this 'methodmap' object as e.g. ''''left_only': <function dircmp.phase1 at 0x00000000134DD630>'''; need to explain what this is and how it works
		d0=r'C:\Users\pdumas\Documents\Code\filecmpTestDir0'
		d1=r'C:\Users\pdumas\Documents\Code\filecmpTestDir1'
		dircmp0=filecmp.dircmp(d0,d1,ignore=filecmp.DEFAULT_IGNORES,hide=None)
		for a0 in dir(dircmp0):
			print(a0,getattr(dircmp0,a0),sep='     ',end='\n')
	'report()','report_partial_closure()','report_full_closure()' all seem to print the same thing.. why  and  can we provide an example where they print different things
		for function0 in [dircmp0.report,dircmp0.report_partial_closure,dircmp0.report_full_closure]:
			print(function0,function0())

https://docs.python.org/3/library/difflib.html#difflib.IS_LINE_JUNK
https://docs.python.org/3/library/difflib.html#difflib.IS_CHARACTER_JUNK
	for the both the above, if you define own function, doesn't seem to work (default is the same as None is the same as own function)..  why  and  can we provide an example where they print different things
		import difflib
		l0=['ab','c d',' ef','a ef','# ef']
		l1=['ab','c de','ef','b ee','z ef']
		differ0=difflib.ndiff(l0,l1,linejunk=None,charjunk=None)
		differ1=difflib.ndiff(l0,l1,linejunk=None,charjunk=difflib.IS_CHARACTER_JUNK)
		differ2=difflib.ndiff(l0,l1,linejunk=difflib.IS_LINE_JUNK,charjunk=difflib.IS_CHARACTER_JUNK)
		for differ00 in [differ0,differ1,differ2]:
			for i,d in enumerate(differ00):
				print(differ00,i,d,sep='      ')
			print('')
		def linejunk0(string0):
			if string0.startswith('a'):
				return True
			return False
		def charjunk0(string0):
			if string0.startswith('f'):
				return True
			return False
		differ3=difflib.ndiff(l0,l1,linejunk=linejunk0,charjunk=charjunk0)
		for differ00 in [differ3]:
			for i,d in enumerate(differ00):
				print(differ00,i,d,sep='      ')
			print('')




https://docs.python.org/3/library/pprint.html#pprint.pformat
https://docs.python.org/3/library/pprint.html#pprint.pprint
	both of the above:  '''depth controls the number of nesting levels which may be printed; if the data structure being printed is too deep, the next contained level is replaced by .... By default, there is no constraint on the depth of the objects being formatted.'''  but '''depth''' only seems to apply to first instance of recursion; if there are multiple instances, the 2nd, 3rd, 4th, etc. instances are all not applied the '''depth''' kwarg value; said another way, '...' will only happen once, then everything is printed
		with open(r'C:\Users\pdumas\Documents\Code\pprint20230111\pprint20230111.txt','w+') as f0:
			print(pprint.pformat(rl2,indent=10,width=40,compact=True,depth=4,sort_dicts=False,underscore_numbers=True))
			pprint.pprint(rl2,indent=10,width=40,stream=f0,compact=True,depth=4,sort_dicts=False,underscore_numbers=True)
		[         [1, 2, [3, 4, [5, 6, [...]]]],
				  [         20_001, 22,
							[         23, 24,
									  [         25,
												26,
												[         27,
														  28,
														  [         29,
																	30,
																	[         31,
																			  32,
																			  [         33,
																						14]]]]]]],
				  {10: 1, 9: 2, 6: 5, 7: 4}]
		[         [1, 2, [3, 4, [5, 6, [...]]]],
				  [         20_001, 22,
							[         23, 24,
									  [         25,
												26,
												[         27,
														  28,
														  [         29,
																	30,
																	[         31,
																			  32,
																			  [         33,
																						14]]]]]]],






https://docs.python.org/3/library/unittest.html#unittest.doModuleCleanups
	'''If you need cleanup functions to be called prior to tearDownModule() then you can call doModuleCleanups() yourself.''' but cannot call it since it doesn't exist (see below code/result).. if it does, where and can we add a docs example of this
		try:
			unittest.doModuleCleanups()
		except Exception as e:
			print(e)

		module 'unittest' has no attribute 'doModuleCleanups'

https://docs.python.org/3/library/unittest.html#unittest.TestCase.run
		t1i0=t1(methodName='runTest')#only run seems to work whereas runTest does not
		try:
			print(t1i0.runTest(result=None))
		except Exception as e:
			print(e)
		try:
			print(t1i0())
		except Exception as e:
			print(e)
		t1i0=t1(methodName='run')#this will work!
		print(t1i0)
		print(t1i0.run(result=None))

https://docs.python.org/3/library/unittest.html#unittest.TestCase.addTypeEqualityFunc
	how useful is this really (and if it is useful, can we add an example); I spent quite a bit of time just now trying to get this working and all it seems to do is to allow the user to print more detail if a type matches vs. mismatches..  what all more detail could a user need? if the aforementioned is false, what else can it do? just trying to keep the module not too large / less is sometimes more!


https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.MultiIndex.from_arrays.html
	'''sortorderint or None   Level of sortedness (must be lexicographically sorted by that level).''' doesn't seem to do anything no matter what is specified..
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',sortorder0,pandas.MultiIndex.from_arrays([ia0,ia1],sortorder=sortorder0,names=None)) 
		 0 MultiIndex([(1, 3),
					(1, 2),
					(1, 1),
					(2, 3),
					(2, 2),
					(2, 1),
					(3, 3),
					(3, 2),
					(3, 1),
					(4, 3),
					(4, 2),
					(4, 1)],
				   )
				print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',sortorder0,pandas.MultiIndex.from_arrays([ia0,ia1],sortorder=sortorder0,names=pandas._NoDefault.no_default))
		 
		 module 'pandas' has no attribute '_NoDefault'
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',sortorder0,pandas.MultiIndex.from_arrays([ia0,ia1],sortorder=sortorder0,names=None)) 
		 1 MultiIndex([(1, 3),
					(1, 2),
					(1, 1),
					(2, 3),
					(2, 2),
					(2, 1),
					(3, 3),
					(3, 2),
					(3, 1),
					(4, 3),
					(4, 2),
					(4, 1)],
				   )
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',sortorder0,pandas.MultiIndex.from_arrays([ia0,ia1],sortorder=sortorder0,names=['1st','2nd'])) 
		 0 MultiIndex([('a', 'C'),
					('a', 'b'),
					('a', 'a'),
					('b', 'C'),
					('b', 'b'),
					('b', 'a'),
					('C', 'C'),
					('C', 'b'),
					('C', 'a'),
					('d', 'C'),
					('d', 'b'),
					('d', 'a')],
				   names=['1st', '2nd'])
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',sortorder0,pandas.MultiIndex.from_arrays([ia0,ia1],sortorder=sortorder0,names=['1st','2nd'])) 
		 1 MultiIndex([('a', 'C'),
					('a', 'b'),
					('a', 'a'),
					('b', 'C'),
					('b', 'b'),
					('b', 'a'),
					('C', 'C'),
					('C', 'b'),
					('C', 'a'),
					('d', 'C'),
					('d', 'b'),
					('d', 'a')],
				   names=['1st', '2nd'])



https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.MultiIndex.to_frame.html
	'''allow_duplicates   bool, optional default False   Allow duplicate column labels to be created'''  need to mention that if attempting to create duplicates when 'allow_duplicates=False' then error and include [similar to the] below as an example:
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd')).to_frame(index=False,name=['col0','col0'],allow_duplicates=False))
		Cannot create duplicate column labels if allow_duplicates is False

https://pandas.pydata.org/docs/user_guide/indexing.html#indexing-with-list-with-missing-labels-is-deprecated
	'''Current behavior
		s.loc[[1, 2, 3]]
		Passing list-likes to .loc with any non-matching elements will raise
		KeyError in the future, you can use .reindex() as an alternative.'''
		but this is not the CURRENT behavior for pandas 1.5.2, which are the docs I'm looking at and testing with; this will give a key error (see code/result below); we need to replace '''Current behavior''' example with an actual key error (not a deprecation warning)
			    print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).loc[[0,1,11]])
				'[11] not in index'


https://matplotlib.org/stable/api/dates_api.html#matplotlib.dates.relativedelta
	need to mention that if using kwargs 'dt1' and 'dt2' then overrides any (?) kwargs 'years','year',months','month',... (see below code/result for some examples)
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(dt1=datetime.date(2023,1,16),dt2=datetime.date(2023,1,23))) 
		 relativedelta(days=-7)
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(dt1=datetime.date(2023,1,17),dt2=datetime.date(2023,1,23))) 
		 relativedelta(days=-6)
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(dt1=datetime.date(2023,1,17),dt2=datetime.date(2023,1,23),years=2)) 
		 relativedelta(days=-6)
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(dt1=datetime.date(2023,1,17),dt2=datetime.date(2023,1,23),year=2020)) 
		 relativedelta(days=-6)
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2023,1,10)+matplotlib.dates.relativedelta(dt1=datetime.date(2023,1,17),dt2=datetime.date(2023,1,23),year=2020)) 
		 2023-01-04
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2023,1,10)+matplotlib.dates.relativedelta(year=2020)) 
		 2020-01-10
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2023,1,10)+matplotlib.dates.relativedelta(years=2)) 
		 2025-01-10
	need to note that MO(1),TU(2),WE(-2),... all (?) set 'weeks' attribute to 0 (makes sense since there's no way one can calculate a guaranteed-right week value since it all depends on the other addition operand, which is unknown at the time of creating the matplotlib.dates.relativedelta object!)
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(weekday=matplotlib.dates.TU(-2)).weeks) 
		 0
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(days=14.7,hours=27).weeks) 
		 2
	need to mention that 'nlyearday' will 'override' the check for whether the year is a leap year (whereas 'yearday' will do the opposite and always (?) check); add below code/result as examples
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2020,3,10)+matplotlib.dates.relativedelta(leapdays=1)) 
		 2020-03-11
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2020,3,10)+matplotlib.dates.relativedelta(yearday=92)) 
		 2020-04-01
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2020,3,10)+matplotlib.dates.relativedelta(nlyearday=92)) 
		 2020-04-02
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2021,3,10)+matplotlib.dates.relativedelta(leapdays=1)) 
		 2021-03-10
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2021,3,10)+matplotlib.dates.relativedelta(yearday=92)) 
		 2021-04-02
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2021,3,10)+matplotlib.dates.relativedelta(nlyearday=92)) 
		 2021-04-02

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.tseries.offsets.DateOffset.rollback.html
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.tseries.offsets.DateOffset.rollforward.html
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.tseries.offsets.DateOffset.is_on_offset.html
	can we add an example of a CUSTOM (i.e. not 'BDay', etc.) DateOffset with above called and giving results other than equal to (i.e. no-op) or True / that is interesting (based on the documentation, thought at least some of these would actually roll the date or give False!
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DateOffset(months=1)+pandas.Timestamp('2022-01-15')) 
		 2022-02-15 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DateOffset(months=1).rollback(pandas.DateOffset(months=1)+pandas.Timestamp('2022-01-15'))) 
		 2022-02-15 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3,day=15).is_on_offset(pandas.Timestamp('2023-01-01'))) 
		 True
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3,day=1).is_on_offset(pandas.Timestamp('2023-01-01'))) 
		 True

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.tseries.offsets.DateOffset.nanos.html#pandas.tseries.offsets.DateOffset.nanos
	is 'hours=1' really non-fixed.. why is this giving an error and can we add an example of one without an error
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(hour=1).nanos)
		<DateOffset: hour=1> is a non-fixed frequency
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(hours=1).nanos)
		<DateOffset: hours=1> is a non-fixed frequency

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.tseries.offsets.CustomBusinessHour.html
	we need to add that other kwargs are those of CustomBusinessDay (since below code/result works)
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')))+pandas.Timestamp('2023-01-15T23:40:00')) 
		 2023-01-17 00:00:00

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.cbday_roll.html#pandas.tseries.offsets.CustomBusinessMonthEnd.cbday_roll
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.month_roll.html#pandas.tseries.offsets.CustomBusinessMonthEnd.month_roll
	can we add examples of how these work and how to override these


https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.tseries.offsets.BQuarterEnd.html
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.tseries.offsets.BQuarterBegin.html
	need to mention that what is expected (i.e. aligning with business world) is NOT the default for 'BQuarterBegin' but IS the default for 'BQuarterEnd'; add below code/result as examples
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterEnd(n=-1,startingMonth=3))
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterEnd(n=1,startingMonth=3))
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterEnd(n=2,startingMonth=3))
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(-1))
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(1))
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(1,startingMonth=2))
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(1,startingMonth=0))#this is default  and  aligns with the business world
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(1,startingMonth=1))
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(2))
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterBegin(n=-1,startingMonth=3))
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterBegin(n=1,startingMonth=3))
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterBegin(n=2,startingMonth=3))#startingMonth loops if >2
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(-1))
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(1))
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(1,startingMonth=2))
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(1,startingMonth=0))#this is default
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(1,startingMonth=1))#this aligns with the business world
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(2))

		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterEnd(n=-1,startingMonth=3)) 
		 2022-12-30 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterEnd(n=1,startingMonth=3)) 
		 2023-03-31 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterEnd(n=2,startingMonth=3)) 
		 2023-06-30 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(-1)) 
		 2022-12-30 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(1)) 
		 2023-03-31 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(1,startingMonth=2)) 
		 2023-02-28 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(1,startingMonth=0))#this is default 
		 2023-03-31 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(1,startingMonth=1))#this aligns with the business world 
		 2023-04-28 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(2)) 
		 2023-06-30 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterBegin(n=-1,startingMonth=3)) 
		 2022-12-01 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterBegin(n=1,startingMonth=3)) 
		 2023-03-01 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterBegin(n=2,startingMonth=3))#startingMonth loops if >2 
		 2023-06-01 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(-1)) 
		 2022-12-01 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(1)) 
		 2023-03-01 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(1,startingMonth=2)) 
		 2023-05-01 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(1,startingMonth=0))#this is default 
		 2023-03-01 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(1,startingMonth=1))#this aligns with the business world 
		 2023-04-03 00:00:00
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(2)) 
		 2023-06-01 00:00:00

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.tseries.offsets.Tick.html
	need to add deprecation warning since it seems like 'Tick' is no longer what it once was and if it is indeed being removed (see below code/result)
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10 13:13:13.131313131')+e00())
		'pandas._libs.tslibs.offsets.Tick' object has no attribute '_reso'
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.Tick(5,unit='5D'))
		__init__() got an unexpected keyword argument 'unit'
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.Tick(5,freq='5D'))#seems like this Tick is being deprecated / removed..
		__init__() got an unexpected keyword argument 'freq'

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html
	need axis=1 support, as axis=1 is either NotImplemented (dict/Series gives error) or, if no error, doesn't seem to do anything; see code/result below
	print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3., 4., numpy.nan, 1.],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")).fillna(value={0:42},axis=1))
	Currently only can fill with dict/Series column by column
	print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3., 4., numpy.nan, 1.],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")).fillna(value=pandas.DataFrame([[57, 2, 57, 0],[3, 4, 57, 1],[57, 57, 57, 57],[57, 3, 57, 4]]),axis=1))#axis=1 is either NotImplemented or, if no error, doesn't seem to do anything 
	backfill      A    B   C    D
	0  NaN  2.0 NaN  0.0
	1  3.0  4.0 NaN  1.0
	2  NaN  NaN NaN  NaN
	3  NaN  3.0 NaN  4.0


https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.align.html
	need to update kwarg 'limit' to work in ALL instances (see below code/result for where more '42's showed up than expected! seems to not work when method=None ?)
		this worked as expected:
			print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),globals(),'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,5,1),'b':range(5,9,1),'c':range(9,13,1)}),copy=True,join='outer',broadcast_axis=broadcast_axis0,fill_axis=fill_axis0,method=method0,limit=1,axis=None)[0],'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,5,1),'b':range(5,9,1),'c':range(9,13,1)}),copy=True,join='outer',broadcast_axis=broadcast_axis0,fill_axis=fill_axis0,method=method0,limit=1,axis=None)[1]) {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x00000000036A49A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt', 'axis0': None, 'join0': 'outer', 'fill_axis0': 1, 'method0': 'pad', 'broadcast_axis0': 1, 'fill_value0': None} 
			a    b   c
			0  0.0  0.0 NaN
			1  1.0  1.0 NaN
			2  NaN  NaN NaN
			3  NaN  NaN NaN 
			a  b   c
			0  1  5   9
			1  2  6  10
			2  3  7  11
			3  4  8  12
	this did NOT work as expected:
			print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),globals(),'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,5,1),'b':range(5,9,1),'c':range(9,13,1)}),copy=True,join='outer',broadcast_axis=broadcast_axis0,fill_axis=fill_axis0,fill_value=fill_value0,limit=1,axis=None)[0],'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,5,1),'b':range(5,9,1),'c':range(9,13,1)}),copy=True,join='outer',broadcast_axis=broadcast_axis0,fill_axis=fill_axis0,fill_value=fill_value0,limit=1,axis=None)[1]) {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x00000000036A49A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt', 'axis0': None, 'join0': 'outer', 'fill_axis0': None, 'method0': None, 'broadcast_axis0': None, 'fill_value0': 42} 
				 a   b   c
			0   0  42  42
			1   1  42  42
			2  42  42  42
			3  42  42  42 
				a  b   c
			0  1  5   9
			1  2  6  10
			2  3  7  11
			3  4  8  12
	need to add for kwarg 'broadcast_axis' that '''If specified, either axis=0 or axis=1 must be specified.'''  (see code/result below as examples to add)
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1,2,3,4,5,6],[3,4,5,6,7,8],[4,5,6,7,8,9],[4,5,6,7,8,9]]).align(pandas.Series([1,2]),copy=True,join='outer',broadcast_axis=broadcast_axis0,axis=axis0)[0],'\n',pandas.DataFrame([[1,2,3,4,5,6],[3,4,5,6,7,8],[4,5,6,7,8,9],[4,5,6,7,8,9]]).align(pandas.Series([1,2]),copy=True,join='outer',broadcast_axis=broadcast_axis0,axis=axis0)[1]) 
		 {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x0000000002E549A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt', 'axis0': None, 'join0': 'outer', 'fill_axis0': None, 'method0': None, 'broadcast_axis0': 1, 'fill_value0': None} 
			0  1  2  3  4  5
		0  1  2  3  4  5  6
		1  3  4  5  6  7  8
		2  4  5  6  7  8  9
		3  4  5  6  7  8  9 
			  0    1    2    3    4    5
		0  1.0  1.0  1.0  1.0  1.0  1.0
		1  2.0  2.0  2.0  2.0  2.0  2.0
		2  NaN  NaN  NaN  NaN  NaN  NaN
		3  NaN  NaN  NaN  NaN  NaN  NaN
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1,2,3,4,5,6],[3,4,5,6,7,8],[4,5,6,7,8,9],[4,5,6,7,8,9]]).align(pandas.Series([1,2]),copy=True,join='outer',broadcast_axis=broadcast_axis0,axis=axis0)[0],'\n',pandas.DataFrame([[1,2,3,4,5,6],[3,4,5,6,7,8],[4,5,6,7,8,9],[4,5,6,7,8,9]]).align(pandas.Series([1,2]),copy=True,join='outer',broadcast_axis=broadcast_axis0,axis=axis0)[1])
		 Must specify axis=0 or 1
	 also, need to add examples of how 'broadcast_axis' adds value (on several different sets of arrays, seems to give the same results no matter what the 'broadcast_axis' kwarg value is; where we actually see differences is when you change the kwarg 'axis' NOT 'broadcast_axis'..)


https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby
	need to add for '''by   mapping, function, label, or list of labels''' that for '''mapping''' (e.g. dict) only 1 index level can have it's respective index values mapped to a group (not 2+ index levels; this will result in blank GroupedBy object..)  (based on code/result below)
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).drop("A",axis=1).set_index("B").groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'}))) 
		 {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x00000000032949A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt'} 
		 [('oneGroup',             C         D
		B                      
		one -1.099171 -0.283330
		one -0.313845 -1.358669
		one  0.279506  0.471686), ('otherGroup',               C         D
		B                        
		two   -1.591031 -1.493710
		three  1.606341 -1.695672
		two    0.500125 -1.766381
		two   -0.244692 -0.457272
		three -0.440796 -1.675488)]
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'})))#groupby(dict0) currently either only supported for one index (if you have 2 indices, the output will be an empty DataFrameGroupBy (only columns present; no data)  or  only supported for where all the indices coincide / map from keys to 1 value (in other words, key a with value 1 and key a1 with value 1 all are together, key b with value 2 and key b2 with value 2 are all together, no overlap; tested this below 
		 {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x00000000032949A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt'} 
		 []
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup','foo':'otherGroup','bar':'otherGroup'})))#same as above, returns empty list.. 
		 {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x00000000032949A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt'} 
		 []
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).drop("A",axis=1).set_index("B").groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'}))) 
		 {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x00000000032949A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt'} 
		 [('oneGroup',             C         D
		B                      
		one  0.379833 -0.401130
		one -1.174749 -1.553642
		one -0.163427 -1.399140
		one  0.694996  0.282167), ('otherGroup',               C         D
		B                        
		two    1.184309  0.666505
		two   -0.336130  0.865006
		three -0.092757 -0.815174
		three -0.234335 -1.669025)]
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'}))) 
		 {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x00000000032949A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt'} 
		 []
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup','foo':'oneGroup','bar':'otherGroup'})))#3 lines here and below: no matter what the combination, if it's more than 1 index, returns empty DataFrameGroupBy 
		 {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x00000000032949A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt'} 
		 []
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup','foo':'fooGroup','bar':'barGroup'}))) 
		 {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x00000000032949A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt'} 
		 []
		print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index(["A","B"]).groupby([{"one":'oneGroup','two':'otherGroup','three':'otherGroup'},{'foo':'fooGroup','bar':'barGroup'}]))) 
		 {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x00000000032949A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt'} 
		 []

https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#basics-aggregate
	'''porition''' needs to be '''portion'''


https://pandas.pydata.org/docs/user_guide/window.html
	need to clarify as quite confused: first we say '''Windowing operations currently only support numeric data (integer and float) and will always return float64 values.''' then 	https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.count.html we say '''numeric_only bool, default False
		Include only float, int, boolean columns.''' but 1. weren't only float and int supported to begin with (not bool, object, datetime64[ns], etc.) 2. below code/result shows, even when 'numeric_only=True' that we still get same result as 'numeric_only=False'  so we need to clarify that more than just int,float works for Rolling but also that '''pandas.core.window.rolling.Rolling.count''' kwarg will work in the future (or better yet fix to work now)
			print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df0.dtypes) 
			 {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x00000000038549A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'matplotlib': <module 'matplotlib' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py'>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt', 'df0':        col0      col1 col2       col3
			a b c                                
			f h l     0  0.326972    a 2023-01-21
				m     1  0.987277    a 2023-01-22
				n     2  0.318711    a 2023-01-23
				o     3  0.788549    a 2023-01-24
			  i l     4  0.869897    a 2023-01-25
				m     5  0.391085    a 2023-01-26
				n     6  0.437882    a 2023-01-27
				o     7  0.372749    a 2023-01-28
			  j l     8  0.106954    a 2023-01-29
				m     9  0.478965    a 2023-01-30
				n    10  0.241352    a 2023-01-31
				o    11  0.257145    a 2023-02-01
			  k l    12  0.184732    a 2023-02-02
				m    13  0.193865    a 2023-02-03
				n    14  0.813828    a 2023-02-04
				o    15  0.422984    a 2023-02-05
			g h l    16  0.255921    a 2023-02-06
				m    17  0.590903    b 2023-02-07
				n    18  0.604272    b 2023-02-08
				o    19  0.646858    b 2023-02-09
			  i l    20  0.911356    b 2023-02-10
				m    21  0.150206    b 2023-02-11
				n    22  0.371387    b 2023-02-12
				o    23  0.284621    b 2023-02-13
			  j l    24  0.016782    b 2023-02-14
				m    25  0.181554    b 2023-02-15
				n    26  0.394669    b 2023-02-16
				o    27  0.393311    b 2023-02-17
			  k l    28  0.616728    b 2023-02-18
				m    29  0.452267    b 2023-02-19
				n    30  0.607331    b 2023-02-20
				o    31  0.223060    b 2023-02-21} 
			 col0             int32
			col1           float64
			col2            object
			col3    datetime64[ns]
			dtype: object
			print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df0.rolling(window=3).count(numeric_only=numeric_only0)) 
			 {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x00000000038549A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'matplotlib': <module 'matplotlib' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py'>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt', 'df0':        col0      col1 col2       col3
			a b c                                
			f h l   0.0  0.326972    a 2023-01-21
				m   1.0  0.987277    a 2023-01-22
				n   NaN       NaN  NaN        NaT
				o   NaN       NaN  NaN        NaT
			  i l   NaN       NaN  NaN        NaT
				m   5.0  0.391085    a 2023-01-26
				n   6.0  0.437882    a 2023-01-27
				o   7.0  0.372749    a 2023-01-28
			  j l   8.0  0.106954    a 2023-01-29
				m   9.0  0.478965    a 2023-01-30
				n  10.0  0.241352    a 2023-01-31
				o  11.0  0.257145    a 2023-02-01
			  k l  12.0  0.184732    a 2023-02-02
				m  13.0  0.193865    a 2023-02-03
				n  14.0  0.813828    a 2023-02-04
				o  15.0  0.422984    a 2023-02-05
			g h l  16.0  0.255921    a 2023-02-06
				m  17.0  0.590903    b 2023-02-07
				n  18.0  0.604272    b 2023-02-08
				o  19.0  0.646858    b 2023-02-09
			  i l  20.0  0.911356    b 2023-02-10
				m  21.0  0.150206    b 2023-02-11
				n  22.0  0.371387    b 2023-02-12
				o  23.0  0.284621    b 2023-02-13
			  j l  24.0  0.016782    b 2023-02-14
				m  25.0  0.181554    b 2023-02-15
				n  26.0  0.394669    b 2023-02-16
				o  27.0  0.393311    b 2023-02-17
			  k l  28.0  0.616728    b 2023-02-18
				m  29.0  0.452267    b 2023-02-19
				n  30.0  0.607331    b 2023-02-20
				o  31.0  0.223060    b 2023-02-21, '__warningregistry__': {'version': 38, ('Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version.  Use .loc with labels or .iloc with positions instead.', <class 'FutureWarning'>, 1317): True, ('min_periods=None will default to the size of window consistent with other methods in a future version. Specify min_periods=0 instead.', <class 'FutureWarning'>, 1319): True}, 'numeric_only0': True} 
					col0  col1  col2  col3
			a b c                        
			f h l   1.0   1.0   1.0   1.0
				m   2.0   2.0   2.0   2.0
				n   2.0   2.0   2.0   2.0
				o   1.0   1.0   1.0   1.0
			  i l   0.0   0.0   0.0   0.0
				m   1.0   1.0   1.0   1.0
				n   2.0   2.0   2.0   2.0
				o   3.0   3.0   3.0   3.0
			  j l   3.0   3.0   3.0   3.0
				m   3.0   3.0   3.0   3.0
				n   3.0   3.0   3.0   3.0
				o   3.0   3.0   3.0   3.0
			  k l   3.0   3.0   3.0   3.0
				m   3.0   3.0   3.0   3.0
				n   3.0   3.0   3.0   3.0
				o   3.0   3.0   3.0   3.0
			g h l   3.0   3.0   3.0   3.0
				m   3.0   3.0   3.0   3.0
				n   3.0   3.0   3.0   3.0
				o   3.0   3.0   3.0   3.0
			  i l   3.0   3.0   3.0   3.0
				m   3.0   3.0   3.0   3.0
				n   3.0   3.0   3.0   3.0
				o   3.0   3.0   3.0   3.0
			  j l   3.0   3.0   3.0   3.0
				m   3.0   3.0   3.0   3.0
				n   3.0   3.0   3.0   3.0
				o   3.0   3.0   3.0   3.0
			  k l   3.0   3.0   3.0   3.0
				m   3.0   3.0   3.0   3.0
				n   3.0   3.0   3.0   3.0
				o   3.0   3.0   3.0   3.0
			print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df0.rolling(window=3).count(numeric_only=numeric_only0)) 
			 {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x00000000038549A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'matplotlib': <module 'matplotlib' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py'>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt', 'df0':        col0      col1 col2       col3
			a b c                                
			f h l   0.0  0.326972    a 2023-01-21
				m   1.0  0.987277    a 2023-01-22
				n   NaN       NaN  NaN        NaT
				o   NaN       NaN  NaN        NaT
			  i l   NaN       NaN  NaN        NaT
				m   5.0  0.391085    a 2023-01-26
				n   6.0  0.437882    a 2023-01-27
				o   7.0  0.372749    a 2023-01-28
			  j l   8.0  0.106954    a 2023-01-29
				m   9.0  0.478965    a 2023-01-30
				n  10.0  0.241352    a 2023-01-31
				o  11.0  0.257145    a 2023-02-01
			  k l  12.0  0.184732    a 2023-02-02
				m  13.0  0.193865    a 2023-02-03
				n  14.0  0.813828    a 2023-02-04
				o  15.0  0.422984    a 2023-02-05
			g h l  16.0  0.255921    a 2023-02-06
				m  17.0  0.590903    b 2023-02-07
				n  18.0  0.604272    b 2023-02-08
				o  19.0  0.646858    b 2023-02-09
			  i l  20.0  0.911356    b 2023-02-10
				m  21.0  0.150206    b 2023-02-11
				n  22.0  0.371387    b 2023-02-12
				o  23.0  0.284621    b 2023-02-13
			  j l  24.0  0.016782    b 2023-02-14
				m  25.0  0.181554    b 2023-02-15
				n  26.0  0.394669    b 2023-02-16
				o  27.0  0.393311    b 2023-02-17
			  k l  28.0  0.616728    b 2023-02-18
				m  29.0  0.452267    b 2023-02-19
				n  30.0  0.607331    b 2023-02-20
				o  31.0  0.223060    b 2023-02-21, '__warningregistry__': {'version': 46, ('min_periods=None will default to the size of window consistent with other methods in a future version. Specify min_periods=0 instead.', <class 'FutureWarning'>, 1319): True}, 'numeric_only0': False} 
					col0  col1  col2  col3
			a b c                        
			f h l   1.0   1.0   1.0   1.0
				m   2.0   2.0   2.0   2.0
				n   2.0   2.0   2.0   2.0
				o   1.0   1.0   1.0   1.0
			  i l   0.0   0.0   0.0   0.0
				m   1.0   1.0   1.0   1.0
				n   2.0   2.0   2.0   2.0
				o   3.0   3.0   3.0   3.0
			  j l   3.0   3.0   3.0   3.0
				m   3.0   3.0   3.0   3.0
				n   3.0   3.0   3.0   3.0
				o   3.0   3.0   3.0   3.0
			  k l   3.0   3.0   3.0   3.0
				m   3.0   3.0   3.0   3.0
				n   3.0   3.0   3.0   3.0
				o   3.0   3.0   3.0   3.0
			g h l   3.0   3.0   3.0   3.0
				m   3.0   3.0   3.0   3.0
				n   3.0   3.0   3.0   3.0
				o   3.0   3.0   3.0   3.0
			  i l   3.0   3.0   3.0   3.0
				m   3.0   3.0   3.0   3.0
				n   3.0   3.0   3.0   3.0
				o   3.0   3.0   3.0   3.0
			  j l   3.0   3.0   3.0   3.0
				m   3.0   3.0   3.0   3.0
				n   3.0   3.0   3.0   3.0
				o   3.0   3.0   3.0   3.0
			  k l   3.0   3.0   3.0   3.0
				m   3.0   3.0   3.0   3.0
				n   3.0   3.0   3.0   3.0
				o   3.0   3.0   3.0   3.0
			print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df0.dtypes) 
			 {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x00000000038549A0>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2.py', '__cached__': None, 'pandas': <module 'pandas' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py'>, 'numpy': <module 'numpy' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py'>, 'logging': <module 'logging' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py'>, 'os': <module 'os' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py'>, 'inspect': <module 'inspect' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py'>, 'sys': <module 'sys' (built-in)>, 'matplotlib': <module 'matplotlib' from 'C:\\Users\\pdumas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py'>, 'file0': 'C:\\Users\\pdumas\\Documents\\Code\\pandas2output0.txt', 'df0':        col0      col1 col2       col3
			a b c                                
			f h l   0.0  0.326972    a 2023-01-21
				m   1.0  0.987277    a 2023-01-22
				n   NaN       NaN  NaN        NaT
				o   NaN       NaN  NaN        NaT
			  i l   NaN       NaN  NaN        NaT
				m   5.0  0.391085    a 2023-01-26
				n   6.0  0.437882    a 2023-01-27
				o   7.0  0.372749    a 2023-01-28
			  j l   8.0  0.106954    a 2023-01-29
				m   9.0  0.478965    a 2023-01-30
				n  10.0  0.241352    a 2023-01-31
				o  11.0  0.257145    a 2023-02-01
			  k l  12.0  0.184732    a 2023-02-02
				m  13.0  0.193865    a 2023-02-03
				n  14.0  0.813828    a 2023-02-04
				o  15.0  0.422984    a 2023-02-05
			g h l  16.0  0.255921    a 2023-02-06
				m  17.0  0.590903    b 2023-02-07
				n  18.0  0.604272    b 2023-02-08
				o  19.0  0.646858    b 2023-02-09
			  i l  20.0  0.911356    b 2023-02-10
				m  21.0  0.150206    b 2023-02-11
				n  22.0  0.371387    b 2023-02-12
				o  23.0  0.284621    b 2023-02-13
			  j l  24.0  0.016782    b 2023-02-14
				m  25.0  0.181554    b 2023-02-15
				n  26.0  0.394669    b 2023-02-16
				o  27.0  0.393311    b 2023-02-17
			  k l  28.0  0.616728    b 2023-02-18
				m  29.0  0.452267    b 2023-02-19
				n  30.0  0.607331    b 2023-02-20
				o  31.0  0.223060    b 2023-02-21, '__warningregistry__': {'version': 46, ('min_periods=None will default to the size of window consistent with other methods in a future version. Specify min_periods=0 instead.', <class 'FutureWarning'>, 1319): True}, 'numeric_only0': False} 
			 col0           float64
			col1           float64
			col2            object
			col3    datetime64[ns]

https://docs.python.org/3/library/sys.html#sys.base_exec_prefix
	may be worth mentioning (especially with the popularity of conda, etc.) that prefix,base_prefix,exec_prefix,base_exec_prefix will all be the same in a conda environment (since conda acts like a sort of virtual machine/abstraction with it's own python installed per environment - even though you may have a different python in a different location on your local machine!!)

https://docs.python.org/3/library/marshal.html#marshal.dump
	need to mention that return value is number of bytes written to file

https://docs.python.org/3/library/threading.html#threading.excepthook
	can we include an example of an uncaught exception (currently, I'm trying to simulate to see the functionality but all of my errors seem caught / my custom threading.excepthook is not being called..)

https://docs.python.org/3/using/cmdline.html#cmdoption-m
	need to mention that these (.py files / the modules) need to be in your standard library directory otherwise will get '''No module named ...''' error e.g.:
		in my case '''C:\Users\pdumas\AppData\Local\Programs\Python\Python311\Lib\''' is the standard lib; after copy-pasting a custom module (.py file) over to that directory and doing the same '''py -m moduleTest0''' command, it worked!
	need to mention that works for '.pyc' files but then errors out right after (e.g. if .pyc file has a print('test123'), it WILL print 'test123' but then error with '''''C:\Users\pdumas\AppData\Local\Programs\Python\Python311\python.exe: Error while finding module specification for 'dummyModuleForImport1test0.cpython-311' (ModuleNotFoundError: __path__ attribute not found on 'dummyModuleForImport1test0' while trying to find 'dummyModuleForImport1test0.cpython-311')'''''.. weird

https://docs.python.org/3/reference/toplevel_components.html#programs
	need to update following statement since not true (?) for '''sys''' '''all built-in and standard modules are available, but none have been initialized, except for sys (various system services), builtins (built-in functions, exceptions and None) and __main__.'''
		builtins and __main__ make sense and one can easily confirm that but trying '''sys.version''' for instance after interpreter launch raises '''NameError: name 'sys' is not defined'''..

https://docs.python.org/3/using/cmdline.html#generic-options
	need to add:
		1. --help-all is combination of -?,--help-env,--help-xoptions
		2. -h and --help are the same and give MORE information than -? (at least on Windows 10 Python 3.11.1 they give "Launcher arguments:" which was actually exactly what I needed!)
https://docs.python.org/3/using/cmdline.html#cmdoption-W
	need to add examples of using more parameters (feel free to use code/result below)
		code from line 532 and 533 in '''C:\Users\pdumas\Documents\Code\sys0.py''':
			for i in range(2):
				warnings.warn('d0w0',DeprecationWarning)
		what is passed into cmd.exe (Windows 10):
			#py -Wi:"d0w0":DeprecationWarning:sys0:533 C:\Users\pdumas\Documents\Code\sys0.py#messages are used NOT in quotes (i.e. this line will not pick anything up and will not ignore as intended)
			#py -Wi:d0w0:DeprecationWarning:sys0:533 C:\Users\pdumas\Documents\Code\sys0.py#modules are only for imported modules (not the module your script is currently running) (i.e. this line will not pick anything up and will not ignore as intended)
			#py -Wi:d0w0:DeprecationWarning:__main__:533 C:\Users\pdumas\Documents\Code\sys0.py#from above '''not the module your script is currently running''', if you want to do that, you must specify __main__ (i.e. this line will ignore the warnings as intended!)
			#py -Wi:d0w0:DeprecationWarning::533 C:\Users\pdumas\Documents\Code\sys0.py#(i.e. this line will ignore the warnings as intended!)
			#py -Wi:d0w1:DeprecationWarning::533 C:\Users\pdumas\Documents\Code\sys0.py#display message from warn must match exactly  (i.e. this line will not pick anything up and will not ignore as intended)
			#py -Wi:d0w0:RuntimeWarning::533 C:\Users\pdumas\Documents\Code\sys0.py#warning type from warn must match exactly (or be subclass) (i.e. this line will not pick anything up and will not ignore as intended)

https://docs.python.org/3/library/faulthandler.html#faulthandler.dump_traceback_later
	can we provide examples of this being successful
		nothing I did seems to have worked (no delay or repeat..; rest of the functions in the module worked fine!) except for https://docs.python.org/3/library/faulthandler.html#faulthandler.cancel_dump_traceback_later which I couldn't test of course given I couldn't get the '''dump_traceback_later''' to work!

https://docs.python.org/3/library/linecache.html#linecache.clearcache
	need to mention that if linecache.lazycache 1. is used, 2. no filename is found, 3. but module_globals finds a loader and caches it then 4. linecache.clearcache will wipe that cache (i.e. if linecache.getline is called after with no file found, it'll return None)

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.io.formats.style.Styler.format.html
	need to update / add another example, as the below doesn't work on Windows 10 with Excel (and yes, even when replacing '''lambda v: css''' with '''lambda v: pseudo_css'''); just gives semi-corrupted Excel (can open, gives 'we recovered as much as we can', no formatting..)
		'''Pandas defines a number-format pseudo CSS attribute instead of the .format method to create to_excel permissible formatting. Note that semi-colons are CSS protected characters but used as separators in Excelâ€™s format string. Replace semi-colons with the section separator character (ASCII-245) when defining the formatting here.
		df = pd.DataFrame({"A": [1, 0, -1]})
		pseudo_css = "number-format: 0Â§[Red](0)Â§-Â§@;"
		df.style.applymap(lambda v: css).to_excel("formatted_file.xlsx")'''
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.io.formats.style.Styler.applymap_index.html
	'''level   int, str, list, optional If index is MultiIndex the level(s) over which to apply the function.'''; need to mention that kwarg '''level''', if used on axis with no MultiIndex, kwarg '''level''' is irrelevant/ignored (all elements on that axis will be passed into the func)
		tuples = [
		   ('cobra', 'mark i'), ('cobra', 'mark ii'),
		   ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
		   ('viper', 'mark ii'), ('viper', 'mark iii')
		]
		index = pandas.MultiIndex.from_tuples(tuples)
		values = [[12, 2], [20, 24], [10, 20],
				[21, 34], [17, 26], [36, 56]]
		df4 = pandas.DataFrame(values, columns=['max_speed', 'shield'], index=index)
		def applymap_index0(dataFrameOrSeries0index0,colorForBackground0):
			return f'background-color: {colorForBackground0};' if "i" in dataFrameOrSeries0index0 else None
		stylerto_html7=df4.style.applymap_index(applymap_index0,colorForBackground0='blue',axis=1,level=0).to_html()#if not MultiIndex, 'level' is irrelevant/ignored; in this case, 'shield' gets background-color blue

https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.concat.html
	need to mention that this function not only returns the concatted styler (e.g. a+b=ab; returns ab) but also makes the original styler concatted (e.g. a+b=ab; a is now ab)

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.io.formats.style.Styler.to_html.html
	why is below code giving below error
		stylerto_html3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.background_gradient(subset=numpy.ma.make_mask(numpy.random.default_rng(8).integers(0,1,(5,5),endpoint=True)))#this works
		stylerto_html3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.background_gradient(subset=numpy.ma.make_mask(numpy.random.default_rng(8).integers(0,1,(5,5),endpoint=True))).to_html()#this does NOT work (but not sure why it wouldn't..)
		Traceback (most recent call last):
		  File "C:\Users\pdumas\Documents\Code\pandas2.py", line 10677, in <module>
			stylerto_html3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.background_gradient(subset=numpy.ma.make_mask(numpy.random.default_rng(8).integers(0,1,(5,5),endpoint=True))).to_html()
		  File "C:\Users\pdumas\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\io\formats\style.py", line 1377, in to_html
			html = obj._render_html(
		  File "C:\Users\pdumas\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\io\formats\style_render.py", line 206, in _render_html
			d = self._render(sparse_index, sparse_columns, max_rows, max_cols, "&nbsp;")
		  File "C:\Users\pdumas\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\io\formats\style_render.py", line 163, in _render
			self._compute()
		  File "C:\Users\pdumas\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\io\formats\style_render.py", line 258, in _compute
			r = func(self)(*args, **kwargs)
		  File "C:\Users\pdumas\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\io\formats\style.py", line 1762, in _apply
			self._update_ctx(result)
		  File "C:\Users\pdumas\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\io\formats\style.py", line 1583, in _update_ctx
			if not c or pd.isna(c):
		  File "C:\Users\pdumas\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\generic.py", line 1527, in __nonzero__
			raise ValueError(
		ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.io.formats.style.Styler.from_custom_template.html
	need example
	why is below code not working semantically
		template0='''
		{% for col0 in data.columns %}
			{{col0}}
			{% for i0,v0 in enumerate(data[col0]) %}
				{% if v0 > 4 %}
					<td style="background-color:blue">{{v0}}</td>
				{% else %}
					<td>{{v0}}</td>
				{% endif %}
			{% endfor %}
		{% endfor %}
		'''
		styler0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.from_custom_template(template0)(pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))))#without the final arg pass '''(pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))))''', any to_html() errors saying it's missing self.. with final arg pass, this works but doesn't seem to apply template since below doesn't work..
		stylerto_html0=styler0.to_html()#does NOT work semantically (.html yes but formatting none..)

https://pandas.pydata.org/pandas-docs//stable//reference/api/pandas.io.formats.style.Styler.set_sticky.html
	need to mention that if levels=0 then acts like levels=None and sticks all levels

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.io.formats.style.Styler.to_excel.html
	need to add that requires 'index=True' if MultiIndex is used (otherwise, get '''NotImplementedError: Writing to Excel with MultiIndex columns and no index ('index'=False) is not yet implemented.'''
		relates to '''index  bool, default True  Write row names (index).''' 

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.all.html
	need to mention that numpy.nan evaluates to True (and that's the reason why kwarg 'skipna' adds value)

https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html
	errors/unexpected behaviour with df.agg('functionNameHere',argsHere) where 'functionNameHere' is the following:
		'fillna'
			doesn't seem to take any arg (or no arg!) passed to it (just errors with '''Must specify a fill 'value' or 'method''')
		'cumcount'
			isn't even recognized as function (with nothing or 0 passed in, errors with ''''cumcount' is not a valid function for 'DataFrame' object''')

https://matplotlib.org/stable/api/_as_gen/matplotlib.artist.Artist.set_agg_filter.html
	need to update '''takes a (m, n, depth) float array''' to '''takes a (m, n, depth) float array, whose nested elements are rgba arrays'''

https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.GroupBy.nth.html
	need to add to kwarg '''dropna''' explanation that '''any''' means if ANY member of 0th instance of groups e.g. 0,1,2 is na, then pushes back to last instance of groups; if '''all''' then works like '''None''' but will error if 1. any of 0th instance of groups e.g. 0,1,2 is na AND 2. not all of 0th instance of groups e.g. 0,1,2 are na  (in other words, '''all''' and '''None''' are basically the same unless not all of 0th instance of groups are na)

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.skew.html
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.skew.html
	need to add:
		if less than 3 data points passed into the method (e.g. if series along specified axis has 2 data points), then will return na for all
			makes sesne since you need at least 3 points to determine if there's any skew or not.
		if the method uses 'numeric_only=None' (which is the default) and the function cannot convert (e.g. 'a' doesn't convert to a float 'a.') then 'skipna=True' will not work and the method returns na for all

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.all.html
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.any.html#pandas.Series.any
	none of these implement 'bool_only=True' (if you try that kwarg=value combination, you get '''Series.all does not implement bool only.''','''Series.any does not implement bool only.''')












































Why does Python's super()__new__(cls,iterable0) not work as expected?
I'm trying to demystify super().__new__ and luckily watched [this fantastic video](https://www.youtube.com/watch?v=-zsV0_QrfTw&ab_channel=mCoding). However, when giving it a go myself, as that's the best way to learn, I ran into an unexpected result. When subclassing `cT0` from superclass `list`, in `__new__`, `cls` (as usual) and `iterable0` are the arguments. Taking the items from `iterable0`, adding 100 to each, and then appending them to the blank-initialized list `tL0`, one would expect, if creating a new instance where `iterable0` is `(1,2,3)`, passing `tL0` (**which even prints `[101,102,103]` right before the pass**) into `super().__new__(cls,tL0)`, that we'd get a result of `[101,102,103]` when printed. Why oh why do we still get `(1,2,3)`?  
    (Even in the [video](https://www.youtube.com/watch?v=-zsV0_QrfTw&ab_channel=mCoding), mCoding's James Murphy has his beautiful `UppercaseTuple` example at 2:59, which worked for me when I tried it! Why is the code below not behaving?)
Class definition:
```
class cT0(list):
    def __new__(cls, iterable0):
        tL0=[]
        for arg0 in iterable0:
            print(arg0)
            arg0=arg0+100
            print(arg0)
            tL0.append(arg0)
            print(tL0)
        **print(tL0)**
        return super().__new__(cls,tL0)
```

Class instantiation and printing:
```
cT0I0=cT0((1,2,3))
**print(cT0I0)**
```

Results:
```
1
101
[101]
2
102
[101, 102]
3
103
[101, 102, 103]
**[101, 102, 103]**
**[1, 2, 3]**
```
```








		
resolved
https://numpy.org/doc/stable/user/basics.rec.html#numpy.lib.recfunctions.find_duplicates
		'key' kwarg (even with masked arrays doesn't seem to take..)
			a1=numpy.ma.array([(11,11),(12,12),(13,13),(13,13),(13,13)],dtype=numpy.dtype({'names':['float0','int50'],'formats':['f4','i4']}))
			print(numpy.lib.recfunctions.find_duplicates(a1,key='float0',ignoremask=False,return_index=True))
			(done) (masked_array(data=[(13.0, 13), (13.0, 13), (13.0, 13)],
				(done) mask=[(False, False), (False, False), (False, False)],
			   (done) fill_value=(1.e+20, 999999),
					(done) dtype=[('float0', '<f4'), ('int50', '<i4')]), array([2, 3, 4], dtype=int64))
					
					
					
					
					
					
https://numpy.org/doc/stable/reference/generated/numpy.ma.power.html
	what's the point if you cannot pass in 2 masked arrays
		(error you get when you try this '''unsupported operand type(s) for ** or pow(): 'MaskedIterator' and 'MaskedIterator'''')



https://numpy.org/doc/stable/reference/generated/numpy.polynomial.chebyshev.chebpts1.html
	worth adding that if you numpy.arccos the results, you get the roots of Chebyshev first kind polynomial
		e.g. print(x0,numpy.arccos((-numpy.cos(numpy.pi*(numpy.arange(lenx0)+.5)/lenx0))),sep='\n') will print the original xs one chose, where lenx0 corresponds to the npts in the numpy.polynomial.chebyshev.chebpts1, and the roots (where the function equals 0; of course these are not the original xs!)






https://docs.python.org/3/library/pprint.html#pprint.PrettyPrinter.format
	'''Returns three values: the formatted version of object as a string, a flag indicating whether the result is readable, and a flag indicating whether recursion was detected. ''' but 3rd value (recursion detected) is wrong ? (it gives 'False' when it should be 'True' since clearly the object is recursive)   why  and  can we provide an example of the functionality in code/result form
		import pprint
		prettyPrinter0=pprint.PrettyPrinter(indent=1,width=80,depth=None,stream=None,compact=False,sort_dicts=True,underscore_numbers=False)
		print(prettyPrinter0)
		for a0 in dir(prettyPrinter0):
			print(a0,getattr(prettyPrinter0,a0))
		rl0=[1,2,[3,4,[5,6,[7,8,[9,10,[11,12,[13,14]]]]]]]
		rl1=[1+20000,2+20,[3+20,4+20,[5+20,6+20,[7+20,8+20,[9+20,10+20,[11+20,12+20,[13+20,14]]]]]]]
		d0={10:1,9:2,6:5,7:4}
		rl2=[rl0,rl1,d0]
		print(prettyPrinter0.format(rl0,{id(rl2):rl0},8,1))

		('[1, 2, [3, 4, [5, 6, [7, 8, [9, 10, [11, 12, [13, 14]]]]]]]', True, False)
		
		
		
		
		
https://numpy.org/doc/stable/user/basics.ufuncs.html
	'''All ufuncs have four methods.''' > '''All ufuncs have methods.'''
	'''Ufuncs also have a fifth method,''' > '''Ufuncs also have a method,'''
	
https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply
	# print(df0.apply(lambda x,arg0: np.add(x, arg0),args=(2,),axis=1))#if you go through lambda it works but a straight numpy.add doesn't even though it also takes 2 positional arguments. weird..

https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.html#pandas.PeriodIndex
	need to fix day,hour,minute,second kwargs since everything (including '''print(pandas.PeriodIndex(year=2023,quarter=numpy.arange(1,5,1),freq='Q'))''' which gives '''PeriodIndex(['2023Q1', '2023Q2', '2023Q3', '2023Q4'], dtype='period[Q-DEC]')''') works except when trying '''print(pandas.PeriodIndex(year=2023,month=1,day=1,freq='D'))''' it just gives the below error:
		Traceback (most recent call last):
		  File "C:\Users\pdumas\Documents\SAP\SAP GUI\numpy0.py", line 2814, in <module>
			print(pandas.PeriodIndex(year=2023, month=1, day=1, freq='D'))
		  File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\core\indexes\period.py", line 250, in __new__
			data, freq2 = PeriodArray._generate_range(None, None, None, freq, fields)
		  File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\core\arrays\period.py", line 316, in _generate_range
			subarr, freq = _range_from_fields(freq=freq, **fields)
		  File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\core\arrays\period.py", line 1158, in _range_from_fields
			arrays = _make_field_arrays(year, month, day, hour, minute, second)
		  File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\core\arrays\period.py", line 1177, in _make_field_arrays
			return [
		  File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\core\arrays\period.py", line 1180, in <listcomp>
			else np.repeat(x, length)  # type: ignore[arg-type]
		  File "<__array_function__ internals>", line 180, in repeat
		  File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\numpy\core\fromnumeric.py", line 479, in repeat
			return _wrapfunc(a, 'repeat', repeats, axis=axis)
		  File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\numpy\core\fromnumeric.py", line 54, in _wrapfunc
			return _wrapit(obj, method, *args, **kwds)
		  File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\numpy\core\fromnumeric.py", line 43, in _wrapit
			result = getattr(asarray(obj), method)(*args, **kwds)
		TypeError: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'

https://pandas.pydata.org/docs/reference/api/pandas.Period.now.html#pandas.Period.now
	need to add working example (since '''print(pandas.Period('2023',freq='D').now())''' gives the following error but not sure how..)
		Traceback (most recent call last):
		  File "C:\Users\pdumas\Documents\SAP\SAP GUI\numpy0.py", line 2845, in <module>
			print(pandas.Period('2023',freq='D').now())
		  File "pandas\_libs\tslibs\period.pyx", line 2295, in pandas._libs.tslibs.period._Period.now
		  File "pandas\_libs\tslibs\period.pyx", line 2602, in pandas._libs.tslibs.period.Period.__new__
		ValueError: Must supply freq for datetime value

https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.html#pandas.DatetimeIndex
	need to add working examples of kwargs 'normalize','closed','ambiguous','yearfirst' that have some sort of behaviour as currently always give the same behaviour regardless of what is passed (always non-normalized, always includes both endpoints, always raises, always auto parses whether year first or last UNLESS dayfirst=True)

https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.snap.html#pandas.DatetimeIndex.snap
	need to add working examples (as this method doesn't seem to do anything)
		print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T00:00:00.000010',freq='ns').snap(freq='S'))
		print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T00:00:00.000010',freq='ns').snap(freq='D'))
		print(pandas.date_range('2023-01-01','2023-01-03',freq='D').snap(freq='H'))

		DatetimeIndex([          '2023-01-01 00:00:00', '2023-01-01 00:00:00.000000001', '2023-01-01 00:00:00.000000002', '2023-01-01 00:00:00.000000003', '2023-01-01 00:00:00.000000004', '2023-01-01 00:00:00.000000005', '2023-01-01 00:00:00.000000006', '2023-01-01 00:00:00.000000007', '2023-01-01 00:00:00.000000008', '2023-01-01 00:00:00.000000009',
					   ...
					   '2023-01-01 00:00:00.000009991', '2023-01-01 00:00:00.000009992', '2023-01-01 00:00:00.000009993', '2023-01-01 00:00:00.000009994', '2023-01-01 00:00:00.000009995', '2023-01-01 00:00:00.000009996', '2023-01-01 00:00:00.000009997', '2023-01-01 00:00:00.000009998', '2023-01-01 00:00:00.000009999',    '2023-01-01 00:00:00.000010'], dtype='datetime64[ns]', length=10001, freq=None)
		DatetimeIndex([          '2023-01-01 00:00:00', '2023-01-01 00:00:00.000000001', '2023-01-01 00:00:00.000000002', '2023-01-01 00:00:00.000000003', '2023-01-01 00:00:00.000000004', '2023-01-01 00:00:00.000000005', '2023-01-01 00:00:00.000000006', '2023-01-01 00:00:00.000000007', '2023-01-01 00:00:00.000000008', '2023-01-01 00:00:00.000000009',
					   ...
					   '2023-01-01 00:00:00.000009991', '2023-01-01 00:00:00.000009992', '2023-01-01 00:00:00.000009993', '2023-01-01 00:00:00.000009994', '2023-01-01 00:00:00.000009995', '2023-01-01 00:00:00.000009996', '2023-01-01 00:00:00.000009997', '2023-01-01 00:00:00.000009998', '2023-01-01 00:00:00.000009999',    '2023-01-01 00:00:00.000010'], dtype='datetime64[ns]', length=10001, freq=None)
		DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03'], dtype='datetime64[ns]', freq=None)

https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.round.html#pandas.DatetimeIndex.round
	need to add that doesn't work on nanoseconds (e.g. nanoseconds will not round to nearest second or hour but rather day only (no matter what is passed)) or even better add to work with nanoseconds

https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_perioddelta.html#pandas.DatetimeIndex.to_perioddelta
	1. need to add that it's deprecated to online docs and __doc__
		a. FutureWarning: to_perioddelta is deprecated and will be removed in a future version. Use `dtindex - dtindex.to_period(freq).to_timestamp()` instead.
	2.  need to add working example(s) (feel free to use below, as shows how the delta 'resets' to 0 if we go through just over 1 month in days and the period is month whereas there's no 'reset' if we go through just over 1 month in days and the period is year
		print(pandas.date_range('2023-01-01','2023-02-01',freq='D').to_perioddelta('M'))
		print(pandas.date_range('2023-01-01','2023-02-01',freq='D')-pandas.date_range('2023-01-01','2023-02-01',freq='D').to_period('M').to_timestamp())
		print(pandas.date_range('2023-01-01','2023-02-01',freq='D').to_perioddelta('Y'))
		print(pandas.date_range('2023-01-01','2023-02-01',freq='D')-pandas.date_range('2023-01-01','2023-02-01',freq='D').to_period('Y').to_timestamp())

		TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days', '5 days', '6 days', '7 days', '8 days', '9 days', '10 days', '11 days', '12 days', '13 days', '14 days', '15 days', '16 days', '17 days', '18 days', '19 days', '20 days', '21 days', '22 days', '23 days', '24 days', '25 days', '26 days', '27 days', '28 days', '29 days', '30 days', '0 days'], dtype='timedelta64[ns]', freq=None)
		TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days', '5 days', '6 days', '7 days', '8 days', '9 days', '10 days', '11 days', '12 days', '13 days', '14 days', '15 days', '16 days', '17 days', '18 days', '19 days', '20 days', '21 days', '22 days', '23 days', '24 days', '25 days', '26 days', '27 days', '28 days', '29 days', '30 days', '0 days'], dtype='timedelta64[ns]', freq=None)
		TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days', '5 days', '6 days', '7 days', '8 days', '9 days', '10 days', '11 days', '12 days', '13 days', '14 days', '15 days', '16 days', '17 days', '18 days', '19 days', '20 days', '21 days', '22 days', '23 days', '24 days', '25 days', '26 days', '27 days', '28 days', '29 days', '30 days', '31 days'], dtype='timedelta64[ns]', freq=None)
		TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days', '5 days', '6 days', '7 days', '8 days', '9 days', '10 days', '11 days', '12 days', '13 days', '14 days', '15 days', '16 days', '17 days', '18 days', '19 days', '20 days', '21 days', '22 days', '23 days', '24 days', '25 days', '26 days', '27 days', '28 days', '29 days', '30 days', '31 days'], dtype='timedelta64[ns]', freq=None)

https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_localize.html
	need to add working examples or fix, as kwargs 'axis','level','copy' are not actually kwargs and will all error
		e.g. TypeError: DatetimeIndex.tz_localize() got an unexpected keyword argument 'level'
			and similar errors for the other 2

https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.html
	need to add working examples or fix, as kwarg 'fold' doesn't seem to work (no effect regardless whether 0 or 1 is passed; UNLIKE similar kwarg 'ambiguous', which works in 'pandas.to_datetime' or 'pandas.tz_localize')

https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.ceil.html#pandas.Timestamp.ceil
https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.floor.html#pandas.Timestamp.floor
https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.round.html#pandas.Timestamp.round
	need to add working examples or fix, as kwargs 'ambiguous','nonexistent' don't seem to work (no effect regardless what is passed; UNLIKE similar kwargs 'ambiguous','nonexistent', which work in 'pandas.to_datetime' or 'pandas.tz_localize')
https://pandas.pydata.org/docs/user_guide/timeseries.html
	need to update following as not true '''Constructing a Timestamp or DatetimeIndex with an epoch timestamp with the tz argument specified will raise a ValueError.'''
		update with '''One can construct a Timestamp with an epoch timestamp with the tz argument specified.''' and '''Constructing a DatetimeIndex with an epoch timestamp iterable with the tz argument specified will automatically interpret the unit (dtype) to be nanoseconds and thus must be in nanoseconds for intended results.'''

https://pandas.pydata.org/docs/reference/api/pandas.bdate_range.html#pandas.bdate_range
	need to add working examples or fix, as kwargs 'inclusive','closed' (latter is deprecated) have no effect regardless of what value is passed (i.e. always includes both left and right endpoints)

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html
	method='barycentric',method='krogh' seem to be aliases (give exact same results for a 30x30 random integer -10To100 DataFrame with 40% of values randomly numpy.nan-ed)

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asfreq.html
	need to add note that 'method' is not supported for PeriodIndex (makes sense since returns same size as input with no holes)
		if you try to use you get the following error or similar:
			Traceback (most recent call last):
			  File "C:\Users\pdumas\Documents\SAP\SAP GUI\numpy0.py", line 3772, in <module>
				print(df1.asfreq('1M',fill_value=42,method='bfill'))
			  File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\core\frame.py", line 11364, in asfreq
				return super().asfreq(
			  File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\core\generic.py", line 8235, in asfreq
				return asfreq(
			  File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\core\resample.py", line 2216, in asfreq
				raise NotImplementedError("'method' argument is not supported")
			NotImplementedError: 'method' argument is not supported

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html
	need to add note or better update functionality, as kwarg 'downcast' doesn't seem to have any effect when axis=1
		e.g. downcast='int' downcasted all floats (after NaNs were filled with 42.0) to ints (e.g. 42) when axis=0 but did NOTHING when axis=1 (something to do with taking in series and operating on them working but elements from series horizontal-wise not ? not sure)

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html
	need to add working examples or better update functionality for kwargs 'axis','level' (see below code#errorOrCommentHere)
		df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(10,10)))
		df1.iloc[:,[4,6,7]]=numpy.nan
		# print(df1.where(df1.sum(axis=1)>50,'<=50',axis=1))#axis=1 doesn't take nans..
		df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(10,10)),pandas.MultiIndex.from_product([numpy.arange(5),numpy.arange(2)]))
		df2=pandas.DataFrame(numpy.random.default_rng(8).integers(100,200,(5,10)))
		df3=pandas.DataFrame(numpy.random.default_rng(8).integers(100,200,(20,10)),pandas.MultiIndex.from_product([numpy.arange(10),numpy.arange(2)]))
		# print(df1.where(df1.sum(axis=0)>50,df2,axis=1))#ValueError: operands could not be broadcast together with shapes (10,10) (10,10) (5,10)
		print(df1.where(df1.sum(axis=1)>50,df2,axis=1))
		# print(df1.where(df1.sum(axis=1)>50,df2,axis=0))#ValueError: cannot join with no overlapping index names
		# print(df1.where(df1.sum(axis=1)>50,df3,level=0))#TypeError: Join on level between two MultiIndex objects is ambiguous
		# print(df1.where(df2.sum(axis=0)>50,df3,level=0))#TypeError: Join on level between two MultiIndex objects is ambiguous even though there's only 1 MultiIndex object involved..
		# df2=pandas.DataFrame(numpy.random.default_rng(8).integers(100,200,(5,10)))
		df2=pandas.DataFrame(numpy.random.default_rng(8).integers(100,200,(10,10)))
		print(df1.where(df1.sum(axis=1)>400,df2,axis=1))#ValueError: operands could not be broadcast together with shapes (10,10) (10,10) (5,10)
	need to add note that mask for where condition must be same dimensions as DataFrame unless you pass in a Series (then it truncates it leaving all values after truncation evaluating automatically to True..) (see below code)
		m0=numpy.expand_dims(m0,1)#must be same dims   unless you Series (then it truncates..)
		print(df0.where(m0,df0**2+1))

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html#pandas.DataFrame.dropna
	need working example or better update functionality since kwarg 'thresh' is no-op unless larger than total rows/columns with nas, in which case returns Empty DataFrame (run below code, looking at 'thresh'-related results)
		df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(10,10)))
		df1.iloc[[4,6,7],:]=numpy.nan
		df1.iloc[:,0]=numpy.nan
		print(df1)
		print(df1.dropna(axis=0,how='any',inplace=False))
		print(df1.dropna(axis=0,how='all'))
		print(df1.dropna(axis=1,how='any'))
		print(df1.dropna(axis=1,how='all'))
		print(df1.dropna(thresh=1))
		print(df1.dropna(thresh=2))
		print(df1.dropna(thresh=22))
		print(df1.dropna(thresh=1,axis=1))
		print(df1.dropna(thresh=2,axis=1))
		print(df1.dropna(thresh=2,axis=1,subset=[0,1,2]))
		print(df1.dropna(thresh=22,axis=1,subset=[0,1,2]))

		print('\n\n\n\n')
		df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(10,10)))
		df1.iloc[:,[4,6,7]]=numpy.nan
		df1.iloc[0,:]=numpy.nan
		print(df1)
		print(df1.dropna(axis=0,how='any',inplace=False))
		print(df1.dropna(axis=0,how='all'))
		print(df1.dropna(axis=1,how='any'))
		print(df1.dropna(axis=1,how='all'))
		print(df1.dropna(thresh=1))
		print(df1.dropna(thresh=2))
		print(df1.dropna(thresh=3))
		print(df1.dropna(thresh=22))
		print(df1.dropna(thresh=1,axis=1))
		print(df1.dropna(thresh=2,axis=1))
		print(df1.dropna(thresh=2,axis=1,subset=[0,1,2]))
		print(df1.dropna(thresh=3,axis=1,subset=[0,1,2]))
		print(df1.dropna(thresh=22,axis=1,subset=[0,1,2]))

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html#pandas.DataFrame.replace
	need to update '''If to_replace is a dict and value is not a list, dict, ndarray, or Series''' to If to_replace is a dict and value is not a list, dict, ndarray, Series, or str, regex??, int, float'''

https://pandas.pydata.org/pandas-docs/stable/user_guide/boolean.html
	need to add to '''This differs from how np.nan behaves in logical operations. pandas treated np.nan is always false in the output.''' ''''Pandas-treated' means using a Series or DataFrame on a non-numpy array-like (e.g. list). Otherwise, if using Series or DataFrame on a numpy array-like (e.g. numpy.ndarray), the numpy standard is used, which is treating numpy.nan as True.'''; code in case want to add:
		a0=numpy.array([True,False,numpy.nan],dtype=numpy.bool_)
		s0=pandas.Series(numpy.array([True,False,numpy.nan],dtype=numpy.bool_))#numpy.nan as True
		s0=pandas.Series(numpy.array([True,False,numpy.nan],dtype=numpy.bool_),dtype='object')#numpy.nan as True
		# s0=pandas.Series([True,False,numpy.nan],dtype='object')#numpy.nan as False
		pa0=pandas.array([True,False,pandas.NA],dtype='boolean')
		print(a0|True)
		print(a0&False)
		print(pa0|True)
		print(pa0&False)
		print(a0&True)
		print(a0|False)
		print(pa0&True)
		print(pa0|False)
		print(s0|True)
		print(s0&False)
		print(s0&True)
		print(s0|False)

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.cat.html
	need to add/update since:
		1. '''with the exception of indexed objects (i.e. Series/Index/DataFrame) if join is not None.''' doesn't seem to be true for Index (but does work for Series/DataFrame)
		2. if kwarg 'others' value is longer than caller, will always show <NA> on right or outer joins
		(see below code#commentsOnImportantPoints)
			s0=pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse'],dtype='string')
			for r0 in [s0.str.lower(),s0.str.upper(),s0.str.capitalize(),s0.str.title(),s0.str.swapcase(),s0.str.casefold()]:
				print(r0)
			s1=pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse'],dtype='string')[::-1]
			s1[2]=pandas.NA
			s2=pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse'],dtype='string')[::-2]
			s3=pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse'],dtype='string')[::2]
			s4=pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse','swapCase2'],dtype='string')
			print(s0)
			print(s1)
			print(s2)
			print(s3)
			print(s0.str.cat())
			print(s0.str.cat(s1))
			print(s0.str.cat(s1,na_rep='imNa'))
			print(s0.str.cat(s1,sep=';'))
			for join0 in ['left','right','outer','inner']:
				print(s0.str.cat(s4,sep=';',join=join0))#worth mentioning that even on join='right' this will still give <NA> for index=4 (in other words, if caller is long, will include; but if others is long, will output <NA>; if short, both behave like SQL inner joins)
				print(s0.str.cat(s1,sep=';',join=join0))
				print(pandas.Index(s0).str.cat(pandas.Index(s1),sep=';',na_rep='imNa',join=join0))
				print(pandas.Index(s0).str.cat([s2,s3],sep=';',na_rep='imNa',join=join0))
				try:
					print(pandas.Index(s0).str.cat(pandas.Index(s2),sep=';',na_rep='imNa',join=join0))#join is not None; caller is Index; others is Index; yet errors since different size
				except Exception as e:
					print(e)
				print(s0.str.cat(s2,sep=';',na_rep='imNa',join=join0))#join is not None; caller is Series; others is Series; works!
			print(pandas.Index(pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse','swapCase2'],dtype='string')))

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html#pandas.Series.str.contains
	need to add/update since kwarg 'flags' certain values from module 're' don't seem to have any effect (see below code#commentsOnImportantPoints)
		s0=pandas.Series(["'string to v find things\\n in a'", "'groÃŸ'", "u'Ã¤hnl Ã¤hnlich'",
			   "'newLine\\nnewLine\\nnewLine\\n'",
			   "'newLine\\nnewLine\\nnewLine'",
			   "'cAsEsEnSiTiVe CASESENSITIVE casesensitive'",None,numpy.nan,pandas.NA],dtype='string')
		import re
		for flags0 in [re.DOTALL, re.ASCII, re.MULTILINE, re.IGNORECASE]:#re.DOTALL, re.ASCII, re.MULTILINE don't seem to have any effect; re.IGNORECASE works!
			for pat0 in ['v.*a','gro[a-ÃŸ]','\\w+','Ã¤hn[a-z]+','\\w+[a-z]+','^newLine$','cAsEsEnSiTiVe']:
				print('flags0,pat0',flags0,pat0,'\n',s0)
				print(s0.str.contains(pat0,flags=flags0))
				print('\n')

https://pytorch.org/docs/stable/generated/torch.conj.html#torch.conj
	need to update, as both below code lines produce the below-below error:
		print(torch.tensor([1,2,3])._conj())
		print(torch.tensor([1,2,3]).conj())#note that con_physical does NOT produce the error / result is as per docs
		Traceback (most recent call last):
		  File "C:\Users\pdumas\Documents\SAP\SAP GUI\numpy1.py", line 4738, in <module>
			print(torch.tensor([1,2,3])._conj())
		RuntimeError: isComplexType(typeMetaToScalarType(dtype())) INTERNAL ASSERT FAILED at "C:\\cb\\pytorch_1000000000000\\work\\c10/core/TensorImpl.h":1357, please report a bug to PyTorch.

https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html
	need to add/update since kwarg 'n' values don't seem to have any effect (see below code#commentsOnImportantPoints)
		print(s0.str.replace('Inc.','INCORPORATED',n=2))#where s0 is list of S&P500 company full names; n=2,n=5,n=anyValue all behave the same as n=-1 (the default) and replace every instance of Inc. instead of just the first few!

https://pytorch.org/docs/stable/generated/torch.optim.SGD.html
	need to add/update since kwarg 'differentiable' doesn't have any documentation but does succeed when passed False,True (True makes loss values very small, but not 100% sure what it does). If this is deprecated, adding a note to note should suffice!
	need to add (as example / to give reader an idea) that most parameters passed (lr,weight_decay,momentum,dampening) are typically .1 or lower (e.g. some of these if passed .8 or even .2 give you all nans or infs in the resulting loss-per-epoch array for even the most basic of neural nets!)
	
https://pytorch.org/docs/stable/generated/torch.signbit.html?highlight=negative+bit
	need to update '''signbit handles signed zeros, so negative zero (-0) returns True.''' to '''signbit handles signed zeros, so negative float zero (-0.) returns True, whereas negative int zero (-0)) returns False.'''
	
https://pytorch.org/docs/stable/generated/torch.resolve_neg.html
	need to add more on why this is beneficial / how this is used (below is Bing's AI answer, which was helpful / seems correct ?)
		torch.resolve_neg() and torch.resolve_conj() are functions in PyTorch that resolve the negative and conjugate bit of a tensor respectively. These functions exist to support complex numbers and negative strides in PyTorch.
		When a tensor has a negative stride, it means that the data is accessed in reverse order along that dimension. Similarly, when a tensor has its conjugate bit set, it means that its complex conjugate should be used instead of its actual value. These properties can be useful for certain operations but can also cause issues when working with other libraries or functions that do not support them.
		torch.resolve_neg() and torch.resolve_conj() can be used to create new tensors with the negative and conjugate bits resolved. This means that the data is rearranged in memory so that it can be accessed without using negative strides or complex conjugates. This can make it easier to work with other libraries or functions that do not support these properties.

https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html
	need to add/update since kwarg 'with_mean' regardless of False or True calculates mean (UNLESS 'with_std' is False, which means no mean OR std is calculated)
	need to add that specifiying kwargs 'with_mean','with_std' True vs False will give:
		1. different output (from a transform operation)
		2. different float formatting of output
			both True gives  e.g. 1st record only [[ 8.24449766e-01 
			with_mean=False,with_std=True gives  e.g. 1st record only [[ 5.18265629  
			both False gives  e.g. 1st record only [[1.799e+01

https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html
	need to add that total entries for 'test_size' + 'train_size' (either ratio*totalInput=totalOutput or scalarTotalOutput) must be <= total number in population (e.g. test_size=.2 and train_size=469 on sklearn.datasets.load_breast_cancer dataset will yield error '''The sum of train_size and test_size = 583, should be smaller than the number of samples 569. Reduce test_size and/or train_size.''')

https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rsplit.html#pandas.Series.str.rsplit
	need to add regex functionality and kwarg (similar to https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html#pandas.Series.str.split)
		must be hard if not done already..

https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#text-types
	need to remove '''
	Warning

	Some caution must be taken when dealing with regular expressions! The current behavior is to treat single character patterns as literal strings, even when regex is set to True. This behavior is deprecated and will be removed in a future version so that the regex keyword is always respected.
	''' since outdated (see below code/result)

		s3 = pd.Series(
			["A", "B", "C", "Aaba", "Baca", "", np.nan, "CABA", "dog", "cat", ".Here", ".There"],
			dtype="string",
		)
		print(s3)
		print(s3.str.replace(".", "replacedDot", case=False, regex=True))#only replaces literal '.'
		print(s3.str.replace(".", "replacedDot", case=True, regex=True))#only replaces literal '.'

		0
		0          A
		1          B
		2          C
		3       Aaba
		4       Baca
		5           
		6       <NA>
		7       CABA
		8        dog
		9        cat
		10     .Here
		11    .There
		dtype: string
		0                    A
		1                    B
		2                    C
		3                 Aaba
		4                 Baca
		5                     
		6                 <NA>
		7                 CABA
		8                  dog
		9                  cat
		10     replacedDotHere
		11    replacedDotThere
		dtype: string
		0                    A
		1                    B
		2                    C
		3                 Aaba
		4                 Baca
		5                     
		6                 <NA>
		7                 CABA
		8                  dog
		9                  cat
		10     replacedDotHere
		11    replacedDotThere
		dtype: string

https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#text-types
	need to remove '''
	Warning
	
	If the join keyword is not passed, the method cat() will currently fall back to the behavior before version 0.23.0 (i.e. no alignment), but a FutureWarning will be raised if any of the involved indexes differ, since this default will change to join='left' in a future version.
	''' since outdated (see below code/result)

		s0=pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse'],dtype='string')
		s1=pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse'],dtype='string')[::-1]
		s1[2]=pandas.NA
		s2=pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse'],dtype='string')[::-2]
		for join0 in ['left','right','outer','inner']:
			print('noJoinPassed0',s0.str.cat(s1))
			print('noJoinPassed1',s0.str.cat(s2))
			
		noJoinPassed0 0          lowerlower
		1          UPPERUPPER
		2                <NA>
		3    SwApCAseSwApCAse
		dtype: string
		noJoinPassed1 0                <NA>
		1          UPPERUPPER
		2                <NA>
		3    SwApCAseSwApCAse
		dtype: string

https://pandas.pydata.org/docs/reference/api/pandas.melt.html
	need to add for kwarg 'id_vars' that, if not specified, will assume all MultiIndex column levels as variables and rest as values; however, if specified as scalar, will only take first MultiIndex column level as values, omit any other MultiIndex column level, and take rest as values (add/see below code/result for support)
			
		df0 = pandas.DataFrame({'studentId': ['0', '3', '27'],
						   'Name': ['John', 'Mike', 'Sarah'],
						   'Maths': [90, 80, 75],
						   'Engineering': [92, 82, 73],
						   'Science': [85, 70, 80],
						   'English': [86, 71, 83]})
		df0.columns=[['student0','student0','courseStem0','courseStem0','courseStem0','courseArts0'],[c for c in df0]]
		for frame0 in [df0]:
			for id_vars0 in [None,['Name'],['studentId','Name']]:
				for value_vars0 in [None,['Science','English'],['Maths','Engineering','Science','English']]:
					for var_name0 in [None,'variableNamestudent0']:
						for value_name0 in [None,'variableNamecourseGrade0']:
							for col_level0 in [None,1]:
								for ignore_index0 in [True,False]:
									print(f'frame {frame0}',f'id_vars {id_vars0}',f'value_vars {value_vars0}',f'var_name {var_name0}',f'value_name {value_name0}',f'col_level {col_level0}',f'ignore_index {ignore_index0}',sep='\n')
									try:
										print(pandas.melt(frame0,id_vars=id_vars0,value_vars=value_vars0,var_name=var_name0,value_name=value_name0,col_level=col_level0,ignore_index=ignore_index0))
									except Exception as e:
										print(e)

		frame    student0        courseStem0                     courseArts0
		  studentId   Name       Maths Engineering Science     English
		0         0   John          90          92      85          86
		1         3   Mike          80          82      70          71
		2        27  Sarah          75          73      80          83
		id_vars None
		value_vars None
		var_name None
		value_name value
		col_level None
		ignore_index True
			 variable_0   variable_1  value
		0      student0    studentId      0
		1      student0    studentId      3
		2      student0    studentId     27
		3      student0         Name   John
		4      student0         Name   Mike
		5      student0         Name  Sarah
		6   courseStem0        Maths     90
		7   courseStem0        Maths     80
		8   courseStem0        Maths     75
		9   courseStem0  Engineering     92
		10  courseStem0  Engineering     82
		11  courseStem0  Engineering     73
		12  courseStem0      Science     85
		13  courseStem0      Science     70
		14  courseStem0      Science     80
		15  courseArts0      English     86
		16  courseArts0      English     71
		17  courseArts0      English     83
		id_vars None
		value_vars None
		var_name variableNamestudent0
		value_name value
		col_level None
		ignore_index True
		   variableNamestudent0  value
		0              student0      0
		1              student0      3
		2              student0     27
		3              student0   John
		4              student0   Mike
		5              student0  Sarah
		6           courseStem0     90
		7           courseStem0     80
		8           courseStem0     75
		9           courseStem0     92
		10          courseStem0     82
		11          courseStem0     73
		12          courseStem0     85
		13          courseStem0     70
		14          courseStem0     80
		15          courseArts0     86
		16          courseArts0     71
		17          courseArts0     83

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.IntervalIndex.overlaps.html#pandas.IntervalIndex.overlaps
	need to update since getting error when trying IntervalIndex0.overlaps(IntervalIndex1) (see below code/result for support)
		(example in docs with IntervalArray and Interval works however!)

		try:
			print(pandas.IntervalIndex.from_breaks([0,4,8,12],name='n2',copy=True,dtype=None,closed='right').overlaps(pandas.IntervalIndex.from_breaks([4,9,11],closed='right')))
		except Exception as e:
			print(e,sys.exc_info())

		 (<class 'NotImplementedError'>, NotImplementedError(), <traceback object at 0x000001EE863C5500>)
		<IntervalArray>

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html#pandas.cut
	need to update, as kwarg-value duplicates='raise' doesn't seem 'raise' any error but rather just doesn't remove duplicates (also, duplicates='drop' seems be no-op as well..); kwarg-value precision=3,precision=6 seem to be no-ops as well and do NOT drive precision stored,displayed (see below code/result for support)

		for x0 in [numpy.arange(0,11,2),[0,5,7,8,9.5,9.5]]:
			for bins0 in [5,[0,4,8],pandas.interval_range(0,10,2)]:
				for right0 in [True,False]:
					for labels0 in [None,['bin0','bin1','bin2','bin3','bin4'],False]:
						for precision0 in [3,6]:
							for retbins0 in [False,True]:
								for include_lowest0 in [False,True]:
									for duplicates0 in ['raise','drop']:
										for ordered0 in [True,False]:
											print(f'x {x0}',f'bins {bins0}',f'right {right0}',f'labels {labels0}',f'precision {precision0}',f'retbins {retbins0}',f'include_lowest {include_lowest0}',f'duplicates {duplicates0}',f'ordered {ordered0}',sep='\n')
											try:
												print(pandas.cut(x0,bins0,right=right0,labels=labels0,precision=precision0,retbins=retbins0,include_lowest=include_lowest0,duplicates=duplicates0,ordered=ordered0))
											except Exception as e:
												print(e)

		x [0, 5, 7, 8, 9.5, 9.5]
		bins 5
		right True
		labels None
		precision 3
		retbins False
		include_lowest False
		duplicates raise
		ordered True
		[(-0.0095, 1.9], (3.8, 5.7], (5.7, 7.6], (7.6, 9.5], (7.6, 9.5], (7.6, 9.5]]#why no error if '''duplicates raise'''
		Categories (5, interval[float64, right]): [(-0.0095, 1.9] < (1.9, 3.8] < (3.8, 5.7] < (5.7, 7.6] < (7.6, 9.5]]
		x [0, 5, 7, 8, 9.5, 9.5]
		bins 5
		right True
		labels None
		precision 3
		retbins False
		include_lowest False
		duplicates drop
		ordered True
		[(-0.0095, 1.9], (3.8, 5.7], (5.7, 7.6], (7.6, 9.5], (7.6, 9.5], (7.6, 9.5]]#why 2 '''(7.6, 9.5]''' if '''duplicates drop'''
		Categories (5, interval[float64, right]): [(-0.0095, 1.9] < (1.9, 3.8] < (3.8, 5.7] < (5.7, 7.6] < (7.6, 9.5]]

		x [0, 5, 7, 8, 9.5, 9.5]
		bins 5
		right True
		labels None
		precision 3
		retbins True
		include_lowest True
		duplicates drop
		ordered True
		([(-0.010499999999999999, 1.9], (3.8, 5.7], (5.7, 7.6], (7.6, 9.5], (7.6, 9.5], (7.6, 9.5]]
		Categories (5, interval[float64, right]): [(-0.010499999999999999, 1.9] < (1.9, 3.8] < (3.8, 5.7] < (5.7, 7.6] < (7.6, 9.5]], array([-0.0095,  1.9   ,  3.8   ,  5.7   ,  7.6   ,  9.5   ]))#18 decimal places! precision was 3 though..
		x [0, 5, 7, 8, 9.5, 9.5]
		bins 5
		right True
		labels None
		precision 6
		retbins False
		include_lowest False
		duplicates drop
		ordered True
		[(-0.0095, 1.9], (3.8, 5.7], (5.7, 7.6], (7.6, 9.5], (7.6, 9.5], (7.6, 9.5]]
		Categories (5, interval[float64, right]): [(-0.0095, 1.9] < (1.9, 3.8] < (3.8, 5.7] < (5.7, 7.6] < (7.6, 9.5]]#4 decimal places! precision was 6 though..

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.convert_dtypes.html#pandas.Series.convert_dtypes
	need to add notes to:
		answer this question: '''In pandas.Series.convert_dtypes, what does the kwarg '''infer_objects''' do? No matter what I pass in as value, it seems to have no effect.'''
		also (maybe I was seeing things on this one!) but I swear the first time I ran this, if you pass any explicit args (I passed all = True), then numpy.nans will NOT be replaced with pandas.NA; however, once you pass at least once 0 explicit args (e.g. df.convert_dtypes(),s.convert_dtypes()), then NaNs (numpy.nan) WILL be replaced with pandas.NA (not sure why or how this happens..)

https://pandas.pydata.org/pandas-docs/stable/user_guide/gotchas.html#gotchas-truth
	need to update:
		'''empty()''' to '''empty'''
			(empty is not a callable but rather a boolean)
	need to add:
		"""DataFrame all() and any() methods will return a DataFrame (regardless of whether the original DataFrame is 1d). Hence, you cannot use '''if pd.DataFrame([False,True],dtype='boolean').all()''', as this will raise a '''The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().''' error. Instead, double all() or any() calls (or equivalents) can be used (e.g. pd.DataFrame([False,True],dtype='boolean').all().all() will yield False; pd.DataFrame([False,True],dtype='boolean').any().any() will yield True; similarly, pd.DataFrame([False,True],dtype='boolean').all().item() will yield False and pd.DataFrame([False,True],dtype='boolean').any().item() will yield True). all().all(),any().any() always work, unlike all().item(),any().item(), which you cannot use for a 2+ dimensional DataFrame as item() needs an array of size 1."""

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html
	need to update '''base-2 representation''' to '''base-10 representation''' (at least on mine it's showing this way)
	need to format '''max_cols : int, optional When to switch from the verbose to the truncated output. If the DataFrame has more than max_cols columns, the truncated output is used. By default, the setting in pandas.options.display.max_info_columns is used.''' to another kwarg (like the rest of kwargs)

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack
	need to add note for fill_value since it's a no-op on things already NaN but converts NEW NaNs ('NEW' as in resulting from the unstacking operation ONLY) into fill_value value (see below code/result)

		df = pd.DataFrame({
			'A': ['foo', 'foo', 'bar', 'bar'],
			'B': ['one', 'two', 'one', 'two'],
			'C': [1.0, 2.0, None, 4.0]
		})
		print(df)
		print(df.set_index(['A', 'B']))
		print(df.set_index(['A', 'B']).unstack([0,1],fill_value=42))
		print(df.set_index(['A', 'B']).iloc[[0,1,2],:].unstack([-1],fill_value=42))

			 A    B    C
		0  foo  one  1.0
		1  foo  two  2.0
		2  bar  one  NaN
		3  bar  two  4.0
				   C
		A   B       
		foo one  1.0
			two  2.0
		bar one  NaN
			two  4.0
		   A    B  
		C  foo  one    1.0
				two    2.0
		   bar  one    NaN
				two    4.0
			   C      
		B    one   two
		A             
		bar  NaN  42.0
		foo  1.0   2.0

https://pandas.pydata.org/docs/user_guide/reshaping.html#combining-with-stats-and-groupby
	need to update examples, as original DataFrame we currently have (to get the results below to match) is incorrect:
		incorrect:
			exp                  A         B                   A
			animal             cat       dog       cat       dog
			first second                                        
			bar   one     0.895717  0.805244 -1.206412  2.565646
				  two     1.431256  1.340309 -1.170299 -0.226169
			baz   one     0.410835  0.813850  0.132003 -0.827317
				  two    -0.076467 -1.187678  1.130127 -1.436737
			foo   one    -1.413681  1.607920  1.024180  0.569605
				  two     0.875906 -2.211372  0.974466 -2.006747
			qux   one    -0.410001 -0.078638  0.545952 -1.219217
				  two    -1.226825  0.769804 -1.281247 -0.727707
		corrected:
			exp                  A                   B          
			animal             cat       dog       cat       dog
			first second                                        
			bar   one     0.895717  0.805244 -1.206412  2.565646
				  two     1.431256  1.340309 -1.170299 -0.226169
			baz   one     0.410835  0.813850  0.132003 -0.827317
				  two    -0.076467 -1.187678  1.130127 -1.436737
			foo   one    -1.413681  1.607920  1.024180  0.569605
				  two     0.875906 -2.211372  0.974466 -2.006747
			qux   one    -0.410001 -0.078638  0.545952 -1.219217
				  two    -1.226825  0.769804 -1.281247 -0.727707
		also, here's the source code to generate the corrected (as it wasn't easy doing it from the sections above / to save time for others, that don't have to recreate from scratch like I did!):
			# create the index levels
			index = pd.MultiIndex.from_product([['bar', 'baz', 'foo', 'qux'], ['one', 'two']], names=['first', 'second'])

			# create the column levels
			columns = pd.MultiIndex.from_product([['A', 'B'], ['cat', 'dog']], names=['exp','animal'])

			# create the data values
			data = np.array([[0.895717, 0.805244, -1.206412, 2.565646],
							 [1.431256, 1.340309, -1.170299, -0.226169],
							 [0.410835, 0.813850, 0.132003, -0.827317],
							 [-0.076467, -1.187678, 1.130127, -1.436737],
							 [-1.413681, 1.607920, 1.024180, 0.569605],
							 [0.875906, -2.211372, 0.974466, -2.006747],
							 [-0.410001, -0.078638, 0.545952, -1.219217],
							 [-1.226825, 0.769804, -1.281247, -0.727707]])

			# create the DataFrame
			df = pd.DataFrame(data, index=index, columns=columns)


https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html#pandas.pivot_table
https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html
	need to explain / add the actual code that shows the distinction between observed=False and observed=True and when it applies (see/use below code,result):
		code:
			# Create a sample dataset
			df = pd.DataFrame({
				'color': ['red', 'blue', 'green', 'red', 'red', 'green', 'blue', 'red'],
				'size': ['small', 'large', 'large', 'medium', 'small', 'medium', 'small', 'large'],
				'count': ['a', 'a', 'a', 'a', 'a', 'b', 'b', 'b']
			})

			# Convert the column(s) to a categorical data type
			df['color'] = pd.Categorical(df['color'], categories=['red', 'blue', 'green', 'yellow'])
			df['size'] = pd.Categorical(df['size'], categories=['large', 'medium', 'small'])

			# Pivot the table with observed=<value>
			pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count')
			print(pivot_table_all)
			pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count',observed=False)
			print(pivot_table_all)
			pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count',observed=True)
			print(pivot_table_all,'\n\n')



			# Create a sample dataset
			df = pd.DataFrame({
				'color': ['red', 'blue', 'green', 'red', 'red', 'green', 'blue', 'red'],
				'size': ['small', 'large', 'large', 'medium', 'small', 'medium', 'small', 'large'],
				'count': ['a', 'a', 'a', 'a', 'a', 'b', 'b', 'b']
			})

			# Convert the column(s) to a categorical data type
			df['color'] = pd.Categorical(df['color'], categories=['red', 'blue', 'green', 'yellow'])

			# Pivot the table with observed=<value>
			pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count')
			print(pivot_table_all)
			pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count',observed=False)
			print(pivot_table_all)
			pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count',observed=True)
			print(pivot_table_all,'\n\n')



			# Create a sample dataset
			df = pd.DataFrame({
				'color': ['red', 'blue', 'green', 'red', 'red', 'green', 'blue', 'red'],
				'size': ['small', 'large', 'large', 'medium', 'small', 'medium', 'small', 'large'],
				'count': ['a', 'a', 'a', 'a', 'a', 'b', 'b', 'b']
			})

			# Convert the column(s) to a categorical data type #if this step doesn't happen, then kwarg 'observed' is no-op since there's not at least 1 categorical variable in the mix! (in other words, all the below code will result in the same output!)

			# Pivot the table with observed=<value>
			pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count')
			print(pivot_table_all)
			pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count',observed=False)
			print(pivot_table_all)
			pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count',observed=True)
			print(pivot_table_all,'\n\n')

		result:
			size    large  medium  small
			color                       
			red         1       1      2
			blue        1       0      1
			green       1       1      0
			yellow      0       0      0
			size    large  medium  small
			color                       
			red         1       1      2
			blue        1       0      1
			green       1       1      0
			yellow      0       0      0
			size   large  medium  small
			color                      
			red      1.0     1.0    2.0
			blue     1.0     NaN    1.0
			green    1.0     1.0    NaN 


			size    large  medium  small
			color                       
			red         1       1      2
			blue        1       0      1
			green       1       1      0
			yellow      0       0      0
			size    large  medium  small
			color                       
			red         1       1      2
			blue        1       0      1
			green       1       1      0
			yellow      0       0      0
			size   large  medium  small
			color                      
			red      1.0     1.0    2.0
			blue     1.0     NaN    1.0
			green    1.0     1.0    NaN 


			size   large  medium  small
			color                      
			blue     1.0     NaN    1.0
			green    1.0     1.0    NaN
			red      1.0     1.0    2.0
			size   large  medium  small
			color                      
			blue     1.0     NaN    1.0
			green    1.0     1.0    NaN
			red      1.0     1.0    2.0
			size   large  medium  small
			color                      
			blue     1.0     NaN    1.0
			green    1.0     1.0    NaN
			red      1.0     1.0    2.0 


	need to add, relating to kwargs 'dropna','fill_value', that:
		1. these apply to only cases where no index,columns intersections have at least 1 data point (in other words, the combination of index,columns simply does not exist)
		2. these do NOT apply to cases where data points are present but numpy.nan,pandas.NA (these will just result in a user warning with future-releases errors)  '''FutureWarning: pivot_table dropped a column because it failed to aggregate. This behavior is deprecated and will raise in a future version of pandas. Select only the columns that can be aggregated.''')
		
		example code:
			df = pd.DataFrame({"A": ["foo", "foo", "foo", "foo", "foo",
									 "bar", "bar", "bar", "bar"],
							   "B": ["one", "one", "one", "two", "two",
									 "one", "one", "two", "two"],
							   "C": ["small", "large", "large", "small",
									 "small", "large", "small", "small",
									 "large"],
							   "D": [1, 2, 2, 3, 3, 4, 5, 6, 7],
							   "E": [pandas.NA, pandas.NA, pandas.NA, pandas.NA, pandas.NA, 6, 8, 9, 9]})
			print(df.pivot_table(index=['A','B'],columns='C'))
			print(df.pivot_table(index=['A','B'],columns='C',dropna=False))
			print(df.pivot_table(index=['A','B'],columns='C',dropna=False,fill_value=42))

		example result:
						D      
			C       large small
			A   B              
			bar one   4.0   5.0
				two   7.0   6.0
			foo one   2.0   1.0
				two   NaN   3.0
						D      
			C       large small
			A   B              
			bar one   4.0   5.0
				two   7.0   6.0
			foo one   2.0   1.0
				two   NaN   3.0
						D      
			C       large small
			A   B              
			bar one     4     5
				two     7     6
			foo one     2     1
				two    42     3


https://pandas.pydata.org/docs/user_guide/groupby.html#groupby-specify
	need to add that pandas.Grouper object itself does not appear in the result (regardless of whether in level or key/column)
		import datetime
		df = pd.DataFrame(
			{
				"Branch": "A A A A A B B B".split(),
				"Buyer": "Carl Mark Carl Carl Joe Joe Joe Carl".split(),
				"Quantity": [1, 3, 5, 1, 8, 1, 9, 3],
				"Date": [
					datetime.datetime(2013, 1, 1, 13, 0),
					datetime.datetime(2013, 1, 1, 13, 5),
					datetime.datetime(2013, 10, 1, 20, 0),
					datetime.datetime(2013, 10, 2, 10, 0),
					datetime.datetime(2013, 10, 1, 20, 0),
					datetime.datetime(2013, 10, 2, 10, 0),
					datetime.datetime(2013, 12, 2, 12, 0),
					datetime.datetime(2013, 12, 2, 14, 0),
				],
			}
		)
		print(df1.groupby([pandas.Grouper(freq='1M',level='Date'),'Branch'],as_index=False)[['Quantity']].sum())#Grouper not included in result
		print(df1.groupby([pandas.Grouper(freq='1M',key='Date'),'Branch'],as_index=False)[['Quantity']].sum())#Grouper not included in result

		  Branch  Quantity
		0      A         4
		1      A        14
		2      B         1
		3      B        12
		  Branch  Quantity
		0      A         4
		1      A        14
		2      B         1
		3      B        12


	need to update example to dates (instead of just 1s) to [better] show that the grouping actually happens on year-month (below also has year-week)
		business_dates = pd.date_range(start="4/1/2014", end="6/30/2014", freq="B")
		df = pd.DataFrame(numpy.repeat(business_dates.to_numpy(),2).reshape((business_dates.shape[0],2)), index=business_dates, columns=["a", "b"])
		print(df.groupby([df.index.year, df.index.month]).nth([0, 3, -1]))
		print(df.groupby([df.index.year, df.index.week]).nth([0, 3, -1]))

						a          b
		2014 4 2014-04-01 2014-04-01
			 4 2014-04-04 2014-04-04
			 4 2014-04-30 2014-04-30
			 5 2014-05-01 2014-05-01
			 5 2014-05-06 2014-05-06
			 5 2014-05-30 2014-05-30
			 6 2014-06-02 2014-06-02
			 6 2014-06-05 2014-06-05
			 6 2014-06-30 2014-06-30
						 a          b
		2014 14 2014-04-01 2014-04-01
			 14 2014-04-04 2014-04-04
			 15 2014-04-07 2014-04-07
			 15 2014-04-10 2014-04-10
			 15 2014-04-11 2014-04-11
			 16 2014-04-14 2014-04-14
			 16 2014-04-17 2014-04-17
			 16 2014-04-18 2014-04-18
			 17 2014-04-21 2014-04-21
			 17 2014-04-24 2014-04-24
			 17 2014-04-25 2014-04-25
			 18 2014-04-28 2014-04-28
			 18 2014-05-01 2014-05-01
			 18 2014-05-02 2014-05-02
			 19 2014-05-05 2014-05-05
			 19 2014-05-08 2014-05-08
			 19 2014-05-09 2014-05-09
			 20 2014-05-12 2014-05-12
			 20 2014-05-15 2014-05-15
			 20 2014-05-16 2014-05-16
			 21 2014-05-19 2014-05-19
			 21 2014-05-22 2014-05-22
			 21 2014-05-23 2014-05-23
			 22 2014-05-26 2014-05-26
			 22 2014-05-29 2014-05-29
			 22 2014-05-30 2014-05-30
			 23 2014-06-02 2014-06-02
			 23 2014-06-05 2014-06-05
			 23 2014-06-06 2014-06-06
			 24 2014-06-09 2014-06-09
			 24 2014-06-12 2014-06-12
			 24 2014-06-13 2014-06-13
			 25 2014-06-16 2014-06-16
			 25 2014-06-19 2014-06-19
			 25 2014-06-20 2014-06-20
			 26 2014-06-23 2014-06-23
			 26 2014-06-26 2014-06-26
			 26 2014-06-27 2014-06-27
			 27 2014-06-30 2014-06-30

https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html#pandas.Grouper
	need to add examples for kwargs closed,label,sort and how different values give different results (use/see below code,result)
		code:
			#closed,label example (different values giving different results)
			# Create a DataFrame with a datetime column
			dates = pd.date_range(start='2022-01-01', end='2022-12-31', freq='D')
			df = pd.DataFrame({'date': dates, 'value': np.random.default_rng(8).random(len(dates))})
			# Group the DataFrame by month, with the left endpoint closed and labeling the left boundary
			grouped = df.groupby(pd.Grouper(key='date', freq='M', closed='left', label='left'))
			# Calculate the mean of each group
			grouped_mean = grouped.mean()
			# Print the resulting DataFrame
			print(grouped_mean)
			grouped = df.groupby(pd.Grouper(key='date', freq='M', closed='right', label='right'))
			# Calculate the mean of each group
			grouped_mean = grouped.mean()
			# Print the resulting DataFrame
			print(grouped_mean)
			grouped = df.groupby(pd.Grouper(key='date', freq='M', closed='left', label='right'))#typically you don't want to do this because it would label (using the right labels) but have the values of the left labels, whicih isn't accurate!
			# Calculate the mean of each group
			grouped_mean = grouped.mean()
			# Print the resulting DataFrame
			print(grouped_mean)

			#sort example (different values giving different results)
			# Create a DataFrame with an hourly DatetimeIndex
			dates = pd.date_range(start='2022-01-01', end='2022-01-01 23:00:00', freq='H')
			df = pd.DataFrame({'value': np.random.default_rng(8).random(len(dates)),'value1': numpy.repeat(numpy.arange(len(dates)/2)[::-1],2)})
			grouped_start = df.groupby(pd.Grouper(key='value1',sort=False))
			grouped_start = df.groupby(pd.Grouper(key='value1'))
			# Calculate the mean of each group
			grouped_mean_start = grouped_start.mean()
			# Print the resulting DataFrame
			print(grouped_mean_start)
			grouped_start = df.groupby(pd.Grouper(key='value1',sort=True))
			# Calculate the mean of each group
			grouped_mean_start = grouped_start.mean()
			# Print the resulting DataFrame
			print(grouped_mean_start)
		result:
						   value
			date                
			2021-12-31  0.435459
			2022-01-31  0.467887
			2022-02-28  0.430583
			2022-03-31  0.550312
			2022-04-30  0.517671
			2022-05-31  0.474322
			2022-06-30  0.518028
			2022-07-31  0.519037
			2022-08-31  0.536819
			2022-09-30  0.492556
			2022-10-31  0.480668
			2022-11-30  0.434723
			2022-12-31  0.493654
						   value
			date                
			2022-01-31  0.441004
			2022-02-28  0.462591
			2022-03-31  0.429782
			2022-04-30  0.544300
			2022-05-31  0.518418
			2022-06-30  0.482416
			2022-07-31  0.529355
			2022-08-31  0.510158
			2022-09-30  0.527180
			2022-10-31  0.504534
			2022-11-30  0.476215
			2022-12-31  0.433090
						   value
			date                
			2022-01-31  0.435459
			2022-02-28  0.467887
			2022-03-31  0.430583
			2022-04-30  0.550312
			2022-05-31  0.517671
			2022-06-30  0.474322
			2022-07-31  0.518028
			2022-08-31  0.519037
			2022-09-30  0.536819
			2022-10-31  0.492556
			2022-11-30  0.480668
			2022-12-31  0.434723
			2023-01-31  0.493654

			value1          
			11.0    0.657125
			10.0    0.553630
			9.0     0.630491
			8.0     0.405315
			7.0     0.292960
			6.0     0.249249
			5.0     0.189298
			4.0     0.618406
			3.0     0.423412
			2.0     0.625565
			1.0     0.530781
			0.0     0.328004
					   value
			value1          
			0.0     0.328004
			1.0     0.530781
			2.0     0.625565
			3.0     0.423412
			4.0     0.618406
			5.0     0.189298
			6.0     0.249249
			7.0     0.292960
			8.0     0.405315
			9.0     0.630491
			10.0    0.553630
			11.0    0.657125

	need to add examples for kwarg 'convention' and how different values give different results (was not able to write/find code for this one that actually gave different results, as it seems to be a no-op no matter what I pass)


https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html
	add info from below code.comments (#...) to docs
		s0 = pd.Series(['cat0','cat1','cat2'])
		df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'], 'C': [1, 2, 3]})
		for data0 in [s0,df]:
			for prefix0 in [None,'','prefix0',['prefix0','prefix1'],{'A':'prefix0','B':'prefix1'}]:#if prefix=None, uses each columnName as prefix (e.g. columnName(asPrefix)category0,columnName(asPrefix)category1,columnName(asPrefix)category2,columnName1(asPrefix)category0,...)
				for prefix_sep0 in ['_','']:
					for columns0 in [None,['A','C']]:#any columns not in 'columns'=thisList are still included in output but NOT as get_dummies (i.e. they are not split out but simply passed as is)
						for dummy_na0 in [False,True]:#if dummy_na=True then 1 columnNamenan created for each columnName in DataFrame
							for sparse0 in [False,True]:
								for drop_first0 in [False,True]:
									for dtype0 in [numpy.uint8,numpy.float_]:
										print(f'data {data0}',f'prefix {prefix0}',f'prefix_sep {prefix_sep0}',f'columns {columns0}',f'dummy_na {dummy_na0}',f'sparse {sparse0}',f'drop_first {drop_first0}',f'dtype {dtype0}',sep='\n')
										try:
											print(pandas.get_dummies(data0,prefix=prefix0,prefix_sep=prefix_sep0,columns=columns0,dummy_na=dummy_na0,sparse=sparse0,drop_first=drop_first0,dtype=dtype0))
										except Exception as e:
											print(e)


https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html#pandas.crosstab
	add info from below code.comments (#...) to docs
		s0=pandas.Series(numpy.random.default_rng(8).integers(0,5,(50,)))
		s1=pandas.Series(numpy.random.default_rng(7).integers(0,5,(50,)))
		s2=pandas.Series(numpy.random.default_rng(6).integers(0,5,(50,)))
		s3=pandas.Series(numpy.random.default_rng(5).integers(0,5,(50,)))
		print(s0,s1,s2,s3,sep='\n')
		for index0 in [None,s0,[s0,s1]]:#if None but columns is something, then will just show empty df basically
			for columns0 in [None,s2,[s2,s3]]:#if None but index is something, then will just show empty df basically; can't BOTH be None otherwise errors
				for values0 in [None,s3]:#must have aggfunc otherwise errors
					for rownames0 in [None,['rowNames0','rowNames1']]:
						for colnames0 in [None,['colNames0','colNames1']]:
							for aggfunc0 in [None,numpy.mean]:#must have values otherwise errors
								for margins0 in [False,True]:
									for margins_name0 in ['All','total0']:
										for dropna0 in [False,True]:#renders NaN values
											for normalize0 in [False,True,'all','index','columns']:#with margins=True AND normalize='index', shows ONLY 'All' margins at bottom (makes sense since we have to have this to normalize across that index); with margins=True AND normalize='columns', shows ONLY 'All' margins at right (makes sense since we have to have this to normalize down that column); with margins=True AND normalize=<anythingElseNotMentionedPreviously>, shows 'All' margins at bottom AND right (makes sense since we have to have this to normalize/total all)
												print(f'index {index0}',f'columns {columns0}',f'values {values0}',f'rownames {rownames0}',f'colnames {colnames0}',f'aggfunc {aggfunc0}',f'margins {margins0}',f'margins_name {margins_name0}',f'dropna {dropna0}',f'normalize {normalize0}',sep='\n')
												try:
													print(pandas.crosstab(index0,columns0,values=values0,rownames=rownames0,colnames=colnames0,aggfunc=aggfunc0,margins=margins0,margins_name=margins_name0,dropna=dropna0,normalize=normalize0))
													print('validHit0')
												except Exception as e:
													print(e)


https://pandas.pydata.org/docs/reference/api/pandas.from_dummies.html#pandas.from_dummies
	add info from below code.comments (#...) to docs
		df = pd.DataFrame({"a": [1, 0, 0, 1], "b": [0, 1, 0, 0],"c": [0, 0, 1, 0]})
		df1 = pd.DataFrame({"col1_a": [1, 0, 1], "col1_b": [0, 1, 0],"col2_a": [0, 1, 0], "col2_b": [1, 0, 0],"col2_c": [0, 0, 1]})
		df2 = pd.DataFrame({"col1_a": [1, 0, 0], "col1_b": [0, 1, 0],"col2_a": [0, 1, 0], "col2_b": [1, 0, 0],"col2_c": [0, 0, 0]})
		for data0 in [df,df1,df2]:
			for sep0 in [None,'','_']:#'' not same as None and will error if no sep in df
				for default_category0 in [None,'default_category0',{'col1':42,'col2':13}]:#must be same length as data otherwise errors (e.g. '''Length of 'default_category' (2) did not match the length of the columns being encoded (1)''')
					print(f'data {data0}',f'sep {sep0}',f'default_category {default_category0}',sep='\n')
					try:
						print(pandas.from_dummies(data0,sep=sep0,default_category=default_category0))
						print('validHit0')
					except Exception as e:
						print(e)

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.explode.html#pandas.DataFrame.explode
	dataFrame0=pandas.DataFrame([[['a','b'],['c','d']],[['a','b','b1'],['c','d','d1']]]).T.rename((lambda c0: 'col'+str(c0)),axis=1)#in the real-world, data often comes in the form of all-elements-in-list1 associated with all-elements-in-list2 e.g. in this example here, a is associated with a,b,b1; b1 is in turn associated with a,b; hence, explode needs to have functionality that loops through the columns and explodes each separately to make one all-columns-exploded-sequentially DataFrame (instead of erroring out with '''columns must have matching element counts''', which isn't very useful); this is achieved with the following code ('''dataFrame1=dataFrame0.copy()...print(dataFrame0)'''); let's add this and maybe a kwarg iter=False (meaning do what we've been doing and raise if number of elements not equal) vs iter=True (apply the below code or equivalent, returning the result)
	print(dataFrame0)
	dataFrame1=dataFrame0.copy()
	for c0 in dataFrame1:
		dataFrame0=dataFrame0.explode(c0)
		print(dataFrame0)

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.insert.html
	need to return new DataFrame (instead of None; can still insert into original DataFrame of course!); this aligns with:
		1. https://pandas.pydata.org/docs/reference/api/pandas.Index.insert.html#pandas.Index.insert
		2. most other pandas DataFrame operations

https://pandas.pydata.org/docs/reference/api/pandas.Index.insert.html#pandas.Index.insert
	need to mention that original index is NOT modified

https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.view.html#pandas.api.extensions.ExtensionArray.view
	need to add that kwarg 'dtype' value must have been implemented in the ExtensionDtype otherwise will raise 'NotImplementedError'
	
https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray._formatter.html#pandas.api.extensions.ExtensionArray._formatter
	add working example to explain ''' This may be useful if you want scalar values to appear differently within a Series versus on its own (e.g. quoted or not).''' since seems like same regardless of boxed value
		code:
			object0=AngleArray([1,2.2,5.6,2.3,1.2],unit='rad',copy=True)#full implementation of AngleArray https://stackoverflow.com/questions/68893521/simple-example-of-pandas-extensionarray
			print(pandas.Series([1.0]).apply(object0._formatter()))
			print(pandas.Series([1.0]).apply(object0._formatter(boxed=True)))
			print(pandas.Series(1.0).apply(object0._formatter()))
			print(pandas.Series(1.0).apply(object0._formatter(boxed=True)))
		result:
			0    1.0
			dtype: object
			0    1.0
			dtype: object
			0    1.0
			dtype: object
			0    1.0
			dtype: object


https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray._from_factorized.html#pandas.api.extensions.ExtensionArray._from_factorized
	need to add working example showing what the purpose/value of this is since it doesn't seem to undo factorization as docs says it would (see below code/result)
		code:
			object0=AngleArray([1,1,2,2],unit='rad',copy=True)#full implementation of AngleArray https://stackoverflow.com/questions/68893521/simple-example-of-pandas-extensionarray
			print(object0.factorize())
			try:
				print(object0._from_factorized(object0.factorize()))
			except Exception as e:
				print(e)
			print(object0._from_factorized(object0.factorize()[0],object0))
			print('')
			print(object0._from_factorized(object0.factorize()[1],object0))
			print('')
			try:
				print(object0._from_factorized(object0.factorize()[1],object0.factorize()[0]))
			except Exception as e:
				print(e)
			print('')
			print(object0._from_factorized(object0.factorize()[0],object0.factorize()[1]))

			object0=pandas.array(['a','a','b','b'])
			print(object0.factorize())
			try:
				print(object0._from_factorized(object0.factorize()))
			except Exception as e:
				print(e)
			try:
				print(object0._from_factorized(object0.factorize()[0],object0))
			except Exception as e:
				print(e)
			print('')
			try:
				print(object0._from_factorized(object0.factorize()[1],object0))
			except Exception as e:
				print(e)
			print('')
			try:
				print(object0._from_factorized(object0.factorize()[1],object0.factorize()[0]))
			except Exception as e:
				print(e)
			print('')
			try:
				print(object0._from_factorized(object0.factorize()[0],object0.factorize()[1]))
			except Exception as e:
				print(e)
		result:
			(array([0, 0, 1, 1], dtype=int64), <AngleArray>
			[1, 2]
			Length: 2, dtype: angle[rad])
			AngleArray._from_factorized() missing 1 required positional argument: 'original'
			<AngleArray>
			[0, 0, 1, 1]
			Length: 4, dtype: angle[rad]

			<AngleArray>
			[1, 2]
			Length: 2, dtype: angle[rad]

			'numpy.dtype[int64]' object has no attribute 'unit'

			<AngleArray>
			[0, 0, 1, 1]
			Length: 4, dtype: angle[rad]
			(array([0, 0, 1, 1], dtype=int64), <StringArray>
			['a', 'b']
			Length: 2, dtype: string)
			NDArrayBackedExtensionArray._from_factorized() missing 1 required positional argument: 'original'




		'numpy.ndarray' object has no attribute '_ndarray'



https://pandas.pydata.org/docs/reference/api/pandas.Categorical.html#pandas.Categorical
	add info from below code.comments (#...) to docs
		for values0 in [[1,3,2],['a','c','b']]:
			for categories0 in [None,[1,3,2]]:
				for ordered0 in [None,False,True]:
					for dtype0 in [None,pandas.CategoricalDtype(categories=[3,2,1],ordered=True)]:#overrides inferred when not None; also, raises error '''Cannot specify `categories` or `ordered` together with `dtype`.''' when trying to specify `categories` or `ordered` together with `dtype` 
						for fastpath0 in [False,True]:#10x faster when True (skip some internal checks and memory inefficient but faster (e.g. timeit.repeat results when False [0.0020938999950885773, 0.001845099963247776, 0.0020455000922083855] vs timeit.repeat results when True [0.0001822998747229576, 0.00014039967209100723, 0.00013450020924210548]))
							for copy0 in [False,True]:#True seems to be faster per timeit.repeat runs (don't have to update same memory by allocating some tmp memory and updating back from there (e.g. timeit.repeat results when False [0.004346900153905153, 0.0036661000922322273, 0.0025372998788952827] vs timeit.repeat results when True [0.0023807003162801266, 0.002176800277084112, 0.002770999912172556]))
								print(f'values {values0}',f'categories {categories0}',f'ordered {ordered0}',f'dtype {dtype0}',f'fastpath {fastpath0}',f'copy {copy0}',sep='\n')
								try:
									print(pandas.Categorical(values0,categories=categories0,ordered=ordered0,dtype=dtype0,fastpath=fastpath0,copy=copy0))
									print(timeit.repeat('''pandas.Categorical(values0,categories=categories0,ordered=ordered0,dtype=dtype0,fastpath=fastpath0,copy=copy0)''',number=10,repeat=3,globals=globals()))
								except Exception as e:
									print(e)
								print('\n')

https://pandas.pydata.org/docs/user_guide/categorical.html#renaming-categories
	last code example really doesn't show functionality of dict-like object so may want to replace with one that does i.e. replace '''
		# You can also pass a dict-like object to map the renaming
		s = s.cat.rename_categories({1: "x", 2: "y", 3: "z"})

		s
		Out[73]: 
		0    Group a
		1    Group b
		2    Group c
		3    Group a
		dtype: category
		Categories (3, object): ['Group a', 'Group b', 'Group c']
		''' with '''
		# You can also pass a dict-like object to map the renaming
		s = s.cat.rename_categories({'Group a': "x", 'Group b': "y", 'Group c': "z"})
		s
		Out[73]: 
		0    x
		1    y
		2    z
		3    x
		dtype: category
		Categories (3, object): ['x', 'y', 'z']
		'''

	need to remove '''Be aware that assigning new categories is an inplace operation, while most other operations under Series.cat per default return a new Series of dtype category.''' as it's false / no longer true
		code:
			c0=pandas.Categorical(['b','a','c'],categories=['a','b','c','d'])
			print(c0)
			print(c0.rename_categories((lambda c0: c0.upper())))#returns array of dtype='category' with new categories but does NOT modify original in place
			print(c0)#original still returns same as 2 lines above
		result:
			['b', 'a', 'c']
			Categories (4, object): ['a', 'b', 'c', 'd']
			['B', 'A', 'C']
			Categories (4, object): ['A', 'B', 'C', 'D']
			['b', 'a', 'c']
			Categories (4, object): ['a', 'b', 'c', 'd']

https://pandas.pydata.org/docs/user_guide/categorical.html#reordering
	need to update '''If the Categorical is not ordered, Series.min() and Series.max() will raise TypeError. Numeric operations like +, -, *, / and operations based on them (e.g. Series.median(), which would need to compute the mean between two values if the length of an array is even) do not work and raise a TypeError.''' to '''If the Categorical is not ordered, Series.min() and Series.max() will raise TypeError. Numeric operations like +, -, *, / and operations based on them (e.g. Series.median(), which would need to compute the mean between two values if the length of an array is even) do not work and raise a TypeError. Although Series.min(), Series.max(), and other sorting-based operations work on string and numeric categorical data alike, strict numeric operations like -, *, / do not work between 2 string categorical data elements (e.g. 'a'-'b' is not supported).'''

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html#pandas.DataFrame.at
	add info from below code.comments (#...) to docs
		df0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,100,(100,100)))
		for accessor0 in [df0.loc,df0.iloc,df0.at,df0.iat]:
			try:
				print(accessor0,accessor0[42,42],timeit.repeat('''accessor0[42,42]''',repeat=5,number=1000,globals=globals()),sep='\n')#based on below results, 1. at and iat are faster versions of loc and iloc respectively (when accessing 1 element, of course) 2. at < loc < iat < iloc in terms of speed (less is faster; probably due to necessary integer conversion of i* counterparts)
			except Exception as e:
				print(e)
		#results:
		# <pandas.core.indexing._LocIndexer object at 0x000001DFA82C9260>
		# 66
		# [0.012458200100809336, 0.011787200346589088, 0.01323659997433424, 0.01086620008572936, 0.011760300025343895]
		# <pandas.core.indexing._iLocIndexer object at 0x000001DFA830BD30>
		# 66
		# [0.03606580011546612, 0.03956490010023117, 0.036243699956685305, 0.03244740003719926, 0.03638960001990199]
		# <pandas.core.indexing._AtIndexer object at 0x000001DFA86F9A30>
		# 66
		# [0.004322299733757973, 0.005972200073301792, 0.004386099986732006, 0.005179999861866236, 0.004408000037074089]
		# <pandas.core.indexing._iAtIndexer object at 0x000001DFA86FBBA0>
		# 66
		# [0.027216500137001276, 0.02658300008624792, 0.029891499783843756, 0.028673999942839146, 0.03217059979215264]

https://pandas.pydata.org/docs/reference/api/pandas.api.types.union_categoricals.html
	add info from below code.comments (#...) to docs
		c0=pandas.Categorical([2,1,3])
		c1=pandas.Categorical([5,4,6])
		# c0=pandas.Categorical([2,1,3],ordered=True)
		# c1=pandas.Categorical([5,4,6],ordered=True)
		c2=pandas.Categorical(['a','b','c'])
		for e00 in [c0,c1,c2]:
			for e10 in [c0,c1,c2]:
				for to_union0 in [[e00,e10]]:
					for sort_categories0 in [False,True]:#errors if used with ordered=True categoricals; seems to be no-op with ordered=False categoricals but seems to work in https://pandas.pydata.org/docs/user_guide/categorical.html#unioning simpler example (not sure what's going on)
						for ignore_order0 in [False,True]:
							print(f'e0 {e00}',f'e1 {e10}',f'to_union {to_union0}',f'sort_categories {sort_categories0}',f'ignore_order {ignore_order0}',sep='\n')
							try:
								print(pandas.concat([pandas.Series(to_union0[0]),pandas.Series(to_union0[1])]).astype('category'))#pro: can be used with different dtypes so long as  con: must be in Series or DataFrame (e.g. Categorical not allowed)
								print(pandas.api.types.union_categoricals(to_union0,sort_categories=sort_categories0,ignore_order=ignore_order0))#con: cannot be used with different dtypes but pro: can be in Categorical, Series, any list-like
							except Exception as e:
								print(e)
							print('\n')

https://pandas.pydata.org/docs/user_guide/categorical.html#differences-to-r-s-factor
	remove '''Itâ€™s not possible to specify labels at creation time. Use s.cat.rename_categories(new_labels) afterwards.''' if not true since pandas.Categorical(['a','b','c'],categories=['a','b','c','d']) allows you to specify 4 categories on creation (if this is not what was meant OR kwarg 'categories' actually uses 'set_categories' under the hood, let's specify that and add a working example)



https://pandas.pydata.org/docs/user_guide/categorical.html#side-effects
	need to resolve why below example not working as expected (particularly line with '''#not entirely sure why this was not updated if categories were updated in df with copy=False..''') (it works with example provided in docs so again not sure if it's a functionality thing or a end-user (me) mistake thing)
		print(pandas.Categorical([0,1,2,3],categories=[0,1,2,3]))
		c0=pandas.Categorical([0,1,2,3],categories=[0,1,2,3])
		print(pandas.Series(c0,copy=False))
		s0=pandas.Series(c0)
		s0[0]=3
		print(s0)
		print(c0)#this was updated as expected
		df0=pandas.DataFrame(s0,columns=['col0'],copy=False)
		df0['col0']=df0['col0'].cat.rename_categories([90,1,2,42])#this will properly rename/relabell categories AND values (e.g. 3 -> 42)
		# df0['col0']=df0['col0'].cat.set_categories([90,1,2,42])#this will completely remove and then add categories, setting underlying values (that change e.g. 3 -> 42) to NaN instead of 42
		print(df0['col0'].cat.categories)
		print(df0)
		print(c0)#not entirely sure why this was not updated if categories were updated in df with copy=False..

https://pandas.pydata.org/docs/user_guide/basics.html#comparing-array-like-objects
	need to update info from below code.comments (#...) to docs
		print(numpy.array([1,2,3])==numpy.array([1,2]))#deprecated and will raise error in future to align with pandas
		print(numpy.array([1,2,3])==numpy.array([1]))#broadcast so no error; broadcast powerful so numpy keeping it this way (and don't have to worry about indices since not pandas)

https://pandas.pydata.org/docs/reference/api/pandas.Series.combine.html#pandas.Series.combine
	update '''Function that takes two scalars as inputs and returns an element.''' to '''Function that takes two scalars as inputs (the 1st from Series and the 2nd from other) and returns an element.'''

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_records.html#pandas.DataFrame.from_records
	add info from below code.comments (#...) to docs
		d0=[(1,'a'),(2,'b'),(3,'c')]
		# d1=numpy.array([(1,'a'),(2,'b'),(3,'c')],dtype=[('int0',numpy.int_),('unicode0',numpy.unicode_)])#numpy.unicode_ is 0 length so will give ''..
		d1=numpy.array([(1,'a'),(2,'b'),(3,'c')],dtype=[('int0',numpy.int_),('unicode0','U4')])
		d2=[{'int1':1,'unicode1':'a'},{'int1':2,'unicode1':'b'},{'int1':3,'unicode1':'c'}]
		d3=list(range(3))
		for data0 in [d0,d1,d2,d3]:
			for index0 in [None,[0,1],[1,2,3]]:#must match length of incoming data else errors
				for exclude0 in [None,['int1']]:#AFTER columns
					for columns0 in [None,['int1','int2']]:#renames 0,1,... defaults; if not default, then picks (nans for new)
						for coerce_float0 in [False,True]:#no-op (no float conversion)?
							for nrows0 in [None,2#no-op (all rows taken regardless)?
								print(f'data {data0}',f'index {index0}',f'exclude {exclude0}',f'columns {columns0}',f'coerce_float {coerce_float0}',f'nrows {nrows0}',sep='\n')
								try:
									print(pandas.DataFrame.from_records(data0,index=index0,exclude=exclude0,columns=columns0,coerce_float=coerce_float0,nrows=nrows0))
								except Exception as e:
									print(e)


https://pandas.pydata.org/docs/reference/api/pandas.arrays.SparseArray.html#pandas.arrays.SparseArray
	add info from below code.comments (#...) to docs
		for data0 in [[0,1,2,0],[[False,False,False,False],[False,False,True,True]]]:
			for sparse_index0 in [None,[0,1],False,True]:#this is actually a SparseIndex that you must pass in (otherwise, stick with None and it'll create that SparseIndex for you)
				for fill_value0 in [None,42]:#this is what value means sparse in the data / what value the system interprets as sparse/notAUsefulValue in the data (usually this is 0 for ints, etc. but can be whatever value you specify here); see https://pandas.pydata.org/docs/user_guide/sparse.html#sparsedtype for more info and an example (just add the latter/reference)
					for kind0 in ['integer','block']:#returns start and end block points (e.g. start at 1 and then ends at 4 means [1:4] are all contiguous data points / non-sparse)
						for dtype0 in [int,bool]:
							for copy0 in [False,True]:
								print(f'data {data0}',f'sparse_index {sparse_index0}',f'fill_value {fill_value0}',f'kind {kind0}',f'dtype {dtype0}',f'copy {copy0}',sep='\n')
								try:
									print(pandas.arrays.SparseArray(data0,sparse_index=sparse_index0,fill_value=fill_value0,kind=kind0,dtype=dtype0,copy=copy0))
								except Exception as e:
									print(e)

https://pandas.pydata.org/docs/user_guide/sparse.html#sparse-accessor
	add info from below code.comments (#...) to docs
		try:
			print(pandas.array([1,0,0,3],dtype='Sparse[bool]').sparse.density)#docs '''This accessor is available only on data with SparseDtype, and on the Series class itself for creating a Series with sparse data from a scipy COO matrix with.''' needs to be updated to '''This accessor is available only on a Series with data of SparseDtype (e.g. for creating a Series with sparse data from a scipy COO matrix with).''', as this code line gives error ''''SparseArray' object has no attribute 'sparse''' even though it's of SparseDtype..
		except Exception as e:
			print(e)
	also, why doesn't Series DOCUMENTATION have / can we add Series.sparse.to_dense() docs to match DataFrame.sparse.to_dense() (since both actually exist/work)  (add to here as well https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.to_dense.html (link doesn't yet exist but should))
		example code/result to support:
			print(pandas.Series([0,0,0,4],dtype='Sparse[int]').sparse.to_dense())
			print(type(pandas.Series([0,0,0,4],dtype='Sparse[int]').sparse.to_dense()))
			
			0    0
			1    0
			2    0
			3    4
			dtype: int32
			<class 'pandas.core.series.Series'>
https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.to_coo.html
	add info from below code.comments (#...) to docs
		code:
			s = pd.Series([3.0, np.nan, 1.0, 3.0, np.nan, np.nan])
			s.index = pd.MultiIndex.from_tuples(
				[
					(1, 2, "a", 0),
					(1, 2, "a", 1),
					(1, 1, "b", 0),
					(1, 1, "b", 1),
					(2, 1, "b", 0),
					(2, 1, "b", 1)
				],
				names=["A", "B", "C", "D"],
			)
			print(s)
			ss = s.astype("Sparse")
			print(ss)
			A, rows, columns = ss.sparse.to_coo(row_levels=["A", "B"], column_levels=["C", "D"], sort_labels=True)
			print(A)
			print(A.todense())
			print(rows)
			print(columns)

			A, rows, columns = ss.sparse.to_coo(row_levels=["A", "B"], column_levels=["C", "D"], sort_labels=False)
			print(A)
			print(A.todense())
			print(rows)
			print(columns)

			print(timeit.timeit('''ss.sparse.to_coo(row_levels=["A", "B"], column_levels=["C", "D"], sort_labels=True)''',number=15,globals=globals()))#append '''When row_levels and/or column_levels refer to multiple levels, set to False for a faster execution.''' to '''Sort the row and column labels before forming the sparse matrix. When row_levels and/or column_levels refer to a single level, set to True for a faster execution.'''
			print(timeit.timeit('''ss.sparse.to_coo(row_levels=["A", "B"], column_levels=["C", "D"], sort_labels=False)''',number=15,globals=globals()))

		results (just last 2 lines / timeit):
			0.006448500003898516
			0.005935399996815249

https://python-zstandard.readthedocs.io/en/latest/dictionaries.html
	need to add working example and explanation as to what arg 2 must be (it says below '''argument 2 must be list, not bytes''' but then, when passing list, reverts to '''samples must be bytes''' (wish it would make up its mind!)
	original code (subsequent mods are in error messages themselves):
		import zstandard
		samples0='sampleText0sampleText0111110,sampleText0sampleText0111110,sampleText0sampleText0111110\nval0,val1,val2'.encode()
		train_dictionary0=zstandard.train_dictionary(16384,samples0,k=20,d=6,f=20,split_point=.8,accel=8,dict_id=424242,steps=200,threads=-1,level=2,notifications=4)
	resulting errors:
		(env0) C:\Users\pdumas\Downloads>python "C:\Users\pdumas\Documents\SAP\SAP GUI\numpy1.py"
		Traceback (most recent call last):
		  File "C:\Users\pdumas\Documents\SAP\SAP GUI\numpy1.py", line 9167, in <module>
			train_dictionary0=zstandard.train_dictionary(16384,samples0,k=20,d=6,f=20,split_point=.8,accel=8,dict_id=424242,steps=200,threads=-1,level=2,notifications=4)
		TypeError: train_dictionary() argument 2 must be list, not bytes
		(env0) C:\Users\pdumas\Downloads>python "C:\Users\pdumas\Documents\SAP\SAP GUI\numpy1.py"
		Traceback (most recent call last):
		  File "C:\Users\pdumas\Documents\SAP\SAP GUI\numpy1.py", line 9167, in <module>
			train_dictionary0=zstandard.train_dictionary(16384,list(samples0),k=20,d=6,f=20,split_point=.8,accel=8,dict_id=424242,steps=200,threads=-1,level=2,notifications=4)
		ValueError: samples must be bytes
		(env0) C:\Users\pdumas\Downloads>python "C:\Users\pdumas\Documents\SAP\SAP GUI\numpy1.py"
		Traceback (most recent call last):
		  File "C:\Users\pdumas\Documents\SAP\SAP GUI\numpy1.py", line 9167, in <module>
			train_dictionary0=zstandard.train_dictionary(16384,bytes(list(samples0)),k=20,d=6,f=20,split_point=.8,accel=8,dict_id=424242,steps=200,threads=-1,level=2,notifications=4)
		TypeError: train_dictionary() argument 2 must be list, not bytes


pd2023-04-06 starting here moving forward, all commentary will be in original source code (#...) and will merge with github for efficiency

pd2023-04-07 13:59:21 switch to pandas2.0.0

https://pandas.pydata.org/docs/user_guide/io.html?
	skiprows needs update from '''list-like or integer, default None''' to 'list-like or integer or callable, default None'



https://www.youtube.com/watch?v=iUhwCfz18os
	comment '''
At 7:40, why is """z.delta = x.delta + y.delta*i""" if, in the above function """f(z) = 2y + x*i""", the imaginary part (the part tied to the i) is """x""". Why is it not """z.delta = y.delta + x.delta*i""" instead?
	Please note that you still get to a similar answer either way (that the function is not holomorphic) but just want to make sure it's as accurate as possible! (Also, your videos are the bomb!)
	'''



OLD  DO NOTE USE
Not passing ordered=True will still if not  automatically infer categories from data and still arrange them in lexicographical order despite the ordered attribute resulting in False.'''

Not passing ordered=True will (if categories=<dataCategories> is not stated) still automatically infer categories from data and arrange them in lexicographical order.


https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html#working-with-categories
	need to update '''New categorical data are not automatically ordered. You must explicitly pass ordered=True to indicate an ordered Categorical.''' to '''New categorical data are not automatically ordered. You must explicitly pass ordered=True to indicate an ordered Categorical. Passing ordered=True even regardles of whether the data is lexicographically ordered in categories=<dataCategories> will set the ordered attribute to True, as this primarily serves to show that ordering is important (and does NOT have to do with lexicographical ordering).'''
		




















































































Examples (Code)
#pd2023-03-31 17:05:34 way to many different (e.g. string0.py, inspect0.py, sys0.py, numpy0.py, this file here) code examples + some need scrubbing to remove clientConfidentialInformation so only compile,send to email iff needed  (same thing on B_ computer)
import pandas,sys,numpy,os,inspect,pandas.tseries.holiday,pandas.io.formats.style,time,webbrowser,datetime,matplotlib#,dataclasses#,numba#,numpy,logging,os,inspect,sys,matplotlib,numba,timeit,time,random#,numba#matplotlib.pyplot,numpy.fft#,pandas#,pdb,matplotlib.pyplot,scipy.stats,scipy.special,time,random,multiprocessing,mmap,tempfile,os.path,io,numpy.distutils.system_info,datetime,inspect#,dask,dask.distributed,dask_kubernetes,numba,tensorflow
file0=r'C:\Users\pdumas\Documents\Code\pandas2output0.txt'
sys.stdout = open(file0,'w+',encoding='utf-8')

numpy.set_printoptions(edgeitems=100,linewidth=1000000)
# print('percentile')
# print(numpy.percentile(numpy.arange(20),10,method='hazen'))
# print(len(['linear','median_unbiased','normal_unbiased','hazen','weibull','interpolated_inverted_cdf','averaged_inverted_cdf','inverted_cdf','closest_observation','higher','midpoint','nearest','lower']))
# i=1
# # for method0 in ['linear','median_unbiased','normal_unbiased','hazen','weibull','interpolated_inverted_cdf','averaged_inverted_cdf','inverted_cdf','closest_observation','higher','midpoint','nearest','lower']:
    # # for overwrite_input0 in [False,True]:
        # # print(method0,overwrite_input0,numpy.percentile(numpy.arange(100),numpy.around(numpy.linspace(0,100,20),0).astype(int),method=method0,overwrite_input=overwrite_input0))
        # # matplotlib.pyplot.plot(numpy.around(numpy.linspace(0,100,20),0).astype(int),numpy.percentile(numpy.arange(100),numpy.around(numpy.linspace(0,100,20),0).astype(int),method=method0,overwrite_input=overwrite_input0))
        # # matplotlib.pyplot.subplot(2,7,i).plot(numpy.around(numpy.linspace(0,100,20),0).astype(int),numpy.percentile(numpy.arange(100),numpy.around(numpy.linspace(0,100,20),0).astype(int),method=method0,overwrite_input=overwrite_input0))
# # matplotlib.pyplot.show()
# for method0 in ['linear','median_unbiased','normal_unbiased','hazen','weibull','interpolated_inverted_cdf','averaged_inverted_cdf','inverted_cdf','closest_observation','higher','midpoint','nearest','lower']:
    # for overwrite_input0 in [False,True]:
        # for axis0 in [None,0,1,2]:
            # print(method0,overwrite_input0,axis0,numpy.percentile(numpy.arange(100).reshape(2,2,25),numpy.around(numpy.linspace(0,100,20),0).astype(int),method=method0,overwrite_input=overwrite_input0,keepdims=False))
# for method0 in ['linear','median_unbiased','normal_unbiased','hazen','weibull','interpolated_inverted_cdf','averaged_inverted_cdf','inverted_cdf','closest_observation','higher','midpoint','nearest','lower']:
    # for overwrite_input0 in [False,True]:
        # for axis0 in [None,0,1,2]:
            # print(method0,overwrite_input0,axis0,numpy.percentile(numpy.arange(100).reshape(2,2,25),numpy.around(numpy.linspace(0,100,20),0).astype(int),method=method0,overwrite_input=overwrite_input0,keepdims=True))
# out0 = numpy.empty((1,1,20))
# print(numpy.percentile(numpy.arange(100).reshape(2,2,25),numpy.around(numpy.linspace(0,100,20),0).astype(int),method='linear',overwrite_input=False,keepdims=True,out=out0))
# print(out0)
# a=numpy.arange(100,dtype=numpy.float64)
# a[40:45]=numpy.nan
# print(numpy.percentile(a,numpy.around(numpy.linspace(0,100,20),0).astype(int),method='linear',overwrite_input=False,keepdims=False))
# print('nanpercentile')
# print(numpy.nanpercentile(a,numpy.around(numpy.linspace(0,100,20),0).astype(int),method='linear',overwrite_input=False,keepdims=False))
# a=numpy.arange(100,dtype=numpy.float64)[::-1]
# print(a)
# a[40:45]=numpy.nan
# print(a)
# print('quantile')
# print(numpy.quantile(a,numpy.around(numpy.linspace(1,0,20),0).astype(int),method='linear',overwrite_input=False,keepdims=False))
# print('nanaquantile')
# print(numpy.nanquantile(a,numpy.around(numpy.linspace(1,0,20),0).astype(int),method='linear',overwrite_input=False,keepdims=False))
# print(numpy.nanquantile(a,numpy.linspace(1,0,20),method='linear',overwrite_input=False,keepdims=False))
# a=numpy.arange(100,dtype=numpy.float64)
# a[40:45]=numpy.nan
# print(numpy.nanquantile(a,numpy.linspace(0,1,20),method='linear',overwrite_input=False,keepdims=False))
# print('median')
# out0 = numpy.empty(())
# print(numpy.median(a.reshape(2,2,25),axis=None,out=out0,overwrite_input=True,keepdims=True))
# print(out0)
# print(numpy.median(a.reshape(2,2,25),axis=-1,overwrite_input=True,keepdims=True))
# print('nanmedian')
# out0 = numpy.empty(())
# print(numpy.nanmedian(a.reshape(2,2,25),axis=None,out=out0,overwrite_input=True,keepdims=True))
# print(out0)
# print(numpy.nanmedian(a.reshape(2,2,25),axis=-1,overwrite_input=True,keepdims=True))
# print('mean')
# a=numpy.arange(100,dtype=numpy.float64)
# a[40:45]=numpy.nan
# out0 = numpy.empty((1,1,1))
# print(numpy.mean(a.reshape(2,2,25),axis=None,out=out0,keepdims=True,where=numpy.repeat([True,True,True,True,False],5)))
# print(out0)
# print(numpy.mean(a.reshape(2,2,25),axis=-1,dtype=numpy.complex64,keepdims=True,where=numpy.repeat([True,True,True,True,False],5)))
# print('nanmean')
# out0 = numpy.empty((1,1,1))
# print(numpy.nanmean(a.reshape(2,2,25),axis=None,out=out0,keepdims=True,where=numpy.repeat([True,True,True,True,False],5)))
# print(out0)
# print(numpy.nanmean(a.reshape(2,2,25),axis=-1,dtype=numpy.complex64,keepdims=True,where=numpy.repeat([True,True,True,True,False],5)))
# print('std')
# a=numpy.arange(100,dtype=numpy.float64)
# a[40:45]=numpy.nan
# out0 = numpy.empty((1,1,1))
# print(numpy.std(a.reshape(2,2,25),axis=None,out=out0,keepdims=True,where=numpy.repeat([True,True,True,True,False],5)))
# print(out0)
# print(numpy.std(a.reshape(2,2,25),axis=-1,dtype=numpy.complex64,keepdims=True,where=numpy.repeat([True,True,True,True,False],5)))
# print('nanstd')
# out0 = numpy.empty((1,1,1))
# print(numpy.nanstd(a.reshape(2,2,25),axis=None,out=out0,keepdims=True,where=numpy.repeat([True,True,True,True,False],5)))
# print(out0)
# print(numpy.nanstd(a.reshape(2,2,25),axis=-1,dtype=numpy.complex64,keepdims=True,where=numpy.repeat([True,True,True,True,False],5)))
# print('ddof0')
# for ddof0 in list(range(102)):
    # try:
        # print(ddof0,numpy.nanstd(a.reshape(2,2,25),axis=None,dtype=numpy.float64,keepdims=True,where=numpy.repeat([True,True,True,True,False],5),ddof=ddof0))
    # except Exception as e:
        # print(e)
# for ddof0 in list(range(102)):
    # try:
        # print(ddof0,numpy.nanstd(a.reshape(2,2,25),axis=None,dtype=numpy.float64,keepdims=True,where=numpy.repeat([True,True,True,True,True],5),ddof=ddof0))
    # except Exception as e:
        # print(e)
# print(numpy.std(1j*numpy.linspace(-5,5,21)))
# print('var')
# a=numpy.arange(100,dtype=numpy.float64)
# a[40:45]=numpy.nan

# out0 = numpy.empty((1,1,1))
# print(numpy.var(a.reshape(2,2,25),axis=None,out=out0,keepdims=True,where=numpy.repeat([True,True,True,True,False],5)))
# print(out0)
# print(numpy.var(a.reshape(2,2,25),axis=-1,dtype=numpy.complex64,keepdims=True,where=numpy.repeat([True,True,True,True,False],5)))
# print('nanvar')
# out0 = numpy.empty((1,1,1))
# print(numpy.nanvar(a.reshape(2,2,25),axis=None,out=out0,keepdims=True,where=numpy.repeat([True,True,True,True,False],5)))
# print(out0)
# print(numpy.nanvar(a.reshape(2,2,25),axis=-1,dtype=numpy.complex64,keepdims=True,where=numpy.repeat([True,True,True,True,False],5)))
# print('ddof0')
# for ddof0 in list(range(102)):
    # try:
        # print(ddof0,numpy.nanvar(a.reshape(2,2,25),axis=None,dtype=numpy.float64,keepdims=True,where=numpy.repeat([True,True,True,True,False],5),ddof=ddof0))
    # except Exception as e:
        # print(e)
# for ddof0 in list(range(102)):
    # try:
        # print(ddof0,numpy.nanvar(a.reshape(2,2,25),axis=None,dtype=numpy.float64,keepdims=True,where=numpy.repeat([True,True,True,True,True],5),ddof=ddof0))
    # except Exception as e:
        # print(e)
# print(numpy.var(1j*numpy.linspace(-5,5,21)))
# print(numpy.nanmean(numpy.repeat(numpy.nan,5)))
# print(numpy.nanstd(numpy.repeat(numpy.nan,5)))
# print(numpy.nanvar(numpy.repeat(numpy.nan,5)))
# print('corrcoef')
# print(numpy.corrcoef(numpy.arange(20).reshape(5,4)))
# c=numpy.arange(20)
# c[10:20]=numpy.arange(10,0,-1)
# print(c.reshape(5,4))
# print(numpy.corrcoef(c.reshape(5,4)))
# print(numpy.corrcoef(c.reshape(5,4),rowvar=False))
# d=numpy.arange(20)
# print(numpy.corrcoef(c.reshape(5,4),d.reshape(5,4),rowvar=True,dtype=numpy.complex64))
# print(numpy.corrcoef(c.reshape(5,4),d.reshape(5,4),rowvar=True,dtype=numpy.float64))
# print('convolve')
# print(numpy.ones(20),numpy.arange(20),sep='\n')
# print(numpy.convolve(numpy.ones(20),numpy.arange(20)))
# for mode0 in ['full','same','valid']:
    # print(mode0,numpy.convolve(numpy.ones(20),numpy.arange(20),mode=mode0))
    # print(mode0,numpy.convolve(numpy.ones(20),numpy.arange(20),mode=mode0).size)
# for mode0 in ['full','same','valid']:
    # print(mode0,numpy.convolve(numpy.ones(20)*2,numpy.arange(20),mode=mode0))
# print(numpy.sum([numpy.ones(20),numpy.arange(20)]))
# print(numpy.sum([numpy.arange(20)]))
# print(numpy.sum(numpy.arange(20)[9:]))
# print(numpy.ones(5),numpy.arange(20),sep='\n')
# print(numpy.convolve(numpy.ones(5),numpy.arange(20)))
# for mode0 in ['full','same','valid']:
    # print(mode0,numpy.convolve(numpy.ones(5),numpy.arange(20),mode=mode0))
    # print(mode0,numpy.convolve(numpy.ones(5),numpy.arange(20),mode=mode0).size)
# for mode0 in ['full','same','valid']:
    # print(mode0,numpy.convolve(numpy.ones(5)*2,numpy.arange(20),mode=mode0))
# print(numpy.arange(4))
# print(numpy.arange(3,-1,-1))
# for mode0 in ['full','same','valid']:
    # print(mode0,numpy.convolve(numpy.arange(4),numpy.arange(4),mode=mode0))
# for mode0 in ['full','same','valid']:
    # print(mode0,numpy.convolve(numpy.arange(3,-1,-1),numpy.arange(4),mode=mode0))
# print('correlate')
# print(numpy.conj(1))
# print(numpy.ones(20),numpy.arange(20),sep='\n')
# print(numpy.correlate(numpy.ones(20),numpy.arange(20)))
# for mode0 in ['full','same','valid']:
    # print(mode0,numpy.correlate(numpy.ones(20),numpy.arange(20),mode=mode0))
    # print(mode0,numpy.correlate(numpy.ones(20),numpy.arange(20),mode=mode0).size)
# for mode0 in ['full','same','valid']:
    # print(mode0,numpy.correlate(numpy.ones(20)*2,numpy.arange(20),mode=mode0))
# print(numpy.sum([numpy.ones(20),numpy.arange(20)]))
# print(numpy.sum([numpy.arange(20)]))
# print(numpy.sum(numpy.arange(20)[9:]))
# print(numpy.ones(5),numpy.arange(20),sep='\n')
# print(numpy.correlate(numpy.ones(5),numpy.arange(20)))
# for mode0 in ['full','same','valid']:
    # print(mode0,numpy.correlate(numpy.ones(5),numpy.arange(20),mode=mode0))
    # print(mode0,numpy.correlate(numpy.ones(5),numpy.arange(20),mode=mode0).size)
# for mode0 in ['full','same','valid']:
    # print(mode0,numpy.correlate(numpy.ones(5)*2,numpy.arange(20),mode=mode0))
# print(numpy.arange(4))
# print(numpy.arange(3,-1,-1))
# for mode0 in ['full','same','valid']:
    # print(mode0,numpy.correlate(numpy.arange(4),numpy.arange(4),mode=mode0))
# for mode0 in ['full','same','valid']:
    # print(mode0,numpy.correlate(numpy.arange(3,-1,-1),numpy.arange(4),mode=mode0))
# print(numpy.correlate([1j,2j,3j,1,2,3],[.5,.5j],mode='full'))
# print(numpy.correlate([1j,2j,3j,1,2,3],[.5,1j],mode='full'))
# print('cov')
# print(numpy.cov([1,2,3],[4,5,6]))
# print(numpy.cov([1,2,3],[-4,-5,-6]))
# print(numpy.cov([1,2,3],[-4,-9,3]))
# print(numpy.cov([1,2,3],[-4,-9,3],dtype=numpy.complex64))
# print(numpy.cov([1,2,3],[-4,-9,3],dtype=numpy.float64,bias=False))
# print(numpy.cov([1,2,3],[-4,-9,3],dtype=numpy.float64,bias=True))
# print(numpy.cov([1,2,3],[-4,-9,3],dtype=numpy.float64,bias=True,ddof=1))
# print(numpy.cov([1,2,3],[-4,-9,3],dtype=numpy.float64,bias=True,ddof=0))
# for ddof0 in list(range(6)):
    # try:
        # print(numpy.cov([1,2,3],[-4,-9,3],dtype=numpy.float64,bias=True,ddof=ddof0))
    # except Exception as e:
        # print(e)
# print(numpy.cov([1,2,3],[-4,-9,3],dtype=numpy.float64,bias=False,fweights=[10,5,1]))
# print(numpy.cov([1,2,3],[-4,-9,3],dtype=numpy.float64,bias=False,aweights=[10,5,1]))
# print(numpy.cov([1,2,3],[-4,-9,3],dtype=numpy.float64,bias=False,fweights=[10,5,1],aweights=[10,5,1]))
# print(numpy.cov([1,2,3],[-4,-9,3],dtype=numpy.float64,bias=True,fweights=[10,5,1]))
# print(numpy.cov([1,2,3],[-4,-9,3],dtype=numpy.float64,bias=True,aweights=[10,5,1]))
# print(numpy.cov([1,2,3],[-4,-9,3],dtype=numpy.float64,bias=True,fweights=[10,5,1],aweights=[10,5,1]))
# print('promote_types')
# print(numpy.promote_types('i4','i8'))
# print(numpy.promote_types(numpy.promote_types('i4','i8'),'u1'))
# print(numpy.promote_types(numpy.promote_types('i4','u1'),'i8'))
# # types0=[numpy.bool_,numpy.byte,numpy.ubyte,numpy.short,numpy.ushort,numpy.intc,numpy.uintc,numpy.int_,numpy.uint,numpy.longlong,numpy.ulonglong,numpy.half,numpy.float16,numpy.single,numpy.double,numpy.longdouble,numpy.csingle,numpy.cdouble,numpy.clongdouble]
# # for type0 in types0:
    # # for type1 in types0:
        # # print(type0,type1,numpy.promote_types(type0,type1),sep='|')
# # print(numpy.dtype('u1'))
# types0=numpy.array([numpy.generic,numpy.number,numpy.integer,numpy.signedinteger,numpy.byte,numpy.short,numpy.intc,numpy.int_,numpy.longlong,numpy.unsignedinteger,numpy.ubyte,numpy.ushort,numpy.uintc,numpy.uint,numpy.ulonglong,numpy.inexact,numpy.floating,numpy.half,numpy.single,numpy.double,numpy.longdouble,numpy.complexfloating,numpy.csingle,numpy.cdouble,numpy.clongdouble,numpy.bool_,numpy.datetime64,numpy.timedelta64,numpy.object_,numpy.flexible,numpy.bytes_,numpy.str_,numpy.void],dtype=object)
# try:
    # for type0 in types0:
        # for type1 in types0:
            # print(type0,type1,numpy.promote_types(type0,type1),sep='|')
# except Exception as e:
    # print(e)
# types0=[numpy.number,numpy.integer,numpy.signedinteger,numpy.byte,numpy.short,numpy.intc,numpy.int_,numpy.longlong,numpy.unsignedinteger,numpy.ubyte,numpy.ushort,numpy.uintc,numpy.uint,numpy.ulonglong,numpy.inexact,numpy.floating,numpy.half,numpy.single,numpy.double,numpy.longdouble,numpy.complexfloating,numpy.csingle,numpy.cdouble,numpy.clongdouble,numpy.bool_,numpy.datetime64,numpy.timedelta64,numpy.object_,numpy.flexible,numpy.bytes_,numpy.str_]
# try:
    # for type0 in types0:
        # for type1 in types0:
            # print(type0,type1,numpy.promote_types(type0,type1),sep='|')
# except Exception as e:
    # print(e)
# types0=[numpy.number,numpy.integer,numpy.signedinteger,numpy.byte,numpy.short,numpy.intc,numpy.int_,numpy.longlong,numpy.unsignedinteger,numpy.ubyte,numpy.ushort,numpy.uintc,numpy.uint,numpy.ulonglong,numpy.inexact,numpy.floating,numpy.half,numpy.single,numpy.double,numpy.longdouble,numpy.complexfloating,numpy.csingle,numpy.cdouble,numpy.clongdouble,numpy.bool_,numpy.bytes_,numpy.str_]
# for type0 in types0:
    # for type1 in types0:
        # print(type0,type1,numpy.promote_types(type0,type1),sep='|')
# try:
    # print(numpy.promote_types(numpy.dtype(numpy.datetime64('M')),numpy.datetime64('Y')))
# except Exception as e:
    # print(e)
# print(numpy.promote_types('datetime64[M]','datetime64[Y]'))
# print(numpy.promote_types('datetime64[ms]','datetime64[s]'))
# print('min_scalar_type')
# min_scalar_typeVectorized0 = numpy.vectorize(numpy.min_scalar_type)
# print(numpy.geomspace(1,9e18,5))
# print(min_scalar_typeVectorized0(numpy.around(numpy.geomspace(1,9e18,5),0).astype(int)))
# print(numpy.geomspace(1,9e307,10))
# print(min_scalar_typeVectorized0(numpy.geomspace(1,9e307,10)))
# class dummyClass0:
    # def __init__(self):
        # return None
# print(numpy.array([6,6j,2e307j,'abc',b'abc',int,dummyClass0()]))
# print(min_scalar_typeVectorized0([6,6j,2e307j,'abc',b'abc',int,dummyClass0()]))
# print('result_type')
# print(numpy.geomspace(1,9e18,5))
# print(numpy.result_type(numpy.around(numpy.geomspace(1,9e18,5),0).astype(int)))
# print(numpy.geomspace(1,9e307,10))
# print(numpy.result_type(numpy.geomspace(1,9e307,10)))
# print(numpy.array([6,6j,2e307j,'abc',b'abc',int,dummyClass0()]))
# try:
    # print(numpy.result_type(([6,6j,2e307j,'abc',b'abc',int,dummyClass0()])))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.result_type(([6])))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.result_type((['abc',b'abc',int,dummyClass0()])))  #min_scalar_type succeeds but then promote_types fails since not of same DType..
# except Exception as e:
    # print(e)
# print('common_type')
# try:
    # print(numpy.common_type(numpy.int8))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.common_type([2,3]))
# except Exception as e:
    # print(e)
# print(numpy.common_type(numpy.array([2,3])))
# print(numpy.common_type(numpy.array([2,3,5.6])))
# print(numpy.common_type(numpy.array([5.6])))
# print(numpy.common_type(numpy.array([2,3,5.6,3e307])))
# print(numpy.common_type(numpy.array([5.6,2j])))
# print(numpy.common_type(numpy.array([2,3,5.6,2j])))
# print(numpy.common_type(numpy.array([2,3,5.6,2j,3e307j])))
# try:
    # print(numpy.common_type(numpy.array(['a'*2])))
# except Exception as e:
    # print(e)
# print(numpy.common_type(numpy.array([numpy.timedelta64(5,'M')])))
# print(numpy.common_type(numpy.array([numpy.timedelta64(5,'M'),numpy.timedelta64(7,'M')])))
# try:
    # print(numpy.common_type(numpy.array([numpy.timedelta64(5,'M'),numpy.timedelta64(7,'D')])))
# except Exception as e:
    # print(e)
# print('obj2sctype')
# for rep0 in [2,2e307,5.0,5.0e307,5j,5e307j,'string0',b'bytes0',True,tuple,list,dict,set,int,float]:
    # print(rep0,numpy.obj2sctype(rep0))
    # print(rep0,numpy.obj2sctype(rep0,default='cannotFindScalarType'))
    # try:
        # print(numpy.array(rep0),numpy.obj2sctype(numpy.array(rep0)))
    # except Exception as e:
        # print(e)
# print('format_parser')
# print(numpy.dtype('b1'))
# print(numpy.format_parser(['U5','S3','i4','f8','b1'],['nameUnicode','nameBytes','nameInteger','nameFloat','nameBoolean'],['TitleUnicode','TitleBytes','TitleInteger','TitleFloat','TitleBoolean'],aligned=True,byteorder='l'))
# print(numpy.format_parser(['U5','S3','i4','f8','b1'],['nameUnicode','nameBytes','nameInteger','nameFloat','nameBoolean'],['TitleUnicode','TitleBytes','TitleInteger','TitleFloat','TitleBoolean'],aligned=True,byteorder='l').dtype)
# print(numpy.format_parser(['U5','S3','i4','f8','b1'],['nameUnicode','nameBytes','nameInteger','nameFloat','nameBoolean'],['TitleUnicode','TitleBytes','TitleInteger','TitleFloat','TitleBoolean'],aligned=False,byteorder='l'))
# print(numpy.format_parser(['U5','S3','i4','f8','b1'],['nameUnicode','nameBytes','nameInteger','nameFloat','nameBoolean'],['TitleUnicode','TitleBytes','TitleInteger','TitleFloat','TitleBoolean'],aligned=False,byteorder='l').dtype)
# print(numpy.format_parser(['U5','S3','i4','f8','b1'],['nameUnicode','nameBytes','nameInteger','nameFloat','nameBoolean'],['TitleUnicode','TitleBytes','TitleInteger','TitleFloat','TitleBoolean'],aligned=False,byteorder='b'))
# print(numpy.format_parser(['U5','S3','i4','f8','b1'],['nameUnicode','nameBytes','nameInteger','nameFloat','nameBoolean'],['TitleUnicode','TitleBytes','TitleInteger','TitleFloat','TitleBoolean'],aligned=False,byteorder='b').dtype)
# print('issctype')
# for rep0 in [2,2e307,5.0,5.0e307,5j,5e307j,'string0',b'bytes0',True,tuple,list,dict,set,int,float]:
    # print(rep0,numpy.issctype(rep0))
    # try:
        # print(numpy.array(rep0),numpy.issctype(numpy.array(rep0)))
    # except Exception as e:
        # print(e)
    # print(type(rep0),numpy.issctype(type(rep0)))
# print('issubdtype')
# types0=[numpy.generic,numpy.number,numpy.integer,numpy.signedinteger,numpy.byte,numpy.short,numpy.intc,numpy.int_,numpy.longlong,numpy.unsignedinteger,numpy.ubyte,numpy.ushort,numpy.uintc,numpy.uint,numpy.ulonglong,numpy.inexact,numpy.floating,numpy.half,numpy.single,numpy.double,numpy.longdouble,numpy.complexfloating,numpy.csingle,numpy.cdouble,numpy.clongdouble,numpy.bool_,numpy.datetime64,numpy.timedelta64,numpy.object_,numpy.flexible,numpy.bytes_,numpy.str_,numpy.void]
# for type0 in types0:
    # for type1 in types0:
        # print(type0,type1,numpy.issubdtype(type0,type1),sep='|')
# print(numpy.issubdtype('S1',numpy.bytes_),sep='|')
# print(numpy.issubdtype('S1',numpy.unicode),sep='|')
# try:
    # print(numpy.issubdtype(b'abc',numpy.bytes_),sep='|')
# except Exception as e:
    # print(e)
# try:
    # print(numpy.issubdtype('abc',numpy.unicode),sep='|')
# except Exception as e:
    # print(e)
# print('issubsctype')#needs ndarray if nesting actual value (as opposed to type) (similar to common_type and obj2sctype)
# for type0 in types0:
    # for type1 in types0:
        # try:
            # print(type0,type1,numpy.issubsctype(type0,type1),sep='|')
        # except Exception as e:
            # print(e)
# print(numpy.issubdtype('S1',numpy.bytes_),sep='|')
# print(numpy.issubdtype('S1',numpy.unicode),sep='|')
# try:
    # print(numpy.issubsctype(b'abc',numpy.bytes_),sep='|')
# except Exception as e:
    # print(e)
# try:
    # print(numpy.issubsctype('abc',numpy.unicode),sep='|')
# except Exception as e:
    # print(e)
# print(numpy.issubsctype(numpy.array([b'abc']),numpy.bytes_),sep='|')
# print(numpy.issubsctype(numpy.array(['abc']),numpy.bytes_),sep='|')
# print(numpy.issubdtype('S1','S1'),sep='|')
# print(numpy.issubdtype('S1','S2'),sep='|')
# print(numpy.issubdtype('S1','U1'),sep='|')
# try:
    # print(numpy.issubsctype(b'abc',numpy.bytes_),sep='|')
# except Exception as e:
    # print(e)
# try:
    # print(numpy.issubsctype('abc',numpy.unicode),sep='|')
# except Exception as e:
    # print(e)
# try:
    # print(numpy.issubsctype(numpy.bytes_,b'abc'),sep='|')
# except Exception as e:
    # print(e)
# try:
    # print(numpy.issubsctype(numpy.unicode,'abc'),sep='|')
# except Exception as e:
    # print(e)
# print('issubclass_')#doesn't recognize ndarray subdtype as type (will just return False)
# for type0 in types0:
    # for type1 in types0:
        # try:
            # print(type0,type1,numpy.issubclass_(type0,type1),sep='|')
        # except Exception as e:
            # print(e)
# print(numpy.issubclass_('S1',numpy.bytes_),sep='|')
# print(numpy.issubclass_('S1',numpy.unicode),sep='|')
# try:
    # print(numpy.issubclass_(b'abc',numpy.bytes_),sep='|')
# except Exception as e:
    # print(e)
# try:
    # print(numpy.issubclass_('abc',numpy.unicode),sep='|')
# except Exception as e:
    # print(e)
# print(numpy.issubclass_(numpy.array([b'abc']),numpy.bytes_),sep='|')
# print(numpy.issubclass_(numpy.array(['abc']),numpy.bytes_),sep='|')
# print(numpy.issubclass_('S1','S1'),sep='|')
# print(numpy.issubclass_('S1','S2'),sep='|')
# print(numpy.issubclass_('S1','U1'),sep='|')
# try:
    # print(numpy.issubclass_(b'abc',numpy.bytes_),sep='|')
# except Exception as e:
    # print(e)
# try:
    # print(numpy.issubclass_('abc',numpy.unicode),sep='|')
# except Exception as e:
    # print(e)
# try:
    # print(numpy.issubclass_(numpy.bytes_,b'abc'),sep='|')
# except Exception as e:
    # print(e)
# try:
    # print(numpy.issubclass_(numpy.unicode,'abc'),sep='|')
# except Exception as e:
    # print(e)
# print('find_common_type')
# print(numpy.find_common_type(numpy.array([numpy.int32,numpy.float32]),numpy.array([numpy.int32,numpy.float32])))
# print(numpy.find_common_type(numpy.array([numpy.int32,numpy.float32]),numpy.array([numpy.int64,numpy.float64])))
# print(numpy.find_common_type(numpy.array([numpy.int64,numpy.float64]),numpy.array([numpy.int32,numpy.float32])))
# print(numpy.find_common_type(numpy.array(['i4','f4']),numpy.array(['i4','f4'])))
# print(numpy.find_common_type(numpy.array(['i4','f4']),numpy.array(['i8','f8'])))
# print(numpy.find_common_type(numpy.array(['i8','f8']),numpy.array(['i4','f4'])))
# print(numpy.find_common_type(numpy.array([numpy.int32,numpy.float32]),numpy.array([numpy.int32,numpy.float32,numpy.bool_])))
# print(numpy.find_common_type(numpy.array([numpy.int32,numpy.float32]),numpy.array([numpy.int64,numpy.float64,numpy.bool_])))
# print(numpy.find_common_type(numpy.array([numpy.int64,numpy.float64]),numpy.array([numpy.int32,numpy.float32,numpy.bool_])))
# print(numpy.find_common_type(numpy.array([numpy.int32,numpy.float32]),numpy.array([numpy.int32,numpy.float32,numpy.complex_])))
# print(numpy.find_common_type(numpy.array([numpy.int32,numpy.float32]),numpy.array([numpy.int64,numpy.float64,numpy.complex_])))
# print(numpy.find_common_type(numpy.array([numpy.int64,numpy.float64]),numpy.array([numpy.int32,numpy.float32,numpy.complex_])))
# print(numpy.find_common_type(numpy.array([numpy.int32,numpy.float32]),numpy.array([numpy.int32,numpy.float32,numpy.string_])))
# print(numpy.find_common_type(numpy.array([numpy.int32,numpy.float32]),numpy.array([numpy.int64,numpy.float64,numpy.string_])))
# print(numpy.find_common_type(numpy.array([numpy.int64,numpy.float64]),numpy.array([numpy.int32,numpy.float32,numpy.string_])))
# print(numpy.find_common_type(numpy.array([numpy.int32,numpy.float32,numpy.complex_]),numpy.array([numpy.int32,numpy.float32])))
# print(numpy.find_common_type(numpy.array([numpy.int32,numpy.float32,numpy.complex_]),numpy.array([numpy.int64,numpy.float64])))
# print(numpy.find_common_type(numpy.array([numpy.int64,numpy.float64,numpy.complex_]),numpy.array([numpy.int32,numpy.float32])))
# print(numpy.find_common_type(numpy.array([numpy.float64]),numpy.array([numpy.longfloat])))
# print(numpy.find_common_type(numpy.array([numpy.longfloat]),numpy.array([numpy.float64])))
# print(numpy.find_common_type(numpy.array([numpy.complex64]),numpy.array([numpy.complex128])))
# print(numpy.find_common_type(numpy.array([numpy.complex128]),numpy.array([numpy.complex64])))
# print('typename')
# types0=[numpy.generic,numpy.number,numpy.integer,numpy.signedinteger,numpy.byte,numpy.short,numpy.intc,numpy.int_,numpy.longlong,numpy.unsignedinteger,numpy.ubyte,numpy.ushort,numpy.uintc,numpy.uint,numpy.ulonglong,numpy.inexact,numpy.floating,numpy.half,numpy.single,numpy.double,numpy.longdouble,numpy.complexfloating,numpy.csingle,numpy.cdouble,numpy.clongdouble,numpy.bool_,numpy.datetime64,numpy.timedelta64,numpy.object_,numpy.flexible,numpy.bytes_,numpy.str_,numpy.void]
# for type0 in types0:
    # print(type0,numpy.dtype(type0).char,sep='|')
# try:
    # for type0 in types0:
        # print(type0,numpy.typename(numpy.dtype(type0).char),sep='|')
# except Exception as e:
    # print(e)
# types0=[numpy.generic,numpy.number,numpy.integer,numpy.signedinteger,numpy.byte,numpy.short,numpy.intc,numpy.int_,numpy.longlong,numpy.unsignedinteger,numpy.ubyte,numpy.ushort,numpy.uintc,numpy.uint,numpy.ulonglong,numpy.inexact,numpy.floating,numpy.single,numpy.double,numpy.longdouble,numpy.complexfloating,numpy.csingle,numpy.cdouble,numpy.clongdouble,numpy.bool_,numpy.object_,numpy.flexible,numpy.bytes_,numpy.str_,numpy.void]
# for type0 in types0:
    # print(type0,numpy.typename(numpy.dtype(type0).char),sep='|')#numpy.half,numpy.datetime64,numpy.timedelta64 are not in this function's mapping..
# print(type0,numpy.typename('f'),sep='|')
# print('sctype2char')
# types0=[numpy.generic,numpy.number,numpy.integer,numpy.signedinteger,numpy.byte,numpy.short,numpy.intc,numpy.int_,numpy.longlong,numpy.unsignedinteger,numpy.ubyte,numpy.ushort,numpy.uintc,numpy.uint,numpy.ulonglong,numpy.inexact,numpy.floating,numpy.half,numpy.single,numpy.double,numpy.longdouble,numpy.complexfloating,numpy.csingle,numpy.cdouble,numpy.clongdouble,numpy.bool_,numpy.datetime64,numpy.timedelta64,numpy.object_,numpy.flexible,numpy.bytes_,numpy.str_,numpy.void]
# for type0 in types0:
    # try:
        # print(type0,numpy.sctype2char(type0),sep='|')
    # except Exception as e:
        # print(e)
# try:
    # print(numpy.sctype2char(2))
# except Exception as e:
    # print(e)
# print(numpy.sctype2char(numpy.array([2])))
# print(numpy.sctype2char(numpy.array([2,3j])))
# print(numpy.sctype2char(set))
# print('mintypecode')
# try:
    # print(numpy.mintypecode(2))
# except Exception as e:
    # print(e)
# print(numpy.mintypecode(numpy.array([2])))
# print(numpy.mintypecode(numpy.array([2,3j])))
# print(numpy.mintypecode(numpy.array([2,3j]),typeset='gdf',default='abc'))
# try:
    # print(numpy.mintypecode(set))
# except Exception as e:
    # print(e)
# print(numpy.mintypecode([set,list,tuple]))
# print('maximum_sctype')
# types0=[numpy.generic,numpy.number,numpy.integer,numpy.signedinteger,numpy.byte,numpy.short,numpy.intc,numpy.int_,numpy.longlong,numpy.unsignedinteger,numpy.ubyte,numpy.ushort,numpy.uintc,numpy.uint,numpy.ulonglong,numpy.inexact,numpy.floating,numpy.half,numpy.single,numpy.double,numpy.longdouble,numpy.complexfloating,numpy.csingle,numpy.cdouble,numpy.clongdouble,numpy.bool_,numpy.datetime64,numpy.timedelta64,numpy.object_,numpy.flexible,numpy.bytes_,numpy.str_,numpy.void]
# for type0 in types0:
    # try:
        # print(type0,numpy.maximum_sctype(type0),sep='|')
    # except Exception as e:
        # print(e)
# print(numpy.maximum_sctype(numpy.array([2])))
# print('unwrap')
# period0=numpy.arange(8)
# for period1 in period0:
    # print(numpy.unwrap(numpy.linspace(0,14,9),discont=None,axis=-1,period=period0))
# period0=numpy.arange(8)[::2]
# for period1 in period0:
    # print(numpy.unwrap(numpy.linspace(0,14,5),discont=None,axis=-1,period=period0))
# print('.')
# print(numpy.unwrap([2,5,8],discont=3,period=4))
# print(numpy.unwrap([2,5,8],discont=2,period=4))
# print(numpy.unwrap([2,5,8],discont=1,period=4))
# print(numpy.unwrap([2,5,8],discont=5,period=5))
# print(numpy.unwrap([2,5,8],discont=4,period=5))
# print(numpy.unwrap([2,5,8],discont=3,period=5))
# print(numpy.unwrap([2,5,8],discont=2,period=5))
# print(numpy.unwrap([2,5,8],discont=1,period=5))
# print(numpy.unwrap([2,5,8,9,10,13],discont=4,period=5))
# print(numpy.unwrap([2,5,8,9,10,13],discont=3,period=5))
# print(numpy.unwrap([2,5,8,9,10,13],discont=2,period=5))
# print(numpy.unwrap([2,5,8,9,10,13],discont=1,period=5))
# print(numpy.unwrap(numpy.broadcast_to([2,5,8],(3,3)),discont=3,period=5))
# print(numpy.unwrap(numpy.broadcast_to([2,5,8],(3,3)),discont=3,axis=0,period=5))
# print('prod')
# print(numpy.prod(numpy.repeat(53687910.,4)))
# print(numpy.mod(numpy.prod(numpy.repeat(53687910.,4)),53687910))
# print(numpy.prod(numpy.repeat(53687910,4).astype(int)))
# for axis0 in [None,0,1,2]:
    # for where0 in [[True,True,True],[False,True,True]]:
        # for initial0 in [1,10]:
            # for dtype0 in [None,numpy.complex64]:
                # for keepdims0 in [False,True]:
                    # print('axis0={}'.format(axis0),'where0={}'.format(where0),'initial0={}'.format(initial0),'dtype0={}'.format(dtype0),'keepdims0={}'.format(keepdims0),'\n',numpy.prod(numpy.arange(27).reshape(3,3,3),axis=axis0,dtype=dtype0,keepdims=keepdims0,where=where0,initial=initial0))
# out0 = numpy.empty(())
# print(numpy.prod(numpy.arange(27).reshape(3,3,3)+1,out=out0))
# print(out0)
# print(numpy.prod([]))
# a=numpy.arange(27,dtype=numpy.float64).reshape(3,3,3)
# a[(0,0,0)]=numpy.nan
# print('a=')
# print(a)
# a=numpy.arange(27,dtype=numpy.float64).reshape(3,3,3)
# a[0]=numpy.nan
# print('a=')
# print(a)
# print('prod2')
# for axis0 in [None,0,1,2]:
    # for where0 in [[True,True,True],[False,True,True]]:
        # for initial0 in [1,10]:
            # for dtype0 in [None,numpy.complex64]:
                # for keepdims0 in [False,True]:
                    # print('axis0={}'.format(axis0),'where0={}'.format(where0),'initial0={}'.format(initial0),'dtype0={}'.format(dtype0),'keepdims0={}'.format(keepdims0),'\n',numpy.prod(a,axis=axis0,dtype=dtype0,keepdims=keepdims0,where=where0,initial=initial0))
# print('nanprod')
# for axis0 in [None,0,1,2]:
    # for where0 in [[True,True,True],[False,True,True]]:
        # for initial0 in [1,10]:
            # for dtype0 in [None,numpy.complex64]:
                # for keepdims0 in [False,True]:
                    # print('axis0={}'.format(axis0),'where0={}'.format(where0),'initial0={}'.format(initial0),'dtype0={}'.format(dtype0),'keepdims0={}'.format(keepdims0),'\n',numpy.nanprod(a,axis=axis0,dtype=dtype0,keepdims=keepdims0,where=where0,initial=initial0))
# print(numpy.nanprod(numpy.repeat(numpy.nan,2)))
# print('sum')
# for axis0 in [None,0,1,2]:
    # for where0 in [[True,True,True],[False,True,True]]:
        # for initial0 in [1,10]:
            # for dtype0 in [None,numpy.complex64]:
                # for keepdims0 in [False,True]:
                    # print('axis0={}'.format(axis0),'where0={}'.format(where0),'initial0={}'.format(initial0),'dtype0={}'.format(dtype0),'keepdims0={}'.format(keepdims0),'\n',numpy.sum(a,axis=axis0,dtype=dtype0,keepdims=keepdims0,where=where0,initial=initial0))
# print('nansum')
# for axis0 in [None,0,1,2]:
    # for where0 in [[True,True,True],[False,True,True]]:
        # for initial0 in [1,10]:
            # for dtype0 in [None,numpy.complex64]:
                # for keepdims0 in [False,True]:
                    # print('axis0={}'.format(axis0),'where0={}'.format(where0),'initial0={}'.format(initial0),'dtype0={}'.format(dtype0),'keepdims0={}'.format(keepdims0),'\n',numpy.nansum(a,axis=axis0,dtype=dtype0,keepdims=keepdims0,where=where0,initial=initial0))
# print(numpy.nansum([]))
# print(numpy.nansum(numpy.repeat(numpy.nan,2)))
# print(numpy.nansum([numpy.nan,numpy.nan]))
# print(numpy.nansum(numpy.array([numpy.nan,numpy.nan])))
# print('mintypecode,sctype2char,maximum_sctype')
# print(numpy.mintypecode(numpy.array([0,1j,2.]),typeset='dfgDFGMm',default=list))
# print(numpy.issctype(numpy.array(numpy.complex128)))
# print(numpy.issctype(numpy.complex128))
# try:
    # print(numpy.issctype(numpy.array([0,1j,2.])))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.sctype2char(numpy.array([0,1j,2.])))
# except Exception as e:
    # print(e)
# print(numpy.sctype2char(numpy.array([2.])))
# print(numpy.maximum_sctype(numpy.array([0,1j,2.])))
# print('cumprod')
# for axis0 in [None,0,1,2]:
    # for dtype0 in [None,numpy.complex64]:
        # print('axis0={}'.format(axis0),'dtype0={}'.format(dtype0),'\n',numpy.cumprod(a,axis=axis0,dtype=dtype0))
# print('nancumprod')
# for axis0 in [None,0,1,2]:
    # for dtype0 in [None,numpy.complex64]:
        # print('axis0={}'.format(axis0),'dtype0={}'.format(dtype0),'\n',numpy.nancumprod(a,axis=axis0,dtype=dtype0))
# print(numpy.nancumprod(numpy.repeat(numpy.nan,2)))
# print('cumsum')
# for axis0 in [None,0,1,2]:
    # for dtype0 in [None,numpy.complex64]:
        # print('axis0={}'.format(axis0),'dtype0={}'.format(dtype0),'\n',numpy.cumsum(a,axis=axis0,dtype=dtype0))
# print(a)
# print('nancumsum')
# for axis0 in [None,0,1,2]:
    # for dtype0 in [None,numpy.complex64]:
        # print('axis0={}'.format(axis0),'dtype0={}'.format(dtype0),'\n',numpy.nancumsum(a,axis=axis0,dtype=dtype0))
# print(numpy.nancumsum(numpy.repeat(numpy.nan,2)))
# print('diff')
# a=numpy.around(numpy.linspace(1,100,27),0).astype(int).reshape(3,3,3)
# print(a.shape)
# print(a)
# for axis0 in [None,0,1,2]:
    # for n0 in [0,1,2,3]:
        # for prepend0 in [None,1000,[2000,20000],[3000,30000,300000]]:
            # for append0 in [None,1000,[2000,20000],[3000,30000,300000]]:
                # print('axis={}'.format(axis0),'n={}'.format(n0),'prepend={}'.format(prepend0),'append={}'.format(append0))
                # try:
                    # print(numpy.diff(a,axis=axis0,n=n0,prepend=prepend0,append=append0))
                # except Exception as e:
                    # print(e)
# a=numpy.around(numpy.linspace(1,100,6),0).astype(int).reshape(2,3)
# print(a.shape)
# print(a)
# print(numpy.diff(a))
# for prepend0 in [[1000],[2000,20000],[3000,30000,300000],[[3000,30000,300000],[3000,30000,300000]],[[1,1,1],[1,1,1]],[[2,2,2],[2,2,2]],[[2],[2]]]:
    # print(prepend0)
    # try:
        # print(numpy.diff(a,prepend=prepend0))
    # except Exception as e:
        # print(e)
# for append0 in [[1000],[2000,20000],[3000,30000,300000],[[3000,30000,300000],[3000,30000,300000]],[[1,1,1],[1,1,1]],[[2,2,2],[2,2,2]],[[2],[2]]]:
    # print(append0)
    # try:
        # print(numpy.diff(a,append=append0))
    # except Exception as e:
        # print(e)
# print(numpy.diff(numpy.array([1,0],dtype=numpy.uint16)))
# print(numpy.diff(numpy.array([1,0],dtype=numpy.int16)))
# try:
    # print(numpy.linspace('2022-01-01','2022-12-31',num=18,dtype=numpy.datetime64))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.linspace('2022-01-01','2022-12-31',num=18,dtype='datetime64[D]'))
# except Exception as e:
    # print(e)
# import pandas
# print(pandas.date_range(start='2022-01-01',end='2022-12-31',periods=18))
# dates0 = pandas.date_range(start='2022-01-01',end='2022-12-31',periods=18)
# print(dates0.values)
# print(numpy.array(dates0.values,dtype='datetime64[D]'))
# dates0Days = numpy.array(dates0.values,dtype='datetime64[D]')
# print(numpy.diff(dates0Days))
# print('ediff1d')
# print(numpy.ediff1d(numpy.array([1,0],dtype=numpy.uint16)))
# print(numpy.ediff1d(numpy.array([1,0],dtype=numpy.int16)))
# print(numpy.ediff1d(numpy.array([1,0],dtype=numpy.int16),to_end=20))
# print(numpy.ediff1d(numpy.array([1,0],dtype=numpy.int16),to_end=[20,200,2000]))
# print(numpy.ediff1d(numpy.array([1,0],dtype=numpy.int16),to_begin=20))
# print(numpy.ediff1d(numpy.array([1,0],dtype=numpy.int16),to_begin=[20,200,2000]))
# print(numpy.ediff1d(numpy.array([1,0],dtype=numpy.int16),to_end=20,to_begin=20))
# print(numpy.ediff1d(numpy.array([1,0],dtype=numpy.int16),to_end=[20,200,2000],to_begin=[20,200,2000]))
# print(numpy.ediff1d(numpy.array([1,0],dtype=numpy.int16),to_end=[[20,20],[20,20]],to_begin=[20,200,2000]))
# print('cumsum2')
# import math
# s=[7e-35,8e-35]*100000
# print(math.fsum(s))
# print(numpy.cumsum(s)[-1])
# print('gradient')
# for step0 in numpy.arange(-3,4,1):
    # if step0 < 0:
        # print(numpy.gradient(numpy.arange(20,0,step0)))
    # elif (step0 == 0):
        # try:
            # print(numpy.gradient(0))
        # except Exception as e:
            # print(e)
    # else:
        # print(numpy.gradient(numpy.arange(0,20,step0)))
# try:
    # print(numpy.gradient(numpy.geomspace(1,100000,num=1)))
# except Exception as e:
    # print(e)
# for edge_order0 in [1,2]:
    # for n0 in numpy.arange(9,1,-1):
        # try:
            # print('num={}'.format(n0),'edge_order={}'.format(edge_order0),numpy.geomspace(1,100000,num=n0).size,numpy.gradient(numpy.geomspace(1,100000,num=n0),edge_order=edge_order0).size,numpy.gradient(numpy.geomspace(1,100000,num=n0),edge_order=edge_order0))
        # except Exception as e:
            # print(e)
# for n0 in numpy.arange(9,1,-1):
    # try:
        # print('num={}'.format(n0),numpy.geomspace(1,100000,num=n0).size,numpy.gradient(numpy.geomspace(1,100000,num=n0)).size,numpy.gradient(numpy.geomspace(1,100000,num=n0)))
    # except Exception as e:
        # print(e)
# print(numpy.gradient(numpy.geomspace(1,100000,9).reshape(3,3),axis=0))
# print(numpy.gradient(numpy.geomspace(1,100000,9).reshape(3,3),axis=1))
# for spacing0 in [0,1,1e3,1e5,numpy.arange(1,10,1),numpy.arange(1,10,2),[1,2,8,8.1,250,250.001,260,270,280]]:
    # try:
        # print('varargs={}'.format(spacing0),numpy.gradient(numpy.geomspace(1,100000,9),spacing0))
    # except Exception as e:
        # print(e)
# a=numpy.geomspace(1,100000,9).reshape(3,3)
# print(a.shape,a.ndim,a)
# try:
    # print('varargs=[1,2,8,8.1],[250,250.001,260]',numpy.gradient(a,[1,2,8,8.1],[250,250.001,260]))
# except Exception as e:
    # print(e)
# try:
    # print('varargs=[[1,2,8,8.1],[1,2,8,8.1],[250,250.001,260]]',numpy.gradient(a,[[1,2,8,8.1],[1,2,8,8.1],[250,250.001,260]]))
# except Exception as e:
    # print(e)
# try:
    # print('varargs=[[1,2,8,8.1],[1,2,8,8.1],[250,250.001,260]]',numpy.gradient(a,numpy.array([[1,2,8,8.1],[1,2,8,8.1],[250,250.001,260]])))
# except Exception as e:
    # print(e)
# print('varargs=10000,.00001',numpy.gradient(a,10000,.00001))
# varargScalar0=10000
# varargArray0=[1,10000,10000.01]
# print('varargs=varargScalar0,varargArray0',numpy.gradient(a,varargScalar0,varargArray0))
# print('varargs=varargArray0,varargScalar0',numpy.gradient(a,varargArray0,varargScalar0))
# print('varargs=varargArray0,varargArray0',numpy.gradient(a,varargArray0,varargArray0))
# print('numpy.cross')
# end0=27
# end1=132
# print(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3))
# print(numpy.around(numpy.linspace(1,end1,end0),0).astype(int).reshape(3,3,3))
# print(numpy.cross(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3),numpy.around(numpy.linspace(1,end1,end0),0).astype(int).reshape(3,3,3)))
# axisa0=0
# print(numpy.cross(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3),numpy.around(numpy.linspace(1,end1,end0),0).astype(int).reshape(3,3,3),axisa=axisa0))
# axisb0=0
# print(numpy.cross(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3),numpy.around(numpy.linspace(1,end1,end0),0).astype(int).reshape(3,3,3),axisb=axisb0))
# print(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3)[0,0,0])
# print(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3)[:,0,0])
# print(numpy.cross(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3)[:,0,0],numpy.around(numpy.linspace(1,end1,end0),0).astype(int).reshape(3,3,3)[0,0,:]))
# axisc0=0
# print(numpy.cross(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3),numpy.around(numpy.linspace(1,end1,end0),0).astype(int).reshape(3,3,3),axisa=axisa0,axisc=axisc0))
# print(numpy.cross(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3),numpy.around(numpy.linspace(1,end1,end0),0).astype(int).reshape(3,3,3),axisa=axisa0,axisb=axisb0,axisc=axisc0))
# axis0=0
# print(numpy.cross(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3),numpy.around(numpy.linspace(1,end1,end0),0).astype(int).reshape(3,3,3),axis=axis0))
# for a0 in [[1],[1,2],[1,2,0],[1,2,3],[1,2,3,4]]:
    # for b0 in [[4],[4,3],[4,3,0],[4,3,2],[27,9,3],[4,3,2,1]]:
        # print(a0,b0,sep='\n')
        # try:
            # print(numpy.cross(a0,b0),end='\n\n')
        # except Exception as e:
            # print(e)
# print('numpy.trapz')
# print(numpy.trapz([1,2,3,4,5],x=[8,6,4,2,0]))
# print(numpy.trapz([1,2,3,4,5],x=[8,6,4,6,8]))
# circle0=numpy.linspace(0,numpy.pi*2,10000,endpoint=True)
# print(numpy.trapz(numpy.cos(circle0),x=circle0))
# print(numpy.trapz(numpy.sin(circle0),x=circle0))
# print(numpy.trapz(numpy.tan(circle0),x=circle0))
# circle0=numpy.linspace(0,numpy.pi,10000,endpoint=True)
# print(numpy.trapz(numpy.cos(circle0),x=circle0))
# print(numpy.trapz(numpy.sin(circle0),x=circle0))
# print(numpy.trapz(numpy.tan(circle0),x=circle0))
# end0=27
# end1=132
# print(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3))
# print(numpy.trapz(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3),dx=1,axis=0))
# print(numpy.trapz(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3),dx=1,axis=1))
# print(numpy.trapz(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3),dx=1,axis=2))
# print(numpy.trapz(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3)))
# print(numpy.trapz(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3),dx=2,axis=0))
# print(numpy.trapz(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3),dx=2,axis=1))
# print(numpy.trapz(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3),dx=2,axis=2))
# print(numpy.trapz(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3),x=numpy.around(numpy.linspace(1,end1,end0),0).astype(int).reshape(3,3,3),dx=1,axis=2))
# print(numpy.trapz(numpy.around(numpy.linspace(1,end0,end0),0).astype(int).reshape(3,3,3),x=numpy.around(numpy.linspace(1,end1,end0),0).astype(int).reshape(3,3,3),dx=2,axis=2))
# # print('p-series')
# # import matplotlib.pyplot
# # for exp0 in numpy.linspace(.0001,2,6):
    # # matplotlib.pyplot.plot(numpy.linspace(1,1000,1000),(1/(numpy.linspace(1,1000,1000)**exp0)),label=exp0)#p-seires converges when exp0>1 ONLY
# # matplotlib.pyplot.legend()
# # # matplotlib.pyplot.show()
# # matplotlib.pyplot.cla()
# print('i0 modified bessel')
# print(numpy.i0(numpy.linspace(1,1000,1000)))
# import matplotlib.pyplot
# matplotlib.pyplot.plot(numpy.linspace(1,1000,1000),numpy.i0(numpy.linspace(1,1000,1000)))
# matplotlib.pyplot.show()
# print('sinc')
# # print(numpy.sinc(numpy.linspace(-9,9,1000)))
# import matplotlib.pyplot
# matplotlib.pyplot.plot(numpy.linspace(-9,9,1000),numpy.sinc(numpy.linspace(-9,9,1000)),label='normalized')
# matplotlib.pyplot.plot(numpy.linspace(-9,9,1000),numpy.sinc(numpy.linspace(-9,9,1000)/numpy.pi),label='unnormalized')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# print('real')
# print('imag')
# r0=numpy.real(numpy.ones(1))
# try:
    # r0.real=numpy.arange(-5,6,1)
# except Exception as e:
    # print(e)
# r0=numpy.real(numpy.ones(10))
# print(r0)
# r0=numpy.arange(-5,6,1)
# print(r0)
# try:
    # r0.imag=numpy.arange(-5,6,1)
# except Exception as e:
    # print(e)
# r0=numpy.array(r0,dtype=numpy.complex_)
# r0.imag=numpy.arange(-5,6,1)
# print(r0)
# print(numpy.real(r0),numpy.imag(r0))
# print('clip')
# min0=24
# max0=79
# array0=numpy.arange(0,100,1)
# print(array0)
# print(numpy.clip(array0,min0,max0))
# out0=numpy.ones(100)
# out0=numpy.clip(array0,min0,max0)
# print(out0)
# print(numpy.clip(array0,max0,min0))
# min0=numpy.linspace(99,0,100)
# max0=numpy.linspace(0,99,100)
# print(numpy.clip(array0,min0,max0))#not sure how this one works?
# print(numpy.clip(array0,max0,min0))
# print('nan_to_num')
# array1=[numpy.nan]
# print(array1)
# numpy.nan_to_num(array1,copy=False)#regardless of 'False', forces copy anyways given needs to create ndarray
# print(array1)
# array1=[numpy.nan]
# print(array1)
# numpy.nan_to_num(array1,copy=True)
# print(array1)
# print(numpy.nan_to_num(array1,copy=False))
# print(numpy.nan_to_num(array1,copy=True))
# array0=numpy.array([0,1,numpy.PINF,numpy.NINF,numpy.nan])
# print(numpy.nan_to_num(array0))
# print(numpy.nan_to_num(array0,copy=False,nan=69,posinf=96,neginf=-96))
# complex0Vectorized=numpy.vectorize(complex)
# array0=numpy.array([0,1,numpy.PINF,numpy.NINF,numpy.nan])#need to reinit given 'copy=False' and ndarray above
# complexArray0=complex0Vectorized(numpy.zeros(array0.size),array0)
# print(numpy.nan_to_num(complexArray0))
# print(numpy.nan_to_num(complexArray0,copy=False,nan=69,posinf=96,neginf=-96))
# print('real_if_close')
# print(numpy.finfo(float).eps)
# arrayIsClose=numpy.array([1+1e-14j,1+1.1e-14j,1+2.1e-14j])
# arrayIsNotClose=numpy.array([1+1e-14j,1+1.1e-14j,1+2.3e-14j])
# print(numpy.real_if_close(arrayIsClose))
# print(numpy.real_if_close(arrayIsNotClose))
# print(numpy.real_if_close(arrayIsNotClose,tol=1000))
# print(numpy.real_if_close(arrayIsClose,tol=10))
# print('interp')
# xTrue0=numpy.linspace(-9,9,20)
# yTrue0=numpy.sinc(numpy.linspace(-9,9,20))
# xInterp0=numpy.linspace(-9.5,9.5,200)
# import matplotlib.pyplot
# matplotlib.pyplot.plot(xTrue0,yTrue0,marker='<',label='true')
# matplotlib.pyplot.plot(xInterp0,numpy.interp(xInterp0,xTrue0,yTrue0,left=-1,right=1),marker='>',label='interp')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.clf()
# xTrue0=numpy.array([0,1,2,3,4,3,2,1,0])
# period0=4
# yTrue0=numpy.linspace(10,34,9)
# yTrue0[5:]=numpy.linspace(24,10,4)
# xInterp0=numpy.linspace(-5.5,5.5,200)
# print(len(xTrue0))
# matplotlib.pyplot.plot(xTrue0,yTrue0,marker='<',label='true')
# matplotlib.pyplot.plot(xInterp0,numpy.interp(xInterp0,xTrue0,yTrue0,left=-1,right=1),marker='>',label='interp')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.clf()
# matplotlib.pyplot.plot(xTrue0,yTrue0,marker='<',label='true')
# matplotlib.pyplot.plot(xInterp0,numpy.interp(xInterp0,xTrue0,yTrue0,left=-1,right=1,period=period0),marker='>',label='interp')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.title(period0)
# matplotlib.pyplot.show()
# matplotlib.pyplot.clf()
# period0=5
# matplotlib.pyplot.plot(xTrue0,yTrue0,marker='<',label='true')
# matplotlib.pyplot.plot(xInterp0,numpy.interp(xInterp0,xTrue0,yTrue0,left=-1,right=1,period=period0),marker='>',label='interp')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.title(period0)
# matplotlib.pyplot.show()
# matplotlib.pyplot.clf()
# period0=2
# matplotlib.pyplot.plot(xTrue0,yTrue0,marker='<',label='true')
# matplotlib.pyplot.plot(xInterp0,numpy.interp(xInterp0,xTrue0,yTrue0,left=-1,right=1,period=period0),marker='>',label='interp')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.title(period0)
# matplotlib.pyplot.show()
# matplotlib.pyplot.clf()
# matplotlib.pyplot.plot(xTrue0,yTrue0,marker='<',label='true')
# period0=2
# matplotlib.pyplot.plot(xInterp0,numpy.interp(xInterp0,xTrue0,yTrue0,left=-1,right=1,period=period0),marker='>',label='interp'+str(period0))
# period0=4
# matplotlib.pyplot.plot(xInterp0,numpy.interp(xInterp0,xTrue0,yTrue0,left=-1,right=1,period=period0),marker='>',label='interp'+str(period0))
# period0=5
# matplotlib.pyplot.plot(xInterp0,numpy.interp(xInterp0,xTrue0,yTrue0,left=-1,right=1,period=period0),marker='>',label='interp'+str(period0))
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.clf()
# xTrue0=numpy.linspace(-9-9j,9+9j,20)
# yTrue0=numpy.linspace(10+10j,20+20j,20)
# xInterp0=numpy.linspace(-9.5-9.5j,9.5+9.5j,200)
# matplotlib.pyplot.plot(xTrue0,yTrue0,marker='<',label='true')
# try:
    # matplotlib.pyplot.plot(xInterp0,numpy.interp(xInterp0,xTrue0,yTrue0,left=-1-1j,right=1+1j),marker='>',label='interp')
# except Exception as e:
    # print(e)
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.clf()
# xTrue0=numpy.linspace(-9,9,20)
# yTrue0=numpy.linspace(10+10j,20+20j,20)
# xInterp0=numpy.linspace(-9.5,9.5,200)
# matplotlib.pyplot.plot(xTrue0,yTrue0,marker='<',label='true')
# matplotlib.pyplot.plot(xInterp0,numpy.interp(xInterp0,xTrue0,yTrue0,left=-1-1j,right=1+1j),marker='>',label='interp')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.clf()
# xTrue0=numpy.linspace(-9,9,20)
# yTrue0=numpy.linspace(10+10j,20+20j,20)
# xInterp0=numpy.linspace(-9.5,9.5,200)
# matplotlib.pyplot.plot(xTrue0,yTrue0,marker='<',label='true')
# matplotlib.pyplot.plot(xInterp0,numpy.interp(xInterp0,xTrue0,yTrue0),marker='>',label='interp')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.clf()
# try:
    # print(numpy.interp([0,1,2],[0,numpy.nan,3],[3,4,5]))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.interp([0,1,2],[0,1,3],[3,4,5],period=0))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.interp([0,1,2],[[0,1,3]],[[3,4,5]]))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.interp([0,1,2],[1,3],[3,4,5]))
# except Exception as e:
    # print(e)
# array3D=numpy.arange(27).reshape(3,3,3)
# for i in list(range(array3D.ndim)):
    # print(i,array3D[i])
# for axis0item in array3D:
    # print(axis0item)
# for item0 in array3D.flat:
    # print(item0)
# print('numpy.array')
# print(numpy.array([(1,2.,3),(4,5.,6),(7,8.,9)],dtype=[('a','i4'),('b','f8'),('c','i4')])['c'])
# try:
    # print(numpy.array([1,2,3],dtype=numpy.complex_,copy=False,subok=True,order='A',ndmin=3,like=None))
# except Exception as e:
    # print(e)
# print(numpy.array([1,2,3],dtype=numpy.complex_,copy=False,subok=True,order='A',ndmin=3))
# print(numpy.array(numpy.matrix([[1,2],[3,4]]),dtype=numpy.complex_,copy=True,subok=True,order='A',ndmin=1))
# print('numpy.asarray')
# print('numpy.asanyarray')
# try:
    # print(numpy.asarray([(1,2.,3),(4,5.,6),(7,8.,9)],dtype=[('a','i4'),('b','f8'),('c','i4')],order='A',like=None))
# except Exception as e:
    # print(e)
# a0=numpy.array([(1,2.,3),(4,5.,6),(7,8.,9)],dtype=[('a','i4'),('b','f8'),('c','i4')],order='A').view(numpy.recarray)
# print(a0)
# aAsArray0=numpy.asarray(a0)
# aAsAnyArray0=numpy.asanyarray(a0)
# print(aAsArray0)
# print(aAsArray0 is a0)
# print(aAsAnyArray0)
# print(aAsAnyArray0 is a0)
# print(numpy.asarray([1,2,3,4],dtype=numpy.complex_,order='A'))
# print(numpy.asanyarray([1,2,3,4],dtype=numpy.complex_,order='A'))
# print('numpy.ascontiguousarray')
# aAsContiguousArray0=numpy.ascontiguousarray(a0)
# print(aAsContiguousArray0)
# print(aAsContiguousArray0 is a0)
# print(aAsContiguousArray0.flags['C_CONTIGUOUS'])
# print(numpy.ascontiguousarray([1,2,3,4],dtype=numpy.complex_))
# try:
    # print(numpy.ascontiguousarray([1,2,3,4],dtype=numpy.complex_,like=None))
# except Exception as e:
    # print(e)
# print(numpy.ascontiguousarray([1,2,3,4],dtype=numpy.complex_))
# print(numpy.ascontiguousarray(1,dtype=numpy.complex_))
# print('numpy.asmatrix')
# a0=numpy.array([1,2,3,4],dtype=numpy.complex_)
# a0=a0.reshape(2,2)
# a0Matrix=numpy.matrix(a0,dtype=numpy.float64)
# print(a0)
# a0[1,1]=100
# print(a0)
# print(a0Matrix)
# a0[1,1]=4
# a0Matrix=numpy.matrix(a0,copy=False,dtype=numpy.float64)
# print(a0)
# a0[1,1]=100
# print(a0)
# print(a0Matrix)
# a0[1,1]=4
# print(numpy.asmatrix(a0,dtype=numpy.float64))
# a0AsMatrix=numpy.asmatrix(a0,dtype=numpy.float64)
# print(a0)
# a0[1,1]=100
# print(a0)
# print(a0Matrix)
# a0[1,1]=4
# print('numpy.copy')
# a0=[[1,2],3,4,5]
# print(a0)
# print(numpy.copy(a0))
# a0Copy=numpy.copy(a0)
# a0Copy[1]=100
# print(a0Copy)
# print(a0)
# a0Copy[0][1]=100
# print(a0Copy)
# print(a0)
# a0=[[1,2],3,4,5]
# print(a0)
# import copy
# a0DeepCopy=copy.deepcopy(a0)
# a0DeepCopy[1]=100
# print(a0DeepCopy)
# print(a0)
# a0DeepCopy[0][1]=100
# print(a0DeepCopy)
# print(a0)
# a0=[[1,2],3,4,5]
# print(a0)
# print(numpy.copy(a0,order='F',subok=True))
# a0=[1,2,3,4,5]
# try:
    # print(a0.flags['WRITEABLE'])
# except Exception as e:
    # print(e)
# a0=numpy.array([1,2,3,4,5])
# print(a0.flags['WRITEABLE'])
# a0.flags['WRITEABLE']=False
# print(a0.flags['WRITEABLE'])
# a1=numpy.copy(a0,order='F',subok=True)
# print(a1.flags['WRITEABLE'])
# print('numpy.frombuffer')
# buffer0=b'IAmABuffer'
# try:
    # arrayFromBuffer0=numpy.frombuffer(buffer0)
# except Exception as e:
    # print(e)
# try:
    # arrayFromBuffer0=numpy.frombuffer(buffer0,dtype=numpy.bytes_)
# except Exception as e:
    # print(e)
# arrayFromBuffer0=numpy.frombuffer(buffer0,dtype='S1')
# print(arrayFromBuffer0)
# try:
    # arrayFromBuffer0=numpy.frombuffer(buffer0,dtype='S1',count=3,offset=3,like=None)
# except Exception as e:
    # print(e)
# arrayFromBuffer0=numpy.frombuffer(buffer0,dtype='S1',count=3,offset=3)
# print(arrayFromBuffer0)
# print('numpy._from_dlpack')
# import torch
# torchArray0=torch.arange(15)
# try:
    # print(numpy.from_dlpack(torchArray0))
# except Exception as e:
    # print(e)
# # print(numpy._from_dlpack(torchArray0))#Numpy1.22
# print(numpy.from_dlpack(torchArray0))#Numpy1.23
# print('numpy.fromiter')
# iterable0=numpy.arange(27).reshape(3,3,3).flat
# try:
    # print(numpy.fromiter(iterable0,count=5,dtype=numpy.complex_,like=None))
# except Exception as e:
    # print(e)
# print(numpy.fromiter(iterable0,count=5,dtype=numpy.complex_))
# datatype0=numpy.dtype((float,3))
# iterable1=((x*2,x*3,x*4) for x in numpy.arange(4.))
# print(numpy.fromiter(iterable1,dtype=datatype0))#needs Numpy1.23
# print('numpy.fromstring')
# string0='1.,2.,3.'
# try:
    # print(numpy.fromstring(string0,dtype='U1',count=3,sep='A'))
# except Exception as e:
    # print(e)
# string0='0.+1.j,1.+2.j,2.+3.j,3.+4.j'
# try:
    # print(numpy.fromstring(string0))
# except Exception as e:
    # print(e)
# print(numpy.fromstring(string0,dtype=numpy.complex_,count=2,sep=','))
# string0='1.2.3.4.'
# print(numpy.fromstring(string0,sep=''))
# try:
    # print(numpy.fromstring(string0,dtype=numpy.complex_,count=2,sep=',',like=None))
# except Exception as e:
    # print(e)
# print('numpy.loadtxt')
# fileName0=r'C:\Users\pdumas\Documents\Code\numpy0loadtxtExample0.txt'
# txtToWrite0='1;2;3;a;b;c\n4;5;6;d;e;f\n7;8;9;g;h;i\n"""-1;2;3""";11;12;j;k;l\n"""-1;2;3""";11;12;j;k;l'
# with open(fileName0,mode='w+') as f0:
    # f0.write(txtToWrite0)
# def converter0(val0):
    # return str(val0)+' '
# try:
    # array0LoadTxt=numpy.loadtxt(fileName0,delimiter=';',usecols=(0,2),unpack=False,skiprows=1,max_rows=3,encoding=None,quotechar='"',comments='-',converters=converter0,ndmin=2,like=None)
# except Exception as e:
    # print(e)
# array0LoadTxt=numpy.loadtxt(fileName0,delimiter=';',usecols=(0,2),unpack=False,skiprows=1,max_rows=3,encoding=None,quotechar='"',comments='-',converters=converter0,ndmin=2,dtype='U8',like=None)
# array0LoadTxt=numpy.loadtxt(fileName0,delimiter=';',usecols=(0,2),unpack=False,skiprows=1,max_rows=3,encoding=None,quotechar='"',comments='-',converters=converter0,ndmin=2,dtype='U8')
# print(array0LoadTxt)
# try:
    # array0LoadTxt=numpy.loadtxt(fileName0,delimiter=';',usecols=(0,2),unpack=False,skiprows=1,max_rows=3,encoding=None,quotechar='"',comments='-',converters={0:converter0})
# except Exception as e:
    # print(e)
# col0,col2=numpy.loadtxt(fileName0,delimiter=';',usecols=(0,2),unpack=True,skiprows=1,max_rows=3,encoding=None,quotechar='"',comments='-',converters=converter0,ndmin=2,dtype='U8')
# print(col0,col2)
# print('numpy.core.records.array')
# array0=numpy.arange(27).reshape(3,3,3)
# print(numpy.core.records.array(array0))
# try:
    # print(numpy.core.records.array(array0,dtype=numpy.complex_,offset=2))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.core.records.array(fileName0))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.core.records.array(fileName0,dtype='U8',offset=6))
# except Exception as e:
    # print(e)
# with open(fileName0,mode='rb') as f0:
    # print(numpy.core.records.array(f0,dtype=float,offset=6))
    # f0.seek(0)
# with open(fileName0,mode='rb') as f0:
    # print(numpy.core.records.array(f0,dtype=float,offset=6).shape)
    # f0.seek(0)
# with open(fileName0,mode='rb') as f0:
    # print(numpy.core.records.array(f0,dtype=float,offset=6,shape=(2,5)))
    # f0.seek(0)
# with open(fileName0,mode='rb') as f0:
    # print(numpy.core.records.array(f0,dtype=float,offset=2,shape=(2,5)))
    # f0.seek(0)
# print(numpy.core.records.array(b'123456789',dtype=numpy.int64,strides=(1,)))
# print(numpy.core.records.array(b'123456789',dtype=numpy.int64,strides=(2,)))
# print(numpy.core.records.array(b'123456789',dtype=numpy.int64,strides=(4)))
# print(numpy.core.records.array(b'123456789',dtype=numpy.int64,strides=(3,)))
# print(numpy.core.records.array(b'123456789',dtype=numpy.int64))
# try:
    # print(numpy.core.records.array(b'123456789',strides=(3,)))
# except Exception as e:
    # print(e)
# try:
    # with open(fileName0,mode='rb') as f0:
        # print(numpy.core.records.array(f0,dtype=numpy.unicode_,offset=6))
# except Exception as e:
    # print(e)
# for end0 in numpy.array([3,9,27,81,2,4,8,16]):
    # for dtype0 in [int,float,complex]:
        # print(end0,dtype0,numpy.arange(end0,dtype=dtype0).strides,sep='|')
# print(numpy.arange(20).reshape(1,2,2,5).strides)
# print(numpy.arange(20).reshape(2,2,5).strides)
# print(numpy.arange(20).reshape(4,5).strides)
# print(numpy.core.records.array([(1,2.,'a'),(3,4.,'b'),],names=['int0','float0','str0'],formats=['i4','f4','U1'],titles=['col0','col1','col2']))
# recarray0=numpy.core.records.array([(1,2.,'a'),(3,4.,'b'),],names=['int0','float0','str0'],formats=['i4','f4','U1'],titles=['col0','col1','col2'])
# try:
    # print(recarray0.titles)
# except Exception as e:
    # print(e)
# print(recarray0.col0)
# print(recarray0.int0)
# recarray0.flags['WRITEABLE']=False
# recarray1=numpy.core.records.array(recarray0,copy=False)
# print(recarray0.flags['WRITEABLE'])
# recarray1=numpy.core.records.array(recarray0,copy=True)
# print(recarray0.flags['WRITEABLE'])
# print('numpy.recarray.ctypes and attributes')
# print(recarray0.T)
# print(recarray1.base)
# print(recarray0.dtype)
# print(recarray0.data)
# print(recarray0.ctypes.data)
# print(recarray0.ctypes.shape)
# print(recarray0.ctypes.strides)
# import ctypes
# print(recarray0.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)))
# try:
    # print(recarray0.ctypes.shape_as(ctypes.POINTER(ctypes.c_int32)))
# except Exception as e:
    # print(e)
# try:
    # recarray0=numpy.rec.array([[[1,2],[3,4],[5,6]]],dtype=numpy.int64)
# except Exception as e:
    # print(e)
# print('redefinition occurs')
# recarray0=numpy.array([[[1,2],[3,4],[5,6]]],dtype=numpy.int64)
# recarray1=numpy.core.records.array(recarray0,copy=True)
# print(recarray0.T)
# print(recarray1.base)
# print(recarray0.dtype)
# print(recarray0.data)
# print(recarray0.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)))
# print(recarray0.ctypes.shape_as(ctypes.c_int64))
# print(recarray0.ctypes.shape_as(ctypes.c_int32))
# print(recarray0.ctypes.strides_as(ctypes.c_int32))
# print(recarray0.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)).contents)
# try:
    # print(recarray0.ctypes.shape_as(ctypes.c_int32).contents)
# except Exception as e:
    # print(e)
# print(recarray0.ctypes.data_as(ctypes.POINTER(ctypes.c_int64)))
# print(recarray0.ctypes.shape_as(ctypes.c_int64))
# print(recarray0.ctypes.strides_as(ctypes.c_int64))
# print(recarray0.ctypes.data_as(ctypes.POINTER(ctypes.c_int64)))
# print(recarray0.flags)
# print(recarray1.flags)
# print(recarray1.flags['C_CONTIGUOUS'])
# print(recarray1.flags.c_contiguous)
# try:
    # print(recarray1.flags.C_CONTIGUOUS)
# except Exception as e:
    # print(e)
# try:
    # print(recarray1.flags.updateifcopy)#gone in Numpy1.23 onwards
# except Exception as e:
    # print(e)
# recarray1=recarray1.copy('F')
# for flags0attribute in ['c_contiguous','f_contiguous','owndata','writeable','aligned','writebackifcopy','fnc','forc','behaved','carray','farray']:
    # print('recarray0',flags0attribute,getattr(recarray0.flags,flags0attribute),sep='|')
    # print('recarray1',flags0attribute,getattr(recarray1.flags,flags0attribute),sep='|')
# for attribute0 in ['shape','strides','nbytes','ndim','itemsize','size','flat','real','imag']:
    # print('recarray0',attribute0,getattr(recarray0,attribute0),sep='|')
    # print('recarray1',attribute0,getattr(recarray1,attribute0),sep='|')
# y=numpy.reshape(numpy.arange(2*3*4),(2,3,4))
# print(y)
# print(y.strides)
# print(y[1,1,1])
# offset0=sum(y.strides*numpy.array((1,1,1)))
# print(offset0/y.itemsize)
# print(recarray0)
# print(recarray0.strides)
# print(recarray0.shape)
# print(recarray0[0,1,1])
# offset0=sum(recarray0.strides*numpy.array((0,1,1)))
# print(offset0/recarray0.itemsize)
# print('numpy.ndarray')
# print(numpy.ndarray((3,),dtype=numpy.complex_,order='C'))
# print(numpy.ndarray((2,),buffer=numpy.arange(3.),offset=numpy.arange(3).itemsize*2,strides=(4,),order='C'))
# try:
    # print(numpy.ndarray((2,),buffer=numpy.arange(3.),offset=numpy.arange(3).itemsize*2,strides=(4,),order='C'))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.ndarray((2,),buffer=numpy.arange(3.),offset=numpy.arange(3.).itemsize*2,order='C').strides)
# except Exception as e:
    # print(e)
# try:
    # print(numpy.ndarray((2,),buffer=numpy.arange(3),offset=numpy.arange(3).itemsize*2,order='C'))
# except Exception as e:
    # print(e)
# for bufferArangeSize0 in numpy.arange(9):
    # print(bufferArangeSize0)
    # try:
        # print(numpy.ndarray((2,),buffer=numpy.arange(bufferArangeSize0),offset=numpy.arange(3).itemsize*2,order='C'))
    # except Exception as e:
        # print(e)
# print(numpy.ndarray((2,),buffer=numpy.arange(9),offset=numpy.arange(3).itemsize*2,order='C'))
# print(numpy.ndarray((2,),buffer=numpy.arange(9,dtype=int),offset=numpy.arange(3,dtype=int).itemsize*2,dtype=int,order='C'))
# import numpy.typing
# print(numpy.arange(2).dtype)
# print(numpy.typing.NDArray)
# print(numpy.typing.NDArray[numpy.complex128])
# NDArrayThroughTyping0=numpy.typing.NDArray[numpy.complex128]
# NDArrayThroughTyping0=numpy.linspace(0+0j,5+5j,5)
# print(NDArrayThroughTyping0)
# print('ndarray.item')
# ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3)
# print(ndarray0.item(26))
# print(ndarray0.item((2,2,2)))
# try:
    # print(ndarray0.item())
# except Exception as e:
    # print(e)
# ndarray0=numpy.array([100])
# print(ndarray0.item())
# ndarray0=numpy.array([100],dtype=numpy.float64)
# print(ndarray0.item())
# dtype0=numpy.dtype([('subFloat0','=f8',(3,3,3))])
# ndarray0=numpy.array(numpy.arange(27).reshape(3,3,3),dtype=dtype0)
# print(ndarray0.item(26))
# print('ndarray.tolist')
# for ndarray0 in [numpy.array(0),numpy.arange(1,dtype=numpy.int64),numpy.arange(27,dtype=numpy.int64),numpy.arange(27,dtype=numpy.int64).reshape(3,3,3)]:
    # print(ndarray0)
    # try:
        # print(list(ndarray0))
    # except Exception as e:
        # print(e)
    # print(ndarray0.tolist(),end='\n\n')
# # ndarray0=numpy.arange(1,dtype=numpy.int64)
# # ndarray0=numpy.arange(27,dtype=numpy.int64)
# # print(ndarray0.tolist())
# # print(list(ndarray0))
# # ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3)
# # print(ndarray0.tolist())
# # print(list(ndarray0))
# print('ndarray.itemset')
# ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3)
# print(ndarray0.itemset(26,1000))
# print(ndarray0)
# print(ndarray0.itemset((2,2,2),1000))
# print(ndarray0)
# try:
    # print(ndarray0.itemset())
# except Exception as e:
    # print(e)
# ndarray0=numpy.array([100])
# print(ndarray0.itemset(1000))
# print(ndarray0)
# ndarray0=numpy.array([100],dtype=numpy.float64)
# print(ndarray0.itemset(1000))
# print(ndarray0)
# dtype0=numpy.dtype([('subFloat0','=f8',(3,3,3))])
# ndarray0=numpy.array(numpy.arange(27).reshape(3,3,3),dtype=dtype0)
# print(ndarray0.itemset(26,1000))
# print(ndarray0)
# ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3)
# for item0 in ndarray0.flat:
    # ndarray0.itemset(item0,1000)
# print(ndarray0)
# print('ndarray.tostring')
# print('ndarray.tobytes')
# ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3)
# print(ndarray0)
# print(ndarray0.tobytes(order='C'))
# print(ndarray0.tostring(order='C'))
# print(ndarray0.tobytes(order='F'))
# print(ndarray0.tostring(order='F'))
# print(ndarray0.tobytes(order='A'))
# print(ndarray0.tostring(order='A'))
# print('ndarray.dump')
# import pickle
# with open(r'C:\Users\pdumas\Documents\Code\numpyPickleTest0.txt','wb') as f0:
    # ndarray0.dump(f0)
# with open(r'C:\Users\pdumas\Documents\Code\numpyPickleTest0.txt','rb') as f0:
    # ndarray0=numpy.load(f0,allow_pickle=True)
# print(ndarray0)
# with open(r'C:\Users\pdumas\Documents\Code\numpyPickleTest0.txt','wb') as f0:
    # ndarray0.dump(f0)
# with open(r'C:\Users\pdumas\Documents\Code\numpyPickleTest0.txt','rb') as f0:
    # ndarray0=pickle.load(f0)
# print(ndarray0)
# ndarray0.dump(r'C:\Users\pdumas\Documents\Code\numpyPickleTest0.txt')
# print(numpy.load(r'C:\Users\pdumas\Documents\Code\numpyPickleTest0.txt',allow_pickle=True))
# with open(r'C:\Users\pdumas\Documents\Code\numpyPickleTest0.txt','wb') as f0:
    # pickle.dump([1,2,3],f0)
# with open(r'C:\Users\pdumas\Documents\Code\numpyPickleTest0.txt','rb') as f0:
    # print(pickle.load(f0))
# print('ndarray.dumps')
# stringWithndarray0=ndarray0.dumps()
# print(pickle.loads(stringWithndarray0))
# print('ndarray.astype')
# print(ndarray0)
# ndarray1=ndarray0.astype(numpy.complex64,order='F',casting='unsafe',subok=False,copy=False)
# print(ndarray1.base is ndarray0)
# print(ndarray1)
# print(ndarray1.strides)
# print('ndarray.byteswap')
# number240=numpy.binary_repr(240)
# print(number240)
# print(numpy.array(int(number240,2),dtype=numpy.uint8))
# print(numpy.array(int(number240,2),dtype=numpy.uint8).byteswap(inplace=True))
# print(numpy.binary_repr(numpy.array(int(number240,2),dtype=numpy.uint8).byteswap(inplace=True)))
# print(numpy.binary_repr(numpy.array(int(number240,2),dtype=numpy.uint8).newbyteorder().byteswap(inplace=True)))
# print(numpy.arange(0,256,20))
# print(numpy.arange(0,256,20).byteswap())
# print(list(map(hex,numpy.arange(0,256,20))))
# print(list(map(hex,numpy.arange(0,256,20).byteswap())))
# print(list(map(hex,numpy.arange(0,256,20).byteswap(inplace=True))))
# # buffer0=b'abcdef'
# # print(numpy.frombuffer(buffer0,count=3).
# print(numpy.array([b'abc',b'def']))
# print(numpy.array([b'abc',b'def']).byteswap())
# try:
    # print(list(map(hex,numpy.array([b'abc',b'def']))))
# except Exception as e:
    # print(e)
# try:
    # print(list(map(hex,numpy.array([b'abc',b'def']).byteswap())))
# except Exception as e:
    # print(e)
# print(numpy.array([0,1,2]).view(numpy.uint8))
# print(numpy.array([0,1,2]).newbyteorder('S').view(numpy.uint8))
# print(numpy.array([0,1,2]).newbyteorder('S').byteswap().view(numpy.uint8))
# print('ndarray.copy')
# print(ndarray0)
# print(ndarray0.copy())
# print(ndarray0.copy().strides)
# print(ndarray0.copy('F').strides)
# print('ndarray.view')
# ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3)
# print(ndarray0)
# print(ndarray0.view())
# ndarray0.flags.writeable=False
# print(ndarray0.view().flags.writeable)
# print(ndarray0.view().dtype)
# print(ndarray0.view(numpy.int32))
# print(ndarray0.view(numpy.int32).dtype)
# print(ndarray0.view(numpy.recarray))
# recarray0=ndarray0.view(numpy.recarray)
# ndarray0.flags.writeable=True
# recarray0.flags.writeable=True
# recarray0.itemset(0,1000)
# ndarray0.itemset(1,10000)
# print(recarray0)
# print(ndarray0)
# ndarray0=numpy.arange(9,dtype=numpy.int64).reshape(3,3)
# print(ndarray0.view(numpy.matrix))
# # ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3).copy('F')
# ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3)[:,:,0]
# print(ndarray0)
# recarray0=ndarray0.view(numpy.recarray)
# try:
    # ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3)[:,:,0].view(numpy.int32)
# except Exception as e:
    # print(e)
# try:
    # ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3)[:,:,0].copy('F').view(numpy.int32)#contiguous (NOT specifically C-contiguous) is NOT ok
# except Exception as e:
    # print(e)
# ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3)[:,:,0].copy('C').view(numpy.int32)
# print(ndarray0)
# print('ndarray.setflags')
# ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3).copy('C')
# print(ndarray0.flags)
# ndarray0.setflags(write=False,align=False,uic=False)
# print(ndarray0.flags)
# try:
    # ndarray0.setflags(write=False,align=False,uic=True)
# except Exception as e:
    # print(e)
# ndarray0.setflags(write=True,align=True,uic=False)
# print(ndarray0.flags)
# ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3)
# print(ndarray0.flags)
# ndarray0.setflags(write=False,align=False,uic=False)
# print(ndarray0.flags)
# try:
    # ndarray0.setflags(write=False,align=False,uic=True)
# except Exception as e:
    # print(e)
# ndarray0.setflags(write=True,align=True,uic=False)
# print(ndarray0.flags)
# print('ndarray.fill')
# print(ndarray0.fill(10000))
# print(ndarray0)
# print('ndarray.resize')
# ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3)
# try:
    # print(numpy.arange(27,dtype=numpy.int64).reshape(3,3,3).resize(2,2))
# except Exception as e:
    # print(e)
# print(ndarray0.copy('C').resize(2,2))
# ndarray1=ndarray0.copy('C')
# ndarray1.resize(2,2)
# print(ndarray1)
# print(ndarray0.copy('C').resize(2,2))
# ndarray1=ndarray0.copy('C')
# ndarray1.resize(3,3)
# print(ndarray1)
# print(ndarray0.copy('C').resize(2,2))
# ndarray1=ndarray0.copy('C')
# ndarray1.resize(4,4,4)
# print(ndarray1)

# print(ndarray0.copy('F').resize((2,2)))
# ndarray1=ndarray0.copy('F')
# ndarray1.resize((2,2))
# print(ndarray1)
# print(ndarray0.copy('F').resize((2,2)))
# ndarray1=ndarray0.copy('F')
# ndarray1.resize((3,3))
# print(ndarray1)
# print(ndarray0.copy('F').resize((2,2)))
# ndarray1=ndarray0.copy('F')
# ndarray1.resize((4,4,4))
# print(ndarray1)

# try:
    # print(ndarray0.resize((4,4,4)))
# except Exception as e:
    # print(e)
# try:
    # print(ndarray0.resize((4,4,4),refcheck=False))
# except Exception as e:
    # print(e)
# ndarray0=numpy.arange(27,dtype=numpy.int64).reshape(3,3,3).copy('C')
# ndarray1=ndarray0
# print(ndarray1.resize((4,4,4),refcheck=False))
# ndarray1.resize((4,4,4),refcheck=False)
# print(ndarray1)
# print('ndarray.squeeze')
# for ndarray0 in [numpy.array(1000),numpy.array([1000]),numpy.array([[[1000]]]),numpy.array([[[1000,2000,3000]]])]:
    # print(ndarray0.shape,ndarray0)
    # print(ndarray0.squeeze())
    # for axis0 in list(range(ndarray0.ndim)):
        # try:
            # print(ndarray0.squeeze(axis=axis0))
        # except Exception as e:
            # print(e)
# print(numpy.array([[[1000,2000,3000]]]).squeeze(axis=(0,1)))
# print(numpy.squeeze(numpy.array([[[1000,2000,3000]]]),axis=(0,1)))
# print('ndarray.take')
# ndarray0=numpy.arange(10,61,1)
# print(ndarray0.take([[[0,2,4],[6,8,10],[12,14,16]]]))
# ndarray0=numpy.arange(27).reshape(3,3,3)
# print(ndarray0.take([[0,2],[1,1]],axis=2))
# print(ndarray0.take([[0,2],[1,1]],axis=0))
# print('ndarray.compress')
# ndarray0=numpy.arange(10,61,1)
# print(ndarray0.compress(ndarray0>14))
# ndarray0=numpy.arange(27).reshape(3,3,3)
# try:
    # print(ndarray0.compress(ndarray0>14,axis=2))
# except Exception as e:
            # print(e)
# print(ndarray0.compress([False,True],axis=2))
# print(ndarray0.compress([False,True],axis=0))
# print('ndarray.__lt,le,gt,ge,eq,ne__')
# # ndarray0=numpy.arange(9).reshape(3,3).copy('C')
# # ndarray1=numpy.arange(9,0,-1).reshape(3,3).copy('C')
# ndarray0=numpy.arange(9).copy('C')
# ndarray1=numpy.arange(8,-1,-1).copy('C')
# try:
    # print(ndarray0.not_equal(ndarray1))
# except Exception as e:
    # print(e)
# print(ndarray0)
# print(ndarray1)
# print(ndarray0.__lt__(ndarray1))
# print(ndarray0.__le__(ndarray1))
# print(ndarray0.__gt__(ndarray1))
# print(ndarray0.__ge__(ndarray1))
# print(ndarray0.__eq__(ndarray1))
# print(ndarray0.__ne__(ndarray1))
# try:
    # print(ndarray0.__bool__())
# except Exception as e:
    # print(e)
# ndarray0=numpy.array(1).copy('C')
# print(ndarray0.__bool__())
# ndarray0=numpy.array(0).copy('C')
# print(ndarray0.__bool__())
# print('ndarray.__neg,pos,abs,invert__')
# ndarray0=numpy.arange(-5,6,1).copy('C')
# print(ndarray0.__pos__())
# print(ndarray0.__abs__())
# print(ndarray0.__neg__())
# print(ndarray0.__invert__())
# print('ndarray.__add...__')
# ndarray0=numpy.arange(9).copy('C')
# ndarray1=numpy.arange(8,-1,-1).copy('C')
# print(ndarray0)
# print(ndarray1)
# print(ndarray0.__add__(ndarray1))
# print(ndarray0.__sub__(ndarray1))
# print(ndarray0.__mul__(ndarray1))
# print(ndarray0.__truediv__(ndarray1))
# print(ndarray0.__mod__(ndarray1))
# print(ndarray0.__divmod__(ndarray1))
# print(ndarray0.__floordiv__(ndarray1))
# print(ndarray0.__pow__(ndarray1))
# print(ndarray0.__pow__(ndarray1,ndarray1))
# try:
    # print(ndarray0.__pow__(ndarray1,mod=ndarray1))
# except Exception as e:
    # print(e)
# print(ndarray0.__lshift__(ndarray1))
# print(ndarray0.__rshift__(ndarray1))
# print(ndarray0.__and__(ndarray1))
# print(ndarray0.__or__(ndarray1))
# print(ndarray0.__xor__(ndarray1))

# print('ndarray.__iadd...__')
# ndarray0=numpy.arange(9).copy('C')
# ndarray1=numpy.arange(8,-1,-1).copy('C')
# print(ndarray0)
# print(ndarray1)
# print(ndarray0.__iadd__(ndarray1))
# print(ndarray0.__isub__(ndarray1))
# print(ndarray0.__imul__(ndarray1))
# try:
    # print(ndarray0.__itruediv__(ndarray1))
# except Exception as e:
    # print(e)
# ndarray0=numpy.arange(9,dtype=numpy.int32).copy('K')
# ndarray1=numpy.arange(8,-1,-1,dtype=numpy.int32).copy('K')
# try:
    # print(ndarray0.__itruediv__(ndarray1,casting='unsafe'))
# except Exception as e:
    # print(e)
# # print(numpy.array(4).__itruediv__(3))
# print(ndarray0.__imod__(ndarray1))
# try:
    # print(ndarray0.__idivmod__(ndarray1))
# except Exception as e:
    # print(e)
# print(ndarray0.__ifloordiv__(ndarray1))
# print(ndarray0.__ipow__(ndarray1))
# ndarray0=numpy.arange(9,dtype=numpy.int32).copy('K')
# ndarray1=numpy.arange(8,-1,-1,dtype=numpy.int32).copy('K')
# print(ndarray0.__ilshift__(ndarray1))
# print(ndarray0.__irshift__(ndarray1))
# print(ndarray0.__iand__(ndarray1))
# print(ndarray0.__ior__(ndarray1))
# print(ndarray0.__ixor__(ndarray1))
# print('upcast vs downCastBackToOriginal')
# ndarray0=numpy.array([1]).copy('C')
# ndarray1=numpy.array([2],dtype=numpy.int64).copy('C')
# ndarray2=ndarray0+ndarray1
# print(ndarray2.dtype)
# print(ndarray2)
# ndarray0+=ndarray1
# print(ndarray0.dtype)
# print(ndarray0)
# print('ndarray.__matmul__')
# ndarray0=numpy.arange(9).copy('C')
# ndarray1=numpy.arange(8,-1,-1).copy('C')
# print(ndarray0)
# print(ndarray1)
# print(ndarray0.__matmul__(ndarray1))
# print(ndarray0.__matmul__(numpy.repeat(2,ndarray1.size)))
# print(ndarray0.__matmul__(numpy.repeat(1,ndarray1.size)))
# print(7+12+15+16+7+12+15)
# ndarray0=numpy.arange(9).copy('F')
# ndarray0copy=ndarray0.__copy__()
# print(ndarray0copy)
# print(ndarray0copy.flags.f_contiguous)
# ndarray0=numpy.arange(9).copy('F')
# ndarray0.put(2,list([100,1000]))
# numpy.insert(ndarray0,2,list([100,1000]))
# ndarray0=numpy.array([[100,1000],1,2])
# print(ndarray0)
# ndarray0deepcopy=ndarray0.__deepcopy__(None)
# ndarray0[0][0]=200
# print(ndarray0)
# print(ndarray0deepcopy)
# print(ndarray0deepcopy.flags.f_contiguous)
# print('ndarray.__reduce,setstate__')
# print(ndarray0.__reduce__())
# try:
    # print(ndarray0.__setstate__([0,(3,),'U1',True,b'iAm']))
# except Exception as e:
    # print(e)
# try:
    # print(ndarray0.__setstate__([(3,),'U1',True,b'iAm']))
# except Exception as e:
    # print(e)
# try:
    # print(ndarray0.__setstate__([(3,),numpy.unicode_,True,b'iAm']))
# except Exception as e:
    # print(e)
# dtype0=numpy.dtype('S1')
# try:
    # print(ndarray0.__setstate__([(3,),dtype0,True,b'iAm']))
# except Exception as e:
    # print(e)
# ndarray0=numpy.empty(3,dtype=dtype0)
# print(ndarray0.__setstate__([(3,),dtype0,True,b'iAm']))
# print(ndarray0)
# print('ndarray.__new...class_getitem__')
# ndarray0=numpy.arange(2,dtype=numpy.float64).copy('C')
# try:
    # print(ndarray0.__new__(dtype=numpy.complex64))
# except Exception as e:
    # print(e)
# try:
    # print(ndarray0.__new__(numpy.complex64))
# except Exception as e:
    # print(e)
# try:
    # print(ndarray0.__new__(numpy.recarray))
# except Exception as e:
    # print(e)
# print(ndarray0.__new__(numpy.recarray,(3,)))
# try:
    # print(ndarray0.__array__(dtype=numpy.float64) is ndarray0)
# except Exception as e:
    # print(e)
# print(ndarray0.__array__(numpy.float64) is ndarray0)
# print(ndarray0.__array__(numpy.complex64) is ndarray0)
# try:
    # print(ndarray0.__array_wrap__().base is ndarray0)
# except Exception as e:
    # print(e)
# print(ndarray0.__array_wrap__(ndarray0) is ndarray0)
# print(ndarray0.__array_wrap__(ndarray0).base is ndarray0)
# print(ndarray0.__len__())
# print(ndarray0.__getitem__(0))
# print(ndarray0.__setitem__(0,100))
# print(ndarray0)
# print(ndarray0.__contains__(0))
# print(ndarray0.__contains__(1))
# ndarray0=numpy.array(100)
# print(ndarray0.__int__())
# print(ndarray0.__float__())
# print(ndarray0.__float__().__int__())
# print(ndarray0.__complex__())
# print(ndarray0.__str__())
# print(ndarray0.__repr__())
# print('usefulness of records')
# dtype0=[('age','i4'),('height','f8')]
# try:
    # recarray0=numpy.recarray(3,dtype=dtype0,buf=[(31,6.2),(31,6.2),(31,6.2)])
# except Exception as e:
    # print(e)
# recarray0=numpy.rec.array([(31,6.2),(29,6.8),(30,6.9)],dtype=dtype0,shape=3)
# print(recarray0)
# print(recarray0.age.mean())
# print(recarray0.height.mean())
# print('numpy.rec.fromarrays')
# ndarray0=numpy.arange(4,dtype=complex)
# ndarray1=numpy.arange(4,dtype=float)
# try:
    # ndarray2=numpy.fromstring('a b c d',dtype='U1')
# except Exception as e:
    # print(e)
# ndarray2=numpy.fromiter('abcd',dtype='U1')
# recarray0fromarrays=numpy.rec.fromarrays((ndarray0,ndarray1,ndarray2),names=['column0','column1','column2'])
# print(recarray0fromarrays)
# try:
    # print(recarray0fromarrays.names)
# except Exception as e:
    # print(e)
# print(recarray0fromarrays.column0)
# print(recarray0fromarrays.column2)
# ndarray2=numpy.fromiter('abcde',dtype='U1')
# try:
    # recarray0fromarrays=numpy.rec.fromarrays((ndarray0,ndarray1,ndarray2),names=['column0','column1','column2'])
# except Exception as e:
    # print(e)
# print('numpy.rec.fromrecords')
# ndarray0=numpy.arange(4,dtype=complex)
# ndarray1=numpy.arange(4,dtype=float)
# try:
    # ndarray2=numpy.fromstring('a b c d',dtype='U1')
# except Exception as e:
    # print(e)
# ndarray2=numpy.fromiter('abcd',dtype='U1')
# recarray0fromrecords=numpy.rec.fromrecords((ndarray0,ndarray1,ndarray2),names=['column0','column1','column2'])
# print(recarray0fromrecords)
# try:
    # print(recarray0fromrecords.names)
# except Exception as e:
    # print(e)
# print(recarray0fromrecords.column0)
# print(recarray0fromrecords.column2)
# print('numpy.rec.fromstring')
# ndarray0=numpy.arange(4,dtype=complex)
# ndarray0bytes=ndarray0.tobytes()
# try:
    # recarray0fromstring=numpy.rec.fromstring(ndarray0bytes)
# except Exception as e:
    # print(e)
# recarray0fromstring=numpy.rec.fromstring(ndarray0bytes,dtype='S1,S1,S1,S1')
# print(recarray0fromstring)
# recarray0fromstring=numpy.rec.fromstring(ndarray0bytes,dtype='u1,u1,u1,u1')
# print(recarray0fromstring)
# recarray0fromstring=numpy.rec.fromstring(ndarray0bytes,dtype='u1,u1,u1,u1',offset=2)
# print(recarray0fromstring)
# # ndarray2=numpy.fromiter('abcd',dtype='U1')
# # print(ndarray2)
# try:
    # recarray0fromstring=numpy.rec.fromstring('abcd',dtype='U1,U1,U1,U1')
# except Exception as e:
    # print(e)
# print('numpy.rec.fromfile')
# try:
    # recarray0fromfile=numpy.rec.fromfile(r'C:\Users\pdumas\Documents\Code\numpyPickleTest0.txt')
# except Exception as e:
    # print(e)
# recarray0fromfile=numpy.rec.fromfile(r'C:\Users\pdumas\Documents\Code\numpyPickleTest0.txt',dtype='S1')
# print(recarray0fromfile)
# recarray0fromfile=numpy.rec.fromfile(r'C:\Users\pdumas\Documents\Code\numpyPickleTest0.txt',dtype='S1',offset=4)
# print(recarray0fromfile)
# print('numpy.core.defchararray numpy.char')
# print(numpy.core.defchararray is numpy.char)
# print('numpy.char.array')
# list0=['word0','word1','longword0','  longwordWithPreWhitespace','longwordWithPostWhitespace  ','longwordWithPostWhitespace         ','Ãœberschrift0','     longwordWithPreWhitespace',]
# print(numpy.char.array(list0))
# print(numpy.char.array(list0,itemsize=None,copy=True,unicode=None,order='C'))
# print(numpy.char.array(list0,itemsize=None,copy=True,unicode=None))#order 'C'(or'F'?) seems to trim trailing whitespace..
# ndarray0=numpy.array(list0)
# chararray0=numpy.char.array(ndarray0,itemsize=None,copy=False,unicode=None,order='C')
# print(chararray0.base is ndarray0)
# print(numpy.char.array(list0,itemsize=2,copy=True,unicode=None,order='C'))
# print(numpy.char.array(list0,itemsize=4,copy=True,unicode=None,order='C'))
# print(numpy.char.array(list0,itemsize=4,copy=False,unicode=None,order='C'))
# try:
    # print(numpy.char.array(list0,itemsize=4,copy=False,unicode=False,order='C'))
# except Exception as e:
    # print(e)
# print(numpy.char.array(list0,itemsize=4,copy=False,unicode=True,order='C'))
# print(numpy.char.array(list0,itemsize=4,copy=False,unicode=True,order='F'))
# chararray0=numpy.char.array(list0)
# print(chararray0)
# print(chararray0[4])
# print(chararray0[5])
# print(chararray0[4]==chararray0[5])
# print(chararray0[4]+chararray0[5])
# print(numpy.char.add(chararray0[4],chararray0[5]))
# print(chararray0[3])
# print(chararray0[7])
# print(chararray0[3]==chararray0[7])
# print(chararray0[3]+chararray0[7])
# print('numpy.char.asarray')
# ndarray0=numpy.array(list0)
# print(ndarray0)
# chararray0=numpy.char.asarray(ndarray0,itemsize=None,unicode=None,order='C')
# print(chararray0)
# print(chararray0.base is ndarray0)
# print(numpy.char.add(chararray0[4],chararray0[5]))#numpy.char.asarray() seems to not apply trailing whitespace trim on index, comparison, and other operations..
# list1=['simplea','simpleb','simplec']
# ndarray0=numpy.array(list1)
# print(ndarray0)
# chararray1=numpy.char.asarray(ndarray0,itemsize=None,unicode=None,order='C')
# print(chararray1)
# print(chararray1.base is ndarray0)
# print(chararray1.base is list1)
# print('numpy.char.add')
# chararray0=numpy.char.array(list0)
# print(chararray0)
# print(numpy.char.add(chararray0[4],chararray0[5]))
# print(numpy.char.multiply(chararray0[4],4))
# print(numpy.char.multiply(chararray0[4],-4))
# print(numpy.char.multiply(chararray0[4],0))
# print(numpy.char.mod(chararray0[4],2))
# print(numpy.char.mod(chararray0[4],4))
# print(numpy.char.mod(chararray0[4],1))
# print(numpy.char.mod(chararray0[4],400))
# print(numpy.char.mod(chararray0,400))
# print(numpy.char.mod(chararray0,400))
# print(numpy.char.mod(chararray0,[1,2,4,400,1,2,5,400]))
# print(numpy.char.mod('%s',chararray0))
# try:
    # print(numpy.char.mod('%f',chararray0))
# except Exception as e:
    # print(e)
# list3=[10,20,30,400]
# chararray3=numpy.char.array(list3)
# print(chararray3)
# try:
    # print(numpy.char.mod('%f',chararray3))
# except Exception as e:
    # print(e)
# list3=[10,20,30,400]
# ndarray3=numpy.array(list3)
# print(ndarray3)
# print(numpy.char.mod('%d',ndarray3))
# print(numpy.char.mod('%f',ndarray3))
# print(numpy.char.mod('%s',ndarray3))
# try:
    # print(numpy.char.mod(chararray0[4],'abc'))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.char.mod(chararray0[4],'s'))
# except Exception as e:
    # print(e)
# print('numpy.char.capitalize')
# print(numpy.char.capitalize(chararray0))
# print('numpy.char.center')
# try:
    # print(numpy.char.center(chararray0,width=-2,fillchar=' '))
# except Exception as e:
    # print(e)
# print(numpy.char.center(chararray0,width=0,fillchar=' '))
# print(numpy.char.center(chararray0,width=1,fillchar=' '))
# print(numpy.char.center(chararray0,width=4,fillchar=' '))
# print(numpy.char.center(chararray0,width=34,fillchar=' '))
# print(numpy.char.center(chararray0,width=34,fillchar='<'))
# print('numpy.char.encode')
# print('numpy.char.decode')
# print(numpy.char.encode(chararray0,encoding='latin1',errors=None))
# print(numpy.char.decode(numpy.char.encode(chararray0,encoding='latin1',errors=None),encoding='latin1',errors=None))
# print(numpy.char.encode(chararray0,encoding='cp037',errors=None))
# print(numpy.char.decode(numpy.char.encode(chararray0,encoding='cp037',errors=None),encoding='cp037',errors=None))
# print('numpy.char.expandtabs')
# list4=['\ttabBefore','tabAfter\t','tab\tBetween','\t\t2tabBefore','2tabAfter\t\t','2tab\t\tBetween','2tab\t \tBetweenWith1SpaceBetweenAndAfter \n \t']
# chararray4=numpy.char.array(list4)
# print(chararray4)
# for tabsize0 in [-2,0,2,8]:
    # try:
        # print(tabsize0,numpy.char.expandtabs(chararray4,tabsize=tabsize0))
    # except Exception as e:
        # print(e)
# print('numpy.char.join')
# print(chararray0)
# print(chararray0.size)
# print(numpy.char.join('|',chararray0))
# print(numpy.char.join(';',chararray0))
# print(numpy.char.join(',',chararray0))
# print(numpy.char.join(numpy.repeat('|',8),chararray0))
# ndarray0=numpy.array(list0)
# print(ndarray0)
# print(numpy.char.join('|',ndarray0))
# print(numpy.char.join(';',ndarray0))
# print(numpy.char.join(',',ndarray0))
# print(numpy.char.join(numpy.repeat('|',8),ndarray0))
# print(numpy.char.join('',ndarray0))
# print(numpy.char.join('|',(row for row in ndarray0)))
# print(numpy.char.join('',(row for row in ndarray0)))
# print(numpy.char.join(['+','|','|','|','|','|','|','+'],(row for row in ndarray0)))
# list0=['word0','word1','longword0','  longwordWithPreWhitespace','longwordWithPostWhitespace  ','longwordWithPostWhitespace         ','Ãœberschrift0','     longwordWithPreWhitespace','WordWordWord0','Word Word Word0']
# chararray0=numpy.char.array(list0)
# print(chararray0)
# print('numpy.char.lower')
# print(numpy.char.lower(chararray0))
# print('numpy.char.ljust')
# try:
    # print(numpy.char.ljust(chararray0,width=-2,fillchar=' '))
# except Exception as e:
    # print(e)
# print(numpy.char.ljust(chararray0,width=0,fillchar=' '))
# print(numpy.char.ljust(chararray0,width=1,fillchar=' '))
# print(numpy.char.ljust(chararray0,width=4,fillchar=' '))
# print(numpy.char.ljust(chararray0,width=34,fillchar=' '))
# print(numpy.char.ljust(chararray0,width=34,fillchar='<'))
# print('numpy.char.rjust')
# try:
    # print(numpy.char.rjust(chararray0,width=-2,fillchar=' '))
# except Exception as e:
    # print(e)
# print(numpy.char.rjust(chararray0,width=0,fillchar=' '))
# print(numpy.char.rjust(chararray0,width=1,fillchar=' '))
# print(numpy.char.rjust(chararray0,width=4,fillchar=' '))
# print(numpy.char.rjust(chararray0,width=34,fillchar=' '))
# print(numpy.char.rjust(chararray0,width=34,fillchar='<'))
# print('numpy.char.partition')
# print(numpy.char.partition(chararray0,'o'))
# print(numpy.char.partition(chararray0,'z'))
# print('numpy.char.rpartition')
# print(numpy.char.rpartition(chararray0,'o'))
# print(numpy.char.rpartition(chararray0,'z'))
# print('numpy.char.lstrip')
# print(numpy.char.lstrip(chararray0,'o'))
# print(numpy.char.lstrip(chararray0,'rolnwg'))
# print(numpy.char.lstrip(chararray0))
# print('numpy.char.rstrip')
# print(numpy.char.rstrip(chararray0,'o'))
# print(numpy.char.rstrip(chararray0,'0rolwdg'))
# print(numpy.char.rstrip(chararray0))
# print('numpy.char.strip')
# print(numpy.char.strip(chararray0,'o'))
# print(numpy.char.strip(chararray0,'0rolwdg'))
# print(numpy.char.strip(chararray0))
# try:
    # print(chararray0.removeprefix('long'))
# except Exception as e:
    # print(e)
# print('longWord0'.removeprefix('long'))
# print('longWord0'.removeprefix('olng'))
# try:
    # print('longWord0'.removeprefix())
# except Exception as e:
    # print(e)
# try:
    # print(chararray0.removesuffix('Word0'))
# except Exception as e:
    # print(e)
# print('longWord0'.removesuffix('Word0'))
# print('longWord0'.removesuffix('oWrd0'))
# try:
    # print('longWord0'.removesuffix())
# except Exception as e:
    # print(e)
# print('numpy.char.replace')
# print(numpy.char.replace(chararray0,'o','1000000'))
# print(numpy.char.replace(chararray0,'o','1000000',count=1))
# print(numpy.char.replace(chararray0,'o','1000000',count=-1))
# print(numpy.char.replace(chararray0,'o','1000000',count=-2))
# print(numpy.char.replace(chararray0,'or','1000000'))
# print(numpy.char.replace(chararray0,'or','1000000',count=1))
# print(numpy.char.replace(chararray0,'or','1000000',count=-1))
# print(numpy.char.replace(chararray0,'or','1000000',count=-2))
# print('numpy.char.split')
# print('numpy.char.rsplit')
# for function0 in [numpy.char.split,numpy.char.rsplit]:
    # for sep0 in [None,' ','o','or']:
        # for maxsplit0 in [None,-2,-1,1]:
            # print('function {}'.format(function0.__name__),'sep {}'.format(sep0),'maxsplit {}'.format(maxsplit0),function0(chararray0,sep=sep0,maxsplit=maxsplit0))
# list1=['word1\nword2\nword3','word1','longword1\r\nlongword2\r\nlongword3','longword1\n\rlongword2\n\rlongword3','longword1\rlongword2\rlongword3']
# chararray1=numpy.char.array(list1)
# print(chararray1)
# print('numpy.char.splitlines')
# for function0 in [numpy.char.splitlines]:
    # for keepends0 in [None,False,True]:
        # print('function {}'.format(function0.__name__),'keepends {}'.format(keepends0),function0(chararray1,keepends=keepends0))
# print('numpy.char.swapcase')
# print(numpy.char.swapcase(chararray0))
# str0='I need to be converted into the Formal Camel Case notation'
# def camelCase0(v0):
    # # return v0.lower().title().swapcase().replace(' ','')
    # v0 = v0.lower().title().replace(' ','')
    # v0 = v0[0].lower()+v0[1:]
    # return v0
# print(camelCase0(str0))
# print('numpy.char.title')
# print(numpy.char.title(chararray0))
# print('numpy.char.translate')
# table0={'word':'NotAWord','o':'z',48:57,'l':None}
# print(numpy.char.translate(chararray0,table0,deletechars='ng'))
# print(numpy.char.translate(chararray0,table0,deletechars='n'))
# try:
    # maketranstable0=str().maketrans(table0)
# except Exception as e:
    # print(e)
# table0={'w':'NOTw','o':'z',48:57,'l':None}#,'d':LookupError}  '''TypeError: character mapping must return integer, None or str'''
# maketranstable0=str().maketrans(table0)
# print(maketranstable0)
# print(maketranstable0)
# print(numpy.char.translate(chararray0,maketranstable0,deletechars='ng'))
# print(numpy.char.translate(chararray0,maketranstable0,deletechars=103))
# print('numpy.char.upper')
# print(numpy.char.upper(chararray0))
# print('numpy.char.zfill')
# for width0 in [-2,0,2,30]:
    # try:
        # print('width {}'.format(width0),numpy.char.zfill(chararray0,width0))
    # except Exception as e:
        # print(e)
# listCompare0=['00','01','10','11','aa','ab','ba','bb']
# listCompare1=['00','10','01','11','aa','ba','ab','bb']
# chararray0=numpy.char.array(listCompare0)
# chararray1=numpy.char.array(listCompare1)
# print('numpy.char.equal,numpy.char.not_equal,numpy.char.greater_equal,numpy.char.greater,numpy.char.less_equal,numpy.char.less')
# print(chararray0)
# print(chararray1)
# for function0 in [numpy.char.equal,numpy.char.not_equal,numpy.char.greater_equal,numpy.char.greater,numpy.char.less_equal,numpy.char.less]:
    # print('function {}'.format(function0.__name__),function0(chararray0,chararray1))
# listCompare0=['00    ','01    ','10    ','11    ','aa    ','ab    ','ba    ','bb    ']
# listCompare1=['00  ','10  ','01  ','11  ','aa  ','ba  ','ab  ','bb  ']
# chararray0=numpy.char.array(listCompare0)
# chararray1=numpy.char.array(listCompare1)
# print('numpy.char.equal,numpy.char.not_equal,numpy.char.greater_equal,numpy.char.greater,numpy.char.less_equal,numpy.char.less')
# print(chararray0)
# print(chararray1)
# for function0 in [numpy.char.equal,numpy.char.not_equal,numpy.char.greater_equal,numpy.char.greater,numpy.char.less_equal,numpy.char.less]:
    # print('function {}'.format(function0.__name__),function0(chararray0,chararray1))
# listCompare0=['00    ','01    ','10    ','11    ','aa    ','ab    ','ba    ','bb    ']
# listCompare1=['00  ','10  ','01  ','11  ','aa  ','ba  ','ab  ','bb  ']
# chararray0=numpy.char.array(listCompare0)
# chararray1=numpy.char.array(listCompare1)
# print('numpy.char.compare_chararrays')
# print(chararray0)
# print(chararray1)
# for function0 in [numpy.char.compare_chararrays]:
    # for rstrip0 in [True,False]:
        # for cmp0 in ["==","!=",">=",">","<=","<"]:
            # print('function {}'.format(function0.__name__),'cmp {}'.format(cmp0),'rstrip {}'.format(rstrip0),function0(chararray0,chararray1,cmp0,rstrip0))
# try:
    # print(numpy.char.compare_chararrays(chararray0,numpy.arange(8),"==",True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.char.compare_chararrays(chararray0,chararray0,"=",True))
# except Exception as e:
    # print(e)

# try:
    # print(numpy.char.compare_chararrays(chararray0,chararray1,"!="))
# except Exception as e:
    # print(e)    
# listCompare0=['00    ','01    ','10    ','11    ','aa    ','ab    ','ba    ','bb    ']
# listCompare1=['00  ','10  ','01  ','11  ','aa  ','ba  ','ab  ','bb  ']
# chararray0=numpy.char.asarray(listCompare0)
# chararray1=numpy.char.asarray(listCompare1)
# print('numpy.char.equal,numpy.char.not_equal,numpy.char.greater_equal,numpy.char.greater,numpy.char.less_equal,numpy.char.less')
# print(chararray0)
# print(chararray1)
# for function0 in [numpy.char.equal,numpy.char.not_equal,numpy.char.greater_equal,numpy.char.greater,numpy.char.less_equal,numpy.char.less]:
    # print('function {}'.format(function0.__name__),function0(chararray0,chararray1))

# print('numpy.char.count...')
# listCompare0=['00    ','01    ','10    ','11    ','aa    ','ab    ','ba    ','bb    ','']
# chararray0=numpy.char.array(listCompare0)
# for function0 in [numpy.char.count,numpy.char.find,numpy.char.index,numpy.char.rfind,numpy.char.rindex,numpy.char.startswith,numpy.char.endswith]:
    # print(chararray0)
    # for str0 in ['0',' ','']:
        # for start0 in [None,0,1]:
            # for end0 in [None,1,2]:
                # try:
                    # print('function {}'.format(function0.__name__),'str {}'.format(str0),'start {}'.format(start0),'end {}'.format(end0),function0(chararray0,str0,start=start0,end=end0))
                # except Exception as e:
                    # print(e)
# listCompare0=['00    ','01    ','10    ','11    ','aa    ','ab    ','ba    ','bb    ','','00','01','10','11','AA','Ab','ba','bb',' ','  ',"Ù©","\u2075","\u2155"]
# chararray0=numpy.char.array(listCompare0)
# for function0 in [numpy.char.isalpha,numpy.char.isupper,numpy.char.istitle,numpy.char.islower,numpy.char.isalnum,numpy.char.isdecimal,numpy.char.isdigit,numpy.char.isnumeric,numpy.char.isspace,numpy.char.str_len]:
    # print(chararray0)
    # print(listCompare0)
    # try:
        # print('function {}\n'.format(function0.__name__),function0(chararray0))
    # except Exception as e:
        # print(e)
# print("\u2075","\u2155")
# str0='zÙ©'
# print(numpy.char.chararray((2,2),itemsize=2,unicode=True,buffer=str0,offset=1,strides=(4,2),order='C'))
# print(numpy.char.chararray((2,2),itemsize=2,unicode=True,buffer=str0,offset=1,strides=(2,4),order='F'))
# print(numpy.char.chararray((2,2),itemsize=1,unicode=True,buffer=str0,offset=1,strides=(2,4),order='F'))
# try:
    # print(numpy.char.chararray((2,2),buffer=str0))
# except Exception as e:
    # print(e)
# print('numpy.meshgrid')
# start0=50
# stop0=150
# num0=10
# linspaceRows0=numpy.linspace(start0,stop0,num0)
# linspaceColumns0=numpy.linspace(start0,stop0,num0)
# print(numpy.meshgrid(linspaceRows0,linspaceColumns0))
# for indexing0 in ['ij','xy']:
    # for sparse0 in [False,True]:
        # for copy0 in [False,True]:
            # print('indexing {}'.format(indexing0),'sparse {}'.format(sparse0),'copy {}'.format(copy0),numpy.meshgrid(linspaceRows0,linspaceColumns0,copy=copy0,sparse=sparse0,indexing=indexing0),sep='\n')
# import matplotlib.pyplot
# matplotlib.pyplot.contourf(linspaceRows0,linspaceColumns0,(numpy.meshgrid(linspaceRows0,linspaceColumns0,sparse=True)[0]*numpy.meshgrid(linspaceRows0,linspaceColumns0,sparse=True)[1]))
# matplotlib.pyplot.axis('scaled')
# matplotlib.pyplot.colorbar()
# # matplotlib.pyplot.show()
# print(numpy.mgrid[0:6:2,0:6:2])
# try:
    # eval('''for function0 in [numpy.mgrid,numpy.ogrid]:
        # for index0 in [[0:6:2,0:6:2],[0:6:2j,0:6:2j]]:
            # print('function {}'.format(function0.__name__),'index {}'.format(index0),function0(index0))''')
# except Exception as e:
    # print(e)
# try:
    # eval('''for function0 in [numpy.mgrid,numpy.ogrid]:
        # for index0 in (([0:6:2,0:6:2]),([0:6:2j,0:6:2j])):
            # print('function {}'.format(function0.__name__),'index {}'.format(index0),function0(index0))''')
# except Exception as e:
    # print(e)
# # for function0 in [numpy.mgrid,numpy.ogrid]:
    # # for index0 in [[0:6:2],[0:6:2j]]:# not sure how to get over this syntax error.. slice() is how ?
        # # print('function {}'.format(function0.__name__),'index {}'.format(index0),function0(index0))
# print(numpy.mgrid[0:6:2,0:6:2])
# print(numpy.ogrid[0:6:2,0:6:2])
# print(numpy.mgrid[0:6:2j,0:6:2j])
# print(numpy.ogrid[0:6:2j,0:6:2j])
# print('numpy.vander')
# for N0 in [-2,0,2,4,None]:
    # for increasing0 in [True,False,None]:
        # for ndarray0 in [numpy.arange(4),numpy.linspace(0j,4j,num=4,endpoint=False)]:
            # try:
                # print('N {}'.format(N0),'increasing {}'.format(increasing0),'ndarray {}'.format(ndarray0),numpy.vander(ndarray0,increasing=increasing0,N=N0),sep='\n')
            # except Exception as e:
                # print(e)
# print(numpy.arange(4j))#numpy.arange doesn't work / gives empty ndarray on complex 'stop' for whatever reason..
# print('numpy.mat')
# print(numpy.mat(numpy.arange(4),dtype=complex))
# print(numpy.mat(numpy.arange(4).reshape(2,2),dtype=complex))
# print('numpy.bmat')
# print(numpy.bmat(numpy.arange(4),ldict=None,gdict=None))
# try:
    # print(numpy.bmat('0 1;2 3',ldict=None,gdict=None))
# except Exception as e:
    # print(e)
# print(numpy.bmat(numpy.mat('0 1;2 3'),ldict=None,gdict=None))
# try:
    # nestedSequenceInStringFormat0='0 1;2 3'
    # print(numpy.bmat([[nestedSequenceInStringFormat0,nestedSequenceInStringFormat0],[nestedSequenceInStringFormat0,nestedSequenceInStringFormat0]],ldict=None,gdict=None))
# except Exception as e:
    # print(e)
# nestedSequenceInStringFormat0=numpy.mat('0 1;2 3')
# print(numpy.bmat([[nestedSequenceInStringFormat0,nestedSequenceInStringFormat0],[nestedSequenceInStringFormat0,nestedSequenceInStringFormat0]],ldict=None,gdict=None))
# print(numpy.bmat([[nestedSequenceInStringFormat0,nestedSequenceInStringFormat0],[nestedSequenceInStringFormat0,nestedSequenceInStringFormat0]],ldict={0:100},gdict=None))
# print(numpy.bmat([[nestedSequenceInStringFormat0,nestedSequenceInStringFormat0],[nestedSequenceInStringFormat0,nestedSequenceInStringFormat0]],ldict=None,gdict={0:100}))
# print(numpy.bmat([[nestedSequenceInStringFormat0,nestedSequenceInStringFormat0],[nestedSequenceInStringFormat0,nestedSequenceInStringFormat0]],ldict={0:50},gdict={0:100}))
# try:
    # print(numpy.bmat([[nestedSequenceInStringFormat0,nestedSequenceInStringFormat0],[nestedSequenceInStringFormat0,nestedSequenceInStringFormat0]],ldict={nestedSequenceInStringFormat0:numpy.mat('50 100;150 200')},gdict={0:100}))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.bmat('nestedSequenceInStringFormat0 nestedSequenceInStringFormat0; nestedSequenceInStringFormat0 nestedSequenceInStringFormat0',ldict={nestedSequenceInStringFormat0:numpy.mat('50 100;150 200')},gdict={0:100}))
# except Exception as e:
    # print(e)
# print('numpy.copyto')
# ndarray0=numpy.arange(4).reshape(2,2).copy('C')
# ndarray1=numpy.zeros(4,dtype=float).reshape(2,2).copy('C')
# numpy.copyto(ndarray1,ndarray0)
# print(ndarray1)
# ndarray1=numpy.zeros(4,dtype=float).reshape(2,2).copy('C')

# numpy.copyto(ndarray1,ndarray0,casting='unsafe')
# print(ndarray1)
# ndarray1=numpy.zeros(4,dtype=float).reshape(2,2).copy('C')

# numpy.copyto(ndarray1,ndarray0,casting='unsafe',where=[True,False])
# print(ndarray1)
# ndarray1=numpy.zeros(4,dtype=float).reshape(2,2).copy('C')

# numpy.copyto(ndarray1,100.,casting='unsafe',where=[True,False])
# print(ndarray1)
# ndarray1=numpy.zeros(4,dtype=float).reshape(2,2).copy('C')

# numpy.copyto(ndarray1,numpy.array(100.),casting='unsafe',where=[True,False])
# print(ndarray1)
# ndarray1=numpy.zeros(4,dtype=float).reshape(2,2).copy('C')
# print('numpy.shape')
# print(numpy.shape(numpy.arange(1)))
# for reshapeValue0 in [-2,0,2,4,8]:
    # try:
        # print('reshapeValue {}'.format(reshapeValue0),numpy.shape(numpy.arange(reshapeValue0*reshapeValue0).reshape(reshapeValue0,reshapeValue0).copy('C')),sep='\n')
    # except Exception as e:
        # print(e)
# print('numpy.rollaxis')
# ndarray0=numpy.zeros((2,3,4,5,6))
# for axis0 in [-6,-5,0,5,6]:
    # for start0 in [-7,-4,2,4,7]:
        # try:
            # print('axis {}'.format(axis0),'start {}'.format(start0),'ndarray shape {}'.format(ndarray0.shape),numpy.rollaxis(ndarray0,axis0,start=start0).shape,sep='\n')
        # except Exception as e:
            # print(e)
# print('numpy.roll')
# ndarray0=numpy.arange(8).reshape(2,2,2).copy('C')
# for shift0 in [-6,-5,1,5,6]:
    # for axis0 in [-7,-3,0,2,7,None]:
        # try:
            # print('shift {}'.format(shift0),'axis {}'.format(axis0),'ndarray shape {}'.format(ndarray0),numpy.roll(ndarray0,shift0,axis=axis0),sep='\n')
        # except Exception as e:
            # print(e)
# print(numpy.roll(ndarray0,(1,1),axis=(2,0)))
# print('numpy.expand_dims')
# ndarray0=numpy.zeros((2,3,4,5,6))
# for axis0 in [-7,-3,0,2,7,None]:
    # try:
        # print('axis {}'.format(axis0),'ndarray shape {}'.format(ndarray0.shape),numpy.expand_dims(ndarray0,axis0).shape,sep='\n')
    # except Exception as e:
        # print(e)
# print(numpy.expand_dims(numpy.array([1,2,3]),axis=(0,1,2)).shape)
# print(numpy.expand_dims(numpy.array([1,2,3]),axis=(0,1,2,3)).shape)
# print(numpy.expand_dims(numpy.array([1,2,3]),axis=(0,1,2,3,4)).shape)
# try:
    # print(numpy.expand_dims(numpy.array([1,2,3]),axis=(4,3)).shape)
# except Exception as e:
    # print(e)
# print(numpy.expand_dims(numpy.array([1,2,3]),axis=(2,0)).shape)
# print('numpy.asfarray')
# print(numpy.asfarray([0,1,2],dtype=numpy.int64))
# print(numpy.asfarray([0,1,2]))
# print(numpy.asfarray([0.,1.,2.]))
# print('numpy.asfortranarray')
# try:
    # print(numpy.asfortranarray([[0,1],[2,3]],dtype=numpy.int64,like=None))
# except Exception as e:
    # print(e)
# print(numpy.asfortranarray([[0,1],[2,3]],dtype=numpy.float32).flags['C_CONTIGUOUS'])
# print(numpy.asfortranarray([[0,1],[2,3]],dtype=numpy.float32).flags['F_CONTIGUOUS'])
# print('numpy.asarray_chkfinite')
# print(numpy.asarray_chkfinite([[0,1],[2,3]],dtype=numpy.float32,order='F'))
# try:
    # print(numpy.asarray_chkfinite([[0,1],[numpy.nan,3]],dtype=numpy.float32,order='F'))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.asarray_chkfinite([[numpy.NINF,1],[2,3]],dtype=numpy.float32,order='F'))
# except Exception as e:
    # print(e)
# print('numpy.require')
# print(numpy.require(numpy.rec.array([[0,1],[2,3]]).copy('C').view().setflags(write=False,align=False,uic=False),dtype=complex,requirements=['F','A','W','E','O']).flags,type(numpy.require(numpy.rec.array([[0,1],[2,3]]).copy('C').view().setflags(write=False,align=False,uic=False),dtype=complex,requirements=['F','A','W','E','O'])))
# print(numpy.require(numpy.recarray((2,2),buf=numpy.array([[0,1],[2,3]]),formats='i',order='F').copy('F').view().setflags(write=False,align=False,uic=False),dtype=complex,requirements=['F','A','W','E','O']).flags)
# print(numpy.require(numpy.rec.array([[0,1],[2,3]]).copy('F').view().setflags(write=False,align=False,uic=False),dtype=complex,requirements=[]).flags)
# ndarray0=numpy.array(100.).copy('C')
# ndarray0.setflags(write=False,align=False,uic=False)
# print(ndarray0.flags)
# try:
    # ndarray0.flags.f_contiguous=False
# except Exception as e:
    # print(e)
# try:
    # ndarray0.flags.c_contiguous=False
# except Exception as e:
    # print(e)
# try:
    # ndarray0.flags['OWNDATA']=False
# except Exception as e:
    # print(e)
# print(ndarray0.flags)
# ndarray0require=numpy.require(ndarray0,dtype=complex,requirements=[])
# print(ndarray0require.flags)
# ndarray0require2=numpy.require(ndarray0require,dtype=complex,requirements=['F','A','W','E','O'])
# print(ndarray0require2.flags)
# ndarray0require2=numpy.require(ndarray0require,dtype=complex,requirements=['F','A','W','E','O'],like=None)
# print('numpy.concatenate')
# ndarray0=numpy.arange(4).reshape(2,2).copy('C')
# ndarray1=numpy.arange(4,8,1).reshape(2,2).copy('C')
# ndarray2=numpy.arange(8,12,1).reshape(2,2).copy('C')
# out0=numpy.zeros((4,2),dtype=complex)
# print(numpy.concatenate((ndarray0,ndarray1),dtype=complex))
# print(numpy.concatenate((ndarray0,ndarray1),dtype=complex,axis=0))
# print(numpy.concatenate((ndarray0,ndarray1),dtype=complex,axis=1))
# print(numpy.concatenate((ndarray0,ndarray1),out=out0))
# print(numpy.concatenate((ndarray0,ndarray1),dtype=complex,casting='unsafe'))
# print(numpy.concatenate((ndarray0,ndarray1),dtype=numpy.unicode_))
# print('numpy.stack')
# out0=numpy.zeros((2,2,2),dtype=int)
# print(numpy.stack((ndarray0,ndarray1)))
# print(numpy.stack((ndarray0,ndarray1),axis=0))
# print(numpy.stack((ndarray0,ndarray1),axis=1))
# print(numpy.stack((ndarray0,ndarray1),axis=2))
# print(numpy.stack((ndarray0,ndarray1),out=out0))
# print('numpy.block')
# print(numpy.block([ndarray0,ndarray1]))#hstack
# print(numpy.block([[ndarray0],[ndarray1]]))#vstack
# try:
    # print(numpy.block([[ndarray0],[]]))#error:empty list
# except Exception as e:
    # print(e)
# try:
    # print(numpy.block([[ndarray0],[[ndarray1]]]))#error: list nesting mismatch
# except Exception as e:
    # print(e)
# listOfArrays0=[ndarray0,ndarray1,ndarray2]
# ndarray3=numpy.arange(16,20,1)
# ndarray4=numpy.arange(20,24,1)
# ndarray5=numpy.arange(24,28,1)
# listOfArrays1=[ndarray3,ndarray4,ndarray5]
# print(numpy.block(listOfArrays0))
# print(numpy.block(listOfArrays1))
# print('numpy.vstack')
# tupleOfArrays0=(ndarray0,ndarray1,ndarray2)
# tupleOfArrays1=(ndarray3,ndarray4,ndarray5)
# print(numpy.vstack(tupleOfArrays0))
# print(numpy.vstack(tupleOfArrays1))
# print('numpy.hstack')
# print(numpy.hstack(tupleOfArrays0))
# print(numpy.hstack(tupleOfArrays1))
# print('numpy.dstack')
# print(ndarray0,ndarray1,ndarray2,sep='\n')
# print(ndarray3,ndarray4,ndarray5,sep='\n')
# print(numpy.dstack(tupleOfArrays0))
# print(numpy.dstack(tupleOfArrays1))
# print('numpy.row_stack')
# print(numpy.row_stack(tupleOfArrays0))
# print(numpy.row_stack(tupleOfArrays1))
# print('numpy.column_stack')
# print(numpy.column_stack(tupleOfArrays0))
# print(numpy.column_stack(tupleOfArrays1))
# print('numpy.split,numpy.array_split')
# ndarrayDims3=numpy.arange(2*2*2).reshape(2,2,2)
# ndarrayDims2=numpy.arange(2*2).reshape(2,2)
# ndarrayDims1=numpy.arange(2).reshape(2,)
# ndarrayDims0=numpy.array(100.)
# indices_or_sections0=2
# for function0 in [numpy.split,numpy.array_split]:
    # for ndarray0 in [ndarrayDims3,ndarrayDims2,ndarrayDims1,ndarrayDims0]:
        # for axis0 in [2,1,0,None]:
            # for indices_or_sections0 in [2,1,[1,2]]:
                # try:
                    # print('function {}'.format(function0.__name__),'ndarray {}'.format(ndarray0),'axis {}'.format(axis0),'indices_or_sections {}'.format(indices_or_sections0),function0(ndarray0,indices_or_sections0,axis=axis0),sep='  ')
                # except Exception as e:
                    # print(e)
# ndarrayDims2=numpy.arange(3*3).reshape(3,3)
# try:
    # print(numpy.split(ndarrayDims2,2))
# except Exception as e:
    # print(e)
# print(numpy.array_split(ndarrayDims2,2))
# print('numpy.dsplit,numpy.hsplit,numpy.vsplit')
# ndarrayDims3=numpy.arange(2*2*2).reshape(2,2,2)
# ndarrayDims2=numpy.arange(2*2).reshape(2,2)
# ndarrayDims1=numpy.arange(2).reshape(2,)
# ndarrayDims0=numpy.array(100.)
# for function0 in [numpy.dsplit,numpy.hsplit,numpy.vsplit]:
    # for ndarray0 in [ndarrayDims3,ndarrayDims2,ndarrayDims1,ndarrayDims0]:
        # for indices_or_sections0 in [2,1,[1,2]]:
            # try:
                # print('function {}'.format(function0.__name__),'ndarray {}'.format(ndarray0),'indices_or_sections {}'.format(indices_or_sections0),function0(ndarray0,indices_or_sections0),sep='  ')
            # except Exception as e:
                # print(e)
# print('numpy.delete')
# ndarrayDims3=numpy.arange(3*3*3).reshape(3,3,3)
# ndarrayDims1=numpy.arange(3).reshape(3,)
# for function0 in [numpy.delete]:
    # for ndarray0 in [ndarrayDims3,ndarrayDims1]:
        # for axis0 in [2,1,0,None]:
            # for object0 in [2,0,[2,0],slice(0,2)]:
                # try:
                    # print('function {}'.format(function0.__name__),'ndarray {}'.format(ndarray0),'axis {}'.format(axis0),'object {}'.format(object0),function0(ndarray0,object0,axis=axis0),sep='  ')
                # except Exception as e:
                    # print(e)
# mask0=numpy.around(numpy.cos(numpy.linspace(0,numpy.pi,num=10)),0).astype(numpy.bool_)
# print(mask0.astype(int))
# ndarray0=numpy.arange(10)
# print(ndarray0)
# print(numpy.delete(ndarray0,mask0,axis=None))
# print('numpy.insert')
# ndarrayDims3=numpy.arange(3*3*3).reshape(3,3,3)
# ndarrayDims1=numpy.arange(3).reshape(3,)
# for function0 in [numpy.insert]:
    # for ndarray0 in [ndarrayDims3,ndarrayDims1]:
        # for axis0 in [2,1,0,None]:
            # for object0 in [2,0,[2,0],slice(0,2)]:
                # for value0 in [100000,200000.]:
                    # try:
                        # print('function {}'.format(function0.__name__),'ndarray {}'.format(ndarray0),'axis {}'.format(axis0),'object {}'.format(object0),'value {}'.format(value0),function0(ndarray0,object0,value0,axis=axis0),sep='  ')
                    # except Exception as e:
                        # print(e)
# ndarray0=numpy.arange(10)
# print(ndarray0)
# value0=[100,200]
# print(value0)
# try:
    # print(numpy.insert(ndarray0,[2,2,4,4],value0,axis=None))
# except Exception as e:
    # print(e)
# print('numpy.append')
# ndarrayDims3=numpy.arange(3*3*3).reshape(3,3,3)
# ndarrayDims1=numpy.arange(3).reshape(3,)
# for function0 in [numpy.append]:
    # for ndarray0 in [ndarrayDims3,ndarrayDims1]:
        # for axis0 in [2,1,0,None]:
            # for value0 in [100000,200000.,[100000,200000,300000],[[100000,200000,300000]]]:
                # try:
                    # print('function {}'.format(function0.__name__),'ndarray {}'.format(ndarray0),'axis {}'.format(axis0),'value {}'.format(value0),function0(ndarray0,value0,axis=axis0),sep='  ')
                # except Exception as e:
                    # print(e)
# ndarrayDims2=numpy.arange(2*2).reshape(2,2)
# print(ndarrayDims2)
# print(numpy.append(ndarrayDims2,[[100000,200000]],axis=0))
# print(numpy.append(ndarrayDims2,[[100000],[200000]],axis=1))
# print('numpy.trim_zeros')
# mask0=numpy.invert(numpy.around(numpy.cos(numpy.linspace(0,numpy.pi,num=10)),0).astype(numpy.bool_))
# print(mask0.astype(int))
# for function0 in [numpy.trim_zeros]:
    # for trim0 in ['fb','f','b','']:
        # try:
            # print('function {}'.format(function0.__name__),'ndarray {}'.format(mask0.astype(int)),'trim {}'.format(trim0),function0(mask0.astype(int),trim=trim0),sep='  ')
        # except Exception as e:
            # print(e)
# mask0=numpy.around(numpy.cos(numpy.linspace(0,numpy.pi,num=10)),0).astype(numpy.bool_)
# mask0begAndEnd0=numpy.where((mask0==0)|(mask0==1),mask0^1,mask0).astype(int)
# print(mask0begAndEnd0)
# for function0 in [numpy.trim_zeros]:
    # for trim0 in ['fb','f','b','']:
        # try:
            # print('function {}'.format(function0.__name__),'ndarray {}'.format(mask0begAndEnd0),'trim {}'.format(trim0),function0(mask0begAndEnd0.astype(int),trim=trim0),sep='  ')
        # except Exception as e:
            # print(e)
# print('numpy.r_')
# ndarray0=numpy.arange(3)
# ndarray1=numpy.arange(3,6,1)
# print(ndarray0,ndarray1,sep='\n')
# for str0 in ['r','c','0','1','2']:
    # try:
        # print('str {}'.format(str0),numpy.r_[str0,ndarray0,ndarray1],sep='\n')
    # except Exception as e:
        # print(e)
# ndarray0=numpy.expand_dims(numpy.arange(3),(0,1))
# ndarray1=numpy.expand_dims(numpy.arange(3,6,1),(0,1))
# print(ndarray0,ndarray1,sep='\n')
# for str0 in ['r','c','0','1','2','0,0','0,1','0,2','0,5','1,0','1,1','1,2','1,5','2,0','2,1','2,2','2,5','0,0,0','0,1,0','0,2,0','0,5,0','0,0,1','0,1,1','0,2,1','0,5,1','0,0,2','0,1,2','0,2,2','0,5,2']:
    # try:
        # print('str {}'.format(str0),numpy.r_[str0,ndarray0,ndarray1],sep='\n')
    # except Exception as e:
        # print(e)
# try:
    # eval('''print(numpy.r_[[50:100:5j],[50:100:5]])''')#slice doesn't need [] around it..
# except Exception as e:
    # print(e)
# try:
    # print(numpy.r_['-1,2,0',50:100:5j,50:100:5])
# except Exception as e:
    # print(e)
# try:
    # print(numpy.r_['0,2,-1',50:100:5j,50:100:5])
# except Exception as e:
    # print(e)
# print('numpy.c_')
# print(numpy.r_[50:100:5j,50:100:5])
# print(numpy.r_['-1,2,0',50:100:5j,50:100:10])
# print(numpy.c_[50:100:5j,50:100:10])
# print(numpy.r_['-1,2,0',[[1,2],[3,4]]])
# print(numpy.c_[[[1,2],[3,4]]])
# print('numpy.s_')
# print(numpy.arange(4)[2])
# print(numpy.arange(4)[numpy.s_[2]])
# print('numpy.indices')
# ndarrayDims3=numpy.arange(3*3*3).reshape(3,3,3).copy('C')
# reshapeTuple0=(2,2,2)
# try:
    # print(numpy.indices(ndarrayDims3,reshapeTuple0))
# except Exception as e:
    # print(e)
# print(numpy.indices(reshapeTuple0,dtype=float,sparse=True))
# print(numpy.indices(reshapeTuple0,dtype=float))
# print(numpy.indices(reshapeTuple0))
# print('print(numpy.indices(reshapeTuple0)[0])')
# print(numpy.indices(reshapeTuple0)[0])
# print('print(numpy.indices(reshapeTuple0)[1])')
# print(numpy.indices(reshapeTuple0)[1])
# print('print(numpy.indices(reshapeTuple0)[2])')
# print(numpy.indices(reshapeTuple0)[2])
# print(ndarrayDims3[numpy.indices(reshapeTuple0)])
# indices0=numpy.indices(reshapeTuple0)
# print('print(ndarrayDims3[indices0[0],indices0[0]])')
# print(ndarrayDims3[indices0[0],indices0[0]])
# print('print(ndarrayDims3[indices0[0],indices0[1]])')
# print(ndarrayDims3[indices0[0],indices0[1]])
# print('print(ndarrayDims3[indices0[1],indices0[0]])')
# print(ndarrayDims3[indices0[1],indices0[0]])
# print('print(ndarrayDims3[indices0[1],indices0[1]])')
# print(ndarrayDims3[indices0[1],indices0[1]])
# print('numpy.resize')
# print(numpy.resize(ndarrayDims3,reshapeTuple0))
# print(numpy.resize(ndarrayDims3,(4,4,4)))
# print(numpy.resize(ndarrayDims3,(2,3,3,3)))
# print('numpy.indices(sparse=True)')
# print(numpy.indices(reshapeTuple0,sparse=True,dtype=float))
# print(numpy.indices(reshapeTuple0,sparse=True,dtype=float))
# print(numpy.indices(reshapeTuple0,sparse=True))
# print('print(numpy.indices(reshapeTuple0,sparse=True)[0])')
# print(numpy.indices(reshapeTuple0,sparse=True)[0])
# print('print(numpy.indices(reshapeTuple0,sparse=True)[1])')
# print(numpy.indices(reshapeTuple0,sparse=True)[1])
# print('print(numpy.indices(reshapeTuple0,sparse=True)[2])')
# print(numpy.indices(reshapeTuple0,sparse=True)[2])
# print(ndarrayDims3[numpy.indices(reshapeTuple0,sparse=True)])
# indices0=numpy.indices(reshapeTuple0,sparse=True)
# print('print(ndarrayDims3[indices0[0],indices0[0]])')
# print(ndarrayDims3[indices0[0],indices0[0]])
# print('print(ndarrayDims3[indices0[0],indices0[1]])')
# print(ndarrayDims3[indices0[0],indices0[1]])
# print('print(ndarrayDims3[indices0[1],indices0[0]])')
# print(ndarrayDims3[indices0[1],indices0[0]])
# print('print(ndarrayDims3[indices0[1],indices0[1]])')
# print(ndarrayDims3[indices0[1],indices0[1]])
# print('numpy.ix_')
# ndarrayDims3=numpy.arange(3*3*3).reshape(3,3,3).copy('C')
# print(numpy.ix_([0,2],[0,2],[0,2]))
# ix_0=numpy.ix_([0,2],[0,2],[0,2])
# print(ndarrayDims3[ix_0])
# try:
    # print(numpy.ix_([[[False,True,False],[False,True,False],[False,True,False]],[[False,True,False],[False,True,False],[False,True,False]],[[False,True,False],[False,True,False],[False,True,False]]]))
# except Exception as e:
    # print(e)
# print(numpy.ix_([True,False,True],[True,False,True],[True,False,True]))
# ix_0=numpy.ix_([True,False,True],[True,False,True],[True,False,True])
# print(ndarrayDims3[ix_0])
# print('numpy.ravel_multi_index')
# ndarrayDims3=numpy.arange(3*3*3).reshape(3,3,3).copy('C')
# print(numpy.ravel_multi_index(numpy.array([1,1,1]),(2,2,2)))
# print(numpy.ravel_multi_index([1,1,1],(2,2,2)))
# print(numpy.ravel_multi_index([0,1,1],(2,2,2),order='F'))
# print(numpy.ravel_multi_index([1,1,0],(2,2,2),order='C'))
# try:
    # print(numpy.ravel_multi_index([2,2,2],(2,2,2)))
# except Exception as e:
    # print(e)
# print(numpy.ravel_multi_index([2,2,2],(2,2,2),mode='clip'))
# print(numpy.ravel_multi_index([2,2,2],(2,2,2),mode='wrap'))
# print(numpy.ravel_multi_index([2,2,2],(2,2,2),mode=('clip','clip','wrap')))
# print('numpy.unravel_index')
# print(numpy.unravel_index([7,6,0],(2,2,2),order='C'))
# print(numpy.unravel_index([7,6,0],(2,2,2),order='F'))
# print('numpy.diag_indices')
# print('numpy.diag_indices_from')
# ndarrayDims3=numpy.arange(2*2*2).reshape(2,2,2).copy('C')
# print(numpy.diag_indices(2,ndim=3))
# print(numpy.diag_indices_from(ndarrayDims3))
# diag_indices0=numpy.diag_indices(2,ndim=3)
# print(ndarrayDims3[diag_indices0])
# diag_indices0=numpy.diag_indices_from(ndarrayDims3)
# print(ndarrayDims3[diag_indices0])
# print('mask_indices')
# def maskFunction0(ndarray0,if2ThenReturnAll):
    # if if2ThenReturnAll !=2:
        # zeros0=numpy.zeros(ndarray0.shape)
        # zeros0[0]=1
        # # zeros0[zeros0.size-1]=1
        # return zeros0
    # else:
        # return ndarray0
# ndarrayDims2Side3=numpy.arange(3*3).reshape(3,3).copy('C')
# ndarrayDims2=numpy.arange(2*2).reshape(2,2).copy('C')
# for n in [ndarrayDims2,ndarrayDims2Side3]:
    # for k0 in [2,1]:
        # print(numpy.mask_indices(n.shape[0],maskFunction0,k=k0))
# print('numpy.tril_indices,numpy.triu_indices')
# for function0 in [numpy.tril_indices,numpy.triu_indices]:
    # for n0 in [-2,0,2,8]:
        # for m0 in [None,-2,0,2,8]:
            # for k0 in [None,0,-2,2]:
                # try:
                    # print('function {}'.format(function0.__name__),'n {}'.format(n0),'m {}'.format(m0),'k {}'.format(k0),function0(n0,m=m0,k=k0),sep='  ')
                # except Exception as e:
                    # print(e)
# zeros0=numpy.zeros((8,8))
# zeros0[numpy.tril_indices(8,-1)]=100
# print(zeros0)
# zeros0=numpy.zeros((8,8))
# zeros0[numpy.triu_indices(8,-1)]=100
# print(zeros0)
# print('numpy.tril_indices_from,numpy.triu_indices_from')
# for function0 in [numpy.tril_indices_from,numpy.triu_indices_from]:
    # for n0 in [numpy.zeros((2,2)),numpy.zeros((8,8)),numpy.zeros((8,8,8))]:
        # for k0 in [None,0,-2,2]:
            # try:
                # print('function {}'.format(function0.__name__),'n {}'.format(n0),'k {}'.format(k0),function0(n0,k=k0),sep='  ')
            # except Exception as e:
                # print(e)
# print('numpy.lib.stride_tricks.sliding_window_view')
# ndarrayDims2Side4=numpy.arange(4*4).reshape(4,4).copy('C')
# print(ndarrayDims2Side4)
# try:
    # print(numpy.lib.stride_tricks.sliding_window_view(ndarrayDims2Side4))
# except Exception as e:
    # print(e)
# for function0 in [numpy.lib.stride_tricks.sliding_window_view]:
    # for window_shape0 in [-2,0,1,2,4,(2,2),(3,3)]:
        # for axis0 in [-2,None,0,1,2,(0,0),(0,1),(1,0),(1,1)]:
            # print(ndarrayDims2Side4)
            # print('function {}'.format(function0.__name__),'window_shape {}'.format(window_shape0),'axis {}'.format(axis0),sep='  ')
            # try:
                # print(function0(ndarrayDims2Side4,window_shape0,axis=axis0))
            # except Exception as e:
                # print(e)
# sliding_window_view0nonWriteable=numpy.lib.stride_tricks.sliding_window_view(ndarrayDims2Side4,2,axis=0,writeable=False,subok=True)
# try:
    # sliding_window_view0nonWriteable[0]=100
# except Exception as e:
    # print(e)
# sliding_window_view0writeable=numpy.lib.stride_tricks.sliding_window_view(ndarrayDims2Side4,2,axis=0,writeable=True,subok=True)
# sliding_window_view0writeable[0,0,0]=100
# print(sliding_window_view0writeable)
# sliding_window_view0writeable[0,0]=100
# print(sliding_window_view0writeable)
# sliding_window_view0writeable[[0]]=100
# print(sliding_window_view0writeable)
# sliding_window_view0writeable[0]=100
# print(sliding_window_view0writeable)
# print('numpy.lib.stride_tricks.as_strided')
# ndarrayDims2Side4=numpy.arange(4*4).reshape(4,4).copy('C')
# print(ndarrayDims2Side4.shape)
# print(ndarrayDims2Side4.strides)
# for function0 in [numpy.lib.stride_tricks.as_strided]:
    # for shape0 in [-2,0,1,2,(3,),(5,),(2,2),(3,3),None]:
        # for strides0 in [-2,0,1,2,4,(3,),(4,),(8,),(4,4),(8,8),None]:
            # print(ndarrayDims2Side4)
            # print('function {}'.format(function0.__name__),'shape {}'.format(shape0),'strides {}'.format(strides0),sep='  ')
            # try:
                # print(function0(ndarrayDims2Side4,shape=shape0,strides=strides0))
            # except Exception as e:
                # print(e)
# print(ndarrayDims2Side4)
# print(numpy.lib.stride_tricks.as_strided(ndarrayDims2Side4,shape=(3,),strides=(8,)))
# print(numpy.lib.stride_tricks.as_strided(ndarrayDims2Side4,shape=(5,),strides=(8,)))
# print(numpy.lib.stride_tricks.as_strided(ndarrayDims2Side4,shape=(3,),strides=(16,)))
# as_strided0nonWriteable=numpy.lib.stride_tricks.as_strided(ndarrayDims2Side4,shape=(3,),strides=(16,),subok=True,writeable=False)
# print(as_strided0nonWriteable)
# try:
    # as_strided0nonWriteable[0]=100
# except Exception as e:
    # print(e)
# print(as_strided0nonWriteable)
# as_strided0writeable=numpy.lib.stride_tricks.as_strided(ndarrayDims2Side4,shape=(3,),strides=(16,),subok=True,writeable=True)
# print(as_strided0writeable)
# as_strided0writeable[0]=100
# print(as_strided0writeable)
# print('numpy.place,numpy.putmask')
# ndarrayDims2Side4=numpy.arange(4*4).reshape(4,4).copy('C')
# mask0=numpy.zeros_like(ndarrayDims2Side4)
# mask0[:,0]=1
# # vals0=[100,200]
# print(ndarrayDims2Side4)
# for function0 in [numpy.place,numpy.putmask]:#different in 2+-D!
    # for vals0 in [[100,200],[[100],[200]]]:
        # ndarrayDims2Side4=numpy.arange(4*4).reshape(4,4).copy('C')
        # print('function {}'.format(function0.__name__),'mask {}'.format(mask0),'vals {}'.format(vals0),sep='  ')
        # try:
            # print(function0(ndarrayDims2Side4,mask0,vals0))
        # except Exception as e:
            # print(e)
        # print(ndarrayDims2Side4)
# n0=numpy.arange(6)
# print(n0)
# numpy.putmask(n0,n0>1,[-33,-44])
# print(n0)
# n0=numpy.arange(6)
# print(n0)
# numpy.place(n0,n0>1,[-33,-44])
# print(n0)
# n0=numpy.arange(6).reshape(2,3).copy('C')
# print(n0)
# numpy.putmask(n0,n0>1,[-33,-44])
# print(n0)
# n0=numpy.arange(6).reshape(2,3).copy('C')
# print(n0)
# numpy.place(n0,n0>1,[-33,-44])
# print(n0)
# n0=numpy.arange(6)
# print('numpy.extract')
# print(numpy.extract(n0>1,n0))
# print('numpy.fill_diagonal')
# ndarrray0tall=numpy.arange(8*4).reshape(8,4).copy('C')
# ndarrray0tall2=numpy.arange(8*2*2).reshape(8,2,2).copy('C')
# ndarrray0tall21=numpy.arange(4*4*4).reshape(4,4,4).copy('C')
# ndarrray0tall3=numpy.arange(8).copy('C')
# print(ndarrray0tall)
# for ndarrray0tall0 in [ndarrray0tall,ndarrray0tall2,ndarrray0tall21,ndarrray0tall3]:
    # for val0 in [100,[100,200],[100,200,300,400,500,600]]:
        # for wrap0 in [None,False,True]:
            # ndarrray0tall=numpy.arange(8*4).reshape(8,4).copy('C')
            # ndarrray0tall2=numpy.arange(8*2*2).reshape(8,2,2).copy('C')
            # ndarrray0tall3=numpy.arange(8).copy('C')
            # print('ndarrray0tall shape {}'.format(ndarrray0tall0.shape),'val {}'.format(val0),'wrap {}'.format(wrap0),sep='  ')
            # try:
                # print(numpy.fill_diagonal(ndarrray0tall0,val0,wrap=wrap0))
            # except Exception as e:
                # print(e)
            # print(ndarrray0tall0)
# print('numpy.nditer')
# ndarrayDims2Side4=numpy.arange(2*4).reshape(2,4).copy('C')
# ndarrayDims2Side42=numpy.arange(2*4).reshape(2,4).copy('C')
# out0=None
# nditer0=numpy.nditer([ndarrayDims2Side4,ndarrayDims2Side42,out0],flags=['buffered','copy_if_overlap'],op_flags=[['readonly'],['readonly'],['writeonly','allocate']],op_dtypes=('i8','i8','f8'),casting='unsafe',order='F',op_axes=[[1,0],[1,0],[0,1]],itershape=(4,2),buffersize=0)
# operation0=numpy.add
# with nditer0:
    # for (a,b,c) in nditer0:
        # operation0(a,b,out=c)
    # print(ndarrayDims2Side4,ndarrayDims2Side42,out0,nditer0.operands[2],sep='\n')
    # # print(nditer0.dtypes)
    # for attribute0 in ['dtypes','itersize','shape','ndim','nop','operands','itviews','value','has_delayed_bufalloc','has_index','has_multi_index','index','iterindex','multi_index','iterationneedsapi','finished']:
        # print(attribute0)
        # try:
            # print(getattr(nditer0,attribute0))
        # except Exception as e:
            # print(e)
        # print('\n\n')
    # nditer0.reset()
    # print('''nditer0.reset() was called''')
    # for attribute0 in ['dtypes','itersize','shape','ndim','nop','operands','itviews','value','has_delayed_bufalloc','has_index','has_multi_index','index','iterindex','multi_index','iterationneedsapi','finished']:
        # print(attribute0)
        # try:
            # print(getattr(nditer0,attribute0))
        # except Exception as e:
            # print(e)
        # print('\n\n')
    # for method0 in [nditer0.reset,nditer0.iternext,nditer0.debug_print,nditer0.enable_external_loop,nditer0.copy,nditer0.remove_axis,nditer0.remove_multi_index,nditer0.close]:
        # print(method0.__name__)
        # if method0==nditer0.remove_axis:
            # # method0(1)
            # try:
                # print(method0(1))
            # except Exception as e:
                # print(e)
            # print(nditer0)
        # else:
            # try:
                # print(method0())
            # except Exception as e:
                # print(e)
            # print(nditer0)
        # print('\n\n')
# nditer0=numpy.nditer([ndarrayDims2Side4,ndarrayDims2Side42,out0],flags=['buffered','copy_if_overlap','c_index','multi_index'],op_flags=[['readonly'],['readonly'],['writeonly','allocate']],op_dtypes=('i8','i8','f8'),casting='unsafe',order='F',op_axes=[[1,0],[1,0],[0,1]],itershape=(4,2),buffersize=0)
# with nditer0:
    # for (a,b,c) in nditer0:
        # operation0(a,b,out=c)
    # print(ndarrayDims2Side4,ndarrayDims2Side42,out0,nditer0.operands[2],sep='\n')
    # print(nditer0.reset())
    # for method0 in [nditer0.reset,nditer0.iternext,nditer0.debug_print,nditer0.enable_external_loop,nditer0.copy,nditer0.remove_axis,nditer0.remove_multi_index]:
        # print(method0.__name__)
        # if method0==nditer0.remove_axis:
            # # method0(1)
            # try:
                # print(method0(1))
            # except Exception as e:
                # print(e)
            # print(nditer0)
        # else:
            # try:
                # print(method0())
            # except Exception as e:
                # print(e)
            # print(nditer0)
        # print('\n\n')
    # print('''after most methods were called''')
    # for attribute0 in ['dtypes','itersize','shape','ndim','nop','operands','itviews','value','has_delayed_bufalloc','has_index','has_multi_index','index','iterindex','multi_index','iterationneedsapi','finished']:
        # print(attribute0)
        # try:
            # print(getattr(nditer0,attribute0))
        # except Exception as e:
            # print(e)
        # print('\n\n')
# print('numpy.ndenumerate')
# ndarrayDims2Side4=numpy.arange(2*4).reshape(2,4).copy('C')
# print(numpy.ndenumerate(ndarrayDims2Side4))
# ndenumerate0=numpy.ndenumerate(ndarrayDims2Side4)
# for index,value in ndenumerate0:
    # print(index,value)
# print('numpy.ndindex')
# ndarrayDims2Side4shape=numpy.arange(2*4).reshape(2,4).copy('C').shape
# print(numpy.ndindex(ndarrayDims2Side4shape))
# ndindex0=numpy.ndindex(ndarrayDims2Side4shape)
# for index in ndindex0:
    # print(index)
# ndindex0=numpy.ndindex(ndarrayDims2Side4shape)
# for index in ndindex0:
    # print(index)
    # try:
        # ndindex0.ndincr()
        # ndindex0.ndincr()
    # except Exception as e:
        # print(e)
# print('numpy.nested_iters')
# ndarrayDims3Side4=numpy.arange(2*3*4).reshape(2,3,4).copy('C')
# print(numpy.nested_iters([ndarrayDims3Side4,ndarrayDims3Side4],[[2],[1],[0]],flags=['multi_index']))
# nested_iters2,nested_iters1,nested_iters0=numpy.nested_iters([ndarrayDims3Side4,ndarrayDims3Side4],[[2],[1],[0]],flags=['multi_index'])
# # for axis2itme0,axis1itme0,axis0itme0 in nested_iters2,nested_iters1,nested_iters0:
# for axis2itme0 in nested_iters2:
    # # print(axis2itme0,axis1itme0,axis0itme0)
    # print('22222        ',axis2itme0)
    # for axis1itme0 in nested_iters1:
        # print('11111        ',axis1itme0)
        # for axis0itme0 in nested_iters0:
            # print('00000        ',axis0itme0)
# print('numpy.lib.Arrayterator')
# ndarrayDims3=numpy.arange(3*3*3).reshape(3,3,3).copy('C')
# print(numpy.lib.Arrayterator(ndarrayDims3,2))
# arrayterator0=numpy.lib.Arrayterator(ndarrayDims3,2)
# for attribute0 in ['start','stop','step','var','buf_size','shape','flat']:
    # print(attribute0,getattr(arrayterator0,attribute0))
# for block0 in arrayterator0:
    # print(block0,block0.shape)
# for block0 in arrayterator0.flat:
    # print(block0,block0.shape)

# ndarrayDims3=numpy.arange(3*3*3).reshape(3,3,3).copy('C')
# print(numpy.lib.Arrayterator(ndarrayDims3,2))
# arrayterator0=numpy.lib.Arrayterator(ndarrayDims3,4)
# for attribute0 in ['start','stop','step','var','buf_size','shape','flat']:
    # print(attribute0,getattr(arrayterator0,attribute0))
# for block0 in arrayterator0:
    # print(block0,block0.shape)
# for block0 in arrayterator0.flat:
    # print(block0,block0.shape)


# ndarrayDims3=numpy.arange(3*3*3).reshape(3,3,3).copy('C')
# print(numpy.lib.Arrayterator(ndarrayDims3,2))
# arrayterator0=numpy.lib.Arrayterator(ndarrayDims3,6)
# for attribute0 in ['start','stop','step','var','buf_size','shape','flat']:
    # print(attribute0,getattr(arrayterator0,attribute0))
# for block0 in arrayterator0:
    # print(block0,block0.shape)
# for block0 in arrayterator0.flat:
    # print(block0,block0.shape)
# print('numpy.iterable')
# import collections.abc
# print(dir(collections.abc))
# for object0 in (dir(collections.abc)+[numpy.arange(3)]+[numpy.squeeze(numpy.arange(1))]+[3]):
    # try:
        # print(object0,isinstance(object0,collections.abc.Iterable),sep='         ')
        # print(object0,numpy.iterable(object0),sep='         ')
    # except Exception as e:
        # print(e)
# list0=list(range(2))
# print(list0)
# value1=list0[1]
# print(value1)
# value1=100
# print(value1)
# print(list0)
# n0=numpy.arange(2)
# print(n0[1])
# print(n0[1:])
# import numpy.lib.recfunctions
# print('numpy.lib.recfunctions.repack_fields')
# dtype0=numpy.dtype([('bytes5','=S5'),('subBytes7','=S7',(3,3,3)),('subFloat8','=f8',(3,3,3)),('bytes1','=S1'),('integer4','=i4')],align=False)
# for attribute0 in ['names','fields']:
    # print(getattr(dtype0,attribute0))
# print(dtype0.itemsize,dtype0)
# print(numpy.lib.recfunctions.repack_fields(dtype0,align=True))
# print(numpy.lib.recfunctions.repack_fields(dtype0,align=False))
# for attribute0 in ['names','fields']:
    # print(getattr(dtype0,attribute0))
# print(numpy.lib.recfunctions.repack_fields(dtype0,align=False,recurse=True))
# for attribute0 in ['names','fields']:
    # print(getattr(dtype0,attribute0))

# print('dtype.titles')
# dtype0=numpy.dtype([(('titleForbytes5','bytes5'),'=S5'),(('titleForsubBytes7','subBytes7'),'=S7',(3,3,3)),('subFloat8','=f8',(3,3,3)),('bytes1','=S1'),('integer4','=i4')],align=False)
# try:
    # print(dtype0.titles)
# except Exception as e:
    # print(e)
# for attribute0 in ['names','fields']:
    # print(getattr(dtype0,attribute0))

# print(numpy.dtype('i4,3i4,(3,3)i4'))

# print(numpy.sctypeDict.keys())

# print(numpy.dtype(('S',4)))
# print(numpy.dtype(('U',5)))
# print(numpy.dtype(('V',6)))

# print(numpy.dtype([(('title0','name0'),'>f4',(2,2,1))]))

# try:
    # print(numpy.dtype({'titles':['title0',None],'names':['name0','name1'],'formats':['U9','>f4'],'offsets':[0,12],'itemsize':24}))
# except Exception as e:
    # print(e)
# print(numpy.dtype({'titles':['title0',None],'names':['name0','name1'],'formats':['U9','>f4'],'offsets':[0,12],'itemsize':36}))

# print(numpy.dtype({'item0':('U9',0,'title0'),'item1':('>f4',12,None)}))

# print(numpy.dtype((numpy.uint64,{'real0':(numpy.uint32,0),'imag0':(numpy.uint32,4)})))
# print(type(numpy.dtype((numpy.uint64,{'real0':(numpy.uint32,0),'imag0':(numpy.uint32,4)}))))

# print(numpy.zeros(1,dtype=numpy.dtype([(('titleForbytes5','bytes5'),'=S5'),(('titleForsubBytes7','subBytes7'),'=S7',(3,3,3)),('subFloat8','=f8',(3,3,3)),('bytes1','=S1'),('integer4','=i4')],align=False)))
# zeros0on10=numpy.zeros(1,dtype=numpy.dtype([(('titleForbytes5','bytes5'),'=S5'),(('titleForsubBytes7','subBytes7'),'=S7',(3,3,3)),('subFloat8','=f8',(3,3,3)),('bytes1','=S1'),('integer4','=i4')],align=False))
# zeros0on10[:]=9
# print(zeros0on10)
# arangeOf20=numpy.arange(2)
# arangeOf20=zeros0on10
# print('print(arangeOf20)')
# print(arangeOf20)
# print(numpy.zeros(2,dtype=numpy.dtype([(('titleForbytes5','bytes5'),'=S5'),(('titleForsubBytes7','subBytes7'),'=S7',(3,3,3)),('subFloat8','=f8',(3,3,3)),('bytes1','=S1'),('integer4','=i4')],align=False)))
# zeros0on20=numpy.zeros(2,dtype=numpy.dtype([(('titleForbytes5','bytes5'),'=S5'),(('titleForsubBytes7','subBytes7'),'=S7',(3,3,3)),('subFloat8','=f8',(3,3,3)),('bytes1','=S1'),('integer4','=i4')],align=False))
# zeros0on20copy=zeros0on20.copy('C')
# zeros0on20[:]=numpy.arange(2)
# print(zeros0on20)
# try:
    # zeros0on20[:]=(11,13)
# except Exception as e:
    # print(e)
# zeros0on20[:]=(11,13,15,17,19)
# print(zeros0on20)
# zeros0on20[:]=zeros0on20copy
# print(zeros0on20)
# arangeOf20=numpy.arange(2)
# try:
    # arangeOf20=zeros0on20
# except Exception as e:
    # print(e)

# scalar0=numpy.array([(1,5,10)],dtype='i4,i4,i4')
# print(scalar0)
# print(scalar0[0])
# try:
    # print(scalar0[1])
# except Exception as e:
    # print(e)

# scalar0=numpy.array([(1,5,10)],dtype='i4,i4,i4')[0]
# print(scalar0)
# print(scalar0[0])
# print(scalar0[1])

# try:
    # scalar0=numpy.array([(1,5,10)],dtype='i4,i4,i4')[1]
# except Exception as e:
    # print(e)
# scalar0=numpy.array([(1,5,10),(2,6,11)],dtype='i4,i4,i4')[1]
# print(scalar0)
# print(type(scalar0),type(scalar0.item()),scalar0.item(),sep='\n')

# zeros0on20=numpy.zeros(3,dtype=numpy.dtype([(('titleForbytes5','bytes5'),'=S5'),(('titleForsubBytes7','subBytes7'),'=S7',(3,3,3)),('bytes1','=S1'),('integer4','=i4')],align=True))
# print(zeros0on20)
# print(zeros0on20['bytes5'])
# print(zeros0on20[['bytes5','integer4']])
# print(zeros0on20[['integer4','bytes5']])
# zeros0on20[['integer4','bytes5']]=19
# print(zeros0on20)

# ones0on20=numpy.ones(3,dtype=numpy.dtype([(('titleForbytes5','bytes5'),'=S5'),(('titleForsubBytes7','subBytes7'),'=S7',(3,3,3)),('bytes1','=S1'),('integer4','=i4')],align=True))
# ones0on20[['integer4','bytes5']]=19
# print(ones0on20)

# print(numpy.array([(1,1),(2,2),(3,3)],dtype=numpy.dtype('i4,i8')))
# try:
    # print(numpy.array([(1,1,1),(2,2,2),(3,3,3)],dtype=numpy.dtype('i4,i8')))
# except Exception as e:
    # print(e)

# a0=numpy.array([(1,1),(2,2),(3,3)],dtype=numpy.dtype('i4,i8'))
# a1=numpy.array([(1,1),(2,2),(3,3)],dtype=numpy.dtype('f4,f8'))
# print(a0==a1)
# print(numpy.result_type(a0.dtype,a1.dtype))

# a0=numpy.array([(1,1),(2,2),(3,3)],dtype=numpy.dtype('i4,i8',align=True))
# a1=numpy.array([(1,1),(2,2),(3,3)],dtype=numpy.dtype('f4,f8'))
# print(a0==a1)
# print(numpy.result_type(a0.dtype,a1.dtype))

# a0=numpy.array([(1,1),(2,2),(3,4)],dtype=numpy.dtype('i4,i8'))
# a1=numpy.array([(1,1),(2,2),(3,3)],dtype=numpy.dtype('f4,f8'))
# print(a0==a1)

# a0=numpy.array([(3,b'str0')],dtype=numpy.dtype('i4,V'))
# a1=numpy.array([(3,b'str1')],dtype=numpy.dtype('f4,V'))
# try:
    # print(a0==a1)
# except Exception as e:
    # print(e)

# # # # a0=numpy.array([(3,numpy.lib.index_tricks)],dtype=numpy.dtype('i4',object_))
# # # # a1=numpy.array([(3,numpy.lib.index_tricks)],dtype=numpy.dtype('f4,V8'))
# # # # try:
    # # # # print(a0==a1)
# # # # except Exception as e:
    # # # # print(e)









# import numpy.lib.recfunctions
# a0=numpy.array([(1,1),(2,2),(3,3)],dtype=numpy.dtype('i4,i8'))
# try:
    # print(numpy.lib.recfunctions.append_fields(a0,names=['int2,float0'],data=[4,5.],dtypes=None,fill_value=-1,usemask=True,asrecarray=False))
# except Exception as e:
    # print(e)
# print(numpy.lib.recfunctions.append_fields(a0,names=['int2','float0'],data=[4,5.],dtypes=None,fill_value=-1,usemask=True,asrecarray=False))
# print(a0.dtype)
# print(numpy.lib.recfunctions.append_fields(a0,names=['int2','float0'],data=[4,5.],dtypes=[int,float],fill_value=10,usemask=False,asrecarray=False))
# print(numpy.lib.recfunctions.append_fields(a0,names=['int2','float0'],data=[(4,4,4),(5,5,5)],dtypes=[int,complex],fill_value=0,usemask=False,asrecarray=False))
# print(numpy.lib.recfunctions.append_fields(a0,names=['int2','float0'],data=[(4,4,4),(5,5,5)],dtypes=[int,complex],fill_value=1000,usemask=False,asrecarray=False))
# print(numpy.lib.recfunctions.append_fields(a0,names=['int2','float0'],data=[(4,4,4),(5,5,5)],dtypes=[int,complex],fill_value=1000,usemask=False,asrecarray=True))
# try:
    # print(a0['float0'])
# except Exception as e:
    # print(e)
# try:
    # print(a0.float0)
# except Exception as e:
    # print(e)
# a0=numpy.lib.recfunctions.append_fields(a0,names=['int2','float0'],data=[(4,4,4),(5,5,5)],dtypes=[int,complex],fill_value=1000,usemask=False,asrecarray=True)
# print(a0['float0'])
# print(a0.float0)

# def customAdd0(input0,axis=-1):
    # output0=(input0+1)*2
    # return output0
# vectorizedcustomAdd0=numpy.vectorize(customAdd0)
# print(a0)
# print(numpy.lib.recfunctions.apply_along_fields(vectorizedcustomAdd0,a0))
# print(a0)
# a0=numpy.lib.recfunctions.apply_along_fields(vectorizedcustomAdd0,a0)
# print(a0)

# print('numpy.lib.recfunctions.assign_fields_by_name')
# a0=numpy.array([(1,1),(2,2),(3,3)],dtype=numpy.dtype('i4,i8'))
# a0=numpy.lib.recfunctions.append_fields(a0,names=['int2','float0'],data=[(4,4,4),(5,5,5)],dtypes=[int,complex],fill_value=1000,usemask=False,asrecarray=False)
# try:
    # print(a0.names)
# except Exception as e:
    # print(e)
# print(a0.dtype.names)
# a1=numpy.array([(11,11),(12,12),(13,13)],dtype=numpy.dtype({'names':['float0','int50'],'formats':['f4','i4']}))
# print(numpy.lib.recfunctions.assign_fields_by_name(a0,a1))
# print(a0)
# a0=numpy.array([(1,1),(2,2),(3,3)],dtype=numpy.dtype('i4,i8'))
# a0=numpy.lib.recfunctions.append_fields(a0,names=['int2','float0'],data=[(4,4,4),(5,5,5)],dtypes=[int,complex],fill_value=1000,usemask=False,asrecarray=False)
# print(numpy.lib.recfunctions.assign_fields_by_name(a0,a1,zero_unassigned=True))
# print(a0)
# a0=numpy.array([(1,1),(2,2),(3,3)],dtype=numpy.dtype('i4,i8'))
# a0=numpy.lib.recfunctions.append_fields(a0,names=['int2','float0'],data=[(4,4,4),(5,5,5)],dtypes=[int,complex],fill_value=1000,usemask=False,asrecarray=False)
# print(numpy.lib.recfunctions.assign_fields_by_name(a0,a1,zero_unassigned=False))
# print(a0)
# a0=numpy.array([(1,1),(2,2),(3,3)],dtype=numpy.dtype('i4,i8'))
# a0=numpy.lib.recfunctions.append_fields(a0,names=['int2','float0'],data=[(4,4,4),(5,5,5)],dtypes=[int,complex],fill_value=1000,usemask=False,asrecarray=False)
# a0=numpy.lib.recfunctions.assign_fields_by_name(a0,a1,zero_unassigned=False)
# print(a0)

# a1=numpy.array([(11,11),(12,12),(13,13)],dtype=numpy.dtype({'names':['float0','int50'],'formats':['f4','i4']}))
# print(numpy.lib.recfunctions.drop_fields(a1,['float0','int50'],usemask=False))
# print(numpy.lib.recfunctions.drop_fields(a1,['float0','int50']))
# print(numpy.lib.recfunctions.drop_fields(a1,'int50'))
# print(numpy.lib.recfunctions.drop_fields(a1,'int50',usemask=True,asrecarray=False))
# print(numpy.lib.recfunctions.drop_fields(a1,'int50',usemask=False,asrecarray=False))
# print(numpy.lib.recfunctions.drop_fields(a1,'int50',usemask=False,asrecarray=True))
# a1=numpy.lib.recfunctions.drop_fields(a1,'int50',usemask=False,asrecarray=True)
# print(a1.dtype.names)
# print(a1.float0)


# print('numpy.lib.recfunctions.find_duplicates')
# ndtype0 = [('a', int)]
# a0 = numpy.ma.array([1, 1, 1, 2, 2, 3, 3],mask=[0, 0, 1, 0, 0, 0, 1]).view(ndtype0)
# print(numpy.lib.recfunctions.find_duplicates(a0, ignoremask=True, return_index=True))
# print(numpy.lib.recfunctions.find_duplicates(a0, ignoremask=False, return_index=True))
# print(numpy.lib.recfunctions.find_duplicates(a0))
# ndtype0 = [('a', int),('b', int)]
# a0 = numpy.ma.array([(1, 1), (1, 2)],mask=[0, 1,0, 1]).view(ndtype0)
# print(numpy.lib.recfunctions.find_duplicates(a0))

# dtype0=numpy.dtype({'names':['float0','int50'],'formats':['f4','i4']})
# dtype0=numpy.dtype([('float0','f4'),('int50','i4')])
# a1=numpy.ma.array([(11,11),(12,12),(13,13)]).view(dtype0)
# a1=numpy.ma.array([(11,11),(12,12),(13,13),(13,13),(13,13),(14,13)],dtype=numpy.dtype({'names':['float0','int50'],'formats':['f4','i4']}))
# try:
    # print(numpy.lib.recfunctions.find_duplicates(a1))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.lib.recfunctions.find_duplicates(a1,return_index=True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.lib.recfunctions.find_duplicates(a1,key='float0',return_index=True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.lib.recfunctions.find_duplicates(a1,key='float0',ignoremask=False,return_index=True))
# except Exception as e:
    # print(e)
# a1=numpy.ma.array([(11,11),(12,12),(13,13)],dtype=numpy.dtype({'names':['float0','int50'],'formats':['f4','i4']}))
# try:
    # print(numpy.lib.recfunctions.find_duplicates(a1))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.lib.recfunctions.find_duplicates(a1,return_index=True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.lib.recfunctions.find_duplicates(a1,key='float0',return_index=True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.lib.recfunctions.find_duplicates(a1,key='float0',ignoremask=False,return_index=True))
# except Exception as e:
    # print(e)
# a1=numpy.array([(11,11),(12,12),(13,13)],dtype=numpy.dtype({'names':['float0','int50'],'formats':['f4','i4']}))
# try:
    # print(numpy.lib.recfunctions.find_duplicates(a1))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.lib.recfunctions.find_duplicates(a1,return_index=True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.lib.recfunctions.find_duplicates(a1,key='float0',return_index=True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.lib.recfunctions.find_duplicates(a1,key='float0',ignoremask=False,return_index=True))
# except Exception as e:
    # print(e)

# print('numpy.lib.recfunctions.flatten_descr')
# dtype0=numpy.dtype({'titles':['title0',None],'names':['name0','name1'],'formats':['U9','>f4'],'offsets':[0,12],'itemsize':36})
# try:
    # print(numpy.lib.recfunctions.flatten_descr(dtype0))
# except Exception as e:
    # print(e)
# dtype0=numpy.dtype({'names':['name0','name1'],'formats':['U9','>f4']})
# print(numpy.lib.recfunctions.flatten_descr(dtype0))

# print('numpy.lib.recfunctions.get_fieldstructure')
# dtype0=numpy.dtype([('level0',[('level00',[('level000','f4')])]),('level1','f4')])
# print(numpy.lib.recfunctions.get_fieldstructure(dtype0))
# print(numpy.lib.recfunctions.get_fieldstructure(dtype0,lastname='level0'))
# print(numpy.lib.recfunctions.get_fieldstructure(dtype0,parents={'level00':['level0']}))

# print('numpy.lib.recfunctions.get_names')
# print(numpy.lib.recfunctions.get_names(dtype0))
# print(numpy.lib.recfunctions.get_names_flat(dtype0))
# dtype1=numpy.dtype('i4','i8')
# try:
    # print(numpy.lib.recfunctions.get_names(dtype1))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.lib.recfunctions.get_names_flat(dtype1))
# except Exception as e:
    # print(e)


# print('numpy.lib.recfunctions.join_by')
# a0=numpy.array([(0,'a'),(1,'b'),(2,'c'),(3,'d')],dtype=numpy.dtype({'names':['float0','unicode0'],'formats':['f4','U1']}))
# a1=numpy.array([(0,11),(1,12),(2,13),(3,14)],dtype=numpy.dtype({'names':['float0','int50'],'formats':['f4','i4']}))
# print(numpy.lib.recfunctions.join_by('float0',a0,a1))
# a0=numpy.array([(0,'a'),(1,'b'),(3,'c'),(3,'d')],dtype=numpy.dtype({'names':['float0','unicode0'],'formats':['f4','U1']}))
# a1=numpy.ma.array([(0,11,'a'),(1,12,'b'),(4,13,'c'),(3,14,'d')],mask=[0,0,0,1],dtype=numpy.dtype({'names':['float0','int50','unicode0'],'formats':['f4','i4','U1']}))
# print('a0'+str(a0),'a1'+str(a1),sep='\n')
# print(numpy.lib.recfunctions.join_by('float0',a0,a1,jointype='inner',r1postfix='thisIsA0',r2postfix='thisIsA1',defaults={'unicode0':'z'},usemask=True,asrecarray=True))

# a0=numpy.array([(0,'a'),(1,'b'),(2,'c'),(3,'d')],dtype=numpy.dtype({'names':['float0','unicode0'],'formats':['f4','U1']}))
# a1=numpy.ma.array([(0,11,'a'),(1,12,'b'),(4,13,'c'),(3,14,'d')],mask=[0,0,0,1],dtype=numpy.dtype({'names':['float0','int50','unicode0'],'formats':['f4','i4','U1']}))
# print('a0'+str(a0),'a1'+str(a1),sep='\n')
# print(numpy.lib.recfunctions.join_by('float0',a0,a1,jointype='inner',r1postfix='thisIsA0',r2postfix='thisIsA1',defaults={'unicode0':'z'},usemask=True,asrecarray=True))
# print(numpy.lib.recfunctions.join_by('float0',a0,a1,jointype='outer',r1postfix='thisIsA0',r2postfix='thisIsA1',defaults={'unicode0':'z'},usemask=True,asrecarray=True))
# print(numpy.lib.recfunctions.join_by('float0',a0,a1,jointype='leftouter',r1postfix='thisIsA0',r2postfix='thisIsA1',defaults={'unicode0':'z'},usemask=True,asrecarray=True))

# a0=numpy.array([(0,'a'),(1,'b'),(2,'c'),(3,'d')],dtype=numpy.dtype({'names':['float0','unicode0'],'formats':['f4','U1']}))
# a1=numpy.ma.array([(0,11,'a'),(1,12,'b'),(None,13,'c'),(3,14,'d')],mask=[0,0,0,1],dtype=numpy.dtype({'names':['float0','int50','unicode0'],'formats':['f4','i4','U1']}))
# print('a0'+str(a0),'a1'+str(a1),sep='\n')
# print(numpy.lib.recfunctions.join_by('float0',a0,a1,jointype='inner',r1postfix='thisIsA0',r2postfix='thisIsA1',defaults={'unicode0':'z'},usemask=True,asrecarray=True))
# print(numpy.lib.recfunctions.join_by('float0',a0,a1,jointype='outer',r1postfix='thisIsA0',r2postfix='thisIsA1',defaults={'unicode0':'z'},usemask=True,asrecarray=True))
# print(numpy.lib.recfunctions.join_by('float0',a0,a1,jointype='leftouter',r1postfix='thisIsA0',r2postfix='thisIsA1',defaults={'unicode0':'z'},usemask=True,asrecarray=True))

# a0=numpy.array([(0,'a'),(1,'b'),(2,'c'),(3,'d')],dtype=numpy.dtype({'names':['float0','unicode0'],'formats':['f4','U1']}))
# a1=numpy.ma.array([(0,11,'a'),(1,12,'b'),(4,13,'c'),(3,14,'d')],mask=[0,0,0,1],dtype=numpy.dtype({'names':['float0','int50','unicode0'],'formats':['f4','i4','U1']}))
# print('numpy.lib.recfunctions.merge_arrays')
# print(numpy.lib.recfunctions.merge_arrays([a0,a1]))
# try:
    # print(numpy.lib.recfunctions.merge_arrays([a0,a1],fill_value=-2.,flatten=True,usemask=True,asrecarray=True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.lib.recfunctions.merge_arrays([a0,a1],fill_value=-2.,usemask=True,asrecarray=True))
# except Exception as e:
    # print(e)
# print(numpy.lib.recfunctions.merge_arrays([a0,a1],fill_value=-2.,asrecarray=True))
# a0=numpy.array([('a'),('b'),('c'),('d')],dtype=numpy.dtype({'names':['unicode0'],'formats':['U1']}))
# a1=numpy.array([(0),(1),(2),(3),(4)],dtype=numpy.dtype({'names':['float0'],'formats':['f4']}))
# print(numpy.lib.recfunctions.merge_arrays([a0,a1],fill_value=-2.,flatten=True,usemask=True,asrecarray=True))
# print(numpy.lib.recfunctions.merge_arrays([a0,a1],fill_value=-2.,flatten=True,usemask=False,asrecarray=True))


# print('numpy.lib.recfunctions.rec_append_fields')
# a0=numpy.array([(1,1),(2,2),(3,3)],dtype=numpy.dtype('i4,i8'))
# print(numpy.lib.recfunctions.rec_append_fields(a0,names=['int2','float0'],data=[(4,4,4),(5,5,5)],dtypes=[int,float]))
# a0=numpy.lib.recfunctions.rec_append_fields(a0,names=['int2','float0'],data=[(4,4,4),(5,5,5)],dtypes=[int,float])
# print(a0['float0'])
# print(a0.float0)


# print('numpy.lib.recfunctions.rec_drop_fields')
# print(a0)
# a0=numpy.lib.recfunctions.rec_drop_fields(a0,'int2')
# print(a0.dtype.names)
# print(a0)


# print('numpy.lib.recfunctions.rec_join')
# a0=numpy.array([(0,'a'),(1,'b'),(2,'c'),(3,'d')],dtype=numpy.dtype({'names':['float0','unicode0'],'formats':['f4','U1']}))
# a1=numpy.ma.array([(0,11,'a'),(1,12,'b'),(None,13,'c'),(3,14,'d')],mask=[0,0,0,1],dtype=numpy.dtype({'names':['float0','int50','unicode0'],'formats':['f4','i4','U1']}))
# print('a0'+str(a0),'a1'+str(a1),sep='\n')
# print(numpy.lib.recfunctions.rec_join('float0',a0,a1,jointype='inner',r1postfix='thisIsA0',r2postfix='thisIsA1',defaults={'unicode0':'z'}))
# print(numpy.lib.recfunctions.rec_join('float0',a0,a1,jointype='outer',r1postfix='thisIsA0',r2postfix='thisIsA1',defaults={'unicode0':'z'}))
# print(numpy.lib.recfunctions.rec_join('float0',a0,a1,jointype='leftouter',r1postfix='thisIsA0',r2postfix='thisIsA1',defaults={'unicode0':'z'}))

# print('numpy.lib.recfunctions.recursive_fill_fields')
# dtype0=numpy.dtype({'names':['float0','unicode0'],'formats':['f4','U1']})
# a0=numpy.array([(0,'a'),(1,'b'),(2,'c'),(3,'e')],dtype=dtype0)
# a1=numpy.empty((3,3))
# try:
    # print(numpy.lib.recfunctions.recursive_fill_fields(a0,a1))
# except Exception as e:
    # print(e)
# a1=numpy.empty((4,4))
# try:
    # print(numpy.lib.recfunctions.recursive_fill_fields(a0,a1))
# except Exception as e:
    # print(e)
# a1=numpy.empty((2,2),dtype=dtype0)
# try:
    # print(numpy.lib.recfunctions.recursive_fill_fields(a0,a1))
# except Exception as e:
    # print(e)
# a1=numpy.empty((4,4),dtype=dtype0)
# print(numpy.lib.recfunctions.recursive_fill_fields(a0,a1))
# a2=numpy.ma.array([(0,11,'a'),(1,12,'b'),(None,13,'c'),(3,14,'d')],mask=[0,0,0,1],dtype=numpy.dtype({'names':['float0','int50','unicode0'],'formats':['f4','i4','U1']}))
# print(numpy.lib.recfunctions.recursive_fill_fields(a0,a2))


# print('numpy.lib.recfunctions.rename_fields')
# dtype0=numpy.dtype([('level0',[('level00',[('level000','f4')])]),('level1','f4')])
# a0=numpy.empty((4,),dtype=dtype0)
# print(a0.dtype.fields,end='\n\n')
# print(numpy.lib.recfunctions.rename_fields(a0,{'level0':'stage0','level000':'stage000'}),end='\n\n')
# print(numpy.lib.recfunctions.rename_fields(a0,{'level0':'stage0','level000':'stage000'}).dtype.fields)


# print('numpy.lib.recfunctions.require_fields')
# dtype0=numpy.dtype([('level0',[('level00',[('level000','f4')])]),('level1','f4')])
# a0=numpy.ones((4,),dtype=dtype0)
# a0=111
# try:
    # print(numpy.lib.recfunctions.require_fields(a0,numpy.dtype([('level0',[('level00',[('level000','f4')])]),('level1','f4')])))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.lib.recfunctions.require_fields(a0,numpy.dtype([('level0','f4')])))
# except Exception as e:
    # print(e)
# dtype0=numpy.dtype([('level0','f4'),('level1','f4')])
# a0=numpy.ones((4,4),dtype=dtype0)
# print(a0)
# a0=(111,112)#assignment overrides entire dtype..
# print(a0)
# a0=numpy.ones((4,4),dtype=dtype0)
# a0[:]=(111,112)
# print(a0)
# print(numpy.lib.recfunctions.require_fields(a0,numpy.dtype([('level1','f4')])))
# print(numpy.lib.recfunctions.require_fields(a0,numpy.dtype([('level1','f4'),('level1new','f4')])))
# a = numpy.ones(4, dtype=[('a', 'i4'), ('b', 'f8'), ('c', 'u1')])
# print(numpy.lib.recfunctions.require_fields(a, [('b', 'f4'), ('c', 'u1')]))
# print(numpy.lib.recfunctions.require_fields(a, [('b', 'f4'), ('newf', 'u1')]))


# print('numpy.lib.recfunctions.stack_arrays')
# dtype0=numpy.dtype([('level0','f4'),('level1','f4')])
# a0=numpy.ones((4,4),dtype=dtype0)
# a0[:]=(111,112)
# dtype1=numpy.dtype([('level0','f4'),('level1','f8'),('level2','U2')])
# a1=numpy.ones((4,4),dtype=dtype1)
# a1[:]=(111,112,'a')
# dtype2=numpy.dtype([('level0','f4'),('level1','f8'),('level2','U4'),('level3','U6')])
# a2=numpy.ones((4,4),dtype=dtype2)
# a2[:]=(111,112,'a','b')
# try:
    # print(numpy.lib.recfunctions.stack_arrays([a0,a1,a2]))
# except Exception as e:
    # print(e)
# print(numpy.lib.recfunctions.stack_arrays([a0,a1,a2],autoconvert=True))
# print(numpy.lib.recfunctions.stack_arrays([a0,a1,a2],usemask=False,autoconvert=True))
# print(numpy.lib.recfunctions.stack_arrays([a0,a1,a2],usemask=False,asrecarray=True,autoconvert=True))
# print(numpy.lib.recfunctions.stack_arrays([a0,a1,a2],defaults={'level2':'z'},usemask=False,asrecarray=True,autoconvert=True))


# print('numpy.lib.recfunctions.unstructured_to_structured')
# print('numpy.lib.recfunctions.structured_to_unstructured')
# dtype0=numpy.dtype([('float4','f4',(4,4))])
# a0=numpy.arange(16.)
# try:
    # print(numpy.lib.recfunctions.unstructured_to_structured(a0,dtype=dtype0,casting='unsafe',copy=True,align=True))
# except Exception as e:
    # print(e)
# print(numpy.lib.recfunctions.unstructured_to_structured(a0,dtype=dtype0,casting='unsafe',copy=True,align=False))
# a1=numpy.lib.recfunctions.unstructured_to_structured(a0,dtype=dtype0,casting='unsafe',copy=True,align=False)
# print(numpy.lib.recfunctions.structured_to_unstructured(a1,casting='unsafe',copy=True,dtype=float))






# print('back to indexing')
# a0=numpy.arange(4**4).reshape(4,4,4,4).copy('C')
# print(a0,end='\n\n')
# print(a0[(3,3,3,3)],end='\n\n')
# print(a0[3,3,3,3],end='\n\n')
# print(a0[numpy.array([3,3,3,3])],end='\n\n\n\n\n---------------------------------------\n')
# print(a0[[3,3,3,3]],end='\n\n\n\n\n---------------------------------------\n')
# print(a0[[3,3,3,2]],end='\n\n\n\n\n---------------------------------------\n')
# print(a0[[2,3,3,3]],end='\n\n\n\n\n---------------------------------------\n')





# print('numpy.random.default_rng().bit_generator')
# print(numpy.random.default_rng().bit_generator)
# print(numpy.random.default_rng().bit_generator)
# print(numpy.random.default_rng(3).bit_generator)
# print(numpy.random.default_rng(8).bit_generator)
# print(numpy.random.default_rng(8).bit_generator.lock)
# print(numpy.random.default_rng(8).bit_generator.random_raw(size=(4,4),output=False))
# print(numpy.random.default_rng(8).bit_generator.random_raw(size=(4,4),output=True))
# print(numpy.random.default_rng(8).bit_generator.random_raw(size=(4,4)))

# print('numpy.random.BitGenerator()')
# try:
    # print(numpy.random.BitGenerator(8).lock)
    # print(numpy.random.BitGenerator(8).random_raw(size=(4,4),output=False))
    # print(numpy.random.BitGenerator(8).random_raw(size=(4,4),output=True))
    # print(numpy.random.BitGenerator(8).random_raw(size=(4,4)))
# except Exception as e:
    # print(e)

# print('numpy.random.SeedSequence')
# try:
    # print(numpy.random.SeedSequence(None,spawn_key=20,pool_size=5))
# except Exception as e:
    # print(e)
# print(numpy.random.SeedSequence(None,spawn_key=[5,10,15],pool_size=4))
# print(numpy.random.SeedSequence(None,spawn_key=[5,10,15],pool_size=8))
# print(numpy.random.SeedSequence(None,spawn_key=[5,10,15],pool_size=4,n_children_spawned=2))
# print(numpy.random.SeedSequence(None,spawn_key=[5,10,15],pool_size=4,n_children_spawned=3))
# seedSequence0=numpy.random.SeedSequence(None,spawn_key=[5,10,15],pool_size=5)
# print(seedSequence0.spawn(10))
# print(seedSequence0.spawn(9))
# print(seedSequence0.generate_state(12,dtype=numpy.uint32))
# print(seedSequence0.generate_state(14,dtype=numpy.uint64))
# for attribute0 in ['pool','pool_size','entropy','state','spawn_key','n_children_spawned']:
    # print(attribute0,'               ',getattr(seedSequence0,attribute0))
# print(seedSequence0.spawn(9))
# for attribute0 in ['pool','pool_size','entropy','state','spawn_key','n_children_spawned']:
    # print(attribute0,'               ',getattr(seedSequence0,attribute0))
# print(seedSequence0.generate_state(12,dtype=numpy.uint32))
# for attribute0 in ['pool','pool_size','entropy','state','spawn_key','n_children_spawned']:
    # print(attribute0,'               ',getattr(seedSequence0,attribute0))


# print('numpy.random.default_rng().integers')
# print(numpy.random.default_rng().integers(10,size=(4,4)))
# try:
    # print(numpy.random.default_rng().integers(5,high=10,size=(2,2,2,2),dtype=complex,endpoint=True))
# except Exception as e:
    # print(e)
# print(numpy.random.default_rng().integers(5,high=10,size=(2,2,2,2),dtype=numpy.int32,endpoint=True))


# print('numpy.random.default_rng().choice')
# print(numpy.random.default_rng(8).integers(10,size=(4,4)))
# randomInts0=numpy.random.default_rng(8).integers(10,size=(4,4))
# print(numpy.random.default_rng(8).choice(randomInts0,size=(2,2),replace=True,p=None,shuffle=True,axis=0))
# print(numpy.random.default_rng(8).choice(randomInts0,size=(2,2),replace=True,p=None,shuffle=True,axis=1))
# print(numpy.random.default_rng(8).choice(randomInts0,size=(3,3),replace=True,p=None,shuffle=True,axis=1))
# print(numpy.random.default_rng(8).choice(randomInts0,size=(2,2),replace=False,p=None,shuffle=True,axis=1))
# try:
    # print(numpy.random.default_rng(8).choice(randomInts0,size=(3,3),replace=False,p=None,shuffle=True,axis=1))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.random.default_rng(8).choice(randomInts0,size=(2,2),replace=False,p=numpy.linspace(1,0,16,endpoint=True),shuffle=True,axis=1))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.random.default_rng(8).choice(randomInts0.flat,replace=True,p=numpy.linspace(1,0,16,endpoint=True),shuffle=True,axis=0))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.random.default_rng(8).choice(randomInts0.flat,replace=True,p=numpy.linspace(1,0,16,endpoint=True).reshape(4,4),shuffle=True,axis=0))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.random.default_rng(8).choice(randomInts0.flat,replace=True,p='abcdefghijklmnop',shuffle=True,axis=0))
# except Exception as e:
    # print(e)
# z0=numpy.zeros(16)
# z0[:4]=.25
# print(numpy.random.default_rng(8).choice(randomInts0.flat,replace=True,p=z0,shuffle=True,axis=0))
# print(numpy.random.default_rng(8).choice(randomInts0.flat,10,replace=True,p=z0,shuffle=True,axis=0))
# print(numpy.random.default_rng(8).choice(randomInts0.flat,10,replace=True,p=z0,shuffle=False,axis=0))
# try:
    # print(numpy.random.default_rng(8).choice(-1,replace=True,p=z0,shuffle=True,axis=0))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.random.default_rng(8).choice(numpy.array([]),replace=True,p=z0,shuffle=True,axis=0))
# except Exception as e:
    # print(e)
# print(numpy.random.default_rng().choice(numpy.array(['a','b','c','d']),3))
# print(numpy.random.default_rng().choice(numpy.array(['a','b','c','d']),3,p=z0[:4]))


# print('numpy.random.default_rng().bytes')
# print(numpy.random.default_rng(8).bytes(5))
# print(numpy.random.default_rng(8).bytes(15))


# print('numpy.random.default_rng().shuffle')
# print(randomInts0)
# randomInts1=randomInts0.copy('C')
# print(numpy.random.default_rng().shuffle(randomInts1))
# print(numpy.random.default_rng().shuffle(randomInts1,axis=0))
# print(randomInts1)
# print(numpy.random.default_rng().shuffle(randomInts1,axis=1))
# print(randomInts1)
# print('numpy.random.default_rng().permutation')
# randomInts1=randomInts0.copy('C')
# print(numpy.random.default_rng().permutation(randomInts1))
# print(numpy.random.default_rng().permutation(randomInts1,axis=0))
# print(randomInts1)
# print(numpy.random.default_rng().permutation(randomInts1,axis=1))
# print(randomInts1)
# print('numpy.random.default_rng().permuted')
# print(numpy.random.default_rng().permuted(randomInts1))
# print(numpy.random.default_rng().permuted(randomInts1,axis=0))
# print(randomInts1)
# print(numpy.random.default_rng().permuted(randomInts1,axis=1))
# print(randomInts1)
# print(numpy.random.default_rng().permuted(randomInts1,axis=1,out=randomInts1))
# print(randomInts1)


# print('numpy.random.default_rng().beta')
# print(numpy.random.default_rng(8).beta([500,1,50,5,.1],[1,500,50,5,.1],None))
# print(numpy.random.default_rng(7).beta([500,1,50,5,.1],[1,500,50,5,.1],None))
# print(numpy.random.default_rng(6).beta([500,1,50,5,.1],[1,500,50,5,.1],None))
# try:
    # print(numpy.random.default_rng(6).beta([500,1,50,5,.1],[1,500,50,5,.1],size=3))
# except Exception as e:
    # print(e)
# print(numpy.random.default_rng(6).beta([500,1,50,5,.1],[1,500,50,5,.1],size=(3,5)))

# print(numpy.array([])==numpy.array([]))
# print(numpy.array([]) is numpy.array([]))

# print('numpy.random.default_rng().binomial')
# print(numpy.random.default_rng(8).binomial(20,.5,(5,20)))
# print(numpy.random.default_rng(8).binomial(20,.7,(5,20)))
# print(numpy.random.default_rng(8).binomial(40,.5,(5,40)))

# for howManyWellsSuccess0 in list(range(0,10,1)):
    # print(howManyWellsSuccess0,'  ',numpy.format_float_positional((sum(numpy.random.default_rng(8).binomial(9,.1,2000)==howManyWellsSuccess0)/2000.),40,unique=False))

# print('numpy.random.default_rng().chisquare')
# for dOF0 in list(range(-1,12,1)):
    # try:
        # print(dOF0,'   ',numpy.random.default_rng(8).chisquare(dOF0,(20,)))
    # except Exception as e:
        # print(e)

# import matplotlib.pyplot
# print('numpy.random.default_rng().dirichlet')
# try:
    # print(numpy.random.default_rng(8).dirichlet((-1,3,2),10))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.random.default_rng(8).dirichlet((0,3,2),10))
# except Exception as e:
    # print(e)
# print(numpy.random.default_rng(8).dirichlet((5,3,2),10))
# print(numpy.random.default_rng(8).dirichlet((5,3,2),10).transpose())
# sLD0=numpy.random.default_rng(8).dirichlet((5,3,2),10).transpose()
# matplotlib.pyplot.barh(range(10),sLD0[0])
# matplotlib.pyplot.barh(range(10),sLD0[1],left=sLD0[0],color='g')
# matplotlib.pyplot.barh(range(10),sLD0[2],left=(sLD0[0]+sLD0[1]),color='r')
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# sLD0=numpy.random.default_rng(8).dirichlet((20,3,2),10).transpose()
# matplotlib.pyplot.barh(range(10),sLD0[0])
# matplotlib.pyplot.barh(range(10),sLD0[1],left=sLD0[0],color='g')
# matplotlib.pyplot.barh(range(10),sLD0[2],left=(sLD0[0]+sLD0[1]),color='r')
# matplotlib.pyplot.show()


# import matplotlib.pyplot
# print('numpy.random.default_rng().exponential')
# print(numpy.random.default_rng(8).exponential(size=5))
# print(numpy.random.default_rng(8).exponential(4.,size=15))
# print(numpy.random.default_rng(8).exponential(scale=.01,size=15))
# for scale0 in [.01,.1,.5,1.,2.,4.,16.]:
    # matplotlib.pyplot.hist(numpy.random.default_rng(8).exponential(scale=scale0,size=500),bins=100)
    # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
    # # currentFigManager0.window.showMaximized()
    # currentFigManager0.window.state('zoomed')
    # matplotlib.pyplot.show()
    # matplotlib.pyplot.cla()
# try:
    # print(numpy.random.default_rng(8).exponential(scale=-1,size=15))
# except Exception as e:
    # print(e)
# print(numpy.random.default_rng(8).exponential(scale=0,size=15))


# print('numpy.random.default_rng().f')
# testSubjectsGroup0=50
# testSubjectsGroup1=53
# groups=2
# betweenGroupsDegreesOfFreedom=groups-1
# print('betweenGroupsDegreesOfFreedom',betweenGroupsDegreesOfFreedom)
# withinGroupsDegreesOfFreedom=sum([testSubjectsGroup0,testSubjectsGroup1,-groups])
# print('withinGroupsDegreesOfFreedom',withinGroupsDegreesOfFreedom)
# totalDegreesOfFreedom=sum([testSubjectsGroup0,testSubjectsGroup1,-1])
# print('totalDegreesOfFreedom',totalDegreesOfFreedom)
# fDistribution0=numpy.random.default_rng(8).f(betweenGroupsDegreesOfFreedom,withinGroupsDegreesOfFreedom,100)
# fDistribution0.sort()
# print(fDistribution0)
# fDistribution0SortedDescending=fDistribution0[::-1]
# print(fDistribution0SortedDescending)
# import matplotlib.pyplot
# matplotlib.pyplot.plot(range(len(fDistribution0SortedDescending)),fDistribution0SortedDescending)
# matplotlib.pyplot.show()
# for dOFNum0 in [.2,2,200]:
    # for dOFDen0 in [.2,2,200]:
        # # matplotlib.pyplot.plot(range(100),numpy.random.default_rng(8).f(dOFNum0,dOFDen0,100),label=str(['dOFNum0:',dOFNum0,';dOFDen0:',dOFDen0]))
        # matplotlib.pyplot.plot(range(100),numpy.sort(numpy.random.default_rng(8).f(dOFNum0,dOFDen0,100))[::-1],label=str(['dOFNum0:',dOFNum0,';dOFDen0:',dOFDen0]))
        # # matplotlib.pyplot.title('dOFNum0:'dOFNum0,';dOFDen0:'dOFDen0)
        # # matplotlib.pyplot.show()
        # # matplotlib.pyplot.cla()
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()


# print('numpy.random.default_rng().gamma')
# import matplotlib.pyplot
# import scipy.special
# shape0,scale0=2.,2.
# count0,x0bins0,ignored0=matplotlib.pyplot.hist(numpy.random.default_rng(8).gamma(shape0,scale=scale0,size=100),density=True)
# y0=(x0bins0**(scale0-1))*((numpy.exp(-x0bins0/scale0)/(scipy.special.gamma(shape0)*(scale0**shape0))))
# matplotlib.pyplot.plot(x0bins0,y0,linewidth=4,color='g')
# matplotlib.pyplot.show()
# print(numpy.sort(numpy.random.default_rng(8).gamma(shape0,scale=scale0,size=15))[::-1])
# for shape0 in [.2,2,200]:
    # for scale0 in [.2,None,2,200]:
        # try:
            # print('shape0: ',shape0,';scale0: ',scale0,numpy.sort(numpy.random.default_rng(8).gamma(shape0,scale=scale0,size=15))[::-1])
        # except Exception as e:
            # print(e)


# import matplotlib.pyplot
# print('numpy.random.default_rng().geometric')
# size0=15
# for p0 in [.2,.5,.8]:
    # matplotlib.pyplot.plot(range(size0),numpy.sort(numpy.random.default_rng(8).geometric(p0,size=size0))[::-1],label=str(p0))
    # print(p0,'         ',numpy.sort(numpy.random.default_rng(8).geometric(p0,size=size0))[::-1])
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# size0=1000
# for p0 in [.2,.5,.8]:
    # matplotlib.pyplot.plot(range(size0),numpy.sort(numpy.random.default_rng(8).geometric(p0,size=size0))[::-1],label=str(p0))
    # print(p0,'         ',numpy.sort(numpy.random.default_rng(8).geometric(p0,size=size0))[::-1])
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()


# print('numpy.random.default_rng().gumbel()')
# import scipy.stats,matplotlib.pyplot
# print(scipy.stats.gumbel_r.stats(moments='mvsk'))
# print(scipy.stats.gumbel_r.pdf(range(20)))
# print(scipy.stats.gumbel_r.pdf(range(20),1,1))
# print(scipy.stats.gumbel_r.pdf(range(20),1,2))
# print(numpy.sort(numpy.random.default_rng(8).gumbel(size=20))[::-1])
# print(numpy.sort(numpy.random.default_rng(8).gumbel(0,1,size=20))[::-1])
# print(numpy.sort(numpy.random.default_rng(8).gumbel(1,1,size=20))[::-1])
# print(numpy.sort(numpy.random.default_rng(8).gumbel(1,2,size=20))[::-1])
# # # print(numpy.sort(numpy.random.default_rng(8).gumbel(1,1,100))[::-1])
# loc0list=[1,2,3]
# scale0list=[1,2,3]
# # loc0list=[1]
# # scale0list=[1]
# counter0=1
# for loc0 in loc0list:
    # for scale0 in scale0list:
        # # # matplotlib.pyplot.plot(numpy.arange(len(numpy.random.default_rng(8).gumbel(loc=loc0,scale=scale0,size=100))),numpy.random.default_rng(8).gumbel(loc=loc0,scale=scale0,size=100),label=str(['loc0:',loc0,';scale0:',scale0]))
        # # matplotlib.pyplot.subplot(3,3,(1,2))
        # # matplotlib.pyplot.hist(numpy.random.default_rng(8).gumbel(loc=loc0,scale=scale0,size=100),numpy.random.default_rng(8).gumbel(loc=loc0,scale=scale0,size=100).size)
        # # # matplotlib.pyplot.subplot(len(loc0list),len(scale0list),(loc0,scale0),label=str(['loc0:',loc0,';scale0:',scale0]))
        # # # matplotlib.pyplot.subplot(len(loc0list),len(scale0list),label=str(['loc0:',loc0,';scale0:',scale0]))
        # # # matplotlib.pyplot.subplot(len(loc0list)*len(scale0list),1,(counter0,1),label=str(['loc0:',loc0,';scale0:',scale0]))
        # # matplotlib.pyplot.subplot(len(loc0list),len(scale0list),counter0,label=str(['loc0:',loc0,';scale0:',scale0]))
        # matplotlib.pyplot.subplot(len(loc0list),len(scale0list),counter0,title=str(['loc0:',loc0,';scale0:',scale0]))
        # matplotlib.pyplot.hist(numpy.random.default_rng(8).gumbel(loc=loc0,scale=scale0,size=100),numpy.random.default_rng(8).gumbel(loc=loc0,scale=scale0,size=100).size)
        # counter0+=1
        # # # matplotlib.pyplot.plot(numpy.arange(20),scipy.stats.gumbel_r.pdf(range(20)),linewidth=2,color='r')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()


# print('numpy.random.default_rng().hypergeometric')
# try:
    # print(numpy.random.default_rng(8).hypergeometric(12,3,16))
# except Exception as e:
    # print(e)
# print(numpy.random.default_rng(8).hypergeometric(12,3,15))
# print(numpy.random.default_rng(8).hypergeometric(12,3,10,20))
# matplotlib.pyplot.hist(numpy.random.default_rng(8).hypergeometric(500,500,500,5000))
# matplotlib.pyplot.show()


# print('numpy.random.default_rng().laplace')
# print(numpy.random.default_rng(8).laplace(loc=3,scale=5,size=20))
# matplotlib.pyplot.hist(numpy.random.default_rng(8).laplace(loc=5,scale=9,size=20))
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# matplotlib.pyplot.hist(numpy.random.default_rng(8).laplace(loc=0,scale=1,size=20))
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# matplotlib.pyplot.hist(numpy.random.default_rng(8).laplace(size=20),density=True)
# matplotlib.pyplot.plot(numpy.linspace(-1.4,1.4,20),scipy.stats.norm.pdf(numpy.linspace(-1.4,1.4,20)),linewidth=2,color='g')
# matplotlib.pyplot.plot(numpy.linspace(-1.4,1.4,20),scipy.stats.laplace.pdf(numpy.linspace(-1.4,1.4,20)),linewidth=2,color='purple')
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# print('numpy.random.default_rng().logistic')
# print(numpy.random.default_rng(8).logistic(loc=3,scale=5,size=20))
# matplotlib.pyplot.hist(numpy.random.default_rng(8).logistic(loc=5,scale=9,size=20))
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# matplotlib.pyplot.hist(numpy.random.default_rng(8).logistic(loc=0,scale=1,size=20))
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# matplotlib.pyplot.hist(numpy.random.default_rng(8).logistic(size=20),density=True)
# matplotlib.pyplot.plot(numpy.linspace(-3.4,3.4,20),scipy.stats.norm.pdf(numpy.linspace(-3.4,3.4,20)),linewidth=2,color='g')
# matplotlib.pyplot.plot(numpy.linspace(-3.4,3.4,20),scipy.stats.logistic.pdf(numpy.linspace(-3.4,3.4,20)),linewidth=2,color='lightblue')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()


# print('numpy.random.default_rng().lognormal')
# print(numpy.sort(numpy.random.default_rng(8).lognormal(mean=3,sigma=5,size=20))[::-1])
# matplotlib.pyplot.hist(numpy.random.default_rng(8).lognormal(mean=5,sigma=9,size=20))
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# matplotlib.pyplot.hist(numpy.random.default_rng(8).lognormal(mean=0,sigma=1,size=20))
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# matplotlib.pyplot.hist(numpy.random.default_rng(8).lognormal(size=20),density=True)
# matplotlib.pyplot.plot(numpy.linspace(-3.4,3.4,20),scipy.stats.norm.pdf(numpy.linspace(-3.4,3.4,20)),linewidth=2,color='g')
# matplotlib.pyplot.plot(numpy.linspace(-3.4,3.4,20),scipy.stats.lognorm.pdf(numpy.linspace(-3.4,3.4,20),1),linewidth=2,color='lightblue')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()


# print('numpy.random.default_rng().logseries')
# print(numpy.sort(numpy.random.default_rng(8).logseries(.9,size=20))[::-1])
# matplotlib.pyplot.hist(numpy.random.default_rng(8).logseries(.1,size=100),bins=100,density=True)
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# matplotlib.pyplot.hist(numpy.random.default_rng(8).logseries(.5,size=100),bins=100,density=True)
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# matplotlib.pyplot.hist(numpy.random.default_rng(8).logseries(.9,size=100),bins=100,density=True)
# matplotlib.pyplot.plot(numpy.linspace(1,3.4,20),scipy.stats.norm.pdf(numpy.linspace(1,3.4,20)),linewidth=2,color='g')
# matplotlib.pyplot.plot(numpy.linspace(1,3.4,20),scipy.stats.logser.pmf(numpy.linspace(1,3.4,20),.1),linewidth=2,color='darkblue')
# matplotlib.pyplot.plot(numpy.linspace(1,3.4,20),scipy.stats.logser.pmf(numpy.linspace(1,3.4,20),.5),linewidth=2,color='blue')
# matplotlib.pyplot.plot(numpy.linspace(1,3.4,20),scipy.stats.logser.pmf(numpy.linspace(1,3.4,20),.9),linewidth=2,color='lightblue')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()


# print('numpy.random.default_rng().multinomial')
# print(numpy.random.default_rng(8).multinomial(1,[1/6.]*6,5))
# print(numpy.random.default_rng(8).multinomial(20,[1/6.]*6,5))
# print(numpy.random.default_rng(8).multinomial(20,([1/30.]*10)+([5/30.]*2)+([1/30.]*10),5))


# print('numpy.random.default_rng().multivariate_normal')
# for mean0 in [[0,0],[7,7]]:
    # for cov0 in [numpy.array([[1,0],[0,1]]),numpy.array([[3,0],[0,9]]),numpy.array([[1,(3/5.)],[(3/5.),1]]),numpy.array([[1,(.5)],[(.6),1]])]:
        # for check_valid0 in ['warn','raise','ignore']:
            # for tol0 in [1e-8,.5]:
                # for method0 in ['svd','eigh','cholesky']:
                    # try:
                        # startTime0=time.perf_counter()
                        # x0,y0=numpy.random.default_rng(8).multivariate_normal(mean0,cov0,size=150,check_valid=check_valid0,tol=tol0,method=method0).T
                        # # matplotlib.pyplot.plot(x0,y0,marker='.',label=list(map(str,[mean0,cov0,check_valid0,tol0])))
                        # matplotlib.pyplot.plot(x0,y0,'.',label=list(map(str,[mean0,cov0,check_valid0,tol0,method0])))
                        # matplotlib.pyplot.axis('equal')
                        # matplotlib.pyplot.grid()
                        # stopTime0=time.perf_counter()
                        # sTR0=stopTime0-startTime0
                        # matplotlib.pyplot.title(('multivariate_normal;  '+str(sTR0)+' seconds total runtime;'))
                        # matplotlib.pyplot.legend()
                        # current_fig_manager0=matplotlib.pyplot.get_current_fig_manager()
                        # current_fig_manager0.window.state('zoomed')
                        # matplotlib.pyplot.show()
                    # except Exception as e:
                        # print(e)
# # matplotlib.pyplot.title('multivariate_normal')
# # matplotlib.pyplot.legend()
# # matplotlib.pyplot.show()


# print('numpy.random.default_rng().negative_binomial')
# def negative_binomialMean0(p,r):
    # return (p*r/(1-p))
# for p in numpy.linspace(0,1,10):#probSuccess;p
    # for r in numpy.geomspace(1,100,3):
        # print(p,r,negative_binomialMean0(p,r),sep='    ')
# # for probSuccess in numpy.linspace(0,1,3):#probSuccess;p
    # # # for numSuccess in numpy.geomspace(1,100,3):#numSuccess;n
    # # for numSuccess in numpy.linspace(1,10,5):#numSuccess;n
        # # # for numFailure in numpy.geomspace(1,100,3):#numFailure;k
        # # for numFailure in numpy.linspace(1,10,5):#numFailure;k
            # # matplotlib.pyplot.plot(numSuccess,scipy.stats.nbinom.pmf(numFailure,numSuccess,probSuccess),label=list(map(str,[numFailure,numSuccess,probSuccess])))
            # # matplotlib.pyplot.legend()
            # # matplotlib.pyplot.show()
# print(numpy.sort(numpy.random.default_rng(8).negative_binomial(1,.1,100))[::-1])
# print(numpy.sort(numpy.random.default_rng(8).negative_binomial(1,.5,100))[::-1])
# print(numpy.sort(numpy.random.default_rng(8).negative_binomial(1,.9,100))[::-1])
# print(numpy.sort(numpy.random.default_rng(8).negative_binomial(5,.1,100))[::-1])
# print(numpy.sort(numpy.random.default_rng(8).negative_binomial(5,.5,100))[::-1])
# print(numpy.sort(numpy.random.default_rng(8).negative_binomial(5,.9,100))[::-1])
# print(numpy.sort(numpy.random.default_rng(8).negative_binomial(20,.1,100))[::-1])
# print(numpy.sort(numpy.random.default_rng(8).negative_binomial(20,.5,100))[::-1])
# print(numpy.sort(numpy.random.default_rng(8).negative_binomial(20,.9,100))[::-1])
# numSuccess=1
# s=numpy.random.default_rng(8).negative_binomial(numSuccess,.1,100000)
# for i in range(1,11):
    # probability0=sum(s<i)/100000
    # print(i,'wells drilled;',probability0,' probability of getting ',numSuccess,' success(es)')
# numSuccess=5
# s=numpy.random.default_rng(8).negative_binomial(numSuccess,.1,100000)
# for i in range(1,11):
    # probability0=sum(s<i)/100000
    # print(i,'wells drilled;',probability0,' probability of getting ',numSuccess,' success(es)')
# numSuccess=1
# probSuccess=.5
# s=numpy.random.default_rng(8).negative_binomial(numSuccess,probSuccess,100000)
# for i in range(1,11):
    # probability0=sum(s<i)/100000
    # print(i,'wells drilled;',probability0,' probability of getting ',numSuccess,' success(es)')
# numSuccess=5
# probSuccess=.5
# s=numpy.random.default_rng(8).negative_binomial(numSuccess,probSuccess,100000)
# for i in range(1,11):
    # probability0=sum(s<i)/100000
    # print(i,'wells drilled;',probability0,' probability of getting ',numSuccess,' success(es)')

# print('numpy.random.default_rng().noncentral_chisquare')
# print(numpy.sort(numpy.random.default_rng(8).noncentral_chisquare(1,1,size=20))[::-1])
# matplotlib.pyplot.hist(numpy.random.default_rng(8).noncentral_chisquare(1,1,size=100),bins=100,density=True)
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# matplotlib.pyplot.hist(numpy.random.default_rng(8).noncentral_chisquare(1,3,size=100),bins=100,density=True)
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# matplotlib.pyplot.hist(numpy.random.default_rng(8).noncentral_chisquare(1,9,size=100),bins=100,density=True)
# matplotlib.pyplot.plot(numpy.linspace(1,60,60),scipy.stats.norm.pdf(numpy.linspace(1,60,60)),linewidth=2,color='g')
# df0,nc0=1,1
# matplotlib.pyplot.plot(numpy.linspace(1,60,60),scipy.stats.ncx2.pdf(numpy.linspace(1,60,60),df0,nc0),linewidth=2,color='darkblue',label=list(map(str,[df0,nc0])))
# df0,nc0=1,3
# matplotlib.pyplot.plot(numpy.linspace(1,60,60),scipy.stats.ncx2.pdf(numpy.linspace(1,60,60),df0,nc0),linewidth=2,color='blue',label=list(map(str,[df0,nc0])))
# df0,nc0=1,9
# matplotlib.pyplot.plot(numpy.linspace(1,60,60),scipy.stats.ncx2.pdf(numpy.linspace(1,60,60),df0,nc0),linewidth=2,color='lightblue',label=list(map(str,[df0,nc0])))
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# print('numpy.random.default_rng().f')
# testSubjectsGroup0=50
# testSubjectsGroup1=53
# groups=2
# betweenGroupsDegreesOfFreedom=groups-1
# print('betweenGroupsDegreesOfFreedom',betweenGroupsDegreesOfFreedom)
# withinGroupsDegreesOfFreedom=sum([testSubjectsGroup0,testSubjectsGroup1,-groups])
# print('withinGroupsDegreesOfFreedom',withinGroupsDegreesOfFreedom)
# totalDegreesOfFreedom=sum([testSubjectsGroup0,testSubjectsGroup1,-1])
# print('totalDegreesOfFreedom',totalDegreesOfFreedom)
# fDistribution0=numpy.random.default_rng(8).f(betweenGroupsDegreesOfFreedom,withinGroupsDegreesOfFreedom,100)
# fDistribution0.sort()
# print(fDistribution0)
# fDistribution0SortedDescending=fDistribution0[::-1]
# print(fDistribution0SortedDescending)
# noncentral_fDistribution0=numpy.random.default_rng(8).noncentral_f(betweenGroupsDegreesOfFreedom,withinGroupsDegreesOfFreedom,0,100)
# noncentral_fDistribution0.sort()
# print(noncentral_fDistribution0)
# noncentral_fDistribution0SortedDescending=noncentral_fDistribution0[::-1]
# print(noncentral_fDistribution0SortedDescending)
# matplotlib.pyplot.show()
# for dfnum0betweenGroupsDegreesOfFreedom in [2,200]:
    # for dfden0withinGroupsDegreesOfFreedom in [2,200]:
        # for nonc0 in [1,9]:
            # matplotlib.pyplot.hist(numpy.random.default_rng(8).noncentral_f(dfnum0betweenGroupsDegreesOfFreedom,dfden0withinGroupsDegreesOfFreedom,nonc0,size=1000),bins=100,density=True)
            # matplotlib.pyplot.plot(numpy.linspace(0,10,10),scipy.stats.norm.pdf(numpy.linspace(0,10,10)),linewidth=2,color='g')
            # matplotlib.pyplot.plot(numpy.linspace(0,10,10),scipy.stats.f.pdf(numpy.linspace(0,10,10),dfnum0betweenGroupsDegreesOfFreedom,dfden0withinGroupsDegreesOfFreedom),linewidth=2,color='fuchsia',label='f')
            # matplotlib.pyplot.plot(numpy.linspace(0,10,10),scipy.stats.ncf.pdf(numpy.linspace(0,10,10),dfnum0betweenGroupsDegreesOfFreedom,dfden0withinGroupsDegreesOfFreedom,nonc0),linewidth=2,color='navy',label='ncf')
            # matplotlib.pyplot.title(list(map(str,['dfnum0betweenGroupsDegreesOfFreedom:',dfnum0betweenGroupsDegreesOfFreedom,';dfden0withinGroupsDegreesOfFreedom:',dfden0withinGroupsDegreesOfFreedom,'nonc0:',nonc0])))
            # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
            # currentFigManager0.window.state('zoomed')
            # matplotlib.pyplot.show()
            # matplotlib.pyplot.cla()


# print('numpy.random.default_rng().standard_cauchy')
# print(numpy.sort(numpy.random.default_rng(8).standard_cauchy(20))[::-1])
# for loc0 in [0,10]:
    # for scale0 in [1,10]:
        # matplotlib.pyplot.hist(numpy.random.default_rng(8).standard_cauchy(size=1000),bins=100,density=True)
        # matplotlib.pyplot.plot(numpy.linspace(-20,20,40),scipy.stats.norm.pdf(numpy.linspace(-20,20,40)),linewidth=2,color='g')
        # matplotlib.pyplot.plot(numpy.linspace(-20,20,40),scipy.stats.cauchy.pdf(numpy.linspace(-20,20,40),loc0,scale0),linewidth=2,color='crimson',label='f')
        # matplotlib.pyplot.title(list(map(str,['loc0:',loc0,';scale0:',scale0])))
        # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
        # currentFigManager0.window.state('zoomed')
        # matplotlib.pyplot.show()
        # matplotlib.pyplot.cla()

# print('numpy.random.default_rng().levy')
# for loc0 in [0,1]:
    # for scale0 in [1,10]:
        # matplotlib.pyplot.plot(numpy.linspace(0,4,40),scipy.stats.norm.pdf(numpy.linspace(0,4,40)),linewidth=2,color='g')
        # matplotlib.pyplot.plot(numpy.linspace(0,4,40),scipy.stats.levy.pdf(numpy.linspace(0,4,40),loc0,scale0),linewidth=2,color='lime',label='l')
        # matplotlib.pyplot.title(list(map(str,['loc0:',loc0,';scale0:',scale0])))
        # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
        # currentFigManager0.window.state('zoomed')
        # matplotlib.pyplot.show()
        # matplotlib.pyplot.cla()

# print('numpy.random.default_rng().normal')
# print(numpy.sort(numpy.random.default_rng(8).normal(size=20))[::-1])
# out0=numpy.empty(shape=(20,),dtype=numpy.float32)
# print(numpy.sort(numpy.random.default_rng(8).standard_normal(size=20,dtype=numpy.float32,out=out0))[::-1])
# print(numpy.sort(out0)[::-1])
# for loc0 in [0,10]:
    # for scale0 in [1,10]:
        # matplotlib.pyplot.hist(numpy.random.default_rng(8).normal(loc=loc0,scale=scale0,size=1000),bins=100,density=True)
        # matplotlib.pyplot.plot(numpy.linspace(-20,20,40),scipy.stats.norm.pdf(numpy.linspace(-20,20,40),loc=loc0,scale=scale0),linewidth=2,color='navy')
        # matplotlib.pyplot.title(list(map(str,['loc0:',loc0,';scale0:',scale0])))
        # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
        # currentFigManager0.window.state('zoomed')
        # matplotlib.pyplot.show()
        # matplotlib.pyplot.cla()


# print('numpy.random.default_rng().multivariate_hypergeometric')
# for colors0 in [[1,20,200],[1000,20,200]]:
    # for nsample0 in [1,20]:
        # for size0 in [None,5]:
            # for method0 in ['count','marginals']:
                # startTime0=time.perf_counter()
                # try:
                    # print(colors0,nsample0,size0,method0,numpy.random.default_rng(8).multivariate_hypergeometric(colors0,nsample0,size=size0,method=method0),sep='     ')
                # except Exception as e:
                    # print(e)
                # stopTime0=time.perf_counter()
                # sTR0=stopTime0-startTime0
                # print(sTR0)

# print('numpy.random.default_rng().standard_t')
# intake0=numpy.array([5260., 5470, 5640, 6180, 6390, 6515, 6805, 7515, 7515, 8230, 8770])
# print(intake0)
# print(len(intake0))
# tStatistic0=(numpy.mean(intake0)-7725)/(numpy.std(intake0,ddof=1)/numpy.sqrt(len(intake0)))
# print(tStatistic0)
# tDistRand0=numpy.random.default_rng(8).standard_t(len(intake0)-1,size=10000)
# pValue0=numpy.sum(numpy.abs(tStatistic0)<numpy.abs(tDistRand0))/float(len(tDistRand0))
# print('pValue0',pValue0)
# startX0=-100
# endX0=100
# n0=1000
# for df0 in [.5,1,2,50]:
    # matplotlib.pyplot.hist(numpy.random.default_rng(8).standard_t(df0,size=1000),bins=100,density=True)
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.t.pdf(numpy.linspace(startX0,endX0,n0),df0),linewidth=2,color='tan')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.norm.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='navy')
    # matplotlib.pyplot.title(list(map(str,['df0:',df0])))
    # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
    # currentFigManager0.window.state('zoomed')
    # matplotlib.pyplot.show()
    # matplotlib.pyplot.cla()


# print('numpy.random.default_rng().pareto')
# startX0=1
# endX0=100
# n0=100
# for a0 in [.5,1,4,50]:
    # matplotlib.pyplot.hist(numpy.random.default_rng(8).pareto(a0,size=n0),bins=100,density=True)
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.pareto.pdf(numpy.linspace(startX0,endX0,n0),a0),linewidth=2,color='pink')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.lomax.pdf(numpy.linspace(startX0,endX0,n0),a0),linewidth=2,color='lavender')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.genpareto.pdf(numpy.linspace(startX0,endX0,n0),a0),linewidth=2,color='gold')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.norm.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='navy')
    # matplotlib.pyplot.title(list(map(str,['a0:',a0])))
    # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
    # currentFigManager0.window.state('zoomed')
    # matplotlib.pyplot.show()
    # matplotlib.pyplot.cla()



# print('numpy.random.default_rng().zipf')
# startX0=1
# endX0=100
# n0=endX0-startX0
# bins0=10
# for a0 in [2,4,50]:
    # matplotlib.pyplot.hist(numpy.random.default_rng(8).zipf(a0,size=n0),bins=bins0,density=True)
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.zipf.pmf(numpy.linspace(startX0,endX0,n0),a0),linewidth=2,color='aqua',label='zipf')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.pareto.pdf(numpy.linspace(startX0,endX0,n0),a0),linewidth=2,color='pink')
    # # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.lomax.pdf(numpy.linspace(startX0,endX0,n0),a0),linewidth=2,color='lavender')
    # # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.genzipf.pdf(numpy.linspace(startX0,endX0,n0),a0),linewidth=2,color='gold')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.norm.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='navy')
    # matplotlib.pyplot.title(list(map(str,['a0:',a0])))
    # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
    # currentFigManager0.window.state('zoomed')
    # matplotlib.pyplot.legend()
    # matplotlib.pyplot.show()
    # matplotlib.pyplot.cla()

# for a0 in [2,4,50]:
    # print(scipy.special.zeta(a0))

# print('numpy.random.default_rng().poisson')
# startX0=0
# endX0=15
# n0=endX0-startX0
# bins0=10
# for lam0 in [.01,1,4,10]:
    # matplotlib.pyplot.hist(numpy.random.default_rng(8).poisson(lam0,size=n0),bins=bins0,density=True)
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.poisson.pmf(numpy.linspace(startX0,endX0,n0),lam0),linewidth=2,color='aqua',label='poisson')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.pareto.pdf(numpy.linspace(startX0,endX0,n0),lam0),linewidth=2,color='pink')
    # # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.lomax.pdf(numpy.linspace(startX0,endX0,n0),lam0),linewidth=2,color='lavender')
    # # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.genpoisson.pdf(numpy.linspace(startX0,endX0,n0),lam0),linewidth=2,color='gold')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.norm.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='navy')
    # matplotlib.pyplot.title(list(map(str,['lam0:',lam0])))
    # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
    # currentFigManager0.window.state('zoomed')
    # matplotlib.pyplot.legend()
    # matplotlib.pyplot.show()
    # matplotlib.pyplot.cla()

# print('numpy.random.default_rng().power')
# startX0=0
# endX0=1
# # n0=endX0-startX0
# bins0=100
# n0=bins0*10
# b0=1
# for a0 in [.01,1,4,10]:
    # matplotlib.pyplot.hist(numpy.random.default_rng(8).power(a0,size=n0),bins=bins0,density=True)
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.powerlaw.pdf(numpy.linspace(startX0,endX0,n0),a0),linewidth=2,color='plum',label='power')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.beta.pdf(numpy.linspace(startX0,endX0,n0),a0,b0)-.01,linewidth=2,color='black',label='beta')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.genpareto.pdf(numpy.linspace(startX0,endX0,n0),a0),linewidth=2,color='gold')
    # # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.lomax.pdf(numpy.linspace(startX0,endX0,n0),a0),linewidth=2,color='lavender')
    # # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.genpower.pdf(numpy.linspace(startX0,endX0,n0),a0),linewidth=2,color='gold')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.norm.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='navy')
    # matplotlib.pyplot.title(list(map(str,['a0:',a0])))
    # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
    # currentFigManager0.window.state('zoomed')
    # matplotlib.pyplot.legend()
    # matplotlib.pyplot.show()
    # matplotlib.pyplot.cla()

# print(scipy.stats.rayleigh.stats(moments='mvsk'))
# print('numpy.random.default_rng().rayleigh')
# startX0=0
# endX0=20
# n0=endX0-startX0
# bins0=100
# n0=bins0*10
# b0=1
# df0=2
# for scale0 in [.01,1,4,10]:
    # matplotlib.pyplot.hist(numpy.random.default_rng(8).rayleigh(scale=scale0,size=n0),bins=bins0,density=True)
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.rayleigh.pdf(numpy.linspace(startX0,endX0,n0),scale=scale0),linewidth=2,color='red',label='rayleigh')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.chi.pdf(numpy.linspace(startX0,endX0,n0),df0,scale=scale0)-.01,linewidth=2,color='cyan',label='chi')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.norm.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='navy')
    # matplotlib.pyplot.title(list(map(str,['scale0:',scale0])))
    # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
    # currentFigManager0.window.state('zoomed')
    # matplotlib.pyplot.legend()
    # matplotlib.pyplot.show()
    # matplotlib.pyplot.cla()

# print('numpy.random.default_rng().standard_gamma')
# startX0=0
# endX0=20
# n0=endX0-startX0
# bins0=100
# n0=bins0*10
# b0=1
# for shape0 in [.01,2,10]:
    # matplotlib.pyplot.hist(numpy.random.default_rng(8).standard_gamma(shape=shape0,size=n0),bins=bins0,density=True)
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.gamma.pdf(numpy.linspace(startX0,endX0,n0),shape0),linewidth=2,color='green',label='standard_gamma')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.norm.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='navy')
    # matplotlib.pyplot.title(list(map(str,['shape0:',shape0])))
    # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
    # currentFigManager0.window.state('zoomed')
    # matplotlib.pyplot.legend()
    # matplotlib.pyplot.show()
    # matplotlib.pyplot.cla()
# out0=numpy.empty(shape=(20,),dtype=numpy.float32)
# print(numpy.sort(numpy.random.default_rng(8).standard_gamma(shape=10,size=20,dtype=numpy.float32,out=out0))[::-1])
# print(numpy.sort(out0)[::-1])


# print('numpy.random.default_rng().standard_exponential')
# startX0=0
# endX0=20
# n0=endX0-startX0
# bins0=100
# n0=bins0*10
# b0=1
# # for method0 in ['zig','inv']:
# for method0 in ['inv','zig']:
    # startTime0=time.perf_counter()
    # matplotlib.pyplot.hist(numpy.random.default_rng(8).standard_exponential(size=n0,method=method0),bins=bins0,density=True)
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.expon.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='pink',label='standard_exponential')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.norm.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='navy')
    # matplotlib.pyplot.title(list(map(str,['method0:',method0])))
    # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
    # currentFigManager0.window.state('zoomed')
    # matplotlib.pyplot.legend()
    # matplotlib.pyplot.show()
    # matplotlib.pyplot.cla()
    # stopTime0=time.perf_counter()
    # sTR0=stopTime0-startTime0
    # print(sTR0)
    # if method0=='zig':
        # varZig0=sTR0
    # else:
        # varInv0=sTR0
# print(varZig0/varInv0,' varZig0/varInv0')
# print('numpy.random.default_rng().standard_exponential')
# out0=numpy.empty(shape=(20,),dtype=numpy.float32)
# print(numpy.sort(numpy.random.default_rng(8).standard_exponential(size=20,dtype=numpy.float32,method='zig',out=out0))[::-1])
# print(numpy.sort(out0)[::-1])


# print('numpy.random.default_rng().triangular')
# startX0=0
# endX0=2
# n0=endX0-startX0
# bins0=100
# n0=bins0*10
# b0=1
# for left0 in [0,.2]:
    # for mode0 in [.4,.8]:
        # for right0 in [1,2]:
            # startTime0=time.perf_counter()
            # matplotlib.pyplot.hist(numpy.random.default_rng(8).triangular(left0,mode0,right0,size=n0),bins=bins0,density=True)
            # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.triang.pdf(numpy.linspace(startX0,endX0,n0),mode0),linewidth=2,color='teal',label='triangular')
            # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.norm.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='navy',label='normal')
            # matplotlib.pyplot.title(list(map(str,['left0:',left0,'mode0:',mode0,'right0:',right0,])))
            # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
            # currentFigManager0.window.state('zoomed')
            # matplotlib.pyplot.legend()
            # matplotlib.pyplot.show()
            # matplotlib.pyplot.cla()
            # stopTime0=time.perf_counter()
            # sTR0=stopTime0-startTime0
            # print(sTR0,list(map(str,['left0:',left0,'mode0:',mode0,'right0:',right0,])))


# print('numpy.random.default_rng().uniform')
# startX0=0
# endX0=10
# n0=endX0-startX0
# bins0=100
# n0=bins0*10
# b0=1
# for left0 in [0,.5]:
    # for right0 in [1,10]:
        # startTime0=time.perf_counter()
        # matplotlib.pyplot.hist(numpy.random.default_rng(8).uniform(left0,right0,size=n0),bins=bins0,density=True)
        # # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.uniform.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='ivory',label='uniform')
        # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.uniform.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='indigo',label='uniform')
        # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.norm.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='navy',label='normal')
        # matplotlib.pyplot.title(list(map(str,['left0:',left0,'right0:',right0,])))
        # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
        # currentFigManager0.window.state('zoomed')
        # matplotlib.pyplot.legend()
        # matplotlib.pyplot.show()
        # matplotlib.pyplot.cla()
        # stopTime0=time.perf_counter()
        # sTR0=stopTime0-startTime0
        # print(sTR0,list(map(str,['left0:',left0,'right0:',right0,])))



# print('numpy.random.default_rng().vonmises')
# startX0=-15
# endX0=15
# n0=endX0-startX0
# bins0=100
# n0=bins0*10
# for mu0 in [0,.5]:
    # for kappa0 in [.01,1,20]:
        # startTime0=time.perf_counter()
        # matplotlib.pyplot.hist(numpy.random.default_rng(8).vonmises(mu0,kappa0,size=n0),bins=bins0,density=True)
        # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.vonmises.pdf(numpy.linspace(startX0,endX0,n0),kappa0),linewidth=2,color='violet',label='vonmises')
        # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.norm.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='navy',label='normal')
        # matplotlib.pyplot.title(list(map(str,['mu0:',mu0,'kappa0:',kappa0,])))
        # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
        # currentFigManager0.window.state('zoomed')
        # matplotlib.pyplot.legend()
        # matplotlib.pyplot.show()
        # matplotlib.pyplot.cla()
        # stopTime0=time.perf_counter()
        # sTR0=stopTime0-startTime0
        # print(sTR0,list(map(str,['mu0:',mu0,'kappa0:',kappa0,])))


# print('numpy.random.default_rng().wald')
# startX0=0
# endX0=15
# n0=endX0-startX0
# bins0=100
# n0=bins0*10
# for mean0 in [0.1,1,10]:
    # for scale0 in [.01,1,20]:
        # startTime0=time.perf_counter()
        # matplotlib.pyplot.hist(numpy.random.default_rng(8).wald(mean0,scale0,size=n0),bins=bins0,density=True)
        # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.wald.pdf(numpy.linspace(startX0,endX0,n0),scale=scale0),linewidth=2,color='wheat',label='wald')
        # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.invgauss.pdf(numpy.linspace(startX0,endX0,n0),mean0,scale=scale0)-.02,linewidth=2,color='green',label='invgauss')
        # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.norm.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=2,color='navy',label='normal')
        # matplotlib.pyplot.title(list(map(str,['mean0:',mean0,'scale0:',scale0,])))
        # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
        # currentFigManager0.window.state('zoomed')
        # matplotlib.pyplot.legend()
        # matplotlib.pyplot.show()
        # matplotlib.pyplot.cla()
        # stopTime0=time.perf_counter()
        # sTR0=stopTime0-startTime0
        # print(sTR0,list(map(str,['mean0:',mean0,'scale0:',scale0,])))


# print('numpy.random.default_rng().weibull')
# startX0=0
# endX0=15
# n0=endX0-startX0
# bins0=100
# n0=bins0*10
# linewidth0=2
# for shape0 in [0.1,.5,1,10,50]:
    # startTime0=time.perf_counter()
    # matplotlib.pyplot.hist(numpy.random.default_rng(8).weibull(shape0,size=n0),bins=bins0,density=True)
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.weibull_min.pdf(numpy.linspace(startX0,endX0,n0),shape0),linewidth=linewidth0,color='wheat',label='weibull_min')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.weibull_max.pdf(numpy.linspace(startX0,endX0,n0),shape0),linewidth=linewidth0,color='magenta',label='weibull_max')
    # matplotlib.pyplot.plot(numpy.linspace(startX0,endX0,n0),scipy.stats.norm.pdf(numpy.linspace(startX0,endX0,n0)),linewidth=linewidth0,color='navy',label='normal')
    # matplotlib.pyplot.title(list(map(str,['shape0:',shape0])))
    # currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
    # currentFigManager0.window.state('zoomed')
    # matplotlib.pyplot.legend()
    # matplotlib.pyplot.show()
    # matplotlib.pyplot.cla()
    # stopTime0=time.perf_counter()
    # sTR0=stopTime0-startTime0
    # print(sTR0,list(map(str,['shape0:',shape0])))

# for n0 in [5,15]:
    # try:
        # print(random.random(n0))
    # except Exception as e:
        # print(e)
# for n0 in [range(2)]:
    # print(random.random())
# for n0 in list(range(2)):
    # print(random.random())

# print(numpy.iinfo(numpy.int_))
# print(numpy.random.default_rng(8).integers(0,numpy.iinfo(numpy.int_).max,size=10,endpoint=False))

# for l0 in list(range(2)):
    # for bit_generator0 in [numpy.random.MT19937,numpy.random.PCG64,numpy.random.PCG64DXSM,numpy.random.Philox,numpy.random.SFC64]:
        # try:
            # print('Generator; bit_generator0: ',bit_generator0,numpy.random.Generator(bit_generator0(20)).random())
            # bit_generator_instance0=bit_generator0(20)
            # print(bit_generator_instance0.state)
            # print(bit_generator_instance0.state,bit_generator_instance0.cffi,bit_generator_instance0.ctypes,sep='\n')
        # except Exception as e:
            # print(e)
        # try:
            # bit_generator_instance0=bit_generator_instance0.jumped(jumps=2)
            # print('after 2 jumps',bit_generator_instance0.state,bit_generator_instance0.cffi,bit_generator_instance0.ctypes,sep='\n')
        # except Exception as e:
            # print(e)
        # try:
            # bit_generator_instance0=bit_generator_instance0.advance(3)
            # print('after 3 advances',bit_generator_instance0.state,sep='\n')
        # except Exception as e:
            # print(e)
        # try:
            # print('RandomState; bit_generator0: ',bit_generator0,numpy.random.RandomState(bit_generator0(20)).rand())
        # except Exception as e:
            # print(e)

# entropy0=0x8735
# try:
    # print([numpy.random.SeedSequence(entropy0,entropyCounter0) for entropyCounter0 in range(12)])
# except Exception as e:
    # print(e)
# print([numpy.random.SeedSequence((entropy0,entropyCounter0)) for entropyCounter0 in range(12)])

# print(multiprocessing.cpu_count())
# print(os.cpu_count())

# print(numpy.get_include())

# crashes notepad++
# print(mmap.ALLOCATIONGRANULARITY,mmap.PAGESIZE,mmap.ALLOCATIONGRANULARITY/mmap.PAGESIZE,mmap.ACCESS_READ,mmap.ACCESS_WRITE,mmap.ACCESS_COPY,mmap.ACCESS_DEFAULT,sep='\n')
# for length0 in [0,-1,1000]:
    # for tagname0 in [None,'abc','def']:
        # for access0 in [mmap.ACCESS_READ,mmap.ACCESS_WRITE,mmap.ACCESS_COPY,mmap.ACCESS_DEFAULT]:
            # for offset0 in [0,-1*mmap.ALLOCATIONGRANULARITY,1000*mmap.ALLOCATIONGRANULARITY]:
                # try:
                    # with open(r'C:\Users\pdumas\Documents\VVV\2022\pbc\client\computer\final1FileFullPathG,IDM,LOnly10122022.txt','r') as f0:
                        # with mmap.mmap(f0.fileno(),length0,tagname=tagname0,access=access0) as m0:
                            # read0=m0.read()
                            # print(read0)
                # except Exception as e:
                    # print(e)
# for length0 in [0,-1,1000]:
    # try:
        # with open(r'C:\Users\pdumas\Documents\VVV\2022\pbc\client\computer\final1FileFullPathG,IDM,LOnly10122022.txt','r') as f0:
            # with mmap.mmap(f0.fileno(),length0,tagname=None,access=mmap.ACCESS_READ,offset=50*mmap.ALLOCATIONGRANULARITY) as m0:
                # read0=m0.read()
                # print(read0)
    # except Exception as e:
        # print(e)
# for length0 in [-1,100]:
    # try:
        # with mmap.mmap(-1,length0,tagname=None,access=mmap.ACCESS_COPY) as m0:
            # m0.write(b'this is binary\n this is more binary')
            # m0.flush(1,6)
            # m0.seek(0)
            # read0=m0.read()
            # print(read0)
            # m0.seek(0)
            # read0=m0.read(2)
            # print(read0)
            # m0.seek(0)
            # read0=m0.read_byte()
            # print(read0)
            # m0.seek(0)
            # read0=m0.readline()
            # print(read0)
            # m0.seek(0)
            # print(m0.find(b'is is'))
            # m0.seek(0)
            # m0.move(40,2,10)
            # read0=m0.read()
            # print(read0)
            # m0.seek(0)
            # print(m0.rfind(b'is is'))
            # m0.seek(100)
            # print(m0.size())
            # try:
                # print(m0.resize(150))
            # except Exception as e:
                # print(e)
            # print(m0.size())
            # print(m0.tell())
            # try:
                # m0.write_byte(116)
            # except Exception as e:
                # print(e)
            # try:
                # m0.write_byte(2)
            # except Exception as e:
                # print(e)
            # # # m0.write_byte(b'i')
            # m0.seek(0)
            # read0=m0.read()
            # print(read0)
            # print(m0.closed)
            # m0.close()
            # print(m0.closed)
            # print(m0.closed)
            # try:
                # m0.close()
            # except Exception as e:
                # print(e)
    # except Exception as e:
        # print(e)
# for length0 in [-1,100]:
    # try:
        # with mmap.mmap(-1,length0,tagname=None,access=mmap.ACCESS_WRITE) as m0:
            # m0.write(b'this is binary\n this is more binary')
            # m0.flush(1,6)
            # m0.seek(0)
            # m0.seek(100)
            # print(m0.size())
            # # # m0.resize(150)
            # # # try:
                # # # print(m0.resize(100*mmap.ALLOCATIONGRANULARITY))
            # # # except Exception as e:
                # # # print(e)
            # print(m0.size())
            # print(m0.tell())
            # try:
                # m0.write_byte(116)
            # except Exception as e:
                # print(e)
            # try:
                # m0.write_byte(2)
            # except Exception as e:
                # print(e)
            # m0.write_byte(b'i')
            # m0.seek(0)
            # mo0.close()
            # print(m0.closed)
            # print(m0.closed)
            # try:
                # mo0.close()
            # except Exception as e:
                # print(e)
    # except Exception as e:
        # print(e)

# print('tempfile')
# print(tempfile.tempdir,tempfile.gettempdir(),tempfile.gettempdirb(),tempfile.gettempprefix(),tempfile.gettempprefixb(),sep='\n')
# with tempfile.TemporaryFile() as tf0:
    # try:
        # tf0.write('test0')
    # except Exception as e:
        # print(e)
    # tf0.write(b'test0')
    # tf0.seek(0)
    # print(tf0.read())
    # try:
        # print(os.path.abspath(tf0))
    # except Exception as e:
        # print(e)
# try:
    # print(os.environ['TEMPDIR'])
# except Exception as e:
    # print(e)
# try:
    # print(os.environ['TEMP'])
# except Exception as e:
    # print(e)
# try:
    # print(os.environ['TMP'])
# except Exception as e:
    # print(e)
# # print(os.environ['PATH'])
# tempfile.TemporaryFile()
# with tempfile.NamedTemporaryFile(delete=False,prefix='testingTesting0',suffix='.testingTesting0') as tf0:
    # try:
        # tf0.write('test0')
    # except Exception as e:
        # print(e)
    # tf0.write(b'test0')
    # tf0.seek(0)
    # print(tf0.read())
    # try:
        # print(os.path.abspath(tf0))
    # except Exception as e:
        # print(e)
    # try:
        # print(tf0.name)
    # except Exception as e:
        # print(e)
    # try:
        # print(tf0.file)
    # except Exception as e:
        # print(e)
# with tempfile.SpooledTemporaryFile(max_size=2,prefix='testingTesting1',suffix='.testingTesting1') as tf0:
    # try:
        # tf0.write('test0')
    # except Exception as e:
        # print(e)
    # tf0.write(b'test0')
    # tf0.seek(0)
    # print(tf0.read())
    # try:
        # print(os.path.abspath(tf0))
    # except Exception as e:
        # print(e)
    # try:
        # print(tf0.name)
    # except Exception as e:
        # print(e)
    # try:
        # print(tf0.file)
    # except Exception as e:
        # print(e)
# with tempfile.SpooledTemporaryFile(max_size=2,prefix='testingTesting1',suffix='.testingTesting1') as tf0:
    # tf0.rollover()
    # try:
        # tf0.write('test0')
    # except Exception as e:
        # print(e)
    # tf0.write(b'test0')
    # tf0.seek(0)
    # print(tf0.read())
    # try:
        # print(os.path.abspath(tf0))
    # except Exception as e:
        # print(e)
    # try:
        # print(tf0.name)
    # except Exception as e:
        # print(e)
    # try:
        # print(tf0.file)
    # except Exception as e:
        # print(e)
# print(tempfile.TemporaryDirectory(ignore_cleanup_errors=True).name)
# print(tempfile.TemporaryDirectory(ignore_cleanup_errors=True).name)
# print(tempfile.TemporaryDirectory(ignore_cleanup_errors=True).name)
# with tempfile.TemporaryDirectory(ignore_cleanup_errors=True) as tdf0:
    # try:
        # tdf0.cleanup()
    # except Exception as e:
        # print(e)
# try:
    # with tempfile.mkstemp(prefix='testingTesting1',suffix='.testingTesting1',dir=r'C:\Users\pdumas\Downloads\testing0123',text=True) as tf0:
        # tf0.write('testing0')
        # tf0.seek(0)
        # print(tf0.read())
# except Exception as e:
    # print(e)
# try:
    # with tempfile.mkstemp(prefix='testingTesting1',suffix=None,dir=r'C:\Users\pdumas\Downloads\testing0123',text=True) as tf0:
        # tf0.write('testing0')
        # tf0.seek(0)
        # print(tf0.read())
# except Exception as e:
    # print(e)
# try:
    # with tempfile.mkstemp(prefix='testingTesting1',suffix=None,dir=r'C:\Users\pdumas\Downloads\testing0123',text=True) as tf0:
        # tf0.write('testing0')
        # tf0.seek(0)
        # print(tf0.read())
# except Exception as e:
    # print(e)
# try:
    # with tempfile.mkstemp(text=True) as tf0:
        # pass
# except Exception as e:
    # print(e)
# tfTupleHandleAndAFP0=tempfile.mkstemp()
# print(tfTupleHandleAndAFP0[0])
# print(tfTupleHandleAndAFP0[1])
# with open(tfTupleHandleAndAFP0[1]) as tf1:
    # try:
        # tf1.write('testing0')
    # except Exception as e:
        # print(e)
    # try:
        # tf1.write(b'testing0')
    # except Exception as e:
        # print(e)
    # tf1.seek(0)
    # print(tf1.read())
# tAFP0=tempfile.mkdtemp(prefix='testingTesting1',suffix='.testingTesting1',dir=r'C:\Users\pdumas\Downloads\testing0123')
# try:
    # print(tAFP0.name)
# except Exception as e:
    # print(e)
# print(tAFP0)
# tempfile.mktemp()
# os.system(r'''dir /o-d /p "C:\Users\PABLOD~1\AppData\Local\Temp"''')
# os.system(r'''dir /o-d /p "C:\Users\pdumas\Downloads\testing0123"''')

# ntf0=tempfile.NamedTemporaryFile(delete=False)
# print(ntf0)
# print(ntf0.name)
# print(ntf0.file)
# mm0=numpy.memmap(ntf0.name,dtype=numpy.float64,mode='r+',offset=0,shape=(4,4),order='C')
# print(mm0[:])
# mm0[:]=3
# print(mm0[:])
# print(mm0.filename)
# print(mm0.mode)
# print(mm0.offset)
# print(mm0.flush())
# print(mm0[:])
# # # mm0.close()
# ntf0.close()

# ntf0=tempfile.NamedTemporaryFile(delete=False)
# print(ntf0)
# print(ntf0.name)
# print(ntf0.file)
# try:
    # mm0=numpy.memmap(ntf0.name,dtype=numpy.float64,mode='c',offset=40,shape=(2,2),order='C')
# except Exception as e:
    # print(e)
# try:
    # with open(ntf0.name) as ntf1:
        # ntf1.write('1234')
        # ntf1.flush()
# except Exception as e:
    # print(e)
# ntf0.write(b'1234')
# ntf0.seek(0)
# print(ntf0.read())
# try:
    # mm0=numpy.memmap(ntf0.name,dtype=numpy.int32,mode='c',offset=40,order='C')
# except Exception as e:
    # print(e)
# try:
    # mm0=numpy.memmap(ntf0.name,dtype=numpy.int32,mode='c',offset=0,order='C')
# except Exception as e:
    # print(e)
# print(mm0[:])
# mm0[:]=3
# print(mm0[:])
# ntf0.seek(0)
# print(ntf0.read())
# print(mm0.filename)
# print(mm0.mode)
# print(mm0.offset)
# print(mm0.flush())
# print(mm0[:])
# # # mm0.close()
# ntf0.seek(0)
# print(ntf0.read())
# print(mm0.offset)
# ntf0.close()

# def aT0(fPA0,fPA1,*pAs,h0=1,**pKAs):#def aT0(fPA0,fPA1,*pAs,**pKAs,h0=1): > SyntaxError: invalid syntax
    # print(fPA0,fPA1,' and *a',*pAs,' and kw ',h0,' and **kw',**pKAs)
# try:
    # aT0(fPA0=4,fPA1=5)
# except Exception as e:
    # print(e)

# try:
    # aT0(4,5,8,9,h0=1,h1=2)
# except Exception as e:
    # print(e)

# try:
    # aT0(4,5,8,9,h0=1)
# except Exception as e:
    # print(e)

# try:
    # aT0(4,5,8,9)
# except Exception as e:
    # print(e)

# try:
    # aT0(4,5,8,9,1,2)
# except Exception as e:
    # print(e)

# try:
    # aT0(4)
# except Exception as e:
    # print(e)

# try:
    # aT0(4,fpA1=5)#all kw or no kw for fps; mix gives error
# except Exception as e:
    # print(e)

# try:
    # aT0(4,5,pAs=(1,2))
# except Exception as e:
    # print(e)

# l0=[1,2,3]
# l1=[4,5,6]
# mL0=[*l0,*l1]
# print(l0,l1,mL0)
# print(*l0,*l1,*mL0)
# d0={1:'a'}
# d1={2:'b'}
# mD0={**d0,**d1}
# try:
    # print(**d0,**d1,**mD0)
# except Exception as e:
    # print(e)
# try:
    # print(**d0)
# except Exception as e:
    # print(e)
# print({**d0})
# try:
    # eval('''kw0=**d0''')
# except Exception as e:
    # print(e)



# def aT0(fPA0,fPA1,*pAs,h0=1,**pKAs):
    # pAs0=(*pAs,)#    pAs0=*pAs > SyntaxError: can't use starred expression here
    # kWAs0={**pKAs}
    # return str(list([fPA0,fPA1,' and *a',pAs0,' and kw ',h0,' and **kw',kWAs0]))#return str(list([fPA0,fPA1,' and *a',*pAs,' and kw ',h0,' and **kw',**pKAs])) > SyntaxError: invalid syntax
# try:
    # aT0(fPA0=4,fPA1=5)
# except Exception as e:
    # print(e)

# try:
    # print(aT0(4,5,8,9,h0=1,h1=2))
# except Exception as e:
    # print(e)

# try:
    # print(aT0(4,5,8,9,h0=1))
# except Exception as e:
    # print(e)

# try:
    # print(aT0(4,5,8,9))
# except Exception as e:
    # print(e)

# try:
    # print(aT0(4,5,8,9,1,2))
# except Exception as e:
    # print(e)

# try:
    # print(aT0(4))
# except Exception as e:
    # print(e)

# try:
    # print(aT0(4,fpA1=5))
# except Exception as e:
    # print(e)

# try:
    # print(aT0(4,5,pAs=(1,2)))
# except Exception as e:
    # print(e)

# a0=numpy.arange(3)
# a1=numpy.arange(3,6,1)
# print(a0,a1)
# # f0=r'C:\Users\pdumas\Downloads\testing0123\s0'#auto adds ext.
# # if os.path.exists(f0):
    # # os.unlink(f0)
# # numpy.save(f0,(a0+a1),allow_pickle=True,fix_imports=True)
# # numpy.save(f0,(a0),allow_pickle=True,fix_imports=True)
# # numpy.save(f0,(a1),allow_pickle=True,fix_imports=True)
# # f0=r'C:\Users\pdumas\Downloads\testing0123\s0.npy'
# # a0=numpy.load(f0,mmap_mode='r+',allow_pickle=True,fix_imports=True,encoding='latin1')
# # print(a0)
# # a1=numpy.load(f0,mmap_mode='r+',allow_pickle=True,fix_imports=True,encoding='latin1')
# # print(a1)
# # a2=numpy.load(f0,mmap_mode='r+',allow_pickle=True,fix_imports=True,encoding='latin1')
# # print(a2)
# # a0._mmap.close()#this apparently stops all of py.exe from working..
# # a1._mmap.close()
# # a2._mmap.close()
# # os.system(r'start "" "C:\Users\pdumas\Downloads\testing0123\s0.npy"')
# # if os.path.exists(f0):
    # # os.unlink(f0)
# f0=r'C:\Users\pdumas\Downloads\testing0123\s0.npy'
# with open(f0,'wb') as f0:
    # numpy.save(f0,(a0+a1),allow_pickle=True,fix_imports=True)
    # numpy.save(f0,(a0),allow_pickle=True,fix_imports=True)
    # numpy.save(f0,(a1),allow_pickle=True,fix_imports=True)
# f0=r'C:\Users\pdumas\Downloads\testing0123\s0.npy'
# with open(f0,'rb') as f0:
    # try:
        # a0=numpy.load(f0,mmap_mode='r+',allow_pickle=True,fix_imports=True,encoding='latin1')
    # except Exception as e:
        # print(e)
    # a0=numpy.load(f0,mmap_mode=None,allow_pickle=True,fix_imports=True,encoding='latin1')
    # print(a0)
    # a1=numpy.load(f0,mmap_mode=None,allow_pickle=True,fix_imports=True,encoding='latin1')
    # print(a1)
    # a2=numpy.load(f0,mmap_mode=None,allow_pickle=True,fix_imports=True,encoding='latin1')
    # print(a2)

# f0=r'C:\Users\pdumas\Downloads\testing0123\s0.npy'
# f0=f0+'.npz'
# for tr0 in list(range(3)):
    # a0=numpy.arange(9)
    # a1=numpy.arange(9,16,1)
    # t0=time.perf_counter()
    # numpy.savez(f0,ar0=a0,ar1=a1)
    # nzf0=numpy.load(f0)
    # print(nzf0)
    # print(nzf0.files)
    # t1=time.perf_counter()
    # print(str(t1-t0))
    # t0=time.perf_counter()
    # numpy.savez_compressed(f0,ar0=a0,ar1=a1)#takes less time (maybe cause compressed? or caching? )
    # nzf0=numpy.load(f0)
    # print(nzf0)
    # print(nzf0.files)
    # t1=time.perf_counter()
    # print(str(t1-t0))

# f0=r'C:\Users\pdumas\Downloads\testing0123\s0.npy'
# try:
    # numpy.savetxt(f0,numpy.arange(12000,12012,1).copy('C').reshape(4,3),fmt='%-+02.3e+%-+02.3ej',header='tiaf0',footer='titeoaf0',comments='###',encoding='ascii',delimiter='|',newline='\n')
# except Exception as e:
    # print(e)
# f0=r'C:\Users\pdumas\Downloads\testing0123\s1.npy'
# numpy.savetxt(f0,numpy.arange(12000,12012,1).copy('C').reshape(4,3),fmt='%-+02.3e',header='tiaf0',footer='titeoaf0',comments='###',encoding='ascii',delimiter='|',newline='\n')
# os.system(r'''start "" "'''+f0+'''"''')
# f0=r'C:\Users\pdumas\Downloads\testing0123\s2.npy'
# numpy.savetxt(f0,numpy.arange(12000,12012,1).copy('C').reshape(4,3),fmt='%-02.3e',header='tiaf0',footer='titeoaf0',comments='###',encoding='ascii',delimiter='|',newline='\n')
# os.system(r'''start "" "'''+f0+'''"''')
# f0=r'C:\Users\pdumas\Downloads\testing0123\s3.npy'
# numpy.savetxt(f0,numpy.arange(12000,12012,1).copy('C').reshape(4,3),fmt='%2.3e',header='tiaf0',footer='titeoaf0',comments='###',encoding='ascii',delimiter='|',newline='\n')
# os.system(r'''start "" "'''+f0+'''"''')
# f0=r'C:\Users\pdumas\Downloads\testing0123\s0.npy'
# numpy.savetxt(f0,numpy.arange(12000,12012,1).copy('C').reshape(4,3),fmt='%-+02.4e',header='tiaf0',footer='titeoaf0',comments='###',encoding='ascii',delimiter='|',newline='\n')
# os.system(r'''start "" "'''+f0+'''"''')

# f0=r'C:\Users\pdumas\Downloads\testing0123\s0.npy'
# try:
    # nu0=numpy.loadtxt(f0,dtype=numpy.float32,comments='###',encoding='ascii',delimiter='|',newline='\n',skiprows=1,max_rows=1,usecols=(1,3),quotechar='"',ndmin=None,converters=int)
# except Exception as e:
    # print(e)
# try:
    # nu0=numpy.loadtxt(f0,dtype=numpy.float32,comments='###',encoding='ascii',delimiter='|',skiprows=1,max_rows=1,usecols=(1,3),quotechar='"',ndmin=None,converters=int)
# except Exception as e:
    # print(e)
# try:
    # nu0=numpy.loadtxt(f0,dtype=numpy.float32,comments=['###','`'],encoding='ascii',delimiter='|',skiprows=1,max_rows=1,usecols=(1,3),quotechar='"',ndmin=0,converters=int)
# except Exception as e:
    # print(e)
# try:
    # nu0=numpy.loadtxt(f0,dtype=numpy.float32,comments=['###','`'],encoding='ascii',delimiter='|',skiprows=1,max_rows=1,usecols=(1,3),quotechar=None,ndmin=0,converters=int)
# except Exception as e:
    # print(e)
# try:
    # nu0=numpy.loadtxt(f0,dtype="U",comments=['###','`'],encoding='ascii',delimiter='|',skiprows=1,max_rows=1,usecols=(1,3),quotechar=None,ndmin=0,converters=int)
# except Exception as e:
    # print(e)
# try:
    # nu0=numpy.loadtxt(f0,dtype="U",comments=['###','`'],encoding='ascii',delimiter='|',skiprows=1,max_rows=1,usecols=(1,3),quotechar=None,ndmin=0)
# except Exception as e:
    # print(e)
# nu0=numpy.loadtxt(f0,dtype="U",comments=['###','`'],encoding='ascii',delimiter='|',skiprows=1,max_rows=2,usecols=(0,2),quotechar=None,ndmin=0)
# print(nu0)
# u0=numpy.loadtxt(f0,dtype="U",comments=['###','`'],encoding='ascii',delimiter='|',skiprows=1,max_rows=2,usecols=(0,2),unpack=True,quotechar=None,ndmin=0)
# print(u0)
# a=numpy.loadtxt(f0,dtype="U",comments=['###','`'],encoding='ascii',delimiter='|',skiprows=1,max_rows=2,unpack=False,quotechar=None,ndmin=0)
# print(a)
# a,b=numpy.loadtxt(f0,dtype="U",comments=['###','`'],encoding='ascii',delimiter='|',skiprows=1,max_rows=2,unpack=False,quotechar=None,ndmin=0)
# print(a,b)
# a,b,c=numpy.loadtxt(f0,dtype="U",comments=['###','`'],encoding='ascii',delimiter='|',skiprows=1,max_rows=2,unpack=True,quotechar=None,ndmin=0)
# print(a,b,c)

# f0=r'C:\Users\pdumas\Downloads\testing0123\s4.npy'
# try:
    # a0=numpy.genfromtxt(f0,dtype='U',names=True,skip_header=1,skip_footer=1,usecols=(0,1,2,3),loose=True,invalid_raise=False,excludelist='e0',ndmin=2,encoding='latin1',delimiter='|',comments='#',missing_values='m0',filling_values='m1',deletechars='<>?',replace_space='S0',autostrip=True,usemask=True,defaultfmt='f%03i',unpack=False,case_sensitive='lower')
# except Exception as e:
    # print(e)
# a0=numpy.genfromtxt(f0,dtype='U',names=True,skip_header=1,skip_footer=1,usecols=(0,1,2,3),loose=True,invalid_raise=False,excludelist=['e0'],ndmin=2,encoding='latin1',delimiter='|',comments='#',missing_values='m0',filling_values='m1',deletechars='<>?',replace_space='S0',autostrip=True,usemask=True,defaultfmt='f%03i',unpack=False,case_sensitive='lower',converters={0:(lambda a: 100),4:300})
# print(a0)
# try:
    # a0=numpy.genfromtxt(f0,dtype='U',names=True,skip_header=1,skip_footer=1,delimiter='|',comments='#',missing_values='m0',filling_values='m1',deletechars='<>?',replace_space='S0',autostrip=True,usemask=True,defaultfmt='f%03i',unpack=False,case_sensitive='lower',converters={0:(lambda a: 100),4:300})
# except Exception as e:
    # print(e)
# a0=numpy.genfromtxt(f0,dtype='U',names=True,skip_header=1,skip_footer=1,delimiter='|',comments='#',invalid_raise=False,missing_values='m0',filling_values='m1',deletechars='<>?',replace_space='S0',autostrip=True,usemask=True,defaultfmt='f%03i',unpack=False,case_sensitive='lower')
# print(a0)
# a0=numpy.genfromtxt(f0,dtype='U',names=True,skip_header=1,skip_footer=1,delimiter='|',comments='#',invalid_raise=False,missing_values='m0',filling_values='m1')
# print(a0)
# try:
    # a0=numpy.genfromtxt(f0,dtype=None,names=True,skip_header=1,skip_footer=1,delimiter='|',comments='#',invalid_raise=False,missing_values='m0',filling_values='m1')
# except Exception as e:
    # print(e)
# a0=numpy.genfromtxt(f0,dtype="U",skip_header=1,skip_footer=1,delimiter='|',comments='#',invalid_raise=False,missing_values='m0',filling_values='m1')
# print(a0)
# a0=numpy.genfromtxt(f0,dtype="U",names=['a','b','c','d'],skip_header=1,skip_footer=1,delimiter='|',comments='#',invalid_raise=False,missing_values='m0',filling_values='m1')
# print(a0)

# l=[1,2,3,4,5]
# a,*b=l
# print(a,b,*b,sep='\n')
# a=[*"test"]
# print(a)
# *a,="test"
# print(a)
# (*a,)="test"
# print(a)
# *a,="test"
# a=tuple(a)
# print(a)

# f0=r'C:\Users\pdumas\Downloads\testing0123\tRE0.txt'
# n0=numpy.fromregex(f0,'(\d+)(\w+)',dtype=[('id0','i4'),('v0','U4')],encoding='ascii')
# print(n0)
# print(n0.dtype)
# print(n0['id0'])
# print(n0.astype(numpy.recarray))
# try:
    # print(n0.astype(numpy.recarray)['id0'])
# except Exception as e:
    # print(e)
# try:
    # print(n0.astype(numpy.recarray).id0)
# except Exception as e:
    # print(e)
# print(numpy.rec.array(n0).id0)

# try:
    # fs0=numpy.fromstring('a,b,c,d,e,f,g,h',dtype='U',count=-1,sep=',',like=None)
# except Exception as e:
    # print(e)
# try:
    # fs0=numpy.fromstring('a,b,c,d,e,f,g,h',dtype='U',count=-1,sep=',')
# except Exception as e:
    # print(e)
# try:
    # fs0=numpy.fromstring('a,b,c,d,e,f,g,h',dtype='U1',count=-1,sep=',')
# except Exception as e:
    # print(e)
# try:
    # fs0=numpy.fromstring('"a","b"',dtype='U1',count=-1,sep=',')
# except Exception as e:
    # print(e)
# fs0=numpy.fromstring('a,b,c,d,e,f,g,h',dtype=None,count=-1,sep=',')
# print(fs0)
# fs0=numpy.fromstring('1,2,3,4,5,6,7,8',dtype=None,count=-1,sep=',')
# print(fs0)
# fs0=numpy.fromstring('1,2,3,4,5, 6,7 ,8',dtype=None,count=7,sep=',')
# print(fs0)

# f0=r'C:\Users\pdumas\Downloads\testing0123\tTF0.txt'
# numpy.array([[1,2],[3,4]]).tofile(f0,sep=',',format='%s')
# os.system(r'''start "" "'''+f0+'''"''')
# a0=numpy.fromfile(f0,sep=',')#loses dimension (along with endianness,etc.)
# print(a0)

# f0=r'C:\Users\pdumas\Downloads\testing0123\tTF1.txt'
# numpy.array([[1,2],[3,4]]).tofile(f0,sep='',format='%s')
# os.system(r'''start "" "'''+f0+'''"''')
# a0=numpy.fromfile(f0,count=2,sep='',offset=2)
# print(a0)

# f0=r'C:\Users\pdumas\Downloads\testing0123\tTF2.txt'
# print(numpy.array([[1,2],[3,4]]).dtype.str)
# numpy.array([[1,2],[3,4]]).tofile(f0,sep='',format='%s')
# os.system(r'''start "" "'''+f0+'''"''')
# a0=numpy.fromfile(f0,count=8,sep='',offset=8)
# print(a0)

# print(list(numpy.array([[1,2],[3,4]])))
# print(list(numpy.array([1,2,3,4])))
# print(list(numpy.array([1])))
# try:
    # print(list(numpy.array(1)))
# except Exception as e:
    # print(e)
# print(numpy.array([[1,2],[3,4]]).tolist())
# print(numpy.array([1,2,3,4]).tolist())
# print(numpy.array([1]).tolist())
# print(numpy.array(1).tolist())

# try:
    # print(numpy.array2string(numpy.arange(1e4).copy('c').reshape(1e2,1e1,1e1),precision=1,edgeitems=50,threshold=20,prefix='prefix0',suffix='suffix0',max_line_width=80,legacy='1.3',floatmode='fixed',formatter={'int_kind':lambda x:'%2.i'%x},sign=' ',separator='|',suppress_small=True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.array2string(numpy.arange(1e4).copy('c').reshape(1e2,1e1,1e1),precision=1,edgeitems=50,threshold=20,prefix='prefix0',suffix='suffix0',max_line_width=80,legacy='1.3',formatter={'int_kind':lambda x:'%2.i'%x},sign=' ',separator='|',suppress_small=True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.array2string(numpy.arange(1e4).copy('c').reshape(1e2,1e1,1e1),precision=1,edgeitems=50,threshold=20,prefix='prefix0',suffix='suffix0',max_line_width=80,legacy='1.3',sign=' ',separator='|',suppress_small=True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.array2string(numpy.arange(1e4).astype(int).copy('c').reshape(int(1e2),int(1e1),int(1e1)),precision=1,edgeitems=50,threshold=20,prefix='prefix0',suffix='suffix0',max_line_width=80,legacy='1.13',sign=' ',separator='|',suppress_small=True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.array2string(numpy.arange(1e4).astype(int).copy('c').reshape(int(1e2),int(1e1),int(1e1)),precision=1,edgeitems=5,threshold=2,prefix='prefix0',suffix='suffix0',max_line_width=8,legacy='1.13',floatmode='fixed',formatter={'int_kind':lambda x:'%2.i'%x},sign=' ',separator='|',suppress_small=True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.array2string(numpy.arange(1e4).astype(int).copy('c').reshape(int(1e2),int(1e1),int(1e1)),precision=1,edgeitems=5,threshold=2,prefix='prefix0',suffix='suffix0',max_line_width=80,legacy='1.13',floatmode='fixed',formatter={'int_kind':lambda x:'%2.i'%x},sign=' ',separator='|',suppress_small=True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.array2string(numpy.arange(1e4).astype(int).copy('c').reshape(int(1e2),int(1e1),int(1e1)),precision=1,edgeitems=10,threshold=1e5,prefix='prefix0',suffix='suffix0',max_line_width=28,legacy='1.13',floatmode='fixed',formatter={'int_kind':lambda x:hex(x)},sign=' ',separator='|',suppress_small=True))
# except Exception as e:
    # print(e)

# print(numpy.get_printoptions())
# print(numpy.array_repr(numpy.array([1e-12,1e-4,2.3e-6,12000]),max_line_width=2000,precision=5,suppress_small=True))
# print(numpy.array_repr(numpy.array([1e-12,1e-4,1.423414,2.3e-6,2.3123451,12000]),max_line_width=2000,precision=5))
# print(numpy.array_repr(numpy.rec.array(numpy.array([1e-12,1e-4,1.423414,2.3e-6,2.3123451,12000])).astype(numpy.float32),max_line_width=2000,precision=5))
# print(numpy.array_str(numpy.rec.array(numpy.array([1e-12,1e-4,1.423414,2.3e-6,2.3123451,12000])).astype(numpy.float32),max_line_width=2000,precision=5))

# print(numpy.format_float_positional(numpy.pi,pad_left=5,pad_right=10,unique=False,precision=8,fractional=False))
# try:
    # print(numpy.format_float_positional(.4,pad_left=5,pad_right=15,unique=True,precision=8,fractional=False,min_digits=10,sign=True))
# except Exception as e:
    # print(e)
# print(numpy.format_float_positional(.4,pad_left=5,pad_right=15,unique=True,fractional=False,min_digits=10,trim='k'))
# print(numpy.format_float_positional(.4,pad_left=5,pad_right=15,unique=True,fractional=False,min_digits=10,trim='0'))
# print(numpy.format_float_positional(.4,pad_left=5,pad_right=15,unique=True,fractional=False,min_digits=10,trim='.'))
# print(numpy.format_float_positional(.4,pad_left=5,pad_right=15,unique=True,fractional=False,min_digits=10,trim='-'))
# print(numpy.format_float_positional(4.,pad_left=5,pad_right=15,unique=True,fractional=False,min_digits=10,trim='k'))
# print(numpy.format_float_positional(4.,pad_left=5,pad_right=15,unique=True,fractional=False,min_digits=10,trim='0'))
# print(numpy.format_float_positional(4.,pad_left=5,pad_right=15,unique=True,fractional=False,min_digits=10,trim='.'))
# print(numpy.format_float_positional(4.,pad_left=5,pad_right=15,unique=True,fractional=False,min_digits=10,trim='-'))

# print(numpy.format_float_scientific(numpy.pi,pad_left=5,exp_digits=10,unique=False,precision=8))
# print(numpy.format_float_scientific(numpy.pi,pad_left=5,exp_digits=1,unique=False,precision=8))
# try:
    # print(numpy.format_float_scientific(.4,pad_left=5,exp_digits=15,unique=True,precision=8,min_digits=10,sign=True))
# except Exception as e:
    # print(e)
# print(numpy.format_float_scientific(.4,pad_left=5,exp_digits=15,unique=True,min_digits=20,trim='k'))
# print(numpy.format_float_scientific(.4,pad_left=5,exp_digits=15,unique=True,min_digits=20,trim='0'))
# print(numpy.format_float_scientific(.4,pad_left=5,exp_digits=15,unique=True,min_digits=20,trim='.'))
# print(numpy.format_float_scientific(.4,pad_left=5,exp_digits=15,unique=True,min_digits=20,trim='-'))
# print(numpy.format_float_scientific(4.,pad_left=5,exp_digits=15,unique=True,min_digits=20,trim='k'))
# print(numpy.format_float_scientific(4.,pad_left=5,exp_digits=15,unique=True,min_digits=20,trim='0'))
# print(numpy.format_float_scientific(4.,pad_left=5,exp_digits=15,unique=True,min_digits=20,trim='.'))
# print(numpy.format_float_scientific(4.,pad_left=5,exp_digits=15,unique=True,min_digits=20,trim='-'))
# print(numpy.format_float_scientific(40012.,pad_left=5,exp_digits=15,unique=True,min_digits=20,trim='k'))
# print(numpy.format_float_scientific(40012.,pad_left=5,exp_digits=15,unique=True,min_digits=20,trim='0'))
# print(numpy.format_float_scientific(40012.,pad_left=5,exp_digits=15,unique=True,min_digits=20,trim='.'))
# print(numpy.format_float_scientific(40012.,pad_left=5,exp_digits=15,unique=True,min_digits=20,trim='-'))


# numpy.set_printoptions(floatmode='fixed',precision=9)
# print(2.34567)
# print(2.)
# print(2)
# numpy.set_printoptions(floatmode='maxprec_equal',precision=9)
# print(2.34567)
# print(2.)
# print(2)
# numpy.set_printoptions(floatmode='maxprec',precision=9)
# print(2.34567)
# print(2.)
# print(2)
# numpy.set_printoptions(floatmode='fixed',precision=9)
# print(2.34567)
# print(2.)
# print(2)

# numpy.set_printoptions(floatmode='unique',precision=9)
# print(numpy.array([2.34567]))
# print(numpy.array([2.]))
# print(numpy.array([2]))
# numpy.set_printoptions(floatmode='maxprec_equal',precision=9)
# print(numpy.array([2.34567]))
# print(numpy.array([2.]))
# print(numpy.array([2]))
# numpy.set_printoptions(floatmode='maxprec',precision=9)
# print(numpy.array([2.34567]))
# print(numpy.array([2.]))
# print(numpy.array([2]))
# numpy.set_printoptions(floatmode='fixed',precision=9)
# print(numpy.array([2.34567]))
# print(numpy.array([2.]))
# print(numpy.array([2]))

# numpy.set_printoptions(floatmode='unique',precision=9)
# print(numpy.array([2.3456789123456,2.34567,2.,2]))
# numpy.set_printoptions(floatmode='maxprec',precision=9)
# print(numpy.array([2.3456789123456,2.34567,2.,2]))
# numpy.set_printoptions(floatmode='maxprec_equal',precision=9)
# print(numpy.array([2.3456789123456,2.34567,2.,2]))
# numpy.set_printoptions(floatmode='fixed',precision=9)
# print(numpy.array([2.3456789123456,2.34567,2.,2]))

# with numpy.printoptions(legacy='1.21') as po0:
    # d0=numpy.dtype([('n0', 'i4'),('n1', 'i4')])
    # print(numpy.array([(1,2),(3,4)],dtype=d0))
    # print(po0)
    # print(numpy.get_printoptions())
# d0=numpy.dtype([('n0', 'i4'),('n1', 'i4')])
# print(numpy.array([(1,2),(3,4)],dtype=d0))

# numpy.set_printoptions(infstr='IAInf0',nanstr='IANan0',sign=' ')
# print(numpy.inf,numpy.PINF,numpy.NINF,numpy.nan,24,-24,.000003,-.00000000000009,.02)
# print(numpy.array([numpy.inf,numpy.PINF,numpy.NINF,numpy.nan,24,-24,.000003,-.00000000000009,.02]))
# numpy.set_printoptions(infstr='IAInf0',nanstr='IANan0',sign='+',suppress=True)
# print(numpy.array([numpy.inf,numpy.PINF,numpy.NINF,numpy.nan,24,-24,.000003,-.00000000000009,.02]))

# print(numpy.binary_repr(23,width=None))
# print(numpy.binary_repr(-23,width=None))
# print(numpy.binary_repr(23,width=16))
# print(numpy.binary_repr(-23,width=16))

# print(numpy.base_repr(23,base=2,padding=None))
# print(numpy.base_repr(-23,base=2,padding=None))
# print(numpy.base_repr(23,base=2,padding=16))
# print(numpy.base_repr(-23,base=2,padding=16))
# print(numpy.base_repr(23,base=36,padding=16))
# print(numpy.base_repr(-23,base=36,padding=16))
# print(numpy.base_repr(23,base=8,padding=16))
# print(numpy.base_repr(-23,base=8,padding=16))
# print(numpy.base_repr(23,base=10,padding=16))
# print(numpy.base_repr(-23,base=10,padding=16))
# print(numpy.base_repr(23,base=16,padding=16))
# print(numpy.base_repr(-23,base=16,padding=16))
# try:
    # print('%o %d %x'%23,23,23)
# except Exception as e:
    # print(e)
# print('%o %d %x'.format(23))
# print('{0:b} {0:o} {0:d} {0:x}'.format(23))

# os.chdir(r'C:\Users\pdumas\Downloads\testing0123\testing012345')
# print(os.getcwd())
# print(numpy.DataSource(destpath='.'))
# ds0=numpy.DataSource()
# print(ds0.exists(r'https://www.google.com/index.html'),ds0.abspath(r'https://www.google.com/index.html'),ds0.open(r'https://www.google.com/index.html'))
# try:
    # with ds0.open(r'https://www.google.com/index.html',mode='w',encoding='bytes',newline='\n') as ds0f0:
        # r0=ds0f0.read()
        # print(r0)
# except Exception as e:
    # print(e)
# try:
    # with ds0.open(r'https://www.google.com/index.html',mode='r',encoding='bytes',newline='\n') as ds0f0:
        # r0=ds0f0.read()
        # print(r0)
# except Exception as e:
    # print(e)
# try:
    # with ds0.open(r'https://www.google.com/index.html',mode='r',encoding='ascii',newline='\n') as ds0f0:
        # r0=ds0f0.read()
        # print(r0)
# except Exception as e:
    # print(e)
# try:
    # with ds0.open(r'https://www.google.com/index.html',mode='w',encoding=None,newline=None) as ds0f0:
        # r0=ds0f0.read()
        # print(r0)
# except Exception as e:
    # print(e)

# print(numpy.dtype('i4').descr)
# try:
    # print(numpy.float32.descr)
# except Exception as e:
    # print(e)
# print(numpy.dtype(numpy.float32).descr)
# print(numpy.lib.format.descr_to_dtype(numpy.dtype(numpy.float32).descr))
# print(numpy.lib.format.descr_to_dtype('i4'))
# print(numpy.lib.format.dtype_to_descr(numpy.dtype(numpy.float32)))

# print(numpy.lib.format.magic(23,2))
# f0=r'C:\Users\pdumas\Downloads\testing0123\nlfT0.npy'
# print(numpy.lib.format.header_data_from_array_1_0(numpy.arange(10.)))
# with open(f0,'wb') as f1:
    # numpy.lib.format.write_array(f1,numpy.arange(10.),version=(2,0),allow_pickle=False,pickle_kwargs={'fix_imports':False,'encoding':'ascii'})
# with open(f0,'rb') as f1:
    # ra0=numpy.lib.format.read_array(f1,allow_pickle=True,pickle_kwargs={'fix_imports':False,'encoding':'ascii'})
    # print(ra0)
# try:
    # with open(f0,'rb') as f1:
        # rm0=numpy.lib.format.read_magic(f1)
        # rah100=numpy.lib.format.read_array_header_1_0(f1)
        # rah200=numpy.lib.format.read_array_header_2_0(f1)
        # print(rm0,rah100,rah200,sep='\n')
# except Exception as e:
    # print(e)
# with open(f0,'rb') as f1:
    # rm0=numpy.lib.format.read_magic(f1)
    # print(rm0)
# try:
    # with open(f0,'rb') as f1:
        # rah100=numpy.lib.format.read_array_header_1_0(f1)
        # print(rah100)
# except Exception as e:
    # print(e)
# f0=r'C:\Users\pdumas\Downloads\testing0123\nlfT0.npy'
# numpy.save(f0,numpy.arange(10))
# try:
    # with open(f0,'rb') as f1:
        # rah100=numpy.lib.format.read_array_header_1_0(f1)
        # print(rah100)
# except Exception as e:
    # print(e)
# try:
    # with open(f0,'rb') as f1:
        # rah200=numpy.lib.format.read_array_header_2_0(f1)
        # print(rah200)
# except Exception as e:
    # print(e)
# with open(f0,'wb') as f1:
    # numpy.lib.format.write_array_header_1_0(f1,{'descr':[('', '<f4')],'fortran_order':False,'shape':(10,)})
# try:
    # with open(f0,'rb') as f1:
        # rah100=numpy.lib.format.read_array_header_1_0(f1)
        # print(rah100)
# except Exception as e:
    # print(e)
# with open(f0,'wb') as f1:
    # numpy.lib.format.write_array_header_2_0(f1,{'descr':[('', '<f4')],'fortran_order':False,'shape':(10,)})
# try:
    # with open(f0,'rb') as f1:
        # rah200=numpy.lib.format.read_array_header_2_0(f1)
        # print(rah200)
# except Exception as e:
    # print(e)

# try:
    # with mmap.mmap(-1,100,tagname=None,prot=mmap.PROT_READ,access=mmap.ACCESS_WRITE) as m0:#this would error in Linux
        # pass
# except Exception as e:
    # print(e)
# try:
    # with mmap.mmap(-1,100,tagname=None,access=mmap.ACCESS_WRITE) as m0:
        # m0.write(b'this is binary\n this is more binary')
        # m0.flush(1,6)
        # m0.seek(0)
        # m0.seek(100)
        # print(m0.size())
        # m0.resize(150)
        # try:
            # print(m0.resize(100*mmap.ALLOCATIONGRANULARITY))#this would work in python 3.11
        # except Exception as e:
            # print(e)
        # print(m0.size())
        # print(m0.tell())
        # try:
            # m0.write_byte(116)
        # except Exception as e:
            # print(e)
        # try:
            # m0.write_byte(2)
        # except Exception as e:
            # print(e)
        # m0.write_byte(b'i')
        # m0.seek(0)
        # mo0.close()
        # print(m0.closed)
        # print(m0.closed)
        # try:
            # mo0.close()
        # except Exception as e:
            # print(e)
# except Exception as e:
    # print(e)

# s0=io.StringIO('comment0n0,n1,n2\nv0,v1,v2\n3,,m0')
# try:
    # print(numpy.lib.npyio.recfromtxt(s0,comments='comment0',missing_values={1:'',None:'m0'},filling_values={1:'column1mv',None:'iAmNone0'},names=True,usecols=(-2,-1),delimiter=','))
# except Exception as e:
    # print(e)
# s0=io.StringIO('comment0n0,n1,n2\nv0,v1,v2\n3,,m0')
# print(numpy.lib.npyio.recfromtxt(s0,comments='comment0',missing_values={1:'',None:'m0'},filling_values={-2:'column1mv',-1:'iAmNone0'},names=True,usecols=(-2,-1),delimiter=','))
# s0=io.StringIO('comment0n0,n1,n2\nv0,v1,v2\n3,,m0')
# print(numpy.lib.npyio.recfromtxt(s0,comments='comment0',missing_values={1:'',None:'m0'},names=True,usecols=(-2,-1),delimiter=','))
# s0=io.StringIO('comment0n0,n1,n2\nv0,v1,v2\n3,,m0')
# print(numpy.lib.npyio.recfromcsv(s0,comments='comment0',missing_values={1:'',None:'m0'},filling_values={1:'column1mv',2:'iAmNone0'},names=True,usemask=True))
# for d0 in [numpy.bool_,numpy.int_,numpy.float_,numpy.complex_,numpy.string_]:
    # s0=io.StringIO('comment0n0,n1,n2\n,,\n1,1,1')
    # print(numpy.genfromtxt(s0,dtype=d0,comments='comment0',names=True,delimiter=','))
# s0=io.StringIO('v0,v1,v2\n3,,m0')
# print(numpy.lib.npyio.recfromtxt(s0,dtype=('U2','U2','U2'),comments='comment0',defaultfmt='df_%03f',delimiter=',').dtype)

# print(numpy.iinfo(numpy.int_))
# print(sys.version,sys.maxsize,sep='\n')
# print(numpy.distutils.system_info.platform_bits)

# print(numpy.int_([4,5,6]))
# print(numpy.float_([4,5,6]))
# print(numpy.float_([4]))

# l0=[]
# p0=os.getcwd()
# dateString0='10122022'
# directoryWithAllIndividualFiles = os.fsencode(r'C:\Users\pdumas\Documents'+dateString0)
# stringToPrintWithoutBeingAnArg0='stringToPrintWithoutBeingAnArg0'
# global iAmAGlobalInt
# iAmAGlobalInt=0
# def loopThroughDirectoryFilesAndReadFilesInto1FileDelimitedByPipeVVVMSSQL(dateString0,directoryWithAllIndividualFiles):
    # print('local',dateString0,directoryWithAllIndividualFiles)
    # dateString0=str(datetime.date.today())
    # print('localChanged',dateString0,directoryWithAllIndividualFiles)
    # print(inspect.stack()[0][3])
    # print(inspect.stack()[0])
    # l0.append(p0)
    # print(l0)
    # s0='modifyMe'
    # print(s0)
    # s0='iMModified'
    # print(s0)
    # global s1,s2
    # s1 = 'modifyMe1'
    # print(s1)
    # s1='iMModified1'
    # print(s1)
    # print(stringToPrintWithoutBeingAnArg0)
# for i in list(range(3)):
    # iAmAGlobalInt+=1
# loopThroughDirectoryFilesAndReadFilesInto1FileDelimitedByPipeVVVMSSQL(dateString0,directoryWithAllIndividualFiles)
# print('global',dateString0,directoryWithAllIndividualFiles)
# dateString0=str(datetime.date.today())
# print('globalChanged',dateString0,directoryWithAllIndividualFiles)
# print(l0)
# try:
    # print(s0)
# except Exception as e:
    # print(e)
# print(s1)
# print(iAmAGlobalInt)

# for d0 in [bool,int,float,complex]:
    # print(numpy.array([1,2],dtype=d0))

# print(str('Ã¼'))
# try:
    # unicode('Ã¼')
# except Exception as e:
    # print(e)


# df0 = pandas.DataFrame({'Col1': ['Bob', 'Joe', 'Bill', 'Mary', 'Joe'],
                   # 'Col2': ['Joe', 'Steve', 'Bob', 'Bob', 'Steve'],
                   # 'Col3': numpy.random.random(5)})
# print(df0)
# try:
    # print(pandas.unique(df0))
# except Exception as e:
    # print(e)
# try:
    # print(pandas.unique(df0).values)
# except Exception as e:
    # print(e)
# try:
    # print(pandas.unique(df0[['Col1', 'Col2']]))
    # print(pandas.unique(df0[['Col1', 'Col2']]).values)
    # print(pandas.unique(df0[['Col1', 'Col2']]).values.ravel('K'))
# except Exception as e:
    # print(e)
# print(pandas.unique(df0[['Col1', 'Col2']].values.ravel('K')))

# try:
    # from dask.distributed import Client
    # from dask_kubernetes import KubeCluster
    # c0=KubeCluster()
    # cl0=Client(c0)
    # print(cl0)
# except Exception as e:
    # print(e)

# try:
    # lc0=dask.distributed.LocalCluster()
    # print(lc0,lc0.scheduler,lc0.workers,lc0.get_logs(),lc0.dashboard_link,sep='\n\n\n')
    # c0=dask.distributed.Client(lc0)
    # print(c0)
# except Exception as e:
    # print(e)

# try:
    # from numba import cuda
    # computeCoresPerStreamingMultiprocessorDictionary=cc_cores_per_SM_dict = {
        # (2,0) : 32,
        # (2,1) : 48,
        # (3,0) : 192,
        # (3,5) : 192,
        # (3,7) : 192,
        # (5,0) : 128,
        # (5,2) : 128,
        # (6,0) : 64,
        # (6,1) : 128,
        # (7,0) : 64,
        # (7,5) : 64,
        # (8,0) : 64,
        # (8,6) : 128,
        # (8,9) : 128,
        # (9,0) : 128
        # }
    # device0=cuda.get_current_device()
    # streamingMULTIPROCESSOR_COUNT0=getattr(current_device0,'MULTIPROCESSOR_COUNT')
    # print(streamingMULTIPROCESSOR_COUNT0)
    # compute_capability0=current_device0.compute_capability
    # print(compute_capability0)
    # computeCoresPerStreamingMultiprocessor=computeCoresPerStreamingMultiprocessorDictionary[compute_capability0]
    # print(computeCoresPerStreamingMultiprocessor)
    # totalCores0=streamingMULTIPROCESSOR_COUNT0*computeCoresPerStreamingMultiprocessor
    # print(totalCores0)
# except Exception as e:
    # print(e)

# import tensorflow
# print(tensorflow.test.gpu_device_name())
# print(tensorflow.test.is_built_with_cuda())

# print(numpy.getbufsize())
# bs0=numpy.getbufsize()
# print(numpy.setbufsize(bs0*16))
# print(numpy.getbufsize())


# s0='123'
# s1='456'
# s2='789'
# def testPrint0(sPrint0,sPrint1=s0):
    # print(sPrint0)
    # print(sPrint1)
    # x0=0
    # temporaryVariable0='x1'
    # globals()[temporaryVariable0]=1
# testPrint0(s2)
# testPrint0(s2,sPrint1=s1)
# try:
    # print(x0)
# except Exception as e:
    # print(e)
# print(x1)

# o0=numpy.ones(4)
# z0=numpy.zeros(4)
# print(numpy.shares_memory(o0[::2],o0[1::2]))
# print(numpy.shares_memory(o0[::2],o0[::1]))#if shares at least 1, then True; in other words, has to COMPLETELY NOT SHARE memory to return False
# try:
    # print(numpy.shares_memory(o0[::2],o0[::1],max_work=1))
# except Exception as e:
    # print(e)
# print(numpy.shares_memory(o0[::2],o0[::1],max_work=numpy.MAY_SHARE_EXACT))
# try:
    # print(numpy.shares_memory(o0[::2],o0[::1],max_work=numpy.MAY_SHARE_BOUNDS))#not sure why this is erroring..
# except Exception as e:
    # print(e)
# print(numpy.shares_memory(o0,z0,max_work=numpy.MAY_SHARE_BOUNDS))
# print(numpy.may_share_memory(o0[::2],o0[::1]))
# print(numpy.byte_bounds(o0))
# print(numpy.byte_bounds(o0)[0])
# print(numpy.byte_bounds(o0)[1])
# print(numpy.byte_bounds(o0)[1]-numpy.byte_bounds(o0)[0])
# print(id(o0[0]))
# print(id(o0[3]))
# print(id(o0))
# print(o0.itemsize*o0.size)

# print(numpy.lib.mixins.NDArrayOperatorsMixin)
# print(dir(numpy.lib.mixins.NDArrayOperatorsMixin))

# import numbers
# try:
    # print(tuple([1,2])(1,2))
# except Exception as e:
    # print(e)
# import numpy.lib.mixins
# acceptable_functions0={}
# class ArrayLike0(numpy.lib.mixins.NDArrayOperatorsMixin):#when called, this seems to hijack sys.stdout.. script finishes without printing anything to output file.. no idea why.
    # def __init__(self,value):
        # self.value=numpy.asarray(value)
    # _acceptable0=(numbers.Number,numpy.ndarray)
    # def __array_ufunc__(self,ufunc,method,*args,**kwargs):
        # # out=kwargs['out']
        # out=kwargs.get('out',())#default value is better
        # for input0 in args+out:
            # if not isinstance(input0,self._acceptable0+(ArrayLike0,)):
                # return NotImplemented
        # args=tuple(input0.value if isinstance(input0,ArrayLike0) else (input0 for input0 in args))
        # if out:
            # kwargs['out']=tuple(input0.value if isinstance(input0,ArrayLike0) else input0 for input0 in out)
        # result0=getattr(ufunc,method)(*args,**kwargs)
        # if type(result0) is tuple:
            # return tuple(type(self)(output0) for output0 in result0)
        # elif method=='at':
            # return None
        # else:
            # return tuple(type(self)(result0))
    # def __repr__(self):
        # return '{}({})'.format(type(self).__name__,self.value)
    # def __array_function__(self,func,types,*args,**kwargs):
        # if func not in acceptable_functions0:
            # return NotImplemented
        # if not all(issubclass(type0,self.__class__) for type0 in types):
            # return NotImplemented
        # return acceptable_functions0[func](*args,**kwargs)

# a0=ArrayLike0([1,3,5])
# print(a0)
# print(numpy.add(a0,10))
# print(numpy.add.at(a0,[1,1],20))

# import numpy.lib
# print(numpy.lib.NumpyVersion('1.6.0'))
# print(numpy.lib.NumpyVersion(numpy.__version__)>='1.23.0')
# print(numpy.lib.NumpyVersion('1.24.0a1.dev-f1234ada')==numpy.lib.NumpyVersion('1.24.0a2.dev-f1234ada'))
# print(numpy.lib.NumpyVersion('1.24.0a1.dev-f1234ada')==numpy.lib.NumpyVersion('1.24.0a1.dev-f125ada'))
# print(dir(numpy.lib.NumpyVersion))
# print(numpy.lib.NumpyVersion)

# print(numpy.get_include())

# print(numpy.show_config())

# print(numpy.deprecate(numpy.float32,old_name=None,new_name=numpy.float64,message='DO NOT USE OLD'))
# d0=numpy.deprecate(numpy.float32,old_name=None,new_name=numpy.float64,message='DO NOT USE OLD')
# # print(d0)
# print(d0(2.4))

# @numpy.deprecate_with_doc('DO NOT USE THIS D FUNC')
# def dMe0():
    # return 'dMe0'

# print(dMe0())

# print(numpy.broadcast_shapes((2,3),(5,2,1),(1,1,3)))
# try:
    # print(numpy.broadcast_shapes((2,3),(5,2,1),(5,)))
# except Exception as e:
    # print(e)

# g0=numpy.arange(4.)
# g1=numpy.arange(4,dtype=numpy.complex64)
# d0={'l0':numpy.arange(4.),'l1':numpy.arange(4.)}
# print(numpy.who(vardict=d0))
# print(numpy.who(vardict=None))

# numpy.disp('withoutLF',device=None,linefeed=False)
# numpy.disp('withLF',device=None,linefeed=True)

# print(numpy.AxisError(-1,4,'''this really shouldn't be an error'''))
# print(numpy.AxisError(None,None,'''this really shouldn't be an error'''))

# if 1:
    # v0='canIBeSetInsideIfAndGottenOutsideIf'
# print(v0)

# def returnBeforePrint():
    # return 'hello'
    # print('hello2')
# print(returnBeforePrint())

# print({'t0':'test0'}['t0'])

# # ~/.numpy-site.cfg
# #pip install --all-binary:all --dest . --no-cache numpy
# #pip install --no-binary:numpy --dest . --no-cache numpy
# #py setup.py bdist_wheel

# import multipledispatch
# @multipledispatch.dispatch(str,str)
# def concat0(str0,str1):
    # return str0+str1
# @multipledispatch.dispatch(int,int)
# def concat0(int0,int1):
    # return int0+int1
# print(concat0("s0","s1"))
# print(concat0(2,3))
# n0={}
# @multipledispatch.dispatch(str,str,namespace=n0)
# def concat1(str0,str1):
    # return str0+str1
# @multipledispatch.dispatch(int,int,namespace=n0)
# def concat1(int0,int1):
    # return int0+int1
# print(concat1("s0","s1"))
# print(concat1(2,3))
# print(multipledispatch.core.global_namespace)

# a0=numpy.arange(3)
# print(a0)
# a0[:2]=0
# print(a0)
# a1=a0[:2]
# print(a1)
# a1[:]=100
# print(a0)
# print(a1)
# a1=100
# print(a1)




# class cT0(list):
    # def __new__(cls, iterable0):
        # tL0=[]
        # for arg0 in iterable0:
            # print(arg0)
            # arg0=arg0+100
            # print(arg0)
            # tL0.append(arg0)
            # print(tL0)
        # print(tL0)
        # return super().__new__(cls,tL0)
    # def __init__(self,iterable0):
        # tL0=[]
        # for arg0 in iterable0:
            # print(arg0)
            # arg0=arg0+100
            # print(arg0)
            # tL0.append(arg0)
            # print(tL0)
        # print(tL0)
        # return super().__init__(tL0)

    # # def __init__(self,iterable0,*args,**kwargs):
        # # for c0,v0 in enumerate(iterable0):
            # # print(c0)
            # # try:
                # # self[c0]=v0
            # # except Exception as e:
                # # print(e)
        # # return None#TypeError: __init__() should return None, not 'cT0'
# class UppercaseTuple(tuple):
    # def __new__(cls,iterable):
        # UpperIterable=(s.upper() for s in iterable)
        # return super().__new__(cls,UpperIterable)

# # pdb.set_trace()#doesn't work for whatever reason..
# cT0I0=cT0((1,2,3))
# print(cT0I0)
# uT0=UppercaseTuple(('upperMe','upperMe2'))
# print(uT0)
# # for i in uT0:
    # # print(i)    

# # NPY_CBLAS_LIBS
# # NPY_BLAS_LIBS
# # NPY_LAPACK_LIBS
# # NPY_BLAS_ORDER
# # NPY_LAPACK_ORDER

# from astropy.units import Quantity
# print(Quantity)

# class infoArray0(numpy.ndarray):
    # def __new__(subtype,shape,dtype=None,order='C',buffer=None,offset=0,strides=None,info=None):
        # obj0=super().__new__(subtype,shape,dtype,order,buffer,offset,strides)
        # obj0.info=info
        # return obj0
    # def __array_finalize__(self,obj):
        # if obj is None: return
        # self.info=getattr(obj,'info',None)

# # dunderscore __

# class c0():
    # s0='globalish value'
    # s1='globalish value that will be changed'
    # def __new__(cls):
        # # global s1# should work but maybe it's something about 'global' keyword that doesn't take in class functions..
        # s1='globalish value that was changed'
        # # return None
        # return super().__new__(cls)
# print(c0.s0)
# print(c0.s1)
# ci0=c0()
# print(c0.s0)
# print(c0.s1)
# print(ci0.s0)
# print(ci0.s1)
# c0.s1='globalish value that was changed'
# print(c0.s0)
# print(c0.s1)
# print(ci0.s0)
# print(ci0.s1)

# try:
    # 2+'s'
# except:
    # pass

# class mC0(type):
    # def __new__(cls,classname0,bases0,attributes0):
        # print('iM a metaclass')
        # return type(classname0,bases0,attributes0)

# class c0(metaclass=mC0):
    # pass

# c0()

# a0=numpy.arange(5)
# a1=a0[:3]
# a2=a1[:2]
# print(a0.base,a1.base,a2.base)

# try:
    # def print0(v0,*a,**kwa):
        # print('value is {}'.format(v0))
        # print('first arg is {}'.format(a[0]))
        # print('first kwarg is {}'.format(list(kwa.values())[0]))
    # #kwa.keys(),kwa.values(),kwa.items()
    # def print1(v1,*a,**kwa):
        # print('value is {}'.format(v1))
        # print('first arg is {}'.format(a[0]))
        # print('first kwarg is {}'.format(list(kwa.values())[0]))
        # return 1
    # def print2(v2,*a,**kwa):
        # print('value is {}'.format(v2))
        # print('first arg is {}'.format(a[0]))
        # print('first kwarg is {}'.format(list(kwa.values())[0]))
        # return 2
    # ar0=numpy.arange(-3,4,1)
    # c0=(ar0 < 0)
    # c1=(ar0 > 0)
    # fl0=[print0,print1,print2]
    # numpy.piecewise(ar0,[c0,c1],fl0,'imJustARandoArg',randoKWA0='imJustARandoKWArg')
# except Exception as e:
    # print(e)
# def print0(v0,*a,**kwa):
    # print('value is {}'.format(v0))
    # print('first arg is {}'.format(a[0]))
    # print('first kwarg is {}'.format(list(kwa.values())[0]))
    # return 0
# #kwa.keys(),kwa.values(),kwa.items()
# def print1(v1,*a,**kwa):
    # print('value is {}'.format(v1))
    # print('first arg is {}'.format(a[0]))
    # print('first kwarg is {}'.format(list(kwa.values())[0]))
    # return 1
# def print2(v2,*a,**kwa):
    # print('value is {}'.format(v2))
    # print('first arg is {}'.format(a[0]))
    # print('first kwarg is {}'.format(list(kwa.values())[0]))
    # return 2
# ar0=numpy.arange(-3,4,1)
# c0=(ar0 < 0)
# c1=(ar0 > 0)
# fl0=[print0,print1,print2]
# numpy.piecewise(ar0,[c0,c1],fl0,'imJustARandoArg',randoKWA0='imJustARandoKWArg')

# ar0=numpy.arange(-3,4,1)
# try:
    # hexV0=numpy.frompyfunc(hex,1,1,42)
# except Exception as e:
    # print(e)
# try:
    # hexV0=numpy.frompyfunc(hex,1,1,identity=42)
# except Exception as e:
    # print(e)
# hexV0=numpy.frompyfunc(hex,1,1)
# print(hexV0(ar0))
# try:
    # print(hexV0(ar0).identity)
# except Exception as e:
    # print(e)

# import unittest.mock
# import builtins

# class c0():
    # def r0(self):
        # return 0

# ci0=c0()

# print(ci0.r0())
# mm0=unittest.mock.MagicMock(ci0.r0,return_value=100)
# print(mm0())

# with unittest.mock.patch('builtins.input',return_value='iDontCareWhatYouTyped'):
    # i0=input('What do you like?')
    # print(i0)

# # from unittest.mock import patch
# # @patch('builtins.input',return_value='iDontCareWhatYouTyped2')
# @unittest.mock.patch('builtins.input',return_value='iDontCareWhatYouTyped2')
# def mTO0(self,i0):
    # i0=input('What do you like?')
    # print(i0)
# mTO0(i0)
# p0=unittest.mock.patch('builtins.input',return_value='iDontCareWhatYouTyped3')
# p0.start()
# i0=input('What do you like?')
# print(i0)
# p0.stop()
# i0=input('What do you like?')
# print(i0)

# def a1(ia0):
    # ia0[-1]+=1
    # return ia0

# ar0=numpy.arange(9).reshape(3,3).copy('C')
# print(ar0)
# for axis0 in [0,1]:
    # print(numpy.apply_along_axis(a1,axis0,ar0))

# ar0=numpy.arange(9).reshape(3,3).copy('C')
# print(ar0)
# print(numpy.add(ar0,1))
# print(numpy.add.reduce(ar0,1))
# print(numpy.add.at(ar0,[1,1,1,1],20))
# print(ar0)
# print(numpy.add.at(ar0,((1,1),(1,1)),20))
# print(ar0)

# try:
    # print(numpy.lib.format.dtype_to_descr('O'))
    # print(numpy.lib.format.dtype_to_descr('S'))
# except Exception as e:
    # print(e)
# print(numpy.dtype('U'))
# print(numpy.dtype('S'))
# print(numpy.dtype('O'))

# print(numpy.typecodes['All'])
# print(numpy.add.types)
# a0=numpy.empty((3,),dtype=numpy.float_)
# print(numpy.multiply(numpy.array([1,2,3],dtype=numpy.int_),numpy.array([1,2,3],dtype=numpy.int_),dtype=numpy.float_,out=a0))
# print(a0)
# a0=numpy.empty((),dtype=numpy.float_)
# print(numpy.multiply.reduce(numpy.array([1,2,3],dtype=numpy.int_),dtype=numpy.float_,out=a0))
# print(a0)
# a0=numpy.empty((),dtype=numpy.int_)
# print(numpy.multiply.reduce(numpy.array([1,2,3],dtype=numpy.int_),dtype=numpy.float_,out=a0))
# print(a0)

# class dA0:
    # def __init__(self,n,v,d):
        # self.n=n
        # self.v=v
        # self.d=d
    # def __repr__(self):
        # return f'{self.__class__.__name__},n={self.n},v={self.v},d={self.d}'
    # def __array__(self):
        # return self.v*numpy.eye(self.n,dtype=self.d)

# dA0i=dA0(4,2,numpy.complex_)
# print(dA0i)
# print(numpy.array(dA0i))
# print(numpy.asarray(dA0i))



# import numbers
# class dA0:
    # def __init__(self,n,v,d):
        # self.n=n
        # self.v=v
        # self.d=d
    # def __repr__(self):
        # return f'{self.__class__.__name__},n={self.n},v={self.v},d={self.d}'
    # def __array__(self):
        # return self.v*numpy.eye(self.n,dtype=self.d)
    # def __array_ufunc__(self,ufunc,method,*a,**kwa):
        # if method=='__call__':
            # n0=None
            # s0=[]
            # for a0 in a:
                # if isinstance(a0,numbers.Number):
                    # s0.append(a0)
                # elif isinstance(a0,self.__class__):
                    # s0.append(a0.v)
                    # if a0.n is not None:
                        # if a0.n != self.n:
                            # raise TypeError('inconsistentSizes')
                        # else:
                            # n0=a0.n
                # else:
                    # return NotImplemented
            # return self.__class__(n0,ufunc(*s0,**kwa),numpy.float_)
        # else:
            # return NotImplemented

# dA0i=dA0(4,2,numpy.float_)
# print(dA0i)
# print(numpy.array(dA0i))
# print(numpy.asarray(dA0i))
# print(numpy.add(dA0i,2.))
# print(numpy.array(numpy.multiply(dA0i,100.)))


# try:
    # print(numpy.array(1e+5000)+numpy.array(1e+5000))#in reality this will give inf OR not the right value before overflow (most of times); applies to rest except divide by zero
# except Exception as e0:
    # print(f'Error {e0} was raised')
# try:
    # print(numpy.array(1e-5000)+numpy.array(1e-5000))
# except Exception as e0:
    # print(f'Error {e0} was raised')
# try:
    # print(numpy.array(1e20)/numpy.array(0))
# except Exception as e0:
    # print(f'Error {e0} was raised')
# try:
    # print(numpy.array(1e20)+numpy.array('str0'))#can't seem to find something you can do with int but can't with float..
# except Exception as e0:
    # print(f'Error {e0} was raised')
# print(numpy.geterr())
# # d0={'over':'warn','under':'raise','invalid':'print','divide':'log'}
# print(numpy.seterr(over='warn',under='raise',invalid='print',divide='log'))
# print(numpy.geterr())
# print(numpy.geterrcall())
# class eC0:
    # def write(self,s0):
        # print(f'This is the message: {s0}')
# eC0i=eC0()
# print(numpy.seterrcall(eC0i))
# print(numpy.geterrcall())
# try:
    # print(numpy.array(1e+5000)+numpy.array(1e+5000))
# except Exception as e0:
    # print(f'Error {e0} was raised')
# try:
    # print(numpy.array(1e-5000)+numpy.array(1e-5000))
# except Exception as e0:
    # print(f'Error {e0} was raised')
# try:
    # print(numpy.array(1e20)/numpy.array(0))
# except Exception as e0:
    # print(f'Error {e0} was raised')
# try:
    # print(numpy.array(1e20)+numpy.array('str0'))
# except Exception as e0:
    # print(f'Error {e0} was raised')
# # d1={'over':'ignore','under':'warn','invalid':'warn','divide':'call'}
# with numpy.errstate(over='ignore',under='warn',invalid='warn',divide='call'):#context manager only for kwargs (NOT for seterrcall)
    # def hE0(t0,f0):
        # print(f'Type: {t0}. Flag: {f0}')
    # print(numpy.seterrcall(hE0))
    # try:
        # print(numpy.array(1e+5000)+numpy.array(1e+5000))
    # except Exception as e0:
        # print(f'Error {e0} was raised')
    # try:
        # print(numpy.array(1e-5000)+numpy.array(1e-5000))
    # except Exception as e0:
        # print(f'Error {e0} was raised')
    # try:
        # print(numpy.array(1e20)/numpy.array(0))
    # except Exception as e0:
        # print(f'Error {e0} was raised')
    # try:
        # print(numpy.array(1e20)+numpy.array('str0'))
    # except Exception as e0:
        # print(f'Error {e0} was raised')
# def hE0(t0,f0):
    # print(f'Type: {t0}. Flag: {f0}')
# print(numpy.geterrcall())
# print(numpy.geterr())
# print(numpy.geterrobj())
# print(numpy.seterrobj([10000,60,hE0]))
# try:
    # print(numpy.geterr())
# except Exception as e0:
    # print(e0.args,sys.exc_info())#weirdest key error probably due to misalignment?
# print(numpy.geterrobj())
# try:
    # print(numpy.array(1e+5000)+numpy.array(1e+5000))
# except Exception as e0:
    # print(f'Error {e0} was raised')
# try:
    # print(numpy.array(1e-5000)+numpy.array(1e-5000))
# except Exception as e0:
    # print(f'Error {e0} was raised')
# try:
    # print(numpy.array(1e20)/numpy.array(0))
# except Exception as e0:
    # print(f'Error {e0} was raised')
# try:
    # print(numpy.array(1e20)+numpy.array('str0'))
# except Exception as e0:
    # print(f'Error {e0} was raised')

# print(dir(numpy.distutils.system_info))
#baseline
#found
#not found
#define_macros
#language
#include_dirs
#src_dirs
#libraries
#library_dirs

#.whl

# import dis
# def add3store1(a,b,c):
    # d=a+b+c
    # return d
# print(dis.dis(add3store1))

# import collections
# print(collections.Counter([1,1,1,2,2,3]))

# try:
    # eval('''def fNA0:
        # pass''')
# except Exception as e:
    # print(e)
# def fNA0():
    # pass
# print(type(fNA0))

# import dis
# def add3store1(a,b,c):
    # d=a+b+c
    # return d
# print(dis.dis(add3store1))
# print(dir(add3store1.__code__))
# for k0 in dir(add3store1.__code__):
    # print(k0,getattr(add3store1.__code__,k0),sep='    ')

#generic security services api
#secure store and forward
#OllyDbg
#IDA Pro

# print(dir(numpy.array(['s0','s1'])))
# print(dir(numpy.core.defchararray.array(['s0','s1'])))
# print(dir(numpy.char.array(['s0','s1'])))
# sa0=numpy.array(['s0','s1'])
# sa1=numpy.array(['s2','s3'])
# print(numpy.char.endswith(sa0,'1'))

# try:
    # print(numpy.recarray([[1,2,3],['4','5','6']])[1].pprint())
# except Exception as e:
    # print(e)
# print(numpy.recarray((2,3),dtype=[('int0','i4'),('int1','i4'),('str0','U4')])[1])
# try:
    # print(numpy.recarray((2,3),dtype=[('int0','i4'),('int1','i4'),('str0','U4')])[1].pprint())
# except Exception as e:
    # print(e)
# print(numpy.recarray((2),dtype=[('int0','i4'),('int1','i4'),('str0','U4')])[1])
# print(numpy.recarray((2),dtype=[('int0','i4'),('int1','i4'),('str0','U4')])[1].pprint())
# print(numpy.array([[1,2,3],['4','5','6']]).view(numpy.recarray))
# print(numpy.array([[1,2,3],['4','5','6']]).view(numpy.recarray)[1])
# print(type(numpy.array([[1,2,3],['4','5','6']]).view(numpy.recarray)))
# print(type(numpy.array([[1,2,3],['4','5','6']]).view(numpy.recarray).copy('C')))
# try:
    # print(numpy.array([[1,2,3],['4','5','6']]).view(numpy.recarray).copy('C')[1].pprint())
# except Exception as e:
    # print(e)
# try:
    # print(numpy.array([[1,2,3],['4','5','6']]).view(numpy.recarray).copy('C')[1][1].pprint())
# except Exception as e:
    # print(e)
# print(numpy.zeros((2,3),dtype=[('int0','i4'),('int1','i4'),('str0','U4')]))
# print(numpy.zeros((2,3),dtype=[('int0','i4'),('int1','i4'),('str0','U4')]).view(numpy.recarray).copy('C')[1][1].pprint())
# print(type(numpy.zeros((2,3),dtype=[('int0','i4'),('int1','i4'),('str0','U4')]).view(numpy.recarray).copy('C')))

# import numpy.ma
# try:
    # ma0=numpy.ma.array([1,2,3,4],mask=[0,1,0,1],fill_value='filled0')
# except Exception as e:
    # print(e)


# ma0=numpy.ma.array([1,2,3,4],mask=[0,1,0,1],fill_value=42)
# for a0 in list(dir(ma0)):
    # print(a0,getattr(ma0,a0),sep='    ')
# print(ma0)
# print(ma0.torecords())
# print(ma0.toflex())
# print(ma0.torecords() is ma0.toflex())
# print(ma0.torecords is ma0.toflex)
# ma1=numpy.ma.array(numpy.recarray((2,3),dtype=[('int0','i4'),('int1','i4'),('str0','U4')]))
# print(ma1)
# print(ma1.torecords())
# print(ma1.toflex())
# print(ma1.torecords() is ma1.toflex())
# print(ma1.torecords is ma1.toflex)

# print(ma0.astype(numpy.float_,order='C',casting='unsafe',subok=True,copy=True))
# print(ma0.compressed())
# print(ma0.filled(fill_value=978))
# print(ma0.byteswap(inplace=True))
# print(ma0)
# print(ma0.byteswap(inplace=False))
# print(ma0.byteswap(inplace=True))
# print(ma0.tobytes(fill_value=979,order='K'))
# print(ma0.tostring(fill_value=977,order='K'))#deprecated
# try:
    # print(ma0.__float__())
# except Exception as e:
    # print(e)
# ma1=ma0[0]
# print(ma1)
# print(ma1.__float__())
# print(ma1)
# print(ma1.__int__())
# print(ma1)
# print(ma0.tolist(fill_value=801))
# try:
    # print(ma0.tofile(r'C:\users\pdumas\Downloads\testing0123\testfile20221208.txt',sep='\n\n\n',format='%s'))#save and load are preferred
# except Exception as e:
    # print(e)

# ma0=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=numpy.random.default_rng(8).integers(0,1,9,endpoint=True).reshape(3,3).copy('C'))
# print(ma0)
# print(ma0.anom(axis=None,dtype=numpy.float32))
# print(ma0.anom())
# print(ma0.anom(axis=1,dtype=numpy.float64))
# print(ma0.__repr__())
# print(ma0.__str__())
# print(ma0.iscontiguous())
# print(ma0.ids())
# print(ma0.data)
# print(ma0.mask)
# print(id(ma0.data))
# print(id(ma0.mask))
# print(id(ma0.recordmask))
# print(id(ma0))

# numpy.ma.masked_print_options='-----'
# print(numpy.ma.masked_print_options)
# print(numpy.ma.masked)
# print(numpy.ma.nomask)
# print(ma0.harden_mask())
# print(ma0.hardmask)
# print(ma0.soften_mask())
# print(ma0.hardmask)
# print(ma0.unshare_mask())
# print(ma0.unshare_mask().sharedmask)
# print(ma0.__setmask__(False))
# print(ma0.shrink_mask())
# print(ma0.mask)
# print(ma0.set_fill_value(121))
# print(ma0.get_fill_value())
# print(ma0.count())
# print(ma0.count(axis=1))
# print(ma0.count(axis=1,keepdims=True))
# ma0=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=numpy.random.default_rng(8).integers(0,1,9,endpoint=True).reshape(3,3).copy('C'))
# print(ma0.set_fill_value(121))
# print(ma0.get_fill_value())
# print(ma0.count())
# print(ma0.count(axis=1))
# print(ma0.count(axis=1,keepdims=True))
# print(ma0)

# ma0=numpy.ma.masked_values([1,2,3,1,1,2,3],2)
# print(ma0)
# print(ma0.mask)
# print(dir(numpy.ma.MaskedArray))
# print(help(numpy.ma.MaskedArray))

# print(numpy.ma.MaskedArray([1,2,3,1,1,2,3],mask=[0,0,0,0,1,1,1],dtype=None,copy=False,subok=True,ndmin=0,keep_mask=True,hard_mask=False,shrink=True,order='C',fill_value=767))
# print(numpy.ma.array([1,2,3,1,1,2,3],mask=[0,0,0,0,1,1,1],dtype=None,copy=False,subok=True,ndmin=0,keep_mask=True,hard_mask=False,shrink=True,order='C',fill_value=767))
# print(numpy.ma.core.MaskedArray([1,2,3,1,1,2,3],mask=[0,0,0,0,1,1,1],dtype=None,copy=False,subok=True,ndmin=0,keep_mask=True,hard_mask=False,shrink=True,order='C',fill_value=767))
# print(numpy.ma.masked_array([1,2,3,1,1,2,3],mask=[0,0,0,0,1,1,1],dtype=None,copy=False,subok=True,ndmin=0,keep_mask=True,hard_mask=False,shrink=True,order='C',fill_value=767))

# print(numpy.True_)
# print(numpy.False_)
# print(numpy.ma.nomask)
# print(numpy.False_ is numpy.ma.nomask)

# print(numpy.ma.asarray(numpy.arange(11).view(numpy.recarray),dtype=None,order='C'))
# print(type(numpy.ma.asarray(numpy.arange(11).view(numpy.recarray),dtype=None,order='C')))
# print(numpy.ma.asanyarray(numpy.arange(11).view(numpy.recarray),dtype=None))
# print(type(numpy.ma.asanyarray(numpy.arange(11).view(numpy.recarray),dtype=None)))
# a0=numpy.arange(11).view(numpy.recarray).astype(numpy.float_)
# a1=a0.put([2,4,6,8],numpy.nan)
# print(a0)
# print(a1)
# try:
    # print(numpy.ma.masked_values(a0,numpy.nan,shrink=True,copy=True))
# except Exception as e:
    # print(e)
# print(numpy.ma.masked_values(a0,1,shrink=True,copy=True))
# print(numpy.ma.masked_values(a0,1+1e-04,rtol=1e-05,atol=1e-08,shrink=True,copy=True))
# print(numpy.ma.masked_where(a0==1,a0,copy=True))
# print(numpy.ma.masked_equal(a0,1,copy=True))
# print(numpy.ma.masked_not_equal(a0,1,copy=True))
# print(numpy.ma.masked_less_equal(a0,5,copy=True))
# print(numpy.ma.masked_greater_equal(a0,5,copy=True))
# print(numpy.ma.masked_less(a0,5,copy=True))
# print(numpy.ma.masked_greater(a0,5,copy=True))
# m0=numpy.arange(11)
# m0[:2]=1
# m0[2:]=0
# print(numpy.ma.fix_invalid(a0,mask=m0,copy=True,fill_value=676.))
# print(numpy.ma.masked_invalid(a0,copy=True))
# print(numpy.ma.masked_inside(a0,3,7,copy=True))
# print(numpy.ma.masked_outside(a0,3,7,copy=True))
# a0=a0.astype(numpy.object_)
# a0[:5]='below 5'
# a0[5:]='5 or above'
# print(numpy.ma.masked_object(a0,'5 or above',copy=True))

# ma0=numpy.ma.masked_values([1,2,3,1,1,2,3,2],2)
# ma0.reshape((2,4))
# print(ma0)
# print(ma0.data)
# try:
    # print(ma0.getdata())
# except Exception as e:
    # print(e)
# print(numpy.ma.getdata(ma0,subok=True))
# print(ma0.__array__())
# print(ma0.mask)
# try:
    # print(ma0.getmask())
# except Exception as e:
    # print(e)
# print(numpy.ma.getmask(ma0))
# ma0[:]=numpy.ma.nomask
# print(numpy.ma.getmask(ma0))
# print(ma0.shrink_mask())
# print(numpy.ma.getmask(ma0))
# try:
    # print(ma0.getarraymask())
# except Exception as e:
    # print(e)
# try:
    # print(numpy.ma.getarraymask(ma0))
# except Exception as e:
    # print(e)
# print(numpy.ma.getmaskarray(ma0))
# print(ma0[~numpy.ma.nomask])
# print(ma0[numpy.ma.nomask])
# print(ma0.compressed())
# ma0[1]=999
# print(ma0)
# ma1=ma0[:]
# ma1[-1]=998
# print(ma0)
# ma0=numpy.ma.masked_values([1,2,3,1,1,2,3,2],2)
# print(ma0)
# print(numpy.ma.true_divide(ma0-1,2))
# print(numpy.true_divide(ma0-1,2))
# ma0=numpy.ma.array([1,2,3,1,1,2,3,2],mask=numpy.ma.nomask)
# try:
    # ma0.mask[0]=numpy.True_
# except Exception as e:
    # print(e)
# try:
    # ma0=numpy.ma.array([(1,2,3,1),(1,2,3,2)],dtype=[(numpy.int_,numpy.int_,numpy.int_,numpy.int_)],mask=[(0,0,0,0),(1,1,0,0)])
# except Exception as e:
    # print(e)
# try:
    # ma0=numpy.array([(1,2,3,1),(1,2,3,2)],dtype=[(numpy.int_,numpy.int_,numpy.int_,numpy.int_)])
# except Exception as e:
    # print(e)
# ma0=numpy.array([(1,2,3,1),(1,2,3,2)],dtype='i8,i8,i8,i8')# if doing dtype directly, only tuple ('name0','type0'),('name1','type1'),...  or  str 'i8,i8,...' is allowed
# ma0=numpy.ma.array([(1,2,3,1),(1,2,3,2)],dtype='i8,i8,i8,i8',mask=[(0,0,0,0),(1,1,0,0)])
# print(ma0)
# ma1=ma0[0]
# print(ma1)
# print(type(ma1))
# ma1=ma0[1]
# print(ma1)
# print(type(ma1))

# ma0=numpy.ma.masked_values([1,2,3,1,1,2,3,2],2).reshape(2,4).copy('C')
# print(numpy.ma.copy(ma0,order='F'))
# print(numpy.ma.MaskType)
# print(numpy.ma.ones_like(ma0,dtype=numpy.float_,subok=True,order='K'))
# print(numpy.ma.ones((2,5),dtype=numpy.float_,order='C'))
# print(numpy.ma.zeros_like(ma0,dtype=numpy.float_,subok=True,order='K'))
# print(numpy.ma.zeros((2,5),dtype=numpy.float_,order='C'))
# print(numpy.ma.empty_like(ma0,dtype=numpy.float_,subok=True,order='K'))
# print(numpy.ma.empty((2,5),dtype=numpy.float_,order='C'))
# print(numpy.ma.masked_all_like(ma0))
# print(numpy.ma.masked_all((2,5),dtype=numpy.int_))
# print(numpy.ma.frombuffer(b'11234',dtype=numpy.byte,count=4,offset=1))
# print(numpy.ma.frombuffer(b'11234',dtype=numpy.byte,count=4,offset=0))
# print(numpy.ma.frombuffer(b'a1234',dtype=numpy.byte,count=4,offset=0))
# try:
    # print(numpy.ma.frombuffer(0x00,dtype=numpy.byte,count=4,offset=0))
# except Exception as e:
    # print(e)
# print(numpy.ma.frombuffer(b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01',dtype=numpy.byte,count=4,offset=0))
# print(numpy.ma.frombuffer(b'\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01',dtype=numpy.byte,count=4,offset=0))
# def f0(d0i0,d1i0):
    # print('running f0')
    # return d0i0+d1i0
# print(numpy.ma.fromfunction(f0,shape=(2,4),dtype=numpy.int_))

# ma0=numpy.ma.masked_values([1,0,0,1,1,2,0,0],1).reshape(2,4).copy('C')
# print(ma0)
# print(numpy.ma.all(ma0,axis=None,out=None,keepdims=True))
# print(numpy.ma.all(ma0,axis=1,out=None,keepdims=True))
# print(numpy.ma.any(ma0,axis=None,out=None,keepdims=True))
# print(numpy.ma.any(ma0,axis=1,out=None,keepdims=True))
# print(numpy.ma.count(ma0,axis=None,keepdims=True))
# print(numpy.ma.count(ma0,axis=1,keepdims=True))
# print(numpy.ma.count_masked(ma0,axis=None))
# print(numpy.ma.count_masked(ma0,axis=1))
# print(numpy.ma.nonzero(ma0))
# print(numpy.ma.shape(ma0))
# print(numpy.ma.size(ma0))
# print(numpy.ma.size(ma0,axis=1))
# mAllNotMasked0=ma0.copy('C')
# mAllNotMasked0.mask=numpy.False_
# mAllMasked0=mAllNotMasked0.copy('C')
# mAllMasked0[:]=numpy.ma.masked
# a0=numpy.arange(8).reshape(2,4).copy('C')
# for aT0 in [a0,ma0,mAllMasked0,mAllMasked0.mask,mAllNotMasked0]:
    # for f0 in [numpy.ma.isarray,numpy.ma.is_masked,numpy.ma.is_mask,numpy.ma.isMA,numpy.ma.isMaskedArray]:
        # print(aT0,f0,f0(aT0),sep='\n',end='\n\n')

# ma0=numpy.ma.masked_values([1,0,0,1,1,2,0,0],1).reshape(2,1,4).copy('C')
# print(numpy.ma.reshape(ma0,(2,4),order='C'))
# print(numpy.ma.reshape(ma0,(2,4),order='C').shape)
# print(numpy.ma.resize(ma0,(2,8)))
# print(numpy.ma.resize(ma0,(2,8)).shape)
# print(numpy.ma.ravel(ma0,order='F'))
# print(numpy.ma.ravel(ma0,order='F').shape)
# print(numpy.ma.ravel(ma0,order='F').base)
# print(ma0.flatten(order='F'))
# print(ma0.flatten(order='F').shape)
# print(ma0.flatten(order='F').base)
# print(numpy.ma.swapaxes(ma0,0,2))
# print(numpy.ma.swapaxes(ma0,0,2).shape)
# print(numpy.ma.transpose(ma0,(2,0,1)))
# print(numpy.ma.transpose(ma0,(2,0,1)).shape)

# ma0=numpy.ma.masked_values([1,0,0,1,1,2,0,0],1).copy('C')
# print(numpy.ma.atleast_1d(1))
# print(numpy.ma.atleast_1d(ma0))
# print(numpy.ma.atleast_2d(ma0))
# print(numpy.ma.atleast_3d(ma0))
# try:
    # print(numpy.ma.expand_dims(ma0,(0,0,2)))
# except Exception as e:
    # print(e)
# print(numpy.ma.expand_dims(ma0,(0,1,2)))
# try:
    # print(numpy.ma.squeeze(numpy.ma.expand_dims(ma0,(0,0,2)),(0,0)))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.ma.squeeze(numpy.ma.expand_dims(ma0,(0,1,2)),(0,0)))
# except Exception as e:
    # print(e)
# print(numpy.ma.squeeze(numpy.ma.expand_dims(ma0,(0,1,2)),(0,1)))
# print(numpy.ma.expand_dims(ma0,(0,1,2)).squeeze((0,1)))
# listOfArrays0=[numpy.random.default_rng(8).integers(0,10,(3,4)) for c in range(5)]
# print(listOfArrays0)
# print(numpy.ma.stack(listOfArrays0,axis=0))
# print(numpy.ma.stack(listOfArrays0,axis=0).shape)
# print(numpy.ma.stack(listOfArrays0,axis=1))
# print(numpy.ma.stack(listOfArrays0,axis=1).shape)
# print(numpy.ma.stack(listOfArrays0,axis=2))
# print(numpy.ma.stack(listOfArrays0,axis=2).shape)
# print(numpy.ma.concatenate(listOfArrays0,axis=0))
# print(numpy.ma.concatenate(listOfArrays0,axis=0).shape)
# print(numpy.ma.concatenate(listOfArrays0,axis=1))
# print(numpy.ma.concatenate(listOfArrays0,axis=1).shape)
# try:
    # print(numpy.ma.concatenate(listOfArrays0,axis=2))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.ma.concatenate(listOfArrays0,axis=2).shape)
# except Exception as e:
    # print(e)
# print(numpy.ma.row_stack(listOfArrays0))
# print(numpy.ma.row_stack(listOfArrays0).shape)
# print(numpy.ma.column_stack(listOfArrays0))
# print(numpy.ma.column_stack(listOfArrays0).shape)
# print(numpy.ma.dstack(listOfArrays0))
# print(numpy.ma.dstack(listOfArrays0).shape)
# print(numpy.ma.mr_['0,3,0',listOfArrays0])
# print(numpy.ma.mr_['0,3,0',listOfArrays0].shape)
# print(numpy.ma.hstack(listOfArrays0))
# print(numpy.ma.hstack(listOfArrays0).shape)
# print(numpy.ma.hsplit(numpy.ma.hstack(listOfArrays0),1))
# print(numpy.ma.hsplit(numpy.ma.hstack(listOfArrays0),1).shape)
# print(numpy.ma.hsplit(numpy.ma.hstack(listOfArrays0),2))
# print(numpy.ma.hsplit(numpy.ma.hstack(listOfArrays0),2).shape)
# print(numpy.ma.vstack(listOfArrays0))
# print(numpy.ma.vstack(listOfArrays0).shape)
# print(numpy.ma.hstack(listOfArrays0))
# print(numpy.ma.hstack(listOfArrays0).shape)
# print(ma0)
# try:
    # print(numpy.ma.append(ma0.reshape(2,4).copy('C'),[1,2,3,4],axis=0))
# except Exception as e:
    # print(e)
# print(numpy.ma.append(ma0.reshape(2,4).copy('C'),[[1,2,3,4]],axis=0))
# try:
    # print(numpy.ma.append(ma0.reshape(2,4).copy('C'),[[1,2]],axis=1))
# except Exception as e:
    # print(e)
# print(numpy.ma.append(ma0.reshape(2,4).copy('C'),[[1],[2]],axis=1))

# i0=numpy.random.default_rng(8).integers(0,2,9,endpoint=True)
# print(i0)
# print(numpy.ma.make_mask(i0,copy=False,shrink=True,dtype=numpy.int_))
# print(numpy.ma.make_mask_descr(numpy.ma.make_mask(i0,copy=False,shrink=True,dtype=numpy.int_).dtype))
# print(i0.dtype)
# print(numpy.ma.make_mask_none((3,3,3),dtype=numpy.int_))
# d0=numpy.dtype({'names':['n0','n1'],'formats':['f4','i4']})
# print(numpy.ma.make_mask_none((3,3,3),dtype=d0))
# print(numpy.ma.make_mask_descr(numpy.ma.make_mask_none((3,3,3),dtype=d0).dtype))
# print(numpy.ma.make_mask_none((3,3,3),dtype=d0).dtype)
# i1=numpy.random.default_rng(7).integers(0,2,9,endpoint=True)
# print(i0,i1,sep='\n')
# print(numpy.ma.mask_or(i0,i1,copy=False,shrink=True))

# ma0=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=numpy.ma.make_mask(numpy.arange(9).reshape(3,3).copy('C')))
# ndeT0=numpy.ma.ndenumerate(ma0,compressed=True)
# ndeF0=numpy.ma.ndenumerate(ma0,compressed=False)
# print(ndeT0)
# print(ndeF0)
# for i0,v0 in ndeT0:
    # print(i0,v0)
# for i0,v0 in ndeF0:
    # print(i0,v0)

# m0=numpy.ma.make_mask(numpy.arange(9).reshape(3,3).copy('C'))
# m0.flat[5:7]=numpy.False_
# try:
    # m0[5:7]=~numpy.ma.masked
# except Exception as e:
    # print(e)
# print(m0)
# ma0=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=m0)
# print(ma0)
# print(numpy.ma.flatnotmasked_contiguous(ma0))
# print(numpy.ma.flatnotmasked_edges(ma0))
# print(numpy.ma.notmasked_contiguous(ma0))
# print(numpy.ma.notmasked_contiguous(ma0,axis=0))
# print(numpy.ma.notmasked_contiguous(ma0,axis=1))
# print(numpy.ma.notmasked_edges(ma0))
# print(numpy.ma.notmasked_edges(ma0,axis=0))
# print(numpy.ma.notmasked_edges(ma0,axis=1))
# print(numpy.ma.clump_unmasked(ma0))
# print(numpy.ma.clump_masked(ma0))

# m0=numpy.ma.make_mask(numpy.arange(9).reshape(3,3).copy('C'))
# m0.flat[5:8]=numpy.False_
# try:
    # m0[5:8]=~numpy.ma.masked
# except Exception as e:
    # print(e)
# print(m0)
# ma0=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=m0)
# print(ma0)
# print(numpy.ma.flatnotmasked_contiguous(ma0))
# print(numpy.ma.flatnotmasked_edges(ma0))
# print(numpy.ma.notmasked_contiguous(ma0))
# print(numpy.ma.notmasked_contiguous(ma0,axis=0))
# print(numpy.ma.notmasked_contiguous(ma0,axis=1))
# print(numpy.ma.notmasked_edges(ma0))
# print(numpy.ma.notmasked_edges(ma0,axis=0))
# print(numpy.ma.notmasked_edges(ma0,axis=1))
# print(numpy.ma.clump_unmasked(ma0))
# print(numpy.ma.clump_masked(ma0))

# m0=numpy.ma.make_mask(numpy.arange(9).reshape(3,3).copy('C'))
# m0.flat[:5]=numpy.False_
# m0.flat[6:]=numpy.False_
# print(m0)
# ma0=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=m0)
# print(ma0)
# print(numpy.ma.mask_rowcols(ma0,axis=None))
# print(numpy.ma.mask_rowcols(ma0,axis=0))
# print(numpy.ma.mask_rows(ma0))
# print(numpy.ma.mask_rowcols(ma0,axis=1))
# print(numpy.ma.mask_cols(ma0))

# m0=numpy.ma.make_mask(numpy.arange(9).reshape(3,3).copy('C'))
# m0.flat[:5]=numpy.False_
# m0.flat[6:]=numpy.False_
# m0.flat[3]=numpy.True_
# print(m0)
# ma0=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=m0)
# print(ma0)
# print(numpy.ma.mask_rowcols(ma0,axis=None))
# print(numpy.ma.mask_rowcols(ma0,axis=0))
# print(numpy.ma.mask_rows(ma0))
# print(numpy.ma.mask_rowcols(ma0,axis=1))
# print(numpy.ma.mask_cols(ma0))

# print(numpy.ma.harden_mask(ma0))
# print(ma0.hardmask)
# print(numpy.ma.soften_mask(ma0))
# print(ma0.hardmask)

# m0=numpy.ma.make_mask(numpy.arange(9).reshape(3,3).copy('C'))
# m0.flat[:]=numpy.ma.nomask
# print(numpy.put(m0,[3,7],numpy.True_))
# print(m0)
# ma0=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=m0)
# print(ma0)
# print(numpy.ma.compress_rowcols(ma0,axis=None))
# print(numpy.ma.compress_rowcols(ma0,axis=0))
# print(numpy.ma.compress_rows(ma0))
# print(numpy.ma.compress_rowcols(ma0,axis=1))
# print(numpy.ma.compress_cols(ma0))
# print(numpy.ma.compressed(ma0))
# print(numpy.ma.filled(ma0,fill_value=656))

# ma0=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=m0)
# ma1=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=m0)
# print(numpy.ma.set_fill_value(ma0,437))
# print(numpy.ma.set_fill_value(ma1,437))
# print(numpy.ma.common_fill_value(ma0,ma1))
# print(numpy.ma.set_fill_value(ma1,438))
# print(numpy.ma.common_fill_value(ma0,ma1))
# print(numpy.ma.maximum_fill_value(ma0))
# print(numpy.ma.minimum_fill_value(ma0))
# print(numpy.ma.default_fill_value(ma0))
# d0=numpy.dtype({'names':['n0','n1','n2','n3','n4','n5'],'formats':[numpy.bool_,numpy.int_,numpy.float_,numpy.complex_,numpy.object_,numpy.unicode_]})
# print(d0)
# print(numpy.ma.default_fill_value(d0))
# d0=numpy.dtype({'names':['n0','n1','n2','n3','n4','n5'],'formats':[numpy.bool_,numpy.int_,numpy.string_,numpy.bytes_,numpy.str_,numpy.unicode_]})
# print(d0)
# print(numpy.ma.default_fill_value(d0))
# print(numpy.ma.default_fill_value('str0'))

# print(numpy.asmatrix(numpy.arange(9),dtype=numpy.complex_))
# print(numpy.asmatrix(numpy.arange(9).reshape(3,3).copy('C'),dtype=numpy.complex_))
# print(numpy.asmatrix(numpy.arange(9).reshape(3,3).copy('C'),dtype=numpy.complex_).T)
# print(numpy.asmatrix(numpy.arange(9).reshape(3,3).copy('C'),dtype=numpy.complex_).H)
# try:
    # print(numpy.asmatrix(numpy.arange(9).reshape(3,3).copy('C'),dtype=numpy.complex_).I)
# except Exception as e:
    # print(e,sys.exc_info())
# print(numpy.asmatrix([[1,0,2],[0,1,0],[2,0,1]],dtype=numpy.complex_))
# print(numpy.asmatrix([[1,0,2],[0,1,0],[2,0,1]],dtype=numpy.complex_).I)
# print(numpy.asmatrix(numpy.arange(9).reshape(3,3).copy('C'),dtype=numpy.complex_).A)
# print(type(numpy.asmatrix(numpy.arange(9).reshape(3,3).copy('C'),dtype=numpy.complex_).A))

# # # ssf/name=SAPSECULIB
# # # ssf/ssfapi_lib=/sapmnt/NPL/exe/uc/linuxx86_64/libsapcrypto.so
# # # stopsap
# # # startsap
# # # strust
# # # snc/identity/as=p:CN=NPL,OU=IINITIAL,OU=SAP Web AS,O=SAP Trust Community, C=DE
# # # snc/enable=1
# # # snc/gssapi_lib=/sapmnt/NPL/exe/uc/linuxx86_64/libsapcrypto.so
# # # sec/libsapsecu=/sapmnt/NPL/exe/uc/linuxx86_64/libsapcrypto.so
# # # snc/accept_insecure_gui=1
# # # snc/accept_insecure_gui=1
# # # snc_only_encrypted_gui=1

# # # login/password_login_usergroup=group0
# # # snc/identity/as=p:CN=NPL,OU=IINITAL,OU=SAP Web AS,O=SAP Trust Community,C=DE
# # # snc/only_encrypted_gui=1

# m0=numpy.ma.make_mask(numpy.arange(9).reshape(3,3).copy('C'))
# m0.flat[:]=numpy.ma.nomask
# print(numpy.put(m0,[3,7],numpy.True_))
# print(numpy.ma.anom is numpy.ma.anomalies)
# ma0=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=m0)
# print(ma0)
# print(numpy.ma.anom(ma0,axis=None,dtype=None))
# print(numpy.ma.anom(ma0,axis=1,dtype=numpy.float_))
# print(numpy.ma.anomalies(ma0,axis=None,dtype=None))
# print(numpy.ma.anomalies(ma0,axis=1,dtype=numpy.float_))
# try:
    # print(numpy.ma.average(ma0,axis=1,weights=None,returned=True,keepdims=True))
# except Exception as e:
    # print(e)
# print(numpy.ma.average(ma0,axis=1,weights=None,returned=True,keepdims=False))
# o0=numpy.ones(ma0.shape)
# o0[0,2]=900
# print(o0)
# print('                       ',numpy.ma.average(ma0,axis=1,weights=o0,returned=True,keepdims=False))
# print(numpy.ma.average(ma0,axis=1,weights=o0,returned=True,keepdims=True))
# print(numpy.asmatrix([[1,0,2],[0,1,0],[2,0,1]],dtype=numpy.complex_).I)
# print(numpy.ma.conjugate(numpy.asmatrix([[1,0,2],[0,1,0],[2,0,1]],dtype=numpy.complex_).I))
# # print(numpy.ma.put(numpy.ma.make_mask_none(numpy.array([[1,0,2],[0,1,0],[2,0,1]]).shape).flat,[5],numpy.True_))
# m0=numpy.ma.make_mask_none(numpy.array([[1,0,2],[0,1,0],[2,0,1]]).shape)
# numpy.ma.put(m0.flat,[5],numpy.True_)
# a0=numpy.ma.array([[1,0,2],[0,1,0],[2,0,1]],mask=m0)#iterates through 1-2 1-3 2-3 corresponding to:
# # d   .   .
# # 1-2 d   .
# # 1-3 2-3 .   
# print(a0)
# print(a0.mask)
# print(numpy.ma.corrcoef(a0,rowvar=True,allow_masked=True))
# print(numpy.ma.corrcoef(a0,y=a0,rowvar=True,allow_masked=True))
# b0=numpy.arange(9)
# b0[6]=1000
# a1=numpy.ma.array(b0,mask=m0)
# m0=numpy.ma.make_mask_none((9,))
# m0[6]=numpy.True_
# print(m0)
# a2=numpy.ma.array(b0+2,mask=m0)
# a2[6]=-500
# a2=numpy.ma.array(a2,mask=m0)
# print(a2.mask)
# a3=numpy.ma.array(b0+2,mask=m0)
# a3[5]=-3
# a3=numpy.ma.array(a3,mask=m0)
# a4=numpy.ma.array(b0+2,mask=m0)
# a4[6]=-3
# a4=numpy.ma.array(a4,mask=m0)
# print(a1,a2,a3,a4,m0,sep='\n')
# print(numpy.ma.corrcoef(a1,a2,rowvar=True,allow_masked=True))
# print(numpy.ma.corrcoef(a1,a3,rowvar=True,allow_masked=True))#so mask actually does work and give right answer but displaying the 'data' part doesn't necessarily display masked components with '--' every time.. weird.
# print(numpy.ma.corrcoef(a1,a4,rowvar=True,allow_masked=True))

# print(numpy.ma.cov(a1,a2,rowvar=True,allow_masked=True))
# print(numpy.ma.cov(a1,a3,rowvar=True,allow_masked=True))#so mask actually does work and give right answer but displaying the 'data' part doesn't necessarily display masked components with '--' every time.. weird.
# print(numpy.ma.cov(a1,a4,rowvar=True,allow_masked=True))
# print(numpy.ma.cov(a1,a4,bias=True,rowvar=True,allow_masked=True))
# print(numpy.ma.cov(a1,a4,bias=False,rowvar=True,allow_masked=True,ddof=1))
# print(numpy.ma.cov(a1,a4,bias=False,rowvar=True,allow_masked=True,ddof=2))
# print(numpy.ma.cov(a1,a4,bias=False,rowvar=True,allow_masked=True,ddof=50))#more ddof than possible per data item count and then you get nonsense..

# m0=numpy.ma.make_mask(numpy.arange(9).reshape(3,3).copy('C'))
# m0.flat[:]=numpy.ma.nomask
# print(numpy.put(m0,[3,7],numpy.True_))
# print(m0)
# ma0=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=m0)
# ma0.flat[3]=70000
# ma0=numpy.ma.array(ma0.copy('C'),mask=m0)
# print(ma0,m0)
# ma0.flat[3]=numpy.ma.masked
# print(ma0,m0)
# print(numpy.ma.sum(ma0,axis=None,out=None,dtype=None,keepdims=False))
# print(numpy.ma.sum(ma0,axis=1,out=None,dtype=None,keepdims=False))
# print(numpy.ma.prod(ma0,axis=None,out=None,dtype=None,keepdims=False))
# print(numpy.ma.prod(ma0,axis=1,out=None,dtype=None,keepdims=False))
# print(numpy.ma.cumsum(ma0,axis=None,out=None,dtype=None))
# print(numpy.ma.cumsum(ma0,axis=1,out=None,dtype=None))
# print(numpy.ma.cumprod(ma0,axis=None,out=None,dtype=None))
# print(numpy.ma.cumprod(ma0,axis=1,out=None,dtype=None))
# try:
    # print(numpy.ma.power(ma0.flat,ma0.flat,third=None))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.ma.power(ma0.flat,2,third=None))
# except Exception as e:
    # print(e)
# print(numpy.ma.power(ma0,ma0,third=None))
# print('numpy.ma.power')
# print(numpy.ma.power(4,2,third=None))
# print(numpy.power(numpy.arange(5),numpy.arange(5)))
# print(numpy.ma.mean(ma0,axis=None,out=None,dtype=None,keepdims=False))
# print(numpy.ma.mean(ma0,axis=1,out=None,dtype=None,keepdims=False))
# print(numpy.ma.median(ma0,axis=None,out=None,overwrite_input=False,keepdims=False))
# print(numpy.ma.median(ma0,axis=1,out=None,overwrite_input=False,keepdims=False))
# print(numpy.ma.std(ma0,axis=None,out=None,dtype=None,ddof=0,keepdims=False))
# print(numpy.ma.std(ma0,axis=1,out=None,dtype=None,ddof=0,keepdims=False))
# print(numpy.ma.var(ma0,axis=None,out=None,dtype=None,ddof=0,keepdims=False))
# print(numpy.ma.var(ma0,axis=1,out=None,dtype=None,ddof=0,keepdims=False))

# m0=numpy.ma.make_mask(numpy.arange(9).reshape(3,3).copy('C'))
# m0.flat[:]=numpy.ma.nomask
# print(numpy.put(m0,[3,7],numpy.True_))
# print(m0)
# ma0=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=m0)
# ma0.flat[3]=70000
# ma0=numpy.ma.array(ma0.copy('C'),mask=m0)
# ma0.flat[3]=numpy.ma.masked
# print(m0)
# print(ma0)
# print(numpy.ma.argmin(ma0,axis=None,out=None,fill_value=9))
# print(numpy.ma.argmin(ma0,axis=1,out=None,fill_value=9))
# print(numpy.ma.argmax(ma0,axis=None,out=None,fill_value=-4))
# print(numpy.ma.argmax(ma0,axis=1,out=None,fill_value=-4))
# print(numpy.ma.min(ma0,axis=None,out=None,fill_value=9,keepdims=False))
# print(numpy.ma.min(ma0,axis=1,out=None,fill_value=9,keepdims=False))
# print(numpy.ma.max(ma0,axis=None,out=None,fill_value=-4,keepdims=False))
# print(numpy.ma.max(ma0,axis=1,out=None,fill_value=-4,keepdims=False))
# print(numpy.min(ma0,axis=None,out=None,keepdims=False))
# print(numpy.min(ma0,axis=1,out=None,keepdims=False))
# print(numpy.max(ma0,axis=None,out=None,keepdims=False))
# print(numpy.max(ma0,axis=1,out=None,keepdims=False))
# print(numpy.ma.ptp(ma0,axis=None,out=None,fill_value=9))
# print(numpy.ma.ptp(ma0,axis=1,out=None,fill_value=9))
# try:
    # print(numpy.ma.diff(ma0,n=-1,axis=None,prepend=700,append=900))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.ma.diff(ma0,n=20,axis=None,prepend=700,append=900))
# except Exception as e:
    # print(e)
# print(numpy.ma.diff(ma0,n=20,axis=0,prepend=700,append=900))
# print(numpy.ma.diff(ma0,n=2,axis=0,prepend=700,append=900))
# print(numpy.ma.diff(ma0,n=2,axis=1,prepend=700,append=900))
# print(numpy.ma.diff(ma0,n=1,axis=0,prepend=700,append=900))
# print(numpy.ma.diff(ma0,n=1,axis=1,prepend=700,append=900))
# print(numpy.ma.argsort(ma0,axis=None,kind=None,order=None,endwith=True,fill_value=None))
# print(numpy.ma.argsort(ma0,axis=None,kind=None,order=None,endwith=False,fill_value=None))
# print(numpy.ma.argsort(ma0,axis=1,kind='mergesort',order=None,endwith=False,fill_value=-99))
# print(numpy.ma.sort(ma0,axis=None,kind=None,order=None,endwith=True,fill_value=None))
# print(numpy.ma.sort(ma0,axis=None,kind=None,order=None,endwith=False,fill_value=None))
# print(numpy.ma.sort(ma0,axis=1,kind='mergesort',order=None,endwith=False,fill_value=-99))
# m1=numpy.ma.make_mask(numpy.arange(9).reshape(3,3).copy('C'))
# m1.flat[:]=numpy.ma.nomask
# print(numpy.put(m1,[4,8],numpy.True_))
# print(m1)
# ma1=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=m1)
# ma1.flat[4]=-400
# ma1=numpy.ma.array(ma1.copy('C'),mask=m1)
# ma1.flat[4]=numpy.ma.masked
# print(m0,ma0,sep='\n')
# print(m1,ma1,sep='\n')
# print(numpy.ma.diag(ma0,k=0))
# print(numpy.ma.diag(ma0,k=1))
# print(numpy.ma.diag(ma1,k=0))
# print(numpy.ma.diag(ma1,k=1))
# try:
    # print(numpy.ma.identity(ma1,dtype=numpy.float_))
# except Exception as e:
    # print(e)
# print(ma1.dtype)
# a0=numpy.ma.array([[1,0,2],[0,1,0],[2,0,1]])
# print(numpy.identity(5))
# print(numpy.ma.identity(8,dtype=numpy.float_))#not sure how this adds any value compared to just numpy.identity since you can't really mask anything; maybe the dtype but even then.. pd20221226 creates mask array (instead of creating array and then masking..)
# print(numpy.ma.inner(ma0,ma1))
# print(numpy.ma.innerproduct(ma0,ma1))
# print(numpy.ma.inner is numpy.ma.innerproduct)
# print(numpy.ma.dot(ma0,ma1,strict=False,out=None))
# print(numpy.ma.dot(ma0,ma1,strict=True,out=None))
# print(numpy.ma.outer(ma0,ma1))
# print(numpy.ma.outerproduct(ma0,ma1))
# print(numpy.ma.outer is numpy.ma.outerproduct)
# print(numpy.ma.trace(ma0,offset=0,axis1=0,axis2=1,dtype=numpy.float_,out=None))
# print(numpy.ma.trace(ma0,offset=1,axis1=0,axis2=1,dtype=numpy.float_,out=None))
# print(numpy.ma.trace(ma0,offset=1,axis1=1,axis2=0,dtype=numpy.float_,out=None))
# print(numpy.ma.trace(ma0,offset=-1,axis1=1,axis2=0,dtype=numpy.float_,out=None))
# try:
    # print(numpy.ma.vander(numpy.array([1,3,9,12]),n=4,increasing=False,maskval=9))#GPT-3 lies!
# except Exception as e:
    # print(e)
# try:
    # print(numpy.ma.vander(numpy.array([1,3,9,12]),n=4,maskval=9))#GPT-3 lies!
# except Exception as e:
    # print(e)
# print(numpy.ma.vander(numpy.array([1,3,9,12]),n=4))#not sure how this adds any value compared to just numpy.<counterpart> since you can't really mask anything; maybe the dtype but even then.. pd20221226 creates mask array (instead of creating array and then masking..)
# print(type(numpy.ma.vander(numpy.array([1,3,9,12]),n=4)))
# try:
    # print(numpy.ma.vander(numpy.array([1,3,9,12]),n=4).mask)
# except Exception as e:
    # print(e)
# print(numpy.ma.round is numpy.ma.around)
# print(numpy.ma.round(numpy.arange(100,10000,1000),-3,out=None))
# print(numpy.ma.around(numpy.arange(100,10000,1000),-3,out=None))
# print(numpy.ma.round(numpy.arange(100,10000,1000),3,out=None))
# print(numpy.ma.around(numpy.arange(100,10000,1000),3,out=None))
# print(numpy.ma.round(numpy.linspace(100,10000,15),-2,out=None))
# print(numpy.ma.around(numpy.linspace(100,10000,15),-2,out=None))
# print(numpy.ma.round(numpy.linspace(100,10000,15),2,out=None))
# print(numpy.ma.around(numpy.linspace(100,10000,15),2,out=None))
# print(numpy.ma.round(numpy.linspace(100,10000,15),decimals=0,out=None))
# print(numpy.ma.around(numpy.linspace(100,10000,15),decimals=0,out=None))
# try:
    # print(numpy.ma.clip(ma1,3,6))
# except Exception as e:
    # print(e)
# print(numpy.clip(numpy.ma.filled(ma1,fill_value=2),3,6))
# print(numpy.clip(numpy.ma.filled(ma1,fill_value=2),6,3))
# print(numpy.clip(numpy.ma.filled(ma1,fill_value=2).flat,numpy.repeat(3,9),numpy.arange(9)))


# ma0=numpy.ma.array(numpy.arange(5),mask=[0,0,1,1,0])
# ma1=numpy.ma.array(numpy.arange(5),mask=[0,0,1,1,0])
# ma2=numpy.ma.array(numpy.arange(5),mask=[0,0,0,1,0])
# print(ma0,ma1)
# print(numpy.ma.allequal(ma0,ma1,fill_value=True))
# print(numpy.ma.allequal(ma0,ma1,fill_value=False))
# print(numpy.ma.allequal(ma0,ma2,fill_value=True))
# print(numpy.ma.allequal(ma0,ma2,fill_value=False))
# print(numpy.ma.allclose(ma0,ma1,masked_equal=True,rtol=1e-05,atol=1e-08))
# print(numpy.ma.allclose(ma0,ma1,masked_equal=False,rtol=1e-05,atol=1e-08))
# print(numpy.ma.allclose(ma0,ma2,masked_equal=True,rtol=1e-05,atol=1e-08))
# print(numpy.ma.allclose(ma0,ma2,masked_equal=False,rtol=1e-05,atol=1e-08))
# def a1(ia0):
    # ia0[-1]+=1
    # return ia0

# ar0=numpy.arange(9).reshape(3,3).copy('C')#not sure why [0,2]==0..
# m0=numpy.ma.make_mask_none((3,3))
# ma0=numpy.ma.array(ar0,mask=m0,copy=False)
# print(ma0)
# ma0=numpy.ma.array(ar0,mask=m0,copy=True)
# ma0.flat[5]=numpy.ma.masked
# print(ar0,ma0,sep='\n')
# for axis0 in [0,1]:
    # print(numpy.apply_along_axis(a1,axis0,ar0))
    # print(numpy.apply_along_axis(a1,axis0,ma0))

# print(numpy.ma.apply_over_axes(numpy.ma.sum,ma0,[0,1]))
# print(numpy.ma.apply_over_axes(numpy.ma.sum,ar0,[0,1]))

# print(numpy.ma.arange(2,5,1,dtype=numpy.complex_))
# c0=numpy.array([[1,2,1,2],[5,6,6,5],[9,8,8,9]])
# i0=numpy.array([1,1,1,1,1,0,2])
# try:
    # print(numpy.ma.choose(i0,c0,out=None,mode='wrap'))
# except Exception as e:
    # print(e)
# i0=numpy.array([1,1,0,2])
# print(numpy.ma.choose(i0,c0,out=None,mode='wrap'))
# i0=numpy.array([1,1,1,1])
# print(numpy.ma.choose(i0,c0,out=None,mode='wrap'))

# ma0=numpy.ma.array(numpy.arange(5),mask=[0,0,1,1,0])
# ma2=numpy.ma.array(numpy.arange(5),mask=[0,0,0,1,0])
# print(numpy.ma.ediff1d(ma0,to_end=10,to_begin=-10))
# print(numpy.ma.ediff1d(ma2,to_end=10,to_begin=-10))#this one actually preserves masks whereas numpy.ma.diff just skips masks; also this > prepend and append happen after calc whereas numpy.ma.diff happens before calc
# print(numpy.ma.indices((3,3,3),dtype=numpy.int_,sparse=False))#not sure how this adds any value compared to just numpy.<counterpart> since you can't really mask anything; maybe the dtype but even then..

# print(numpy.ma.where(ma0>=2,ma0+10,ma0-10))

# x0=numpy.arange(5)
# y0=numpy.array([3,1.5,0,-1,3])
# d0=3
# import matplotlib.pyplot
# matplotlib.pyplot.plot(x0,y0,marker='o')
# print(numpy.ma.polyfit(x0,y0,d0),sep='\n')
# try:
    # matplotlib.pyplot.plot(x0,numpy.ma.polyfit(x0,y0,d0),color='blue')
# except Exception as e:
    # print(e)
# matplotlib.pyplot.plot(numpy.linspace(0,5,numpy.ma.polyfit(x0,y0,d0).size),numpy.ma.polyfit(x0,y0,d0),color='blue')
# print(x0,y0,numpy.ma.polyfit(x0,y0,d0),sep='\n')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# # matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# for d1 in list(range(6)):#odds better than evens? lower is simpler which is oftentimes better..
    # matplotlib.pyplot.plot(numpy.linspace(0,5,numpy.ma.polyfit(x0,y0,d1).size),numpy.ma.polyfit(x0,y0,d1),label=f'{d1}')
# matplotlib.pyplot.plot(x0,y0,marker='o')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# r0=10
# x0=numpy.arange(r0)
# # y0=numpy.ma.array([3,1.5,0,-1,3,5,6,5,4,1],mask=[0,0,0,1,0,0,0,0,1,0])
# y0=numpy.ma.array([3,1.5,0,-1,3,5,6,5,4,1],mask=[0,0,0,0,0,0,0,0,0,0])#with a lot more points, results become even more off? simple is better..
# # for d1 in list(range(6))+[12]:#high deg means bad results
# for d1 in list(range(6)):
    # matplotlib.pyplot.plot(numpy.linspace(0,r0,numpy.ma.polyfit(x0,y0,d1).size),numpy.ma.polyfit(x0,y0,d1),label=f'{d1}')
# matplotlib.pyplot.plot(x0,y0,marker='o')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# import inspect
# def f0(integerOfLineNumber0):
    # print(inspect.stack()[0][2])
    # print(integerOfLineNumber0)
# for x in [1,2]:
    # if x==1:
        # print(inspect.stack()[0][3])
        # print(inspect.stack()[0][2])
        # f0(inspect.stack()[0][2])
        # f0(inspect.stack()[0][2])
    # elif x==2:
        # print(inspect.stack()[0][3])
        # print(inspect.stack()[0][2])
        # f0(inspect.stack()[0][2])
        # f0(inspect.stack()[0][2])

# numpy.ma.core.MaskedArray.__setitem__
# numpy.ma.core.MaskedArray.__getitem__
# numpy.ma.core.MaskedArray.__delitem__
# numpy.ma.core.MaskedArray.__contains__
# numpy.ma.core.MaskedArray.__xor__
# numpy.ma.core.MaskedArray.__le__
# numpy.polyder
# numpy.polyint
# numpy.polynomial.Polynomial.fit(x0,y0,deg=d0).deriv
# numpy.polynomial.Polynomial.fit(x0,y0,deg=d0).integ
# print(ma0.torecords() is ma0.toflex()) will give False even though they pretty much do the same thing
# MaskedArray.tofile() not implemented yet.  and will probably never be given save,load

# print(3/2)
# print(3//2)
# print(3/-2)
# print(3//-2)

# p0=numpy.polynomial.Polynomial([1,2,3])
# print(p0)
# pc0=p0(numpy.polynomial.Chebyshev([0,1]))
# print(pc0)
# p1=p0(numpy.polynomial.Polynomial([0,1]))
# print(p1)
# print(p1.domain)
# print(p1.window)

# print(help(numpy.polynomial.Polynomial([1,2,3]).integ))
# print(numpy.polynomial.Polynomial([1,2,3]).integ(lbnd=-1))
# print(numpy.polynomial.Polynomial([1,2,3]).integ(lbnd=-.5))
# print(numpy.polynomial.Polynomial([1,2,3]).integ(lbnd=0,k=100))

# c0=0
# def f0():
    # print(c0)
# def f1():
    # print(str(c0))
# def f2():
    # lc0=c0
# def f3():
    # lc0=c0+1
# def f4():
    # lc0=1+c0
# def f5():
    # lc0='1'+str(c0)

# f0()
# f1()
# f2()
# f3()
# f4()
# f5()

# for a0 in dir(numpy.polynomial.Polynomial([1,2,3])):
    # print(a0,getattr(numpy.polynomial.Polynomial([1,2,3]),a0),sep='     ',end='\n')

# print(numpy.polynomial.Polynomial([1,5,9,13]).basis(2,domain=None,window=None,symbol='a'))#doesn't work on 1.23
# print(numpy.polynomial.Polynomial.basis(2,domain=None,window=None,symbol='a'))
# print(numpy.polynomial.Polynomial([1,5,9,13]).basis(2,domain=None,window=None))
# try:
    # print(numpy.polynomial.Polynomial().cast(numpy.polynomial.Chebyshev([.5,1.5,2.5]),domain=None,window=None))
# except Exception as e:
    # print(e)
# print(numpy.polynomial.Polynomial.cast(numpy.polynomial.Chebyshev([.5,1.5,2.5]),domain=None,window=None))
# print(numpy.polynomial.Polynomial([1,5,9,13]).convert(kind=numpy.polynomial.Chebyshev,domain=None,window=None))
# print(numpy.polynomial.Polynomial([1,5,9,13]).convert(kind=numpy.polynomial.Chebyshev,domain=[-10,10],window=None))
# print(numpy.polynomial.Polynomial([1,5,9,13]).convert(kind=numpy.polynomial.Chebyshev,domain=None,window=[-10,10]))
# print(id(numpy.polynomial.Polynomial([1,5,9,13])))
# print(id(numpy.polynomial.Polynomial([1,5,9,13]).copy()))
# print(numpy.polynomial.Polynomial([1,5,9,13]).copy())
# print(numpy.polynomial.Polynomial([1,5,9,13]).cutdeg(4))
# print(numpy.polynomial.Polynomial([1,5,9,13]).cutdeg(2))
# print(numpy.polynomial.Polynomial([1,5,9,13]).degree())
# for n in range(1,5):
    # print(n,numpy.polynomial.Polynomial([1,5,9,13]).deriv(m=n))
# x0=numpy.arange(5)
# y0=numpy.array([3,1.5,0,-1,3])
# print(numpy.polynomial.Polynomial.fit(x0,y0,3),numpy.polynomial.Polynomial.fit(x0,y0,[1,3]),sep='\n')

# # # x   xxxxxxxx    xxxxxx
# # # x   
# # # x   
    
    
# # # xxx xx          x
    # # # xx          x
    # # # xx

# print(numpy.polynomial.Polynomial.fit(x0,y0,3,rcond=1000.))
# print(numpy.polynomial.Polynomial.fit(x0,y0,3,rcond=2.3))
# print(numpy.polynomial.Polynomial.fit(x0,y0,3))

# import matplotlib.pyplot
# x=numpy.array([0,1,2,3])
# y=numpy.array([-1,.2,.9,2.1])
# matplotlib.pyplot.plot(x,y,marker='o',markersize=5)
# A=numpy.vstack([x,numpy.ones(len(x))]).T
# m,c=numpy.linalg.lstsq(A,y,rcond=None)[0]
# print(m,c)
# print(numpy.linalg.lstsq(A,y,rcond=None)[0])
# print(numpy.linalg.lstsq(A,y,rcond=None))
# matplotlib.pyplot.plot(x,m*x+c,label='1')
# A=numpy.vstack([x,numpy.ones(len(x))*2]).T
# m,c=numpy.linalg.lstsq(A,y,rcond=None)[0]
# print(m,c)
# print(numpy.linalg.lstsq(A,y,rcond=None)[0])
# print(numpy.linalg.lstsq(A,y,rcond=None))
# matplotlib.pyplot.plot(x,m*x+c,label='2')
# A=numpy.vstack([x,numpy.ones(len(x))*10]).T#>1 bias is in + direction
# m,c=numpy.linalg.lstsq(A,y,rcond=None)[0]
# print(m,c)
# print(numpy.linalg.lstsq(A,y,rcond=None)[0])
# print(numpy.linalg.lstsq(A,y,rcond=None))
# matplotlib.pyplot.plot(x,m*x+c,label='10')
# A=numpy.vstack([x,numpy.ones(len(x))*.1]).T#<1 bias is in - direction
# m,c=numpy.linalg.lstsq(A,y,rcond=None)[0]
# print(m,c)
# print(numpy.linalg.lstsq(A,y,rcond=None)[0])
# print(numpy.linalg.lstsq(A,y,rcond=None))
# matplotlib.pyplot.plot(x,m*x+c,label='.1')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# import matplotlib.pyplot
# x0=numpy.arange(5)
# y0=numpy.array([3,1.5,0,-1,3])
# w0=[10,2,1,1,1]
# w1=[1,1,1,1,1]
# print(numpy.finfo(numpy.float_))
# p0=numpy.polynomial.Polynomial.fit(x0,y0,2,domain=None,window=None,symbol='x',rcond=numpy.finfo(numpy.float_).eps*len(x0),full=True,w=w0)[0]
# pf0=numpy.polynomial.Polynomial.fit(x0,y0,2,domain=None,window=None,symbol='x',rcond=numpy.finfo(numpy.float_).eps*len(x0),full=True,w=w0)
# print(pf0)
# matplotlib.pyplot.plot(p0.linspace(),label='p0')
# matplotlib.pyplot.plot(x0,y0,label='points')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()


# p1=numpy.polynomial.Polynomial.fit(x0,y0,2,domain=None,window=None,symbol='x',rcond=numpy.finfo(numpy.float_).eps*len(x0),full=True,w=w1)[0]
# pf1=numpy.polynomial.Polynomial.fit(x0,y0,2,domain=None,window=None,symbol='x',rcond=numpy.finfo(numpy.float_).eps*len(x0),full=True,w=w1)
# print(pf1)
# matplotlib.pyplot.plot(p1.linspace(),label='p1')
# matplotlib.pyplot.plot(x0,y0,label='points')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# ma0=numpy.ma.array([1,2,3],mask=[0,1,0])
# print(numpy.ma.array(ma0,keep_mask=False).mask)
# print(numpy.ma.array(ma0,hard_mask=True).hardmask)
# print(numpy.ma.array(ma0,ndmin=2).ndim)
# print(numpy.ma.asarray(ma0,dtype=numpy.complex_,order='A'))
# print(numpy.put(ma0,[0,3],100,mode='clip'))
# print(ma0)

# print(numpy.polynomial.set_default_printstyle('unicode'))
# print(numpy.polynomial.Polynomial([0,1,2]))
# print(numpy.polynomial.set_default_printstyle('ascii'))
# print(numpy.polynomial.Polynomial([0,1,2]))
# p0=numpy.polynomial.Polynomial([0,1,2])
# print(f"{p0:unicode}")

# try:
    # eval('''numpy.True''')
# except Exception as e:
    # print(e)
# print(True is numpy.True_)
# print(False is numpy.False_)

# m0=numpy.ma.make_mask(numpy.arange(9).reshape(3,3).copy('C'))
# m0.flat[:]=numpy.ma.nomask
# numpy.put(m0,[3,7],numpy.True_)
# ma0=numpy.ma.array(numpy.arange(9).reshape(3,3).copy('C'),mask=m0)
# ma0.flat[3]=70000
# ma0=numpy.ma.array(ma0.copy('C'),mask=m0)
# ma0.flat[3]=numpy.ma.masked
# print(ma0,ma0.mask)
# print(numpy.ma.all(ma0,keepdims=True))
# print(numpy.ma.all(ma0,keepdims=False))
# print(numpy.ma.any(ma0,keepdims=True))
# print(numpy.ma.any(ma0,keepdims=False))
# print(numpy.ma.count(ma0,keepdims=True))
# print(numpy.ma.count(ma0,keepdims=False))
# print(numpy.ma.nonzero(ma0))
# print(numpy.ma.size(ma0,1))
# print(numpy.ma.size(ma0,axis=1))
# print(numpy.ma.size(ma0))

# print(numpy.ma.is_mask(numpy.array([(1,0),(1,1)],dtype="b1,b1")))
# l0=[1,2,3]
# t1=(4,5,6)
# print(zip(l0,t1))
# print(dict(zip(l0,t1)))
# print(dict(zip(l0,t1)).keys())
# print(dict(zip(l0,t1)).values())

# print(numpy.polynomial.Polynomial.fromroots([1,5,11],domain=None,window=[-10,10],symbol='a'))
# print(numpy.polynomial.Polynomial.fromroots([1,5,11],domain=None,window=None,symbol='a'))
# print(numpy.polynomial.Polynomial.fromroots([1,5,10],domain=None,window=None,symbol='a'))
# print(numpy.polynomial.Polynomial([1,5,10],domain=None,window=None,symbol='a'))

# pc0=numpy.polynomial.Chebyshev.fromroots([1,5,12],domain=[-.5,.5],window=[-10,10],symbol='a')
# pp0=numpy.polynomial.Polynomial.fromroots([1,5,11],domain=None,window=None,symbol='a')
# pp1=numpy.polynomial.Polynomial.fromroots([1,5,11],domain=None,window=None,symbol='a')
# print(pc0.has_sametype(pp0),pc0.has_samedomain(pp0),pc0.has_samewindow(pp0),pc0.has_samecoef(pp0),pp1.has_sametype(pp0),pp1.has_samedomain(pp0),pp1.has_samewindow(pp0),pp1.has_samecoef(pp0),sep='\n')

# print(numpy.polynomial.Polynomial([1,5,10],domain=None,window=None,symbol='a'))
# print(numpy.polynomial.Polynomial([1,5,10]).identity(domain=None,window=None,symbol='a'))
# print(numpy.polynomial.Polynomial([1,5,10]).identity(domain=[-5,10],window=[-5,15],symbol='a'))
# print(numpy.polynomial.Polynomial([1,5,10]).identity(domain=[-5,10],window=[-5,25],symbol='a'))
# print(numpy.polynomial.Polynomial([1,5,10]).identity(domain=[-5,10],window=[-105,125],symbol='a'))
# print(numpy.polynomial.Polynomial([1,5,10]).integ(m=5,k=[4,6,9,123,553],lbnd=-1))
# print(numpy.polynomial.Polynomial([1,5,10]).integ(m=5,k=[4,6,9,123,3],lbnd=-1))
# print(numpy.polynomial.Polynomial([1,5,10]).integ(m=5,k=[4,6,9,123,553],lbnd=0))
# print(sum([4,6,9,123,553]))

# d0=numpy.dtype('i4,f4')
# tbm0=[(5,0),(4,0),(0,0),(0,0),(-3,0)]
# print(numpy.ma.make_mask(tbm0,dtype=d0,copy=True,shrink=False))#reverse of defaults on last 2 kwargs
# m0=numpy.ma.make_mask(tbm0,copy=True,shrink=False,dtype=d0)
# print(numpy.ma.make_mask_none((5,2),dtype=d0))
# m1=numpy.ma.make_mask_none((5,2),dtype=d0)
# try:
    # print(numpy.ma.make_mask_descr(dtype=d0))
# except Exception as e:
    # print(e)
# print(numpy.ma.make_mask_descr(d0))
# print(numpy.ma.mask_or(m0,m1,copy=True,shrink=False))#reverse of defaults on last 2 kwargs
# print(numpy.ma.make_mask_none((5,),dtype=d0))
# m1=numpy.ma.make_mask_none((5,),dtype=d0)
# try:
    # print(numpy.ma.mask_or(m0,m1,copy=True,shrink=False))#reverse of defaults on last 2 kwargs
# except Exception as e:
    # print(e)

# m=[1,0,1,1]
# n=[0,1,0,0]
# arr=[]
# for man,mouse in zip(m,n):
   # arr.append((man,mouse))
# print(arr)
# dtype=numpy.dtype({'names':['man','mouse'],'formats':[numpy.int64,numpy.int64]})
# # arr=
   
# d0=numpy.dtype({'names':['n0','n1'],'formats':[numpy.int_,numpy.float_]})
# tbm0=[(5,0),(4,0),(0,0),(0,0),(-3,0)]#must convert to array otherwise computer goes into every one as whole; array takes every one as single..
# tbm0=numpy.array(tbm0,dtype=d0)
# print(numpy.ma.make_mask(tbm0,dtype=d0,copy=True,shrink=False))#reverse of defaults on last 2 kwargs
# m0=numpy.ma.make_mask(tbm0,copy=True,shrink=False,dtype=d0)
# print(numpy.ma.make_mask_none((5,),dtype=d0))
# m1=numpy.ma.make_mask_none((5,),dtype=d0)
# try:
    # print(numpy.ma.make_mask_descr(dtype=d0))
# except Exception as e:
    # print(e)
# print(numpy.ma.make_mask_descr(d0))
# print(numpy.ma.mask_or(m0,m1,copy=True,shrink=False))#reverse of defaults on last 2 kwargs
# print(numpy.ma.make_mask_none((5,),dtype=d0))
# m1=numpy.ma.make_mask_none((5,),dtype=d0)
# try:
    # print(numpy.ma.mask_or(m0,m1,copy=True,shrink=False))#reverse of defaults on last 2 kwargs
# except Exception as e:
    # print(e)

# # 6252
# # 6736
# # last_used_passwords
# # maximum_invalid_connect_attempts
# # password_lock_time
# # minimum_password_lifetime
# # maximum_password_lifetime
# # password_expire_warning_time
# # force_first_password_change
# # maximum_unused_initial_password_lifetime
# # maximum_unused_productive_password_lifetime
# # minimal_password_length
# # password_layout

# #SamAccountName
# #ObjectGUID
# #DistinguishedName
# #SID
# # ("CN=India Common Name,OU=Distribution Groups Organizational Unit,DC=gp,DC=gl,DC=google,DC=com Domain Component");

# s0=pandas.Series(['bird','whale',numpy.nan,'lion'])
# print(s0)
# print(s0.map('You are a {}'.format,na_action=None))
# print(s0.map('You are a {}'.format,na_action='ignore'))

# import scipy.stats
# print(scipy.stats.pearsonr(numpy.arange(5),numpy.arange(9,4,-1)+2))

# # On Error GoTo 0
# # On Error GoTo -1
# # On Error GoTo errHandler0
# # On Error Resume Next
# # Debug.Print Err.Description
# # addgroup group123
# # newgrp group123
# # unshadow /etc/passwd /etc/shadow > f0
# # john f0 --wordlist=/usr/share/wordlists/rockyou.txt
# # /etc/skel
# # chown username0:groupname0 filename0

# print(numpy.arange('2022-01-01','2022-02-01',5,dtype=numpy.datetime64))
# print(numpy.diff(numpy.arange('2022-01-01','2022-02-01',5,dtype=numpy.datetime64)))
# a0=numpy.arange('2022-01-01','2022-02-01',5,dtype=numpy.datetime64)
# try:
    # a0[3]=numpy.ma.masked
# except Exception as e:
    # print(e)
# a0=numpy.arange(3,32,5)
# print(a0)
# try:
    # a0[3]=numpy.ma.masked
# except Exception as e:
    # print(e)
# ma0=numpy.ma.arange(3,32,5)
# ma0[3]=numpy.ma.masked
# print(numpy.ma.sort(ma0,endwith=True))
# print(numpy.ma.sort(ma0,endwith=False))
# ma0=numpy.arange('2022-01-01','2022-02-01',5,dtype=numpy.datetime64)
# try:
    # ma0[3]=numpy.ma.masked
# except Exception as e:
    # print(e)
# print(numpy.ma.sort(ma0,endwith=True))
# print(numpy.ma.sort(ma0,endwith=False))

# #force_first_password_change
# # password_expire_warning_time
# #maximum_unused_initial_password_lifetime
# #maximum_unused_productive_password_lifetime
# #maximum_invalid_connect_attempts

# # 47 49 46 38 39  GIF89
# # 89 50 4E 47  PNG
# # mime sniffing

# [System.Security.Principal.WindowsIdentity]::GetCurrent().User.Value

# import matplotlib.pyplot
# print(numpy.polynomial.Polynomial([2,4,6]).linspace(n=10,domain=None))
# print(numpy.polynomial.Polynomial([2,4,9]).linspace(n=10,domain=None))
# print(numpy.polynomial.Polynomial([2,4,9]).linspace(n=10,domain=[-10,10]))
# print(*numpy.polynomial.Polynomial([2,4,9]).linspace(n=10,domain=[-10,10]))
# p0=numpy.polynomial.Polynomial([2,4,6])
# p1=numpy.polynomial.Polynomial([2,4,9])
# # matplotlib.pyplot.plot(p0.linspace()[0],p0.linspace()[1],label='p0')
# # matplotlib.pyplot.plot(p1.linspace()[0],p1.linspace()[1],label='p1')
# matplotlib.pyplot.plot(p0.linspace()[0],p0.linspace()[1],label=f'{p0:unicode}')
# matplotlib.pyplot.plot(p1.linspace()[0],p1.linspace()[1],label=f'{p1:unicode}')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# import matplotlib.pyplot
# p0=numpy.polynomial.Polynomial([2,4,6],domain=[-1000,1000])
# matplotlib.pyplot.plot(p0.linspace()[0],p0.linspace()[1],label=f'{p0:unicode}')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# print(numpy.polynomial.Polynomial([2,4,6]).mapparms())
# print(numpy.polynomial.Polynomial([2,4,9]).mapparms())
# print(numpy.polynomial.Polynomial([2,4,6],domain=[-10,10]).mapparms())
# print(numpy.polynomial.Polynomial([2,4,6],window=[-10,10]).mapparms())
# print(numpy.polynomial.Polynomial([2,4,6],domain=[-10,10],window=[-10,10]).mapparms())
# print(numpy.polynomial.Polynomial([2,4,6],window=[-10,100]).mapparms())
# print(numpy.polynomial.Polynomial([2,4,6],window=[-10,1000]).mapparms())

# print(numpy.polynomial.Polynomial([2,4,6]).roots())
# print(numpy.polynomial.Polynomial([2,4,9]).roots())

# print(numpy.polynomial.Polynomial([2,4,6]))
# print(numpy.polynomial.Polynomial([2,4,6]).trim(tol=0))
# print(numpy.polynomial.Polynomial([2,4,6]).trim(tol=5))
# print(numpy.polynomial.Polynomial([2,4,6]).trim(tol=3))

# print(numpy.polynomial.Polynomial([6,4,2]))
# print(numpy.polynomial.Polynomial([6,4,2]).trim(tol=0))
# print(numpy.polynomial.Polynomial([6,4,2]).trim(tol=5))
# print(numpy.polynomial.Polynomial([6,4,2]).trim(tol=3))

# print(numpy.polynomial.Polynomial([6,4,2]))
# print(numpy.polynomial.Polynomial([6,4,2]).truncate(3))
# print(numpy.polynomial.Polynomial([6,4,2]).truncate(1))
# print(numpy.polynomial.Polynomial([6,4,2]).truncate(2))

# try:
    # print(numpy.polynomial.Polynomial([6,4,2]).polydomain)
# except Exception as e:
    # print(e)
# try:
    # print(numpy.polynomial.Polynomial([6,4,2]).polydomain())
# except Exception as e:
    # print(e)

# for a0 in dir(numpy.polynomial.Polynomial([1,2,3])):
    # print(a0,getattr(numpy.polynomial.Polynomial([1,2,3]),a0),sep='     ',end='\n')

# # # [System.Security.Principal.WindowsIdentity]::GetCurrent()
# print(numpy.polynomial.Polynomial([6,4,2]).mapparms())
# # # passwords.google.com
# # # if password has been hacked or is too weak, alerts

# try:
    # print(numpy.polynomial.Polynomial([2,4,6]).polydomain)
# except Exception as e:
    # print(e)
# try:
    # print(numpy.polynomial.Polynomial([2,4,6]).polyone)
# except Exception as e:
    # print(e)
# try:
    # print(numpy.polynomial.Polynomial([2,4,6]).polyzero)
# except Exception as e:
    # print(e)
# try:
    # print(numpy.polynomial.Polynomial([2,4,6]).polyx)
# except Exception as e:
    # print(e)
# p0=numpy.polynomial.Polynomial([2,4,6])
# p1=numpy.polynomial.Polynomial([2,4,9])
# print('p0,p1              ',p0,p1,sep='\n')
# try:
    # print(p0.polyadd(p1))
# except Exception as e:
    # print(e)
# print(p0+p1)
# print(p0-p1)
# print(p0*p1)
# try:
    # print(p0/p1)
# except Exception as e:
    # print(e)
# print(p0//p1)
# try:
    # print(numpy.divmod(p0,p1))
# except Exception as e:
    # print(e)
# print(p0%p1)
# print(p0**3)
# p0=p0.coef
# p1=p1.coef
# print(numpy.polynomial.polynomial.polyadd(p0,p1))
# print(numpy.polynomial.polynomial.polysub(p0,p1))
# print(numpy.polynomial.polynomial.polymulx(p0))
# print(numpy.polynomial.polynomial.polymul(p0,p1))
# print(type(p0),type(p1))
# print(numpy.polynomial.polynomial.polydiv(p0,p1))
# print(numpy.polynomial.polynomial.polypow(p0,3,maxpower=None))
# p2=numpy.polynomial.Polynomial([0,1])
# print('p2              ',p2)
# p2=p2.coef
# try:
    # print(numpy.polynomial.polynomial.polypow(p2,17,maxpower=None))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.polynomial.polynomial.polypow(p2,17,maxpower=16))
# except Exception as e:
    # print(e)
# print(numpy.polynomial.polynomial.polypow(p2,17,maxpower=17))
# try:
    # print(p2.polyval(3))
# except Exception as e:
    # print(e)
# try:
    # print(p2.polyval([1,2,3]))
# except Exception as e:
    # print(e)
# print(numpy.polynomial.polynomial.polyval(3,[0,1],tensor=True))
# print(numpy.polynomial.polynomial.polyval([1,2,3],[0,1],tensor=True))
# print(numpy.polynomial.polynomial.polyval([1,2,3],[0,1],tensor=False))
# print(numpy.polynomial.polynomial.polyval([1,2,3],[[0,1],[1,2]],tensor=True))
# try:
    # print(numpy.polynomial.polynomial.polyval([1,2,3],[[0,1],[1,2]],tensor=False))
# except Exception as e:
    # print(e)
# print(numpy.polynomial.polynomial.polyval([1,2],[[0,1],[1,2]],tensor=True))
# print(numpy.polynomial.polynomial.polyval([1,2],[[0,1],[1,2]],tensor=False))
# print('polyval2d')
# print(numpy.polynomial.polynomial.polyval2d([1],[1],[[0,1],[1,2]]))
# print(numpy.polynomial.polynomial.polyval2d([1,2],[1,2],[[0,1],[1,2]]))
# print(numpy.polynomial.polynomial.polyval2d([1,3],[1,3],[[0,1],[1,2]]))
# print(numpy.polynomial.polynomial.polyval2d([1,3],[1,3],[[[0,1],[1,2]],[[0,1],[1,50]]]))
# try:
    # print(numpy.polynomial.polynomial.polyval2d([1,3],[1,3,4],[[0,1],[1,2]]))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.polynomial.polynomial.polyval2d([1,3],[1,3,4,5],[[0,1],[1,2]]))
# except Exception as e:
    # print(e)
# print(numpy.polynomial.polynomial.polyval3d([1],[1],[1],[[0,1],[1,2]]))
# print(numpy.polynomial.polynomial.polyval3d([1],[1],[1],[[[0,1],[1,2]]]))
# print(numpy.polynomial.polynomial.polyval3d([1],[1],[1],[[0,1,1],[1,2,1]]))
# print(numpy.polynomial.polynomial.polyval3d([1],[1],[1],[[0,1,2],[1,2,3]]))
# print(numpy.polynomial.polynomial.polyval3d([1],[1],[1],[[[0,1,1],[1,2,2],[2,3,3]]]))
# print(numpy.polynomial.polynomial.polyval3d([1],[1],[1],[[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]]]))
# print(numpy.polynomial.polynomial.polyval3d([2],[2],[2],[[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]]]))
# print(numpy.polynomial.polynomial.polyval3d([2],[2],[2],[[[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]]],[[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,100]]]]))
# print(numpy.polynomial.polynomial.polyval3d([2],[2],[2],[[[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]]],[[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,100]]],[[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,100]]]]))
# print(numpy.polynomial.polynomial.polyval3d([2],[2],[5],[[[0,1,2,2,2],[1,2,3,2,2]]]))
# print(numpy.polynomial.polynomial.polyval3d([5],[2],[2],[[[0,1,2,2,2],[1,2,3,2,2]]]))

# print('polygrid2d')
# print(numpy.polynomial.polynomial.polygrid2d([1],[1],[[0,1],[1,2]]))
# print(numpy.polynomial.polynomial.polygrid2d([1,2],[1,2],[[0,1],[1,2]]))
# print(numpy.polynomial.polynomial.polygrid2d([1,3],[1,3],[[0,1],[1,2]]))
# print(numpy.polynomial.polynomial.polygrid2d([1,3],[1,3],[[[0,1],[1,2]],[[0,1],[1,50]]]))
# try:
    # print(numpy.polynomial.polynomial.polygrid2d([1,3],[1,3,4],[[0,1],[1,2]]))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.polynomial.polynomial.polygrid2d([1,3],[1,3,4,5],[[0,1],[1,2]]))
# except Exception as e:
    # print(e)
# print(numpy.polynomial.polynomial.polygrid3d([1],[1],[1],[[0,1],[1,2]]))
# print(numpy.polynomial.polynomial.polygrid3d([1],[1],[1],[[[0,1],[1,2]]]))
# print(numpy.polynomial.polynomial.polygrid3d([1],[1],[1],[[0,1,1],[1,2,1]]))
# print(numpy.polynomial.polynomial.polygrid3d([1],[1],[1],[[0,1,2],[1,2,3]]))
# print(numpy.polynomial.polynomial.polygrid3d([1],[1],[1],[[[0,1,1],[1,2,2],[2,3,3]]]))
# print(numpy.polynomial.polynomial.polygrid3d([1],[1],[1],[[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]]]))
# print(numpy.polynomial.polynomial.polygrid3d([2],[2],[2],[[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]]]))
# print(numpy.polynomial.polynomial.polygrid3d([2],[2],[2],[[[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]]],[[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,100]]]]))
# print(numpy.polynomial.polynomial.polygrid3d([2],[2],[2],[[[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]]],[[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,100]]],[[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,3]],[[0,1,1],[1,2,2],[2,3,100]]]]))
# print(numpy.polynomial.polynomial.polygrid3d([2],[2],[5],[[[0,1,2,2,2],[1,2,3,2,2]]]))
# print(numpy.polynomial.polynomial.polygrid3d([5],[2],[2],[[[0,1,2,2,2],[1,2,3,2,2]]]))
# import math
# print(math.comb(9,3))
# print(math.perm(9,3))
# print(math.comb(9,9))
# print(math.perm(9,9))
# print(math.comb(3,1))
# print(math.perm(3,1))
# print(math.perm(3,3))
# print(numpy.polynomial.polynomial.polygrid3d([5,2,3],[2,2,3],[2,2,3],[[[0,1,2,2,2],[1,2,3,2,2]]]))
# print(numpy.polynomial.polynomial.polygrid3d([5,2,3],[2,2,3],[2,2,3],[[[0,1,2,2,2],[1,2,3,2,2]]]).shape)
# print(numpy.polynomial.polynomial.polygrid3d([5,2,3],[2,2,3],[2,2,3],[[[0,1,2,2,2],[1,2,3,2,2]]]).size)

# print(numpy.polynomial.polynomial.polyder([[3,2,1,2,3],[3,2,1,2,10],[3,2,10,2,3]],m=1,scl=-1,axis=0))
# print(numpy.polynomial.polynomial.polyder([[3,2,1,2,3],[3,2,1,2,10],[3,2,10,2,3]],m=2,scl=-1,axis=0))
# print(numpy.polynomial.polynomial.polyder([[3,2,1,2,3],[3,2,1,2,10],[3,2,10,2,3]],m=1,scl=-1,axis=1))
# print(numpy.polynomial.polynomial.polyder([[3,2,1,2,3],[3,2,1,2,10],[3,2,10,2,3]],m=2,scl=-1,axis=1))

# print(numpy.polynomial.polynomial.polyint([[3,2,1,2,3],[3,2,1,2,10],[3,2,10,2,3]],m=1,scl=-1,axis=0))
# print(numpy.polynomial.polynomial.polyint([[3,2,1,2,3],[3,2,1,2,10],[3,2,10,2,3]],m=2,scl=-1,axis=0))
# print(numpy.polynomial.polynomial.polyint([[3,2,1,2,3],[3,2,1,2,10],[3,2,10,2,3]],m=2,scl=-1,lbnd=-3,axis=0))
# print(numpy.polynomial.polynomial.polyint([[3,2,1,2,3],[3,2,1,2,10],[3,2,10,2,3]],m=2,scl=-1,lbnd=-3,k=10,axis=0))
# print(numpy.polynomial.polynomial.polyint([[3,2,1,2,3],[3,2,1,2,10],[3,2,10,2,3]],m=1,scl=-1,axis=1))
# print(numpy.polynomial.polynomial.polyint([[3,2,1,2,3],[3,2,1,2,10],[3,2,10,2,3]],m=2,scl=-1,axis=1))
# print(numpy.polynomial.polynomial.polyint([[3,2,1,2,3],[3,2,1,2,10],[3,2,10,2,3]],m=2,scl=-1,lbnd=-3,axis=1))
# print(numpy.polynomial.polynomial.polyint([[3,2,1,2,3],[3,2,1,2,10],[3,2,10,2,3]],m=2,scl=-1,lbnd=-3,k=10,axis=1))

# print(numpy.polynomial.polynomial.polypow([1,2,3],2,maxpower=20))
# print(numpy.polynomial.polynomial.polyder([1,2,3,]))
# print(numpy.polynomial.polynomial.polyint([1,2,3,]))

# print(numpy.polynomial.polynomial.polyfromroots([0-1j,0+1j]))
# print(numpy.polynomial.polynomial.polyfromroots([-1j,1j]))
# print(numpy.polynomial.polynomial.polyfromroots([-1,1]))
# p0=numpy.polynomial.polynomial.polyfromroots([-1j,1j])
# p1=numpy.polynomial.polynomial.polyfromroots([-1,1])
# print(numpy.polynomial.polynomial.polyval(5,p0,tensor=True))
# print(numpy.polynomial.polynomial.polyval(5,p1,tensor=True))
# print(numpy.polynomial.polynomial.polyvalfromroots(5,[-1j,1j]))
# print(numpy.polynomial.polynomial.polyvalfromroots(5,[-1,1]))
# print(numpy.polynomial.polynomial.polyroots(p0))
# print(numpy.polynomial.polynomial.polyroots(p1))
# print(numpy.polynomial.polynomial.polyfromroots([2,2,2,2,2]))
# print(numpy.polynomial.polynomial.polyroots(numpy.polynomial.polynomial.polyfromroots([2,2,2,2,2])))
# print(numpy.polynomial.polynomial.polyfromroots([-1000000,1000000]))
# print(numpy.polynomial.polynomial.polyroots(numpy.polynomial.polynomial.polyfromroots([-1000000,1000000])))

# print(numpy.polynomial.polynomial.polyvander(4,3))
# print(4**3)
# print(numpy.polynomial.polynomial.polyvander(5,4))
# print(numpy.polynomial.polynomial.polyvander(5,3))
# print(numpy.polynomial.polynomial.polyvander(5,2))
# print(numpy.polynomial.polynomial.polyvander([1,2,3],2))
# print(numpy.vander([1,2,3],3,increasing=True))
# print(numpy.polynomial.polynomial.polyvander2d(2,2,[5,5]))
# print(numpy.polynomial.polynomial.polyvander2d(2,2,[3,3]))
# print(numpy.polynomial.polynomial.polyvander2d(2,1,[3,3]))
# print(numpy.polynomial.polynomial.polyvander2d(1,2,[3,3]))
# print(numpy.polynomial.polynomial.polyvander2d([1,2],[1,2],[3,3]))
# print(numpy.polynomial.polynomial.polyvander2d([1,2],[1,2],[3,4]))
# print(numpy.polynomial.polynomial.polyvander2d([[1,2],[4,5]],[[1,2],[4,5]],[3,4]))
# print(numpy.polynomial.polynomial.polyvander2d([1,2,4,5],[1,2,4,5],[3,4]))
# try:
    # print(numpy.polynomial.polynomial.polyvander2d([1,2,3],[1,2],[3,3]))
# except Exception as e:
    # print(e)
# print(numpy.polynomial.polynomial.polyvander3d(2,2,2,[3,3,3]))
# print(numpy.polynomial.polynomial.polyvander3d([1+0j,2+0j],[1+0j,2+0j],[1+0j,2+0j],[3,3,3]))
# print(numpy.polynomial.polynomial.polyvander3d(2,2,2,[3,5,3]))

# print(numpy.polynomial.polynomial.polycompanion([-6,-2,7,-6,5,1]))
# print(numpy.polynomial.polynomial.polycompanion([1,2,1]))
# print(numpy.polynomial.polynomial.polycompanion([1,2,3,1]))
# print(numpy.polynomial.polynomial.polycompanion([1,2,3]))
# print(numpy.polynomial.polynomial.polycompanion([1,2,6]))
# try:
    # print(numpy.polynomial.polynomial.polycompanion([0,0]))
# except Exception as e:
    # print(e)

# print(numpy.polynomial.Polynomial.basis_name)
# print(numpy.polynomial.Polynomial.maxpower)
# try:
    # print(numpy.polynomial.Polynomial.nickname)
# except Exception as e:
    # print(e)
# print(numpy.polynomial.Polynomial.has_sametype)
# p0=numpy.polynomial.Polynomial([1,2,3])
# p1=numpy.polynomial.Polynomial([1,2,3])
# print(p0)
# p0+=2
# print(p0)
# print(p0)
# p0+=p1
# print(p0)
# print(numpy.polynomial.set_default_printstyle('unicode'))
# print(p0)

# ##sample rate (sr) typically around 22050
# # # import librosa
# # # f0,sr0=librosa.load('file.wav')
# # # trimmedf0=librosa.effects.trim(f0,top_db=20)
# # # fTf0=librosa.stft(f0)

# # # minor (all OTHER rows and columns removed) Mij(-1)**i+J=Cij >> for all ijs, sum([aijCij)=|A| (where |A| is determinant)
# # # eigenPolynomialOfMatrix0=(eigenPolynomialOfMatrix0[1,1]*eigenPolynomialOfMatrix0[2,2]) IF[F?[ Matrix0 block triangular
# # # mp0.companionMatrix.eigenPolynomial=mp0; mp0.companionMatrix.minimalPolynomial=mp0

# # # Stripe 2 b; 


# a0=numpy.arange(12)
# print(numpy.polynomial.polynomial.polyfit(a0,a0*2,12))
# numpy.polynomial.polynomial.polyfit(a0,a0*2,12)
# import warnings
# warnings.simplefilter('ignore',numpy.RankWarning)
# print(numpy.polynomial.polynomial.polyfit(a0,a0*2,12))
# numpy.polynomial.polynomial.polyfit(a0,a0*2,12)

# x0=numpy.linspace(0,1,10)
# y0=x0**2+1
# print(numpy.polynomial.polynomial.polyfit(x0,y0,4,rcond=numpy.finfo(numpy.float_).eps*len(x0),full=True,w=None))
# print(f'{numpy.polynomial.Polynomial(numpy.polynomial.polynomial.polyfit(x0,y0,4,rcond=numpy.finfo(numpy.float_).eps*len(x0),full=True,w=None)[0]):unicode}')

# c0=[1,0,2,1,0,0]
# print(c0)
# print(numpy.polynomial.polynomial.polytrim(c0,tol=0))
# print(numpy.polynomial.polynomial.polytrim(c0,tol=1))
# print(numpy.polynomial.polynomial.polytrim(c0,tol=2))

# y0=2
# slope0=.5
# print(numpy.polynomial.polynomial.polyline(y0,slope0))
# y0=[2,3]
# try:
    # print(numpy.polynomial.polynomial.polyline(y0,slope0))
# except Exception as e:
    # print(e)

# def cos0(x0,modX0):
    # cosX0=numpy.cos(x0)
    # finalX0=cosX0-modX0
    # return finalX0
# print(numpy.polynomial.chebyshev.chebinterpolate(lambda x: numpy.cos(x),1))
# print(numpy.polynomial.chebyshev.chebinterpolate(lambda x: numpy.cos(x),5))
# print(numpy.polynomial.chebyshev.chebinterpolate(lambda x: numpy.cos(x),9))
# print(numpy.polynomial.chebyshev.chebinterpolate(lambda x: numpy.cos(x),12))
# cp0c=numpy.polynomial.chebyshev.chebinterpolate(lambda x: numpy.cos(x),12)
# cp0=numpy.polynomial.Chebyshev(cp0c)
# import matplotlib.pyplot
# x0=numpy.linspace(-1,1,100,endpoint=True)#this x0 becomes only 13 y0 because there are only 13 degrees in Chebyshev below (you'd need 100 degrees to have this be 100 y0s..)
# modX0=numpy.linspace(0,.1,13,endpoint=True)
# try:
    # cp1c=numpy.polynomial.chebyshev.chebinterpolate(cos0,12)
# except Exception as e:
    # print(e)
# cp1c=numpy.polynomial.chebyshev.chebinterpolate(cos0,12,args=(modX0,))
# cp1=numpy.polynomial.Chebyshev(cp1c)
# matplotlib.pyplot.plot(cp0.linspace()[0],cp0.linspace()[1],label=f'{cp0:unicode}')
# matplotlib.pyplot.plot(cp1.linspace()[0],cp1.linspace()[1],label=f'{cp1:unicode}')
# matplotlib.pyplot.plot(x0,numpy.cos(x0)-.02,label=f'{numpy.cos}')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# cp0=numpy.polynomial.Chebyshev.interpolate(lambda x: numpy.cos(x),12,domain=[-3,3])
# import matplotlib.pyplot
# x0=numpy.linspace(-1,1,100,endpoint=True)
# matplotlib.pyplot.plot(cp0.linspace()[0],cp0.linspace()[1],label=f'{cp0:unicode}')
# matplotlib.pyplot.plot(x0,numpy.cos(x0)-.02,label=f'{numpy.cos}')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# cp0=numpy.polynomial.Chebyshev.interpolate(lambda x: numpy.cos(x),12,domain=[-30,30])
# import matplotlib.pyplot
# x0=numpy.linspace(-1,1,100,endpoint=True)
# matplotlib.pyplot.plot(cp0.linspace()[0],cp0.linspace()[1],label=f'{cp0:unicode}')
# matplotlib.pyplot.plot(x0,numpy.cos(x0)-.02,label=f'{numpy.cos}')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# cp0=numpy.polynomial.Chebyshev.interpolate(lambda x: numpy.cos(x),100,domain=[-30,30])
# import matplotlib.pyplot
# x0=numpy.linspace(-1,1,100,endpoint=True)
# matplotlib.pyplot.plot(cp0.linspace()[0],cp0.linspace()[1],label=f'{cp0:unicode}')
# matplotlib.pyplot.plot(x0,numpy.cos(x0)-.02,label=f'{numpy.cos}')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# for a0 in dir(numpy.polynomial.Chebyshev([1,2,3])):
    # print(a0,getattr(numpy.polynomial.Chebyshev([1,2,3]),a0),sep='     ',end='\n')

# for x0 in numpy.arange(101):
    # try:
        # print(x0,'       ',numpy.polynomial.chebyshev.chebgauss(x0))
    # except Exception as e:
        # print(e)

# .bin
# .prx
# .puff
# .ko
# .mod

# .bundle


# import pandas
# df0=pandas.DataFrame({'col1':['A','B','C','D','E','F'],'col2':['D','B','C','D','E','F'],'col3':['b','B','C','c','e','F'],'col4':[numpy.nan,2,3,numpy.nan,5,-7]})
# print(df0)
# print(df0.sort_values(by='col2',ascending=True,axis=0,kind='quicksort',key=None,inplace=False,na_position='last',ignore_index=False))
# print(df0.sort_values(by='col2',ascending=False,axis=0,kind='quicksort',key=None,inplace=False,na_position='last',ignore_index=False))
# print(df0.sort_values(by='col2',ascending=False,axis=0,kind='quicksort',key=None,inplace=False,na_position='last',ignore_index=True))
# print(df0.sort_values(by=['col1','col4'],ascending=False,axis=0,kind='quicksort',key=None,inplace=False,na_position='last',ignore_index=True))
# print(df0.sort_values(by=['col1','col4'],ascending=False,axis=0,kind='mergesort',key=None,inplace=False,na_position='last',ignore_index=True))
# print(df0.sort_values(by=['col1','col4'],ascending=False,axis=0,kind='mergesort',key=None,inplace=False,na_position='first',ignore_index=True))
# print(df0.sort_values(by=['col1','col4'],ascending=False,axis=0,kind='mergesort',key=None,inplace=False,na_position='first',ignore_index=True))
# print(df0.sort_values(by=['col2','col4'],ascending=[False,True],axis=0,kind='quicksort',key=None,inplace=False,na_position='first',ignore_index=True))
# print(df0.sort_values(by=['col2','col4'],ascending=[True,False],axis=0,kind='quicksort',key=None,inplace=False,na_position='first',ignore_index=True))
# print(df0.sort_values(by=['col2','col4'],ascending=[True,True],axis=0,kind='quicksort',key=None,inplace=False,na_position='first',ignore_index=True))
# print(',ascending=[False,True] just before')
# print(df0.sort_values(by=['col4'],ascending=False,axis=0,kind='mergesort',key=None,inplace=False,na_position='first',ignore_index=True))
# print(df0.sort_values(by=['col4'],ascending=False,axis=0,kind='mergesort',key=lambda s0: numpy.abs(s0),inplace=False,na_position='first',ignore_index=True))
# print(df0.sort_values(by=0,ascending=False,axis=1,kind='mergesort',key=None,inplace=False,na_position='first',ignore_index=True))
# try:
    # print(df0.sort_values(by=4,ascending=False,axis=1,kind='mergesort',key=None,inplace=False,na_position='first',ignore_index=True))
# except Exception as e:
    # print(e)
# print(df0.sort_values(by=3,ascending=False,axis=1,kind='mergesort',key=None,inplace=False,na_position='first',ignore_index=True))
# print(df0.sort_values(by=3,ascending=False,axis=1,kind='mergesort',key=lambda s0: s0.str.lower(),inplace=False,na_position='first',ignore_index=True))

# ws0=pandas.Series([0,1,2,2,1])
# w0=[0,1,2]
# print(df0)
# print(df0.sample(n=3,frac=None,random_state=2,replace=False,axis=0,weights=ws0,ignore_index=False))
# try:
    # print(df0.sample(n=5,frac=None,random_state=2,replace=False,axis=0,weights=ws0,ignore_index=False))#must have more non-zero weights in population than sample you're choosing (since 0s will automatically NOT be chosen and e.g. 5 of 6 can't be met if only 4 of 6 are non-zero)
# except Exception as e:
    # print(e)
# ws0=pandas.Series([0,1,2,2,1,1])
# print(df0.sample(n=5,frac=None,random_state=2,replace=False,axis=0,weights=ws0,ignore_index=False))
# try:
    # print(df0.sample(n=5,frac=None,random_state=numpy.random.default_rng(8).pareto(3),replace=False,axis=0,weights=ws0,ignore_index=False))
# except Exception as e:
    # print(e)
# try:
    # print(df0.sample(n=5,frac=None,random_state=numpy.random.default_rng(8).pareto,replace=False,axis=0,weights=ws0,ignore_index=False))
# except Exception as e:
    # print(e)
# print(df0.sample(n=5,frac=None,random_state=numpy.random.default_rng(8),replace=False,axis=0,weights=ws0,ignore_index=False))
# print(df0.sample(n=5,frac=None,random_state=2,replace=True,axis=0,weights=ws0,ignore_index=False))
# try:
    # print(df0.sample(n=5,frac=None,random_state=2,replace=True,axis=0,weights=w0,ignore_index=False))
# except Exception as e:
    # print(e)
# print(df0.sample(n=5,frac=None,random_state=2,replace=True,axis=0,weights=None,ignore_index=False))
# print(df0.sample(n=5,frac=None,random_state=2,replace=True,axis=1,weights=None,ignore_index=False))
# print(df0.sample(n=None,frac=.8,random_state=2,replace=True,axis=1,weights=None,ignore_index=False))
# print(df0.sample(n=None,frac=.8,random_state=2,replace=True,axis=1,weights=None,ignore_index=True))
# print(df0.sample(n=None,frac=.99,random_state=2,replace=True,axis=1,weights=None,ignore_index=True))
# for n0 in numpy.arange(8):
    # try:
        # print(n0,'     ',numpy.random.default_rng(8).pareto(n0))
    # except Exception as e:
        # print(e)

# # # [System.Security.Principal.WindowsIdentity]::GetCurrent()

# print(df0.sort_values(by=['col4'],ascending=False,axis=0,kind='mergesort',key=None,inplace=False,na_position='first',ignore_index=True))

# x0=numpy.arange(1,10)
# print(x0,'      ',numpy.polynomial.chebyshev.chebweight(x0))
# x0=numpy.linspace(-1,1,5)
# print(x0,'      ',numpy.polynomial.chebyshev.chebweight(x0))
# lenx0=len(x0)
# print(lenx0,'      ',numpy.polynomial.chebyshev.chebgauss(lenx0))
# ##f(x)/w1  and  f(x)/w2 (approximation)  use different w[eight]s

# import matplotlib.pyplot
# x0=numpy.linspace(-1,1,100,endpoint=True)
# matplotlib.pyplot.plot(x0,numpy.polynomial.chebyshev.chebweight(x0),label=f'{numpy.polynomial.chebyshev.chebweight}')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()


# import matplotlib.pyplot
# x0=numpy.arange(20)
# lenx0=len(x0)
# matplotlib.pyplot.plot(x0,numpy.polynomial.chebyshev.chebpts1(lenx0),label=f'{numpy.polynomial.chebyshev.chebpts1}')
# matplotlib.pyplot.plot(x0,numpy.polynomial.chebyshev.chebpts2(lenx0),label=f'{numpy.polynomial.chebyshev.chebpts2}')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# # matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# print(numpy.polynomial.chebyshev.chebpts1(lenx0))
# print(x0,(-numpy.cos(numpy.pi*(numpy.arange(lenx0)+.5)/lenx0)),sep='\n')
# print(x0,numpy.arccos((numpy.cos(numpy.pi*(numpy.arange(lenx0)+.5)/lenx0))),sep='\n')
# print(x0,numpy.arccos((-numpy.cos(numpy.pi*(numpy.arange(lenx0)+.5)/lenx0))),sep='\n')
# print(numpy.polynomial.chebyshev.chebpts2(lenx0))
# print(x0,(-numpy.cos(numpy.pi*(numpy.arange(lenx0))/(lenx0-1))),sep='\n')
# print(x0,numpy.arccos((numpy.cos(numpy.pi*(numpy.arange(lenx0))/(lenx0-1)))),sep='\n')
# print(x0,numpy.arccos((-numpy.cos(numpy.pi*(numpy.arange(lenx0))/(lenx0-1)))),sep='\n')

# x0=numpy.arange(21)
# lenx0=len(x0)
# matplotlib.pyplot.plot(x0,numpy.polynomial.chebyshev.chebpts1(lenx0),label=f'{numpy.polynomial.chebyshev.chebpts1}')
# matplotlib.pyplot.plot(x0,numpy.polynomial.chebyshev.chebpts2(lenx0),label=f'{numpy.polynomial.chebyshev.chebpts2}')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# # matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# print(numpy.polynomial.Chebyshev.basis(20))
# print(numpy.polynomial.Chebyshev([1,0,-8,0,8]))
# print(numpy.polynomial.Chebyshev([1,0,-8,0,8]).roots())
# lenx0=4
# print(numpy.arccos((-numpy.cos(numpy.pi*(numpy.arange(lenx0))/(lenx0-1)))),sep='\n')#this doesn't give roots (nothing to do with roots really..)
# print(numpy.polynomial.chebyshev.chebpts1(lenx0))
# print(-numpy.cos(numpy.pi*(numpy.arange(lenx0)+.5)/lenx0))

# print(numpy.polynomial.chebyshev.chebpts2(lenx0))
# print(-numpy.cos((numpy.pi*numpy.arange(lenx0))/(lenx0-1)))
# print(-numpy.cos((numpy.pi*numpy.arange(1,lenx0+1))/(lenx0+1)))

# print(numpy.polynomial.chebyshev.cheb2poly([1,0,-8,0,8]))
# print(numpy.polynomial.Polynomial(numpy.polynomial.chebyshev.cheb2poly([1,0,-8,0,8])))
# print(numpy.polynomial.Chebyshev([1,0,-8,0,8]).convert(kind=numpy.polynomial.Polynomial))

# print(numpy.polynomial.chebyshev.poly2cheb([17,0,-80,0,64]))
# print(numpy.polynomial.Chebyshev(numpy.polynomial.chebyshev.poly2cheb([17,0,-80,0,64])))
# print(numpy.polynomial.Polynomial([17,0,-80,0,64]).convert(kind=numpy.polynomial.Chebyshev))

# import time,socket
# socket0=socket.socket()
# print(socket0)
# hostname0=socket.gethostname()
# print(hostname0)
# # port0=8080
# # print(port0)
# # print(socket0.bind(('',port0)))
# # print(socket0.listen())#security risk ?
# # connection0,address0=socket0.accept()
# # print(connection0,address0)
# # print(connection0.send('dir'.encode()))
# # data0=connection0.recv(1024)
# # print(data0)
# # if data0:
    # # print('received and executed on slave')

# # x3
# # 3x2
# # 6x
# # 6
# # 0
# for deg0 in numpy.arange(101):
    # try:
        # print(deg0,'       ',numpy.polynomial.hermite.hermgauss(deg0))
    # except Exception as e:
        # print(e)

# x0=numpy.linspace(-6,6,100)
# print(numpy.polynomial.hermite.hermweight(x0))
# import matplotlib.pyplot
# matplotlib.pyplot.plot(x0,numpy.polynomial.hermite.hermweight(x0),label=f'{numpy.polynomial.hermite.hermweight}')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()


# print(([0,-12,0,8]))
# print(numpy.polynomial.hermite.herm2poly([0,-12,0,8]))
# print(numpy.polynomial.hermite.poly2herm(numpy.polynomial.hermite.herm2poly([0,-12,0,8])))
# print(numpy.polynomial.Hermite(([0,-12,0,8])))


# print(numpy.polynomial.chebyshev.cheb2poly([1,0,-8,0,8]))
# print(numpy.polynomial.Polynomial(numpy.polynomial.chebyshev.cheb2poly([1,0,-8,0,8])))
# print(numpy.polynomial.Chebyshev([1,0,-8,0,8]).convert(kind=numpy.polynomial.Polynomial))

# print(numpy.polynomial.chebyshev.poly2cheb([17,0,-80,0,64]))
# print(numpy.polynomial.Chebyshev(numpy.polynomial.chebyshev.poly2cheb([17,0,-80,0,64])))
# print(numpy.polynomial.Polynomial([17,0,-80,0,64]).convert(kind=numpy.polynomial.Chebyshev))


# for deg0 in numpy.arange(101):
    # try:
        # print(deg0,'       ',numpy.polynomial.hermite_e.hermegauss(deg0))
    # except Exception as e:
        # print(e)

# x0=numpy.linspace(-6,6,100)
# print(numpy.polynomial.hermite_e.hermeweight(x0))
# import matplotlib.pyplot
# matplotlib.pyplot.plot(x0,numpy.polynomial.hermite_e.hermeweight(x0),label=f'{numpy.polynomial.hermite_e.hermeweight}')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()


# print(([0,-12,0,8]))
# print(numpy.polynomial.hermite_e.herme2poly([0,-12,0,8]))
# print(numpy.polynomial.hermite_e.poly2herme(numpy.polynomial.hermite_e.herme2poly([0,-12,0,8])))
# print(numpy.polynomial.HermiteE(([0,-12,0,8])))


# print(numpy.polynomial.chebyshev.cheb2poly([1,0,-8,0,8]))
# print(numpy.polynomial.Polynomial(numpy.polynomial.chebyshev.cheb2poly([1,0,-8,0,8])))
# print(numpy.polynomial.Chebyshev([1,0,-8,0,8]).convert(kind=numpy.polynomial.Polynomial))

# print(numpy.polynomial.chebyshev.poly2cheb([17,0,-80,0,64]))
# print(numpy.polynomial.Chebyshev(numpy.polynomial.chebyshev.poly2cheb([17,0,-80,0,64])))
# print(numpy.polynomial.Polynomial([17,0,-80,0,64]).convert(kind=numpy.polynomial.Chebyshev))

# print(([6/6,-18/6,9/6,-1/6]))
# print(numpy.polynomial.laguerre.lag2poly([6/6,-18/6,9/6,-1/6]))
# print(numpy.polynomial.laguerre.poly2lag(numpy.polynomial.laguerre.lag2poly([6/6,-18/6,9/6,-1/6])))
# print(numpy.polynomial.Laguerre(([6/6,-18/6,9/6,-1/6])))

# print(([0/2,-3/2,0/2,5/2]))
# print(numpy.polynomial.legendre.leg2poly([0/2,-3/2,0/2,5/2]))
# print(numpy.polynomial.legendre.poly2leg(numpy.polynomial.legendre.leg2poly([0/2,-3/2,0/2,5/2])))
# print(numpy.polynomial.Legendre(([0/2,-3/2,0/2,5/2])))
# print(numpy.polynomial.Polynomial(([0/2,-3/2,0/2,5/2])))



# for deg0 in numpy.arange(101):
    # try:
        # print(deg0,'       ',numpy.polynomial.laguerre.laggauss(deg0))
    # except Exception as e:
        # print(e)

# x0=numpy.linspace(-6,6,100)
# print(numpy.polynomial.laguerre.lagweight(x0))
# import matplotlib.pyplot
# matplotlib.pyplot.plot(x0,numpy.polynomial.laguerre.lagweight(x0),label=f'{numpy.polynomial.laguerre.lagweight}')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()


# for deg0 in numpy.arange(101):
    # try:
        # print(deg0,'       ',numpy.polynomial.legendre.leggauss(deg0))
    # except Exception as e:
        # print(e)

# x0=numpy.linspace(-6,6,100)
# print(numpy.polynomial.legendre.legweight(x0))
# import matplotlib.pyplot
# matplotlib.pyplot.plot(x0,numpy.polynomial.legendre.legweight(x0),label=f'{numpy.polynomial.legendre.legweight}')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()

# a0=numpy.array([[0,1,2,3],[4,5,6,0]])
# print(numpy.polynomial.polyutils.RankWarning)
# print(a0)
# print(numpy.polynomial.polyutils.as_series(a0,trim=False))
# print(numpy.polynomial.polyutils.as_series(a0,trim=True))
# print(numpy.polynomial.polyutils.trimseq(a0[0]))
# print(numpy.polynomial.polyutils.trimseq(a0[1]))
# print(numpy.polynomial.polyutils.trimcoef(a0[0],tol=3))
# print(numpy.polynomial.polyutils.trimcoef(a0[1],tol=3))
# print(numpy.polynomial.polyutils.trimcoef(a0[0],tol=2))
# print(numpy.polynomial.polyutils.trimcoef(a0[1],tol=2))
# points0=[-3-3j,-2-1j,2+3j,4+6j]
# print(points0)
# print(numpy.polynomial.polyutils.getdomain(points0))
# print(numpy.polynomial.polyutils.getdomain(numpy.array(points0).real))
# x1=[-.5,.5,1,1.5]
# print(numpy.array(x1).astype(numpy.complex_))
# try:
    # print(numpy.polynomial.polyutils.mapdomain(x1,numpy.polynomial.polyutils.getdomain(points0),numpy.polynomial.polyutils.getdomain(numpy.array(points0).real)))#upcasts to complex
# except Exception as e:
    # print(e)
# d0=[-3.-3.j,4.+6.j]
# d1=[-3.+0.j,4.+0.j]
# print(numpy.polynomial.polyutils.mapdomain(x1,d0,d1))
# d0=[-3.-3.j,4.+6.j]
# d1=[-3.+-2.j,4.+2.j]
# print(numpy.polynomial.polyutils.mapdomain(x1,d0,d1))
# print(x1)
# d0=[-2,2]
# d1=[-3,12]
# print(numpy.polynomial.polyutils.mapdomain(x1,d0,d1))

# try:
    # print(numpy.polynomial.polyutils.mapparms(numpy.polynomial.polyutils.getdomain(points0),numpy.polynomial.polyutils.getdomain(numpy.array(points0).real)))#upcasts to complex
# except Exception as e:
    # print(e)
# d0=[-3.-3.j,4.+6.j]
# d1=[-3.+0.j,4.+0.j]
# print(numpy.polynomial.polyutils.mapparms(d0,d1))
# d0=[-3.-3.j,4.+6.j]
# d1=[-3.+-2.j,4.+2.j]
# print(numpy.polynomial.polyutils.mapparms(d0,d1))
# print(x1)
# d0=[-2,2]
# d1=[-3,12]
# print(numpy.polynomial.polyutils.mapparms(d0,d1))

# import numpy.lib.user_array
# print(numpy.lib.user_array.container)
# print(numpy.lib.user_array.container(data=[1,2,3],dtype=numpy.complex_,copy=False))
# container0=numpy.lib.user_array.container(data=[1,2,3],dtype=numpy.complex_,copy=False)
# for a0 in dir(container0):
    # print(a0,getattr(container0,a0),sep='     ',end='\n')#has less methods so better for less unintended inheritance

# print(numpy.broadcast([[2,3],[10,11]],[0,1]))
# b0=numpy.broadcast([[2,3],[10,11]],[0,1])
# for v0 in b0:
    # print(v0)
# b0=numpy.broadcast([[2,3],[10,11]],[0,20])
# for v0 in b0:
    # print(v0)
# b0=numpy.broadcast([[2,3,4],[10,11,12]],[0,20,40])
# for v0 in b0:
    # print(v0)
# for a0 in dir(b0):
    # print(a0,getattr(b0,a0),sep='     ',end='\n')
# print(numpy.add(numpy.array([[2,3,4],[10,11,12]]),numpy.array([0,20,40])))

# try:
    # print(numpy.polynomial.polynomial.polypow([1,2,3],[1,2,40],maxpower=None))
# except Exception as e:
    # print(e)

# import pandas
# print(numpy.array(['2023-01-06','2023=01-07']))
# print(numpy.array(['2023-01-06','2023=01-07']).dtype)
# numpy.array(['2007-07-13', '2006-01-13', '2010-08-13'], dtype='datetime64')
# print(numpy.array(['2023-01-06','2023-01-07'],dtype='datetime64').dtype)
# print(numpy.datetime64(52,'Y'))
# print(numpy.datetime64('2023-01-06'))
# print(numpy.datetime64('2023-01-06').dtype)
# print(numpy.datetime64('2023-01-06T00:00:00.000000'))
# print(numpy.datetime64('2023-01-06T00:00:00.000000').dtype)
# print(numpy.datetime64('2023-01-06T00:00:00.000000000'))
# print(numpy.datetime64('2023-01-06T00:00:00.000000000').dtype)
# print(numpy.datetime64('2023-01-06T00:00:00.000000000000000000'))
# print(numpy.datetime64('2023-01-06T00:00:00.000000000000000000').dtype)
# print(numpy.datetime64('2024-01-06T00:00:00.000000000000000000'))
# print(numpy.datetime64('2024-01-06T00:00:00.000000000000000000').dtype)
# print(numpy.datetime64('2024-01-06T00:00:00.000001000000000000'))
# print(numpy.datetime64('2024-01-06T00:00:00.000001000000000000').dtype)
# print(numpy.datetime64('2023-01-06')==numpy.datetime64('2023-01-06T00:00:00.000000'))
# print(numpy.datetime64('nAT'))
# print(numpy.datetime64('nAt').dtype)
# try:
    # print(numpy.array([1,50,100],dtype=numpy.datetime64))
# except Exception as e:
    # print(e)
# print(numpy.array([1,50,100],dtype='datetime64[Y]'))
# print(numpy.arange('2023-01-06','2023-02-28',2,dtype='datetime64[D]'))
# print(numpy.timedelta64(40,'D')+numpy.timedelta64(24,'h'))
# print((numpy.timedelta64(40,'D')+numpy.timedelta64(24,'h'))/numpy.timedelta64(1,'D'))
# print(numpy.timedelta64(40,'D')+numpy.timedelta64('naT'))
# try:
    # print(numpy.timedelta64(40,'D')+numpy.timedelta64(2,'M'))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.timedelta64(40,'D')+numpy.timedelta64(2,'Y'))
# except Exception as e:
    # print(e)
# print(numpy.timedelta64(31,'D')/numpy.timedelta64(1,'h'))
# d0=['Y','M','W','D']
# print(d0)
# for t0 in ['h','m','s','ms','us','ns','ps','fs','as']:
    # try:
        # print(t0,numpy.timedelta64(1,'D')/numpy.timedelta64(1,t0),sep='     ',end='\n')
    # except Exception as e:
        # try:
            # print(e,t0,numpy.timedelta64(1,'s')/numpy.timedelta64(1,t0),sep='     ',end='\n')
        # except Exception as e1:
            # print(e1,e,t0,numpy.timedelta64(1,'ns')/numpy.timedelta64(1,t0),sep='     ',end='\n')
# print(numpy.datetime64)
# print(numpy.timedelta64)
# for a0 in dir(numpy.datetime64):
    # print(a0,getattr(numpy.datetime64,a0),sep='     ',end='\n')
# for a0 in dir(numpy.timedelta64):
    # print(a0,getattr(numpy.timedelta64,a0),sep='     ',end='\n')
# ##below p at least on display
# print(pandas.to_datetime(numpy.datetime64('2023-01-06')))#s p
# print(pandas.Timestamp(numpy.datetime64('2023-01-06')))#s p
# print(numpy.datetime64(pandas.Timestamp(numpy.datetime64('2023-01-06'))))#ms p
# print(pandas.Timestamp(numpy.datetime64('2023-01-06')).to_datetime64())#ns p

# # # gdb ./prog0
# # # layout src
# # # br 22

# # # println!("Hi, name is {}",self.name0);

# # # CPI-U,CPI-W; used for pension

# # # tuning fork; 6/30;12/31

# print(pandas.to_datetime(numpy.datetime64('2023-01-06')))#s p
# print(pandas.Timestamp(numpy.datetime64('2023-01-06')).to_datetime64())#ns p

# d0=numpy.datetime64('2023-04-01')
# for roll0 in ['raise','forward','following','backward','preceding','modifiedfollowing','modifiedpreceding']:
    # try:
        # print(roll0,numpy.busday_offset(d0,0,roll=roll0,weekmask='1111100',holidays=[]),sep='     ',end='\n')
    # except Exception as e:
        # print(e)
# try:
    # print('raise',numpy.busday_offset(d0,0,roll='raise',weekmask='1111100',holidays=None,busdaycal=None,out=None),sep='     ',end='\n')
# except Exception as e:
    # print(e)
# try:
    # print('raise',numpy.busday_offset(d0,0,roll='raise',weekmask='1111100',holidays=[],busdaycal=None,out=None),sep='     ',end='\n')
# except Exception as e:
    # print(e)
# try:
    # print('raise',numpy.busday_offset(d0,0,roll='raise',weekmask='1111100',holidays=[],out=None),sep='     ',end='\n')
# except Exception as e:
    # print(e)
# print('forward',numpy.busday_offset(d0,0,roll='forward',weekmask='1111100',holidays=[]),sep='     ',end='\n')
# dB0=d0-numpy.timedelta64(1,'D')
# dA0=d0+numpy.timedelta64(2,'D')
# a0=numpy.array([dB0,dA0],dtype='datetime64[D]')
# print(a0)
# print(a0.dtype)
# print(dB0,dA0)
# bdc0=numpy.busdaycalendar(weekmask='Sun',holidays=[dB0,dA0])
# print(bdc0.weekmask)
# print(bdc0.holidays)
# bdc0=numpy.busdaycalendar(weekmask='Sun',holidays=a0)
# print(bdc0.weekmask)
# print(bdc0.holidays)
# bdc0=numpy.busdaycalendar(weekmask='1111100',holidays=a0)
# print(bdc0.weekmask)
# print(bdc0.holidays)
# try:
    # print('raise',numpy.busday_offset(d0,0,roll='raise',weekmask='1111100',holidays=[],busdaycal=bdc0,out=None),sep='     ',end='\n')
# except Exception as e:
    # print(e)
# for a0 in dir(bdc0):
    # print(a0,getattr(bdc0,a0),sep='     ',end='\n')
# for roll0 in ['raise','forward','following','backward','preceding','modifiedfollowing','modifiedpreceding']:
    # try:
        # print(roll0,numpy.busday_offset(d0,0,roll=roll0,busdaycal=bdc0),sep='     ',end='\n')
    # except Exception as e:
        # print(e)
# try:
    # print(roll0,numpy.busday_offset(d0,0,roll=roll0,weekmask=None,holidays=None,busdaycal=bdc0,out=None),sep='     ',end='\n')
# except Exception as e:
    # print(e)
# ad0=numpy.arange('2023-01-06','2023-02-28',2,dtype='datetime64[D]')
# try:
    # print(numpy.is_busday(ad0,weekmask=[1,1,1,1,1,0,0],holidays=[numpy.datetime64('2023-01-06')],busdaycal=None,out=None))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.is_busday(ad0,weekmask=[1,1,1,1,1,0,0],holidays=[numpy.datetime64('2023-01-06')],out=None))
# except Exception as e:
    # print(e)
# print(numpy.is_busday(ad0,weekmask=[1,1,1,1,1,0,0],holidays=[numpy.datetime64('2023-01-06')]))
# try:
    # print(numpy.busday_count('2023-01-06','2023-02-28',weekmask=[1,1,1,1,1,0,0],holidays=[numpy.datetime64('2023-01-06')],busdaycal=None,out=None))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.busday_count('2023-01-06','2023-02-28',weekmask=[1,1,1,1,1,0,0],holidays=[numpy.datetime64('2023-01-06')],out=None))
# except Exception as e:
    # print(e)
# print(numpy.busday_count('2023-01-06','2023-02-28',weekmask=[1,1,1,1,1,0,0],holidays=[numpy.datetime64('2023-01-06')]))#double because arange is 2
# print(numpy.is_busday(ad0,weekmask=[1,1,1,1,1,0,0],holidays=[numpy.datetime64('2023-01-06')]).nonzero())
# print(numpy.is_busday(ad0,weekmask=[1,1,1,1,1,0,0],holidays=[numpy.datetime64('2023-01-06')]).nonzero()[0].size)

# d0=numpy.dtype('datetime64[2D]')
# print(d0)
# ad0=numpy.arange('2023-01-06','2023-02-28',2,dtype='datetime64[D]')
# print(ad0)
# ad1=numpy.arange('2023-01-06','2023-02-28',dtype=d0)
# print(ad1)
# print(ad0==ad1)
# ad2=numpy.arange('2023-01-07','2023-03-01',dtype=d0)
# print(ad2)
# print(ad0==ad2)
# ad3=numpy.arange('2023-01-06','2023-03-01',dtype=d0)
# print(ad3)
# print(ad0==ad3)
# ad4=numpy.datetime64('2023-01-06',numpy.datetime_data(d0))
# print(ad4)
# print(ad4.dtype)

# ad0=numpy.arange('2023-01-06','2023-01-07',2,dtype='datetime64[s]')
# for unit0 in [None,'auto','ms']:
    # for casting0 in ['unsafe','no']:
        # try:
            # print(unit0,casting0,numpy.datetime_as_string(ad0,unit=unit0,casting=casting0),sep='     ',end='\n')
        # except Exception as e:
            # print(e)
# import pytz
# timezone1=pytz.timezone('US/Central')
# for timezone0 in ['naive','UTC','local',timezone1]:
    # try:
        # print(timezone0,numpy.datetime_as_string(ad0,timezone=timezone0),sep='     ',end='\n')
    # except Exception as e:
        # print(e)
        # print(timezone0,numpy.datetime_as_string(ad0,timezone=timezone0,casting='unsafe'),sep='     ',end='\n')

# print(numpy.datetime64('2016-12-31 23:59:59.450'))
# try:
    # print(numpy.datetime64('2016-12-31 23:59:60.450'))
# except Exception as e:
    # print(e)

# print(numpy.Inf is numpy.inf)
# print(numpy.infty is numpy.inf)
# print(numpy.Infinity is numpy.inf)
# print(numpy.PINF is numpy.inf)
# print(numpy.NINF is numpy.inf)
# print(numpy.NAN is numpy.nan)
# print(numpy.NaN is numpy.nan)
# print(numpy.NaN is numpy.nan)
# print(numpy.pi)
# print(numpy.e)
# print(numpy.euler_gamma)
# print(numpy.PZERO is 0)
# print(numpy.PZERO is numpy.array([0],dtype=numpy.float_)[0])
# print(numpy.NZERO is numpy.PZERO)
# print(numpy.isfinite(numpy.NZERO))
# print(numpy.Inf,numpy.infty,numpy.Infinity,numpy.PINF,numpy.NINF,numpy.NAN,numpy.NaN,numpy.NaN,numpy.pi,numpy.e,numpy.euler_gamma,numpy.PZERO,numpy.NZERO)

# import filecmp
# f0=r'C:\Users\pdumas\Documents\Code\compTest0.txt'
# f1=r'C:\Users\pdumas\Documents\Code\compTest1.txt'
# f2=r'C:\Users\pdumas\Documents\Code\compTest2.txt'
# d0=r'C:\Users\pdumas\Documents\Code\filecmpTestDir0'
# d1=r'C:\Users\pdumas\Documents\Code\filecmpTestDir1'
# d2=r'C:\Users\pdumas\Documents\Code\filecmpTestDir0\filecmpTestDir0'
# d3=r'C:\Users\pdumas\Documents\Code\filecmpTestDir1\filecmpTestDir0'
# print(filecmp.cmp(f0,f1,shallow=True))
# print(filecmp.cmp(f0,f2,shallow=True))#should return False
# print(filecmp.cmp(f0,f2,shallow=False))#can't imagine when this would ever be used realistically..
# try:
    # # eval('''print(filecmp.cmpfiles(d0,d1,['compTest*.txt'],shallow=True))''')
    # print(filecmp.cmpfiles(d0,d1,['compTest*.txt'],shallow=True))
# except Exception as e:
    # print(e)
# print(filecmp.cmpfiles(d0,d1,['compTest0.txt','compTest1.txt','compTest3.txt'],shallow=True))
# print(filecmp.clear_cache())#can't imagine when this would ever be used realistically..
# dircmp0=filecmp.dircmp(d0,d1,ignore=filecmp.DEFAULT_IGNORES,hide=None)
# print(dircmp0)
# print(dircmp0)
# print(dircmp0)
# print(dircmp0)
# class dircmp1Class0(filecmp.dircmp):
    # pass
# dircmp1=dircmp1Class0(d2,d3)
# print(dircmp1)
# for a0 in dir(dircmp0):
    # print(a0,getattr(dircmp0,a0),sep='     ',end='\n')
# for function0 in [dircmp0.report,dircmp0.report_partial_closure,dircmp0.report_full_closure]:
    # print(function0,function0())#'function0()' seems to print to sys.stdout before 'print(...' statement actually does
# print(dircmp0.phase1())


# import difflib
# l0=['ab','c d',' ef','a ef','# ef']
# l1=['ab','c de','ef','b ee','z ef']
# differ0=difflib.ndiff(l0,l1,linejunk=None,charjunk=None)
# differ1=difflib.ndiff(l0,l1,linejunk=None,charjunk=difflib.IS_CHARACTER_JUNK)
# differ2=difflib.ndiff(l0,l1,linejunk=difflib.IS_LINE_JUNK,charjunk=difflib.IS_CHARACTER_JUNK)
# for differ00 in [differ0,differ1,differ2]:
    # for i,d in enumerate(differ00):
        # print(differ00,i,d,sep='      ')
    # print('')
# def linejunk0(string0):
    # if string0.startswith('a'):
        # return True
    # return False
# def charjunk0(string0):
    # if string0.startswith('f'):
        # return True
    # return False
# differ3=difflib.ndiff(l0,l1,linejunk=linejunk0,charjunk=charjunk0)
# for differ00 in [differ3]:
    # for i,d in enumerate(differ00):
        # print(differ00,i,d,sep='      ')
    # print('')

# l0=['ab\n','c d\n',' ef\n','a ef\n','# ef\n']
# l1=['ab\n','c de\n','ef\n','b ee\n','z ef\n']
# differ0=difflib.ndiff(l0,l1,linejunk=None,charjunk=None)
# differ1=difflib.ndiff(l0,l1,linejunk=None,charjunk=difflib.IS_CHARACTER_JUNK)
# differ2=difflib.ndiff(l0,l1,linejunk=difflib.IS_LINE_JUNK,charjunk=difflib.IS_CHARACTER_JUNK)
# for differ00 in [differ0,differ1,differ2]:
    # for i,d in enumerate(differ00):
        # print(differ00,i,d,sep='      ')
    # print('')
# def linejunk0(string0):
    # if string0.startswith('a'):
        # return True
    # return False
# def charjunk0(string0):
    # if string0.startswith('f'):
        # return True
    # return False
# differ3=difflib.ndiff(l0,l1,linejunk=linejunk0,charjunk=charjunk0)
# for differ00 in [differ3]:
    # for i,d in enumerate(differ00):
        # print(differ00,i,d,sep='      ')
    # print('')

# import time,webbrowser,os,os.path
# chromeExecutablePath0 = r'C:\Users\pdumas\AppData\Local\Google\Chrome\Application\chrome.exe'

# webbrowser.register('chrome',None,webbrowser.BackgroundBrowser(chromeExecutablePath0))
# wb0=webbrowser.get('chrome')
# l0=['ab\n','c d\n',' ef\n','a ef\n','# ef\n']
# l1=['ab\n','c de\n','ef\n','b ee\n','z ef\n']
# g0=difflib.context_diff(l0,l1,fromfile='fromfile0.txt',tofile='tofile0.txt',fromfiledate='2023-01-06',tofiledate='2023-01-07',n=3,lineterm='\n')
# print(g0)
# sys.stdout.writelines(g0)
# htmlDiff0=difflib.HtmlDiff(tabsize=8,wrapcolumn=3,linejunk=None,charjunk=None)
# htmlDiff0make_file0=htmlDiff0.make_file(l0,l1,fromdesc='fromdesc0',todesc='todesc0',context=False,numlines=5,charset='utf-8')
# htmlDiff0make_file1=htmlDiff0.make_file(l0,l1,fromdesc='fromdesc0',todesc='todesc0',context=False,numlines=1,charset='utf-8')
# htmlDiff0make_file2=htmlDiff0.make_file(l0,l1,fromdesc='fromdesc0',todesc='todesc0',context=True,numlines=5,charset='utf-8')
# for f0 in [htmlDiff0make_file0,htmlDiff0make_file1,htmlDiff0make_file2]:
    # print(f0)
    # sys.stdout.writelines(f0)
    # with open(str(time.perf_counter())+'hExample0.html','w+') as f00:
        # f00.write(f0)
        # print(os.curdir)
        # print(os.getcwd())
        # print(f00.name)
        # print(os.path.join(os.getcwd(),f00.name))
        # filePath0=os.path.join(os.getcwd(),f00.name)
        # wb0.open(filePath0,new=2,autoraise=True)
# htmlDiff0make_file0
# for a0 in dir(htmlDiff0make_file0):
    # print(a0,getattr(htmlDiff0make_file0,a0))
# htmlDiff0make_table0=htmlDiff0.make_table(l0,l1,fromdesc='fromdesc0',todesc='todesc0',context=False,numlines=5)
# htmlDiff0make_table1=htmlDiff0.make_table(l0,l1,fromdesc='fromdesc0',todesc='todesc0',context=False,numlines=1)
# htmlDiff0make_table2=htmlDiff0.make_table(l0,l1,fromdesc='fromdesc0',todesc='todesc0',context=True,numlines=5)
# for f0 in [htmlDiff0make_table0,htmlDiff0make_table1,htmlDiff0make_table2]:
    # print(f0)
    # sys.stdout.writelines(f0)
    # with open(str(time.perf_counter())+'hExample0.html','w+') as f00:
        # f00.write(f0)
        # print(os.curdir)
        # print(os.getcwd())
        # print(f00.name)
        # print(os.path.join(os.getcwd(),f00.name))
        # filePath0=os.path.join(os.getcwd(),f00.name)
        # wb0.open(filePath0,new=2,autoraise=True)

# word0='daemon'
# possibilities0=['demon','damian','diamond','dime','dog','door','koala','bird']
# for n0 in [3,20]:
    # for cutoff0 in [.6,.0001,.9999]:
        # print(n0,cutoff0,difflib.get_close_matches(word0,possibilities0,n=n0,cutoff=cutoff0),sep='     ',end='\n')

# import copy,itertools
# l0=['ab\n','c d\n',' ef\n','a ef\n','# ef\n']
# l1=['ab\n','c de\n','ef\n','b ee\n','z ef\n']
# differ0=difflib.ndiff(l0,l1,linejunk=None,charjunk=None)
# print(differ0)#once you go through an iterator object, it's gone
# differ1=list(differ0)
# differ2,differ3=itertools.tee(difflib.ndiff(l0,l1,linejunk=None,charjunk=None),2)
# try:
    # differ1=copy.deepcopy(differ0)#generator not able to be pickled
# except Exception as e:
    # print(e)
# try:
    # differ1=copy.copy(differ0)#generator not able to be pickled
# except Exception as e:
    # print(e)
# sys.stdout.writelines(differ1)
# print('\n\n')
# for differ00,which0 in zip([differ2,differ3],[1,2]):
    # restore0=difflib.restore(list(differ00),which0)
    # print(which0,restore0,list(restore0))

# l0=['ab\n','c d\n',' ef\n','a ef\n','# ef\n']
# l1=['ab\n','c de\n','ef\n','b ee\n','z ef\n']
# g0=difflib.context_diff(l0,l1,fromfile='fromfile0.txt',tofile='tofile0.txt',fromfiledate='2023-01-06',tofiledate='2023-01-07',n=3,lineterm='\n')
# print(g0)
# sys.stdout.writelines(g0)

# l0=['ab\n','c d\n',' ef\n','a ef\n','# ef\n']
# l1=['ab\n','c de\n','ef\n','b ee\n','z ef\n']
# g0=difflib.unified_diff(l0,l1,fromfile='fromfile0.txt',tofile='tofile0.txt',fromfiledate='2023-01-06',tofiledate='2023-01-07',n=3,lineterm='\n')
# print(g0)
# sys.stdout.writelines(g0)

# l0=['ab\n','c d\n',' ef\n','a ef\n','# ef\n']
# l1=['ab\n','c de\n','ef\n','b ee\n','z ef\n']
# g0=difflib.unified_diff(l0,l1,fromfile='fromfile0.txt',tofile='tofile0.txt',fromfiledate='2023-01-06',tofiledate='2023-01-07',n=1,lineterm='')
# print(g0)
# sys.stdout.writelines(g0)

# l0b0=[s0.encode() for s0 in l0]
# l1b0=[s0.encode() for s0 in l1]
# d0b0='2023-01-06'.encode()
# d1b0='2023-01-07'.encode()
# for function0 in [difflib.context_diff,difflib.unified_diff]:
    # print(difflib.diff_bytes(function0,fromfile=l0b0,tofile=l1b0,fromfiledate=d0b0,tofiledate=d1b0,n=3,lineterm=b'\n'))

# l0=['ab\n','c d\n',' ef\n','a ef\n','# ef\n']
# l1=['ab\n','c de\n','ef\n','b ee\n','z ef\n']
# l2=['zz\n','c zzzz\n','z\n','b z\n','z zzy\n']
# def linejunk0(string0):
    # if string0.startswith('a'):
        # return True
    # return False
# sequenceMatcher0=difflib.SequenceMatcher(isjunk=None,a='',b='',autojunk=True)
# print(sequenceMatcher0)
# try:
    # sys.stdout.writelines(sequenceMatcher0)
# except Exception as e:
    # print(e)
# print(sequenceMatcher0.bjunk,sequenceMatcher0.bpopular,sequenceMatcher0.b2j)
# sequenceMatcher1=difflib.SequenceMatcher(isjunk=linejunk0,a=l0,b=l1,autojunk=False)
# print(sequenceMatcher1)
# for a0 in dir(sequenceMatcher1):
    # print(a0,getattr(sequenceMatcher1,a0))
# sequenceMatcher0.set_seqs(l0,l1)
# for a0 in dir(sequenceMatcher0):
    # print(a0,getattr(sequenceMatcher0,a0))
# sequenceMatcher0=difflib.SequenceMatcher(isjunk=None,a='',b='',autojunk=True)
# print(sequenceMatcher0.set_seq1(l0))
# print(sequenceMatcher0.__dict__)
# print(sequenceMatcher0.set_seq2(l1))
# print(sequenceMatcher0.__dict__)
# print(sequenceMatcher0.find_longest_match(0,2,0,2))
# print(sequenceMatcher0.find_longest_match(0,4,0,2))
# print(sequenceMatcher0.find_longest_match(0,5,0,5))
# print(sequenceMatcher0.set_seq1(l2))
# print(sequenceMatcher0.__dict__)
# print(sequenceMatcher0.find_longest_match(0,2,0,2))
# print(sequenceMatcher0.find_longest_match(0,4,0,2))
# print(sequenceMatcher0.find_longest_match(0,5,0,5))
# l1=['ab\n','c de\n','ef\n','b ee\n',' z zzy\n']
# l2=['zz\n','c zzzz\n','z\n','b z\n',' z zzy\n']
# print(sequenceMatcher0.set_seqs(l1,l2))
# print(sequenceMatcher0.__dict__)
# print(sequenceMatcher0.find_longest_match(0,2,0,2))
# print(sequenceMatcher0.find_longest_match(0,4,0,2))
# print(sequenceMatcher0.find_longest_match(0,5,0,5))
# l1=['ab\n','c de\n','ef\n','z z\n',' z zzy\n']
# l2=['zz\n','c zzzz\n','z\n','z z\n',' z zzy\n']
# print(sequenceMatcher0.set_seqs(l1,l2))
# print(sequenceMatcher0.__dict__)
# print(sequenceMatcher0.find_longest_match(0,2,0,2))
# print(sequenceMatcher0.find_longest_match(0,4,0,2))
# print(sequenceMatcher0.find_longest_match(0,5,0,5))
# print(sequenceMatcher0.get_matching_blocks())
# l1=['zz\n','c de\n','ef\n','z z\n',' z zzy\n']
# l2=['zz\n','c zzzz\n','z\n','z z\n',' z zzy\n']
# print(sequenceMatcher0.set_seqs(l1,l2))
# print(sequenceMatcher0.__dict__)
# print(sequenceMatcher0.get_matching_blocks())
# print(sequenceMatcher0.get_opcodes())
# get_grouped_opcodes0=sequenceMatcher0.get_grouped_opcodes()
# print(get_grouped_opcodes0)
# try:
    # sys.stdout.writelines(get_grouped_opcodes0)
# except Exception as e:
    # print(e)
# print([e0 for e0 in get_grouped_opcodes0])
# l1='bctfg'
# l2='fghhbc'
# print(sequenceMatcher0.set_seqs(l1,l2))
# print(sequenceMatcher0.__dict__)
# print(sequenceMatcher0.get_matching_blocks())
# print(sequenceMatcher0.get_opcodes())
# get_grouped_opcodes0=sequenceMatcher0.get_grouped_opcodes(n=3)
# print(get_grouped_opcodes0)
# print([e0 for e0 in get_grouped_opcodes0])

# get_grouped_opcodes0=sequenceMatcher0.get_grouped_opcodes(n=2)
# print(get_grouped_opcodes0)
# print([e0 for e0 in get_grouped_opcodes0])
# get_grouped_opcodes0=sequenceMatcher0.get_grouped_opcodes(n=1)
# print(get_grouped_opcodes0)
# print([e0 for e0 in get_grouped_opcodes0])
# get_grouped_opcodes0=sequenceMatcher0.get_grouped_opcodes(n=7)
# print(get_grouped_opcodes0)
# print([e0 for e0 in get_grouped_opcodes0])
# for a0 in dir(get_grouped_opcodes0):
    # print(a0,getattr(get_grouped_opcodes0,a0))
# l1='bctfg'
# l2='fghhbc'
# print(sequenceMatcher0.set_seqs(l1,l2))
# print(sequenceMatcher0.__dict__)
# for function0 in [sequenceMatcher0.ratio,sequenceMatcher0.quick_ratio,sequenceMatcher0.real_quick_ratio]:
    # print(function0,function0(),sep='     ',end='\n')
# l1='bctfg'
# l2='fghhbccccccccccccccccc'
# print(sequenceMatcher0.set_seqs(l1,l2))
# print(sequenceMatcher0.__dict__)
# for function0 in [sequenceMatcher0.ratio,sequenceMatcher0.quick_ratio,sequenceMatcher0.real_quick_ratio]:
    # print(function0,function0(),sep='     ',end='\n')

# l1=['ab\n','c de\n','ef\n','z z\n',' z zzy\n']
# l2=['zz\n','c zzzz\n','z\n','z z\n',' z zzy\n']
# differ0=difflib.Differ(linejunk=None,charjunk=None)
# print(differ0)
# differ0compare0=differ0.compare(l1,l2)
# print(differ0compare0)
# print([e0 for e0 in differ0compare0])#like ndiff

# import pprint
# prettyPrinter0=pprint.PrettyPrinter(indent=1,width=80,depth=None,stream=None,compact=False,sort_dicts=True,underscore_numbers=False)
# print(prettyPrinter0)
# for a0 in dir(prettyPrinter0):
    # print(a0,getattr(prettyPrinter0,a0))
# rl0=[1,2,[3,4,[5,6,[7,8,[9,10,[11,12,[13,14]]]]]]]
# rl1=[1+20000,2+20,[3+20,4+20,[5+20,6+20,[7+20,8+20,[9+20,10+20,[11+20,12+20,[13+20,14]]]]]]]
# d0={10:1,9:2,6:5,7:4}
# rl2=[rl0,rl1,d0]
# rl3=[rl0,rl1,d0]
# rl3.insert(0,rl3)
# with open(r'C:\Users\pdumas\Documents\Code\pprint20230111\pprint20230111.txt','w+') as f0:
    # print(pprint.pformat(rl2,indent=10,width=40,compact=True,depth=4,sort_dicts=False,underscore_numbers=True))
    # pprint.pprint(rl2,indent=10,width=40,stream=f0,compact=True,depth=4,sort_dicts=False,underscore_numbers=True)
# print(pprint.pformat(rl2,indent=1,width=80,depth=None,compact=False,sort_dicts=True,underscore_numbers=False))
# print(pprint.pp(rl2,sort_dicts=False))
# os.system(r'start "" "C:\Users\pdumas\Documents\Code\pprint20230111\pprint20230111.txt"')
# print(pprint.isreadable(rl0))
# print(pprint.isreadable(rl2))
# print(pprint.isreadable(d0))
# print(pprint.isreadable(rl3))
# print(pprint.pprint(rl3))
# print(pprint.isrecursive(rl2))
# print(pprint.isrecursive(d0))
# print(pprint.isrecursive(rl3))
# print(pprint.saferepr(rl2))
# print(pprint.saferepr(d0))
# print(pprint.saferepr(rl3))
# print(prettyPrinter0.pformat(rl2))
# prettyPrinter0.pprint(rl2)
# print(prettyPrinter0.isreadable(rl2))
# print(prettyPrinter0.isreadable(rl3))
# prettyPrinter1=pprint.PrettyPrinter(indent=1,width=80,depth=12,stream=None,compact=False,sort_dicts=True,underscore_numbers=False)
# print(prettyPrinter1.isreadable(rl2))
# prettyPrinter2=pprint.PrettyPrinter(indent=1,width=80,depth=4,stream=None,compact=False,sort_dicts=True,underscore_numbers=False)
# print(prettyPrinter2.isreadable(rl2))
# print(prettyPrinter0.isrecursive(rl2))
# print(prettyPrinter0.isrecursive(rl3))
# print(prettyPrinter0.format(rl0,{id(rl2):rl0},8,1))
# print(prettyPrinter0.format(rl0,{id(rl2):rl0},8,2))
# print(prettyPrinter0.format(rl3,{id(rl3):rl3},8,1))#recursion is NOT the same as nested; nested is a container within another container and can but doesn't necessarily mean recursion; recursion is own id (unique identifier in memory) is nested in itself and ALWAYS imples it's nested
# for f0 in [numpy.bartlett,numpy.hanning,numpy.hamming,numpy.blackman]:
    # for m0 in [0,1,5,25,150]:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',f0(m0))
# for m0 in [0,1,5,25,150]:
    # for b0 in [0,5,6,8.6,14,50]:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.kaiser(m0,b0))
# for b0 in [0,5,6,8.6,14,50]:
    # # matplotlib.pyplot.plot(numpy.linspace(-.5,.5,len(numpy.fft.fft(numpy.kaiser(51,b0),2048)/25.5)),numpy.clip(20*numpy.log10(numpy.abs(numpy.fft.fftshift(numpy.fft.fft(numpy.kaiser(51,b0),2048)/25.5))),-200,10),label=f'{b0}')
    # matplotlib.pyplot.plot(numpy.linspace(-.5,.5,len(numpy.fft.fft(numpy.kaiser(51,b0),2048)/25.5)),numpy.clip(20*numpy.log10(numpy.abs(numpy.fft.fftshift(numpy.fft.fft(numpy.kaiser(51,b0),2048)/25.5))),-500,10),label=f'{b0}')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.abs(2.3+2.7j))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.angle(2.3+2.7j))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.abs(2.3+2.7j)**2)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.abs(.2+5.2j))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.angle(.2+5.2j))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.abs(.2+5.2j)**2)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.arange(-10,11,1),'\n',len(numpy.arange(-10,11,1)),'\n',numpy.fft.fft(numpy.arange(-10,11,1)),'\n',len(numpy.fft.fft(numpy.arange(-10,11,1))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.arange(-10j,11j,1j,dtype=numpy.complex_))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.arange(0-10j,0+11j,0+1j,dtype=numpy.complex_))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.linspace(0-10j,0+10j,21,dtype=numpy.complex_))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.linspace(0-10j,0+10j,21,dtype=numpy.complex_),'\n',len(numpy.linspace(0-10j,0+10j,21,dtype=numpy.complex_)),'\n',numpy.fft.fft(numpy.linspace(0-10j,0+10j,21,dtype=numpy.complex_)),'\n',len(numpy.fft.fft(numpy.linspace(0-10j,0+10j,21,dtype=numpy.complex_))))
# for n0 in [3,21,50]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.linspace(0-10j,0+10j,21,dtype=numpy.complex_),n=n0),'\n')
# for axis0 in [0,1,None]:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.linspace(0-10j,0+10j,20,dtype=numpy.complex_).reshape((2,10)).copy('C'),'\n',numpy.fft.fft(numpy.linspace(0-10j,0+10j,20,dtype=numpy.complex_).reshape((2,10)).copy('C'),axis=axis0),'\n')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for norm0 in ['ortho','forward','backward',None]:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.linspace(0-10j,0+10j,20,dtype=numpy.complex_),'\n',numpy.fft.fft(numpy.linspace(0-10j,0+10j,20,dtype=numpy.complex_),norm=norm0),'\n')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for norm0 in ['ortho','forward','backward',None]:
    # for norm1 in ['ortho','forward','backward',None]:
        # try:
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.linspace(0-10j,0+10j,20,dtype=numpy.complex_),'\n',numpy.fft.ifft(numpy.fft.fft(numpy.linspace(0-10j,0+10j,20,dtype=numpy.complex_),norm=norm0),norm=norm1),'\n')
        # except Exception as e:
            # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.exp((numpy.pi*2j*numpy.arange(-10,11,1))/numpy.arange(-10,11,1)),'\n',numpy.fft.fft(numpy.exp((numpy.pi*2j*numpy.arange(-10,11,1))/numpy.arange(-10,11,1))),'\n')
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.exp(numpy.pi*2j*numpy.arange(8)/numpy.arange(8))),'\n')
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.exp(2j*numpy.pi*numpy.arange(8)/8)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.exp((numpy.pi*2j*numpy.arange(-10,11,1))/21),'\n',numpy.fft.fft(numpy.exp((numpy.pi*2j*numpy.arange(-10,11,1))/21)),'\n')
# matplotlib.pyplot.plot(numpy.fft.fftfreq(numpy.arange(512).shape[0]),numpy.fft.fft(numpy.sin(numpy.arange(512))).real,label='real')
# matplotlib.pyplot.plot(numpy.fft.fftfreq(numpy.arange(512).shape[0]),numpy.fft.fft(numpy.sin(numpy.arange(512))).imag,label='imag')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# print((numpy.pi*2)*1j)
# print(numpy.exp((numpy.pi*2)*1j))
# print(numpy.exp(numpy.random.default_rng(8).uniform(0,(numpy.pi*2),20)*1j))
# print((numpy.pi*1.99)*1j)
# print(numpy.exp((numpy.pi*1.99)*1j))
# print(numpy.sort(numpy.random.default_rng(8).uniform(0,(numpy.pi*2),20)*1j))
# print(numpy.exp(numpy.sort(numpy.random.default_rng(8).uniform(0,(numpy.pi*2),20)*1j)))
# d0=numpy.arange(200)
# v0=numpy.zeros(200)
# v0[90:110]=numpy.exp(numpy.sort(numpy.random.default_rng(8).uniform(0,(numpy.pi*2),20)*1j))
# matplotlib.pyplot.plot(d0,numpy.fft.ifft(v0).real,label='real')
# matplotlib.pyplot.plot(d0,numpy.fft.ifft(v0).imag,label='imag')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# d0=numpy.arange(200)
# v0=numpy.zeros(200)
# v0[20:40]=numpy.exp(numpy.sort(numpy.random.default_rng(8).uniform(0,(numpy.pi*2),20)*1j))
# matplotlib.pyplot.plot(d0,numpy.fft.ifft(v0).real,label='real')
# matplotlib.pyplot.plot(d0,numpy.fft.ifft(v0).imag,label='imag')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# d0=numpy.arange(200)
# v0=numpy.zeros(200)
# v0[20:40]=numpy.exp(numpy.random.default_rng(8).uniform(0,(numpy.pi*2),20)*1j)
# matplotlib.pyplot.plot(d0,numpy.fft.ifft(v0).real,label='real')
# matplotlib.pyplot.plot(d0,numpy.fft.ifft(v0).imag,label='imag')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# d0=numpy.arange(200)
# v0=numpy.zeros(200)
# v0[90:110]=numpy.exp(numpy.sort(numpy.random.default_rng(8).uniform(0,(numpy.pi*2),20)*2j))
# matplotlib.pyplot.plot(d0,numpy.fft.ifft(v0).real,label='real')
# matplotlib.pyplot.plot(d0,numpy.fft.ifft(v0).imag,label='imag')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# d0=numpy.arange(200)
# v0=numpy.zeros(200)
# v0[90:110]=numpy.exp(numpy.sort(numpy.random.default_rng(8).uniform(0,(numpy.pi*2),20)*3j))
# matplotlib.pyplot.plot(d0,numpy.fft.ifft(v0).real,label='real')
# matplotlib.pyplot.plot(d0,numpy.fft.ifft(v0).imag,label='imag')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# print(numpy.mgrid[:5,:5][0])
# print(numpy.mgrid[0:5,0:5][0])
# print(numpy.mgrid[0:4:1j,0:4:1j][0])
# print(numpy.mgrid[0:4:5j,0:4:5j][0])
# print(numpy.ogrid[:5,:5][0])
# print(numpy.ogrid[0:5,0:5][0])
# print(numpy.ogrid[0:4:1j,0:4:1j][0])
# print(numpy.ogrid[0:4:5j,0:4:5j][0])
# print(numpy.ogrid[:5,:5])
# print(numpy.ogrid[0:5,0:5])
# print(numpy.ogrid[0:4:1j,0:4:1j])
# print(numpy.ogrid[0:4:5j,0:4:5j])
# print(numpy.mgrid[:3,:3,:3][0])
# print(numpy.meshgrid(numpy.arange(3),numpy.arange(3),numpy.arange(3)))
# print(numpy.meshgrid(numpy.arange(3),numpy.arange(3)))
# [x,y,z]=numpy.meshgrid(numpy.arange(3),numpy.arange(3),numpy.arange(3))
# print([x,y,z])
# for n0 in [1,3,10]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft2(numpy.mgrid[:n0,:n0][0]))
# for n0 in [1,3,10]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fftn(numpy.mgrid[:n0,:n0,:n0][0]))
# for n0 in [1,3,10]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fftn(numpy.meshgrid(numpy.arange(n0),numpy.arange(n0),numpy.arange(n0))))
# for n0 in [1,3,10]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.mgrid[:n0,:n0,:n0])
# for n0 in [1,3,10]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.meshgrid(numpy.arange(n0),numpy.arange(n0),numpy.arange(n0)))
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.meshgrid((n0),(n0),(n0)))
# for n0 in [1,3,10]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.meshgrid(numpy.arange(n0),numpy.arange(n0),numpy.arange(n0),indexing='ij'))
# for m0 in [1,3,5,7]:
    # i0=m0*numpy.eye(5)
    # print(numpy.fft.ifft2(i0))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft([0,1,0,0]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfft([0,1,0,0]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.exp(2j*numpy.pi*numpy.arange(8)/8)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfft(numpy.exp(2j*numpy.pi*numpy.arange(8)/8)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.exp(2*numpy.pi*numpy.arange(8)/8)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfft(numpy.exp(2*numpy.pi*numpy.arange(8)/8)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfft2(numpy.ones((3,3))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((3,3))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((3,3,3,3))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((3,3,3)),axes=(0,1,2)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((3,3,3)),axes=(2,0)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((3,3,3)),axes=(0,2)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((3,3,3)),s=[1,1],axes=(0,2)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((3,3,3)),s=[1,1],axes=(0,2),norm='ortho'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((3,3,3)),s=[1,1],axes=(0,1),norm='ortho'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((3,3,3))*3,s=[1,1],axes=(0,1),norm='ortho'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfft2(numpy.ones((2,2))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((2,2))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((2,2,2,2))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((2,2,2)),axes=(0,1,2)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((2,2,2)),axes=(2,0)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((2,2,2)),axes=(0,2)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((2,2,2)),s=[1,1],axes=(0,2)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((2,2,2)),s=[1,1],axes=(0,2),norm='ortho'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((2,2,2)),s=[1,1],axes=(0,1),norm='ortho'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftn(numpy.ones((2,2,2))*2,s=[1,1],axes=(0,1),norm='ortho'))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ifft([0,1,0,0]))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft([0,1,0,0]))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ifft(numpy.exp(2j*numpy.pi*numpy.arange(8)/8)))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft(numpy.exp(2j*numpy.pi*numpy.arange(8)/8)))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ifft(numpy.exp(2*numpy.pi*numpy.arange(8)/8)))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft(numpy.exp(2*numpy.pi*numpy.arange(8)/8)))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft2(numpy.ones((3,3))))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.ones((3,3))))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.ones((3,3,3,3))))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.ones((3,3,3)),axes=(0,1,2)))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.ones((3,3,3)),axes=(2,0)))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.ones((3,3,3)),axes=(0,2)))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.ones((3,3,3)),s=[1,1],axes=(0,2)))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.ones((3,3,3)),s=[1,1],axes=(0,2),norm='ortho'))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.ones((3,3,3)),s=[1,1],axes=(0,1),norm='ortho'))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.ones((3,3,3))*3,s=[1,1],axes=(0,1),norm='ortho'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ifft(numpy.fft.fft([0,1,0,0])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft(numpy.fft.rfft([0,1,0,0])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ifft(numpy.fft.fft(numpy.exp(2j*numpy.pi*numpy.arange(8)/8))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft(numpy.fft.rfft(numpy.exp(2j*numpy.pi*numpy.arange(8)/8))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ifft(numpy.fft.fft(numpy.exp(2*numpy.pi*numpy.arange(8)/8))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft(numpy.fft.rfft(numpy.exp(2*numpy.pi*numpy.arange(8)/8))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft2(numpy.fft.rfft2(numpy.ones((3,3)))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.fft.rfftn(numpy.ones((3,3)))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.fft.rfftn(numpy.ones((3,3,3,3)))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.fft.rfftn(numpy.ones((2,2,2,2)))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.fft.rfftn(numpy.ones((3,3,3,3))*4)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.fft.rfftn(numpy.ones((3,3,3)),axes=(0,1,2))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.fft.rfftn(numpy.ones((3,3,3)),axes=(2,0))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.fft.rfftn(numpy.ones((3,3,3)),axes=(0,2))))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.fft.rfftn(numpy.ones((3,3,3)),s=[1,1],axes=(0,2))))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.fft.rfftn(numpy.ones((3,3,3)),s=[1,1],axes=(0,2),norm='ortho')))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.fft.rfftn(numpy.ones((3,3,3)),s=[1,1],axes=(0,1),norm='ortho')))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.fft.rfftn(numpy.ones((3,3,3))*3,s=[1,1],axes=(0,1),norm='ortho')))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfft([0,1,0,0]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',len(numpy.fft.rfft([0,1,0,0])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft(numpy.fft.rfft([0,1,0,0])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft(numpy.fft.rfft([0,1,0,0]),n=numpy.fft.rfft([0,1,0,0]).shape[0]+1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft(numpy.fft.rfft([0,1,0,0]),n=numpy.fft.rfft([0,1,0,0]).shape[0]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft(numpy.fft.rfft([0,1,0,0]),n=len(numpy.fft.rfft([0,1,0,0]))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft(numpy.fft.rfft([0,1,0,0,0])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft(numpy.fft.rfft([0,1,0,0,0]),n=numpy.fft.rfft([0,1,0,0]).shape[0]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfft(numpy.fft.rfft([0,1,0,0,0]),n=len(numpy.fft.rfft([0,1,0,0]))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.irfftn(numpy.fft.rfftn(numpy.ones((3,3,3,3))),s=numpy.fft.rfftn(numpy.ones((3,3,3,3))).shape))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.array([[2,2j],[-2j,3]]).T)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.conj(numpy.array([[2,2j],[-2j,3]]).T))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.conj(numpy.array([[2,2j],[-2j,3]]).T)-numpy.array([[2,2j],[-2j,3]]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.hfft(numpy.array([[2,2j],[-2j,3]])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ihfft(numpy.fft.hfft(numpy.array([[2,2j],[-2j,3]]))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.array([1,2,3,4,3,2])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.hfft(numpy.array([1,2,3,4,3,2])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.hfft(numpy.array([1,2,3,4,3,2])[:4]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.hfft(numpy.array([1,2,3,4,3,2]),6))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.hfft(numpy.array([1,2,3,4,3,2,1,2,3,2])[:6]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.hfft(numpy.array([1,2,3,4,3,2,1,2,3,2]),10))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.array([1,2,3,5,3,2])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.hfft(numpy.array([1,2,3,5,3,2])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.hfft(numpy.array([1,2,3,5,3,2])[:4]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.hfft(numpy.array([1,2,3,5,3,2]),6))
# for n0 in numpy.arange(4,19,1):
    # print(n0,'       ',numpy.fft.hfft(numpy.array([1,2,3,4,3,2,1,2,3,2]),n0))
# for n0 in numpy.arange(4,21,1):
    # print(n0,'       ',numpy.fft.hfft(numpy.array([1,2,3,4,3,2,1,2,3,2,5]),n0))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ihfft(numpy.fft.hfft(numpy.array([[2,2j],[-2j,3]]))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ihfft(numpy.fft.ihfft(numpy.fft.hfft(numpy.array([[2,2j],[-2j,3]])))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ihfft(numpy.fft.hfft(numpy.array([1,2,3,4,3,2]))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ihfft(numpy.fft.hfft(numpy.array([1,2,3,4,3,2])[:4])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ihfft(numpy.fft.hfft(numpy.array([1,2,3,4,3,2]),6)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ihfft(numpy.fft.hfft(numpy.array([1,2,3,4,3,2,1,2,3,2])[:6])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ihfft(numpy.fft.hfft(numpy.array([1,2,3,4,3,2,1,2,3,2]),10)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ihfft(numpy.fft.hfft(numpy.array([1,2,3,5,3,2]))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ihfft(numpy.fft.hfft(numpy.array([1,2,3,5,3,2])[:4])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ihfft(numpy.fft.hfft(numpy.array([1,2,3,5,3,2]),6)))
# for n0 in numpy.arange(4,19,1):
    # print(n0,'       ',numpy.fft.ihfft(numpy.fft.hfft(numpy.array([1,2,3,4,3,2,1,2,3,2]),n0)))
# for n0 in numpy.arange(4,21,1):
    # print(n0,'       ',numpy.fft.ihfft(numpy.fft.hfft(numpy.array([1,2,3,4,3,2,1,2,3,2,5]),n0)))
# print(n0,'       ',numpy.fft.ihfft(numpy.fft.hfft(numpy.array([1,2,3,4,3,2,1,2,3,2,5]))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.array([1,2,3,4,3,2,1,2,3,2,5]).size)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.sort(numpy.fft.fft(numpy.cos(numpy.linspace(0,2*numpy.pi,10)))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.sort(numpy.fft.fft(numpy.sin(numpy.linspace(0,2*numpy.pi,10)))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.cos(numpy.linspace(0,2*numpy.pi,10))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.sin(numpy.linspace(0,2*numpy.pi,10))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.array([1,2,3,4,3,2,1,2,3,2,5])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.sort(numpy.fft.fft(numpy.array([1,2,3,4,3,2,1,2,3,2,5]))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fftfreq(numpy.array([1,2,3,4,3,2,1,2,3,2,5]).size))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fftfreq(numpy.array([1,2,3,4,3,2,1,2,3,2,5]).size,d=.5))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.array([1,2,3,4,3,2,1,2,3,2,5,6]).size)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.array([1,2,3,4,3,2,1,2,3,2,5,6])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fftfreq(numpy.array([1,2,3,4,3,2,1,2,3,2,5,6]).size))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fftfreq(numpy.array([1,2,3,4,3,2,1,2,3,2,5,6]).size,d=.5))
# matplotlib.pyplot.plot(numpy.fft.fftfreq(numpy.linspace(0,2*numpy.pi,10).size,d=.5),numpy.fft.fft(numpy.cos(numpy.linspace(0,2*numpy.pi,10))),label='cos')
# matplotlib.pyplot.plot(numpy.fft.fftfreq(numpy.linspace(0,2*numpy.pi,10).size,d=.5),numpy.fft.fft(numpy.sin(numpy.linspace(0,2*numpy.pi,10))),label='sin')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# matplotlib.pyplot.plot(numpy.fft.fftfreq(numpy.linspace(0,2*numpy.pi,10).size,d=.5),numpy.abs(numpy.fft.fft(numpy.cos(numpy.linspace(0,2*numpy.pi,10)))),label='cos')
# matplotlib.pyplot.plot(numpy.fft.fftfreq(numpy.linspace(0,2*numpy.pi,10).size,d=.5),numpy.abs(numpy.fft.fft(numpy.sin(numpy.linspace(0,2*numpy.pi,10)))),label='sin')
# currentFigManager0=matplotlib.pyplot.get_current_fig_manager()
# currentFigManager0.window.state('zoomed')
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()
# matplotlib.pyplot.cla()
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.array([1,2,3,4,3,2,1,2,3,2,5]).size)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.sort(numpy.fft.fft(numpy.cos(numpy.linspace(0,2*numpy.pi,10)))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.sort(numpy.fft.fft(numpy.sin(numpy.linspace(0,2*numpy.pi,10)))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.cos(numpy.linspace(0,2*numpy.pi,10))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.sin(numpy.linspace(0,2*numpy.pi,10))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.array([1,2,3,4,3,2,1,2,3,2,5])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.sort(numpy.fft.fft(numpy.array([1,2,3,4,3,2,1,2,3,2,5]))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftfreq(numpy.array([1,2,3,4,3,2,1,2,3,2,5]).size))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftfreq(numpy.array([1,2,3,4,3,2,1,2,3,2,5]).size,d=.5))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.array([1,2,3,4,3,2,1,2,3,2,5,6]).size)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.array([1,2,3,4,3,2,1,2,3,2,5,6])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftfreq(numpy.array([1,2,3,4,3,2,1,2,3,2,5,6]).size))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.rfftfreq(numpy.array([1,2,3,4,3,2,1,2,3,2,5,6]).size,d=.5))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fftshift(numpy.fft.fftfreq(numpy.array([1,2,3,4,3,2,1,2,3,2,5]).size,d=1),axes=None))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fftshift(numpy.fft.fftfreq(numpy.array([1,2,3,4,3,2,1,2,3,2,5,6]).size,d=1),axes=None))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ifftshift(numpy.fft.fftshift(numpy.fft.fftfreq(numpy.array([1,2,3,4,3,2,1,2,3,2,5]).size,d=1),axes=None),axes=None))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.ifftshift(numpy.fft.fftshift(numpy.fft.fftfreq(numpy.array([1,2,3,4,3,2,1,2,3,2,5,6]).size,d=1),axes=None),axes=None))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.array([1,2,3,4,3,2,1,2,3,2]))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fft(numpy.array([1,2,3,4,3,2,1,2,3,2]))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fftshift(numpy.fft.fftfreq(numpy.fft.fft(numpy.array([1,2,3,4,3,2,1,2,3,2])).size,d=1).reshape(2,3).copy('C'),axes=None))
# for axes0 in [0,1,(1,0),(0,1),None]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.fft.fftshift(numpy.fft.fftfreq(numpy.fft.fft(numpy.array([1,2,3,4,3,2,1,2,3,2])).size,d=1).reshape(2,5).copy('C'),axes=axes0))
    
# # # # # # pandas2.py start
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),inspect.getframeinfo(inspect.currentframe()).code_context[0].strip()+numpy.__version__)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),inspect.getframeinfo(inspect.currentframe()).code_context[0].strip()+pandas.__version__)
# try:
    # df1=pandas.DataFrame({'f':['2023-01-15','2023-01-16']*10}).to_datetime(infer_datetime_format=True)
# except Exception as e:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),e)
# df1=pandas.DataFrame({'f':['2023-01-15','2023-01-16']*10})
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),inspect.getframeinfo(inspect.currentframe()).code_context[0].strip()+df1)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),str(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df1))
# except Exception as e:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),inspect.getframeinfo(inspect.currentframe()).code_context[0].strip()+str(df1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df1)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df1)
# df1['f']=pandas.to_datetime(df1['f'],infer_datetime_format=True)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df1)
# df1['f']=df1['f'].dt.tz_localize('US/Central')
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df1)
# df0=pandas.DataFrame({'a':[True,False]*10,'b':[1,2]*10,'b1':[1.,2.]*10,'c':[1+1j,2+2j]*10,'d':['cat','dog']*10,'d1':['cat','dog']*10,'e':['2023-01-15','2023-01-16']*10,'e1':[numpy.timedelta64(1,'W'),numpy.timedelta64(1,'D')]*10})
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df0)
# df0['d1']=df0['d1'].astype('category')
# df0['d1']=pandas.Categorical(df0['d1'])
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df0)
# df2=pandas.concat([df0,df1],axis=1)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df2)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df2.select_dtypes(include=numpy.number))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df2.select_dtypes(include=numpy.object_))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df2.select_dtypes(include=numpy.float_))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df2.select_dtypes(include='f'))#only works on df.describe()
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df2.select_dtypes(exclude=numpy.complex_))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df2.select_dtypes(exclude=['datetime64','datetimetz','bool']))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df2.select_dtypes(exclude=['datetime64','datetime64[ns,tz]','bool']))
# except Exception as e:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),e)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df2.select_dtypes(exclude=['timedelta64']))
# except Exception as e:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),df2.select_dtypes(include='category'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',df2)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',df2.describe(percentiles=[.8,.9,.95],include=[numpy.number],datetime_is_numeric=False))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',df2.describe(percentiles=[.8,.9,.95],include=[numpy.number],datetime_is_numeric=True))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',df2.describe(exclude=['f','d'],datetime_is_numeric=True))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',df2.describe(percentiles=[.8,.9,.95],include='all',datetime_is_numeric=False))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',df2.describe(percentiles=[.8,.9,.95],include='all',datetime_is_numeric=True))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.read_csv(r'C:\Users\pdumas\Documents\Code\pandas2.test.csv',header=0))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.read_csv(r'C:\Users\pdumas\Documents\Code\pandas2.test.csv',header=None))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.read_csv(r'C:\Users\pdumas\Documents\Code\pandas2.test.csv',header=[0]))
# # try:
    # # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.read_csv(r'C:\Users\pdumas\Documents\Code\pandas2.test.csv',header=[0,2]))
# # except Exception as e:
    # # print(e)
# # try:
    # # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.read_csv(r'C:\Users\pdumas\Documents\Code\pandas2.test.csv',header=[0,2]))
# # except Exception as e:
    # # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1])
    # # source0=inspect.getsourcelines(inspect.currentframe())
    # # print(source0)
    # # print(source0[0][57])
    # # print(source0[0][sys.exc_info()[2].tb_lineno-1])
    # # for a0 in dir(sys.exc_info()[2]):
        # # print(a0,getattr(sys.exc_info()[2],a0))
    # # print(dir(sys.exc_info()[2]))
    # # print(dir(sys.exc_info()[2].tb_frame))
    # # print(sys.exc_info()[2].tb_frame)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.read_csv(r'C:\Users\pdumas\Documents\Code\pandas2.test.csv',header=[0,2]))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.read_csv(r'C:\Users\pdumas\Documents\Code\pandas2.test.csv',header='infer'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.MultiIndex.from_product([['country0','country1'],['city0','city1','city2']]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.MultiIndex.from_product([['country0','country1'],['city0','city1','city2']],sortorder=1,names=['countries','cities']))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.read_csv(r'C:\Users\pdumas\Documents\Code\pandas2.test.csv',header=[0,1,2]))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.read_csv(r'C:\Users\pdumas\Documents\Code\pandas2.test.csv',sep='t.*?Sep',header='infer'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.read_csv(r'C:\Users\pdumas\Documents\Code\pandas2.test.csv',sep='t.*?Sep',header=[0,1,2]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.read_csv(r'C:\Users\pdumas\Documents\Code\pandas2.test.csv',sep='t.*?Sep',header=0,names=['col0','col2']))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.read_csv(r'C:\Users\pdumas\Documents\Code\pandas2.test.csv',sep='t.*?Sep',header=0,names=['col4','col5','col6','col7']))
# def yi0(s0,n0,n1):
    # for i0 in range(n0):
        # for i1 in range(n1):
            # yield str(s0)+str(i0)
# def yi1(s0,n0,n1):
    # for i0 in range(n0):
        # for i1 in range(n1):
            # yield str(s0)+str(i1)
# print([e0 for e0 in yi0('index',4,2)])
# print([e0 for e0 in yi1('indexindex',4,2)])
# l0=[e0 for e0 in yi0('index',4,2)]
# l01=numpy.repeat(numpy.nan,8).tolist()
# # print(l01)
# l01[7]=102
# l1=[e0 for e0 in yi1('indexindex',4,2)]
# l3=[l0,l1]
# l2OfTuples0=list(zip(*[l0,l1]))
# l21OfTuples0=list(zip(*[l01,l1]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd')))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.MultiIndex.from_tuples(l2OfTuples0,sortorder=1,names=('4th','2nd')))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,8),index=pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd'))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,8),index=pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd'))).index.names)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.MultiIndex.from_tuples(l2OfTuples0))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,8),index=pandas.MultiIndex.from_tuples(l2OfTuples0)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,8),index=pandas.MultiIndex.from_tuples(l2OfTuples0)).index.names)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,8),index=pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd')))['index0','indexindex0'])
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,8),index=pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd')))['index1','indexindex0'])
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd')).to_frame())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd')).to_frame(index=False,name=None,allow_duplicates=True))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd')).to_frame(index=False,name=['col0','col1'],allow_duplicates=False))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd')).to_frame(index=False,name=['col0','col0'],allow_duplicates=True))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd')).to_frame(index=False,name=['col0','col0'],allow_duplicates=False))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.MultiIndex.from_frame(pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd')).to_frame()))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.MultiIndex.from_frame(pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd')).to_frame(),sortorder=1,names=('3rd','2nd')))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.random.default_rng(2).integers(0,10,(8,8)),index=l3,columns=pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd'))))
# pandas.set_option('display.multi_sparse',True)#True by default
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.random.default_rng(2).integers(0,10,(8,8)),index=l3,columns=pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd'))))
# pandas.set_option('display.multi_sparse',False)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.random.default_rng(2).integers(0,10,(8,8)),index=l3,columns=pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd'))))
# for level0 in [0,1,'1st','2nd']:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',level0,pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd')).get_level_values(level0))
# for level0 in [0,1,'1st','2nd']:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',level0,pandas.MultiIndex.from_tuples(l21OfTuples0,names=('1st','2nd')).get_level_values(level0))
# ia0=[1,1,1,2,2,2,3,3,3,4,4,4]
# ia1=[3,2,1,3,2,1,3,2,1,3,2,1]
# for sortorder0 in [0,1]:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',sortorder0,pandas.MultiIndex.from_arrays([ia0,ia1],sortorder=sortorder0,names=pandas._NoDefault.no_default))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',sortorder0,pandas.MultiIndex.from_arrays([ia0,ia1],sortorder=sortorder0,names=None))
# ia0=['a','a','a','b','b','b','C','C','C','d','d','d']
# ia1=['C','b','a','C','b','a','C','b','a','C','b','a']
# for sortorder0 in [0,1]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',sortorder0,pandas.MultiIndex.from_arrays([ia0,ia1],sortorder=sortorder0,names=['1st','2nd']))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.random.default_rng(2).integers(0,10,(8,8)),index=l3,columns=pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd'))).xs('indexindex0',level=1,axis=0,drop_level=True))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.random.default_rng(2).integers(0,10,(8,8)),index=l3,columns=pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd'))).xs('indexindex0',level=1,axis=0,drop_level=False))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.random.default_rng(2).integers(0,10,(8,8)),index=l3,columns=pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd'))).xs('indexindex0',level='2nd',axis=0,drop_level=False))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.random.default_rng(2).integers(0,10,(8,8)),index=l3,columns=pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd'))).xs('indexindex0',level='2nd',axis=1,drop_level=True))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.random.default_rng(2).integers(0,10,(8,8)),index=l3,columns=pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd'))).xs('index0',level='1st',axis=1,drop_level=True))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.random.default_rng(2).integers(0,10,(8,8)),index=l3,columns=pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd'))).index)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.random.default_rng(2).integers(0,10,(8,8)),index=l3,columns=pandas.MultiIndex.from_tuples(l2OfTuples0,names=('1st','2nd'))).loc[[0,1,3]])#won't work with multiindex with string labels
# except Exception as e:
    # print(e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).loc[[0,1,3]])
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).loc[[0,1,11]])
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).reindex([7,8,9]))

# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).loc[pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).index.intersection([7,8,9])])
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).loc[pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).index.intersection([7,8,9])].reindex([7,8,9]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).loc[pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).index.intersection([7,8,9])].reindex([7,8,6]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).reindex([1,2,3]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).reindex([1,2,3,3]))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).reindex([1,2,3,3]).reindex([1,2]))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).reindex([1,2,3,3]).reindex([1,3]))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).reindex([1,2,3,3]).loc[pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).reindex([1,2,3,3]).index.intersection([1,3])])
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).reindex([1,2,3,3]).loc[pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).reindex([1,2,3,3]).index.intersection([1,3])].reindex([1,2]))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Series(numpy.random.default_rng(2).integers(0,10,(8))).reindex([1,2,3,3]).loc[pandas.Series(pandas.date_range('2023-01-16','2023-01-23').random.default_rng(2).integers(0,10,(8))).reindex([1,2,3,3]).index.intersection([1,3])].reindex([1,2]))

# import matplotlib.dates,datetime
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(dt1='2023-01-16',dt2='2023-01-23'))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(dt1=datetime.date(2023,1,16),dt2=datetime.date(2023,1,23)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(dt1=datetime.date(2023,1,17),dt2=datetime.date(2023,1,23)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(dt1=datetime.date(2023,1,17),dt2=datetime.date(2023,1,23),years=2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(dt1=datetime.date(2023,1,17),dt2=datetime.date(2023,1,23),year=2020))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2023,1,10)+matplotlib.dates.relativedelta(dt1=datetime.date(2023,1,17),dt2=datetime.date(2023,1,23),year=2020))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2023,1,10)+matplotlib.dates.relativedelta(year=2020))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2023,1,10)+matplotlib.dates.relativedelta(years=2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2023,1,10)+matplotlib.dates.relativedelta(weekday=matplotlib.dates.MO(1)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2023,1,10)+matplotlib.dates.relativedelta(weekday=matplotlib.dates.MO(2)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2023,1,10)+matplotlib.dates.relativedelta(weekday=matplotlib.dates.MO(-2)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2023,1,10)+matplotlib.dates.relativedelta(weekday=matplotlib.dates.TU(1)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2023,1,10)+matplotlib.dates.relativedelta(weekday=matplotlib.dates.TU(2)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2023,1,10)+matplotlib.dates.relativedelta(weekday=matplotlib.dates.TU(-2)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(weekday=matplotlib.dates.TU(-2),hours=20))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(weekday=matplotlib.dates.TU(-2),hours=20).normalized())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(weekday=matplotlib.dates.TU(-2)).weeks)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(days=14,hours=27))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(days=14,hours=27).normalized())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(days=14,hours=27).weeks)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(days=14.7,hours=27))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(days=14.7,hours=27).normalized())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(days=14.7,hours=27).weeks)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(days=14.7,hours=27,microsecond=2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(days=14.7,hours=27,microsecond=2).normalized())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(days=14.7,hours=27,microsecond=2).weeks)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(leapdays=1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(yearday=23))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(nlyearday=23))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(leapdays=1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(yearday=92))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',matplotlib.dates.relativedelta(nlyearday=92))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2020,3,10)+matplotlib.dates.relativedelta(leapdays=1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2020,3,10)+matplotlib.dates.relativedelta(yearday=92))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2020,3,10)+matplotlib.dates.relativedelta(nlyearday=92))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2021,3,10)+matplotlib.dates.relativedelta(leapdays=1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2021,3,10)+matplotlib.dates.relativedelta(yearday=92))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',datetime.date(2021,3,10)+matplotlib.dates.relativedelta(nlyearday=92))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=1,normalize=False,years=1,month=12,day=25,hours=6.5))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',dir(pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5)))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5).__dict__)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for a0 in dir(pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5)):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5)):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# # import itertools#ifilter was removed from itertools as it became python's built-in filter in python3
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5)+datetime.date(2023,1,16))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5).is_anchored())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5).isAnchored())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5).is_month_end(pandas.Timestamp(datetime.date(2023,3,31))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5).is_month_start(pandas.Timestamp(datetime.date(2023,1,1))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5).is_quarter_start(pandas.Timestamp(datetime.date(2023,1,1))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5).is_quarter_end(pandas.Timestamp(datetime.date(2023,12,31))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5).is_year_start(pandas.Timestamp(datetime.date(2023,1,1))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5).is_year_end(pandas.Timestamp(datetime.date(2023,12,31))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5)+datetime.date(2023,1,16))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3)+datetime.date(2023,1,16))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3).rollback(pandas.tseries.offsets.DateOffset(months=3)+datetime.date(2023,1,16)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3).rollforward(pandas.tseries.offsets.DateOffset(months=3)+datetime.date(2023,1,16)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3)+datetime.date(2023,1,16))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3).rollback(pandas.tseries.offsets.DateOffset(months=2)+datetime.date(2023,1,16)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3).rollforward(pandas.tseries.offsets.DateOffset(months=2)+datetime.date(2023,1,16)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3)+pandas.Timestamp('2023-01-16'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3).rollback(pandas.tseries.offsets.DateOffset(months=2)+pandas.Timestamp('2023-01-16')))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3).rollforward(pandas.tseries.offsets.DateOffset(months=2)+pandas.Timestamp('2023-01-16')))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3,day=15).onOffset(pandas.Timestamp('2023-01-01')))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3,day=15).is_on_offset(pandas.Timestamp('2023-01-01')))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3,day=1).is_on_offset(pandas.Timestamp('2023-01-01')))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.BDay(1).is_on_offset(pandas.Timestamp('2023-01-16')))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.BDay(1).is_on_offset(pandas.Timestamp('2023-01-15')))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3,day=1).rule_code)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DateOffset(months=1)+pandas.Timestamp('2022-01-15'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DateOffset(months=1).rollback(pandas.DateOffset(months=1)+pandas.Timestamp('2022-01-15')))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3,day=1).nanos)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(months=3).nanos)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(hour=1).nanos)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(hours=1).nanos)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5).apply())
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5).apply(pandas.Timestamp('2023-01-16')))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.DateOffset(n=2,normalize=True,years=1,month=12,day=25,hours=6.5).copy())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.BusinessDay is pandas.tseries.offsets.BDay)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas._libs.tslibs.offsets.BusinessDay)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for a0 in dir(pandas.tseries.offsets.BusinessDay()):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.BusinessDay(),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.BusinessDay()):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.BusinessDay(),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.BDay()+pandas.Timestamp('2023-01-15'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.BusinessDay()+pandas.Timestamp('2023-01-15T06:00:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.BusinessHour()+pandas.Timestamp('2023-01-15T06:00:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.BusinessHour()+pandas.Timestamp('2023-01-16T18:00:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-01-17T18:00:00')-pandas.tseries.offsets.BusinessHour())
# for a0 in dir(pandas.tseries.offsets.BusinessHour()):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.BusinessHour(),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.BusinessHour()):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.BusinessHour(),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(numpy.timedelta64(1,'h'))
# try:
    # for a0 in dir(pandas.tseries.offsets.CustomBusinessDay(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=numpy.timedelta64(1,'h'))):
        # pass
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for a0 in dir(pandas.tseries.offsets.CustomBusinessDay(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')))):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.CustomBusinessDay(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h'))),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.CustomBusinessDay(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')))):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.CustomBusinessDay(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h'))),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessDay(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')))+pandas.Timestamp('2023-01-15T23:40:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessDay(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')))+pandas.Timestamp('2023-01-16T23:40:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessDay(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')))+pandas.Timestamp('2023-01-17T23:40:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')))+pandas.Timestamp('2023-01-15T23:40:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')),start='08:00',end='18:00')+pandas.Timestamp('2023-01-15T23:40:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')),start='08:00',end='18:00')+pandas.Timestamp('2023-01-16T23:40:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')),start='08:00',end='18:00')+pandas.Timestamp('2023-01-17T23:40:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=False,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')))+pandas.Timestamp('2023-01-15T23:40:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=False,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')),start='08:00',end='18:00')+pandas.Timestamp('2023-01-15T23:40:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=False,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')),start='08:00',end='18:00')+pandas.Timestamp('2023-01-16T23:40:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=False,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')),start='08:00',end='18:00')+pandas.Timestamp('2023-01-17T23:40:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-01-20T23:40:00')-pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=False,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h'))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-01-20T23:40:00')-pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=False,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')),start='08:00',end='18:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=False,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')),start='08:00',end='18:00')+pandas.Timestamp('2023-01-15 23:40:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=False,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')),start='08:00',end='18:00')+pandas.Timestamp('2023-01-16 23:40:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=False,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')),start='08:00',end='18:00')+pandas.Timestamp('2023-01-17 23:40:00'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-01-20 23:40:00')-pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=False,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h'))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-01-20 23:40:00')-pandas.tseries.offsets.CustomBusinessHour(n=2,normalize=False,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')),start='08:00',end='18:00'))
# try:
    # for a0 in dir(pandas.tseries.offsets.CustomBusinessMonthEnd(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=numpy.timedelta64(1,'h'))):
        # pass
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for a0 in dir(pandas.tseries.offsets.CustomBusinessMonthEnd(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')))):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.CustomBusinessMonthEnd(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h'))),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.CustomBusinessMonthEnd(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h')))):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.CustomBusinessMonthEnd(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'],offset=pandas.to_timedelta(numpy.timedelta64(1,'h'))),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.BusinessMonthEnd is pandas.tseries.offsets.BMonthEnd)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.BusinessMonthBegin is pandas.tseries.offsets.BMonthBegin)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessMonthEnd is pandas.tseries.offsets.CBMonthEnd)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessMonthBegin is pandas.tseries.offsets.CBMonthBegin)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.BusinessMonthEnd()+pandas.Timestamp('2023-02-14'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.BusinessMonthBegin()+pandas.Timestamp('2023-02-14'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-14')+pandas.tseries.offsets.BusinessMonthBegin())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-14')+pandas.tseries.offsets.BusinessMonthBegin(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessMonthEnd(offset=pandas.to_timedelta(numpy.timedelta64(1,'h')))+pandas.Timestamp('2023-02-14'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.offsets.CustomBusinessMonthBegin(offset=pandas.to_timedelta(numpy.timedelta64(1,'h')))+pandas.Timestamp('2023-02-14'))
# try:
    # for a0 in dir(pandas.tseries.offsets.SemiMonthEnd(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'])):
        # pass
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for a0 in dir(pandas.tseries.offsets.SemiMonthEnd(n=2,normalize=True,day_of_month=13)):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.SemiMonthEnd(n=2,normalize=True,day_of_month=13),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.SemiMonthEnd(n=2,normalize=True,day_of_month=13)):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.SemiMonthEnd(n=2,normalize=True,day_of_month=13),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # for a0 in dir(pandas.tseries.offsets.SemiMonthBegin(n=2,normalize=True,weekmask='1111000',holidays=['2023-01-16'])):
        # pass
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for a0 in dir(pandas.tseries.offsets.SemiMonthBegin(n=2,normalize=True,day_of_month=13)):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.SemiMonthBegin(n=2,normalize=True,day_of_month=13),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.SemiMonthBegin(n=2,normalize=True,day_of_month=13)):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.SemiMonthBegin(n=2,normalize=True,day_of_month=13),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.SemiMonthBegin(n=-1,normalize=True,day_of_month=13))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.SemiMonthEnd(n=-1,normalize=True,day_of_month=13))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.SemiMonthEnd(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.SemiMonthEnd(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.SemiMonthEnd(2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.SemiMonthBegin(n=1,normalize=True,day_of_month=13))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.SemiMonthBegin(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.SemiMonthBegin(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.SemiMonthBegin(2))
# for a0 in dir(pandas.tseries.offsets.Week(weekday=3)):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.Week(weekday=3),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.Week(weekday=3)):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.Week(weekday=3),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for a0 in dir(pandas.tseries.offsets.WeekOfMonth(n=2,week=1,weekday=3)):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.WeekOfMonth(n=2,week=1,weekday=3),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.WeekOfMonth(n=2,week=1,weekday=3)):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.WeekOfMonth(n=2,week=1,weekday=3),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for a0 in dir(pandas.tseries.offsets.LastWeekOfMonth(n=2,weekday=3)):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.LastWeekOfMonth(n=2,weekday=3),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.LastWeekOfMonth(n=2,weekday=3)):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.LastWeekOfMonth(n=2,weekday=3),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.Week(n=1,weekday=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.Week(n=2,weekday=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.Week(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.Week(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.Week(2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.WeekOfMonth(n=-1,week=2,weekday=3))#as a rule of thumb, offsets if negative are not going to be AFTER pandas.Timestamp('<baseDate>'); same thing for positive and BEFORE
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.WeekOfMonth(n=2,week=1,weekday=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.WeekOfMonth(n=2,week=2,weekday=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.WeekOfMonth(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.WeekOfMonth(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.WeekOfMonth(2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.LastWeekOfMonth(n=-1,weekday=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.LastWeekOfMonth(n=1,weekday=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.LastWeekOfMonth(n=2,weekday=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.LastWeekOfMonth(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.LastWeekOfMonth(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.LastWeekOfMonth(2))
# import pandas_market_calendars
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas_market_calendars.get_calendar('NYSE').valid_days(start_date=pandas.Timestamp(datetime.date.today())+pandas.tseries.offsets.YearBegin(-1),end_date=pandas.Timestamp(datetime.date.today())+pandas.tseries.offsets.YearEnd(1)))
# for a0 in dir(pandas.tseries.offsets.BQuarterEnd(n=2,startingMonth=2)):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.BQuarterEnd(n=2,startingMonth=2),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.BQuarterEnd(n=2,startingMonth=2)):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.BQuarterEnd(n=2,startingMonth=2),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for a0 in dir(pandas.tseries.offsets.BQuarterBegin(n=2,startingMonth=2)):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.BQuarterBegin(n=2,startingMonth=2),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.BQuarterBegin(n=2,startingMonth=2)):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.BQuarterBegin(n=2,startingMonth=2),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterEnd(n=-1,startingMonth=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterEnd(n=1,startingMonth=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterEnd(n=2,startingMonth=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(1,startingMonth=2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(1,startingMonth=0))#this is default  and  aligns with the business world
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(1,startingMonth=1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterEnd(2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterBegin(n=-1,startingMonth=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterBegin(n=1,startingMonth=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BQuarterBegin(n=2,startingMonth=3))#startingMonth loops if >2
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(1,startingMonth=2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(1,startingMonth=0))#this is default
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(1,startingMonth=1))#this aligns with the business world
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BQuarterBegin(2))
# for a0 in dir(pandas.tseries.offsets.QuarterEnd(n=2,startingMonth=2)):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.QuarterEnd(n=2,startingMonth=2),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.QuarterEnd(n=2,startingMonth=2)):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.QuarterEnd(n=2,startingMonth=2),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for a0 in dir(pandas.tseries.offsets.QuarterBegin(n=2,startingMonth=2)):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.QuarterBegin(n=2,startingMonth=2),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.QuarterBegin(n=2,startingMonth=2)):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.QuarterBegin(n=2,startingMonth=2),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentrame()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.QuarterEnd(n=-1,normalize=True,startingMonth=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.QuarterEnd(n=1,startingMonth=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.QuarterEnd(n=2,startingMonth=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.QuarterEnd(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.QuarterEnd(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.QuarterEnd(1,startingMonth=2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.QuarterEnd(1,startingMonth=0))#this is default  and  aligns with the business world
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.QuarterEnd(1,startingMonth=1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.QuarterEnd(2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.QuarterBegin(n=-1,startingMonth=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.QuarterBegin(n=1,startingMonth=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.QuarterBegin(n=2,startingMonth=3))#startingMonth loops if >2
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.QuarterBegin(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.QuarterBegin(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.QuarterBegin(1,startingMonth=2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.QuarterBegin(1,startingMonth=0))#this is default
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.QuarterBegin(1,startingMonth=1))#this aligns with the business world
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.QuarterBegin(2))
# for a0 in dir(pandas.tseries.offsets.YearEnd(n=2,normalize=True,month=3)):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.YearEnd(n=2,normalize=True,month=3),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.YearEnd(n=2,normalize=True,month=3)):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.YearEnd(n=2,normalize=True,month=3),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for a0 in dir(pandas.tseries.offsets.YearBegin(n=2,normalize=True,month=3)):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.YearBegin(n=2,normalize=True,month=3),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.YearBegin(n=2,normalize=True,month=3)):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.YearBegin(n=2,normalize=True,month=3),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for a0 in dir(pandas.tseries.offsets.BYearEnd(n=2,normalize=True,month=3)):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.BYearEnd(n=2,normalize=True,month=3),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.BYearEnd(n=2,normalize=True,month=3)):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.BYearEnd(n=2,normalize=True,month=3),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for a0 in dir(pandas.tseries.offsets.BYearBegin(n=2,normalize=True,month=3)):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.BYearBegin(n=2,normalize=True,month=3),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.BYearBegin(n=2,normalize=True,month=3)):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.BYearBegin(n=2,normalize=True,month=3),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.YearEnd(n=-1,normalize=True,month=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.YearEnd(n=1,month=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.YearEnd(n=2,month=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.YearEnd(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.YearEnd(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.YearEnd(1,month=2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.YearEnd(2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.YearBegin(n=-1,month=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.YearBegin(n=1,month=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.YearBegin(n=2,month=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.YearBegin(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.YearBegin(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.YearBegin(1,month=2))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.YearBegin(1,month=0))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.YearBegin(1,month=1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.YearBegin(2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BYearEnd(n=-1,normalize=True,month=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BYearEnd(n=1,month=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BYearEnd(n=2,month=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BYearEnd(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BYearEnd(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BYearEnd(1,month=2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BYearEnd(2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BYearBegin(n=-1,month=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BYearBegin(n=1,month=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.BYearBegin(n=2,month=3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BYearBegin(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BYearBegin(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BYearBegin(1,month=2))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BYearBegin(1,month=0))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BYearBegin(1,month=1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.BYearBegin(2))
# for a0 in dir(pandas.tseries.offsets.FY5253(n=2,normalize=True,weekday=3,startingMonth=12,variation='nearest')):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.FY5253(n=2,normalize=True,weekday=3,startingMonth=12,variation='nearest'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.FY5253(n=2,normalize=True,weekday=3,startingMonth=12,variation='nearest')):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.FY5253(n=2,normalize=True,weekday=3,startingMonth=12,variation='nearest'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for a0 in dir(pandas.tseries.offsets.FY5253Quarter(n=2,normalize=True,weekday=3,startingMonth=12,qtr_with_extra_week=4,variation='nearest')):
    # try:
        # print(a0,getattr(pandas.tseries.offsets.FY5253Quarter(n=2,normalize=True,weekday=3,startingMonth=12,qtr_with_extra_week=4,variation='nearest'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.offsets.FY5253Quarter(n=2,normalize=True,weekday=3,startingMonth=12,qtr_with_extra_week=4,variation='nearest')):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.offsets.FY5253Quarter(n=2,normalize=True,weekday=3,startingMonth=12,qtr_with_extra_week=4,variation='nearest'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.FY5253(n=-1,startingMonth=12,variation='nearest',weekday=2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.FY5253(n=1,startingMonth=12,variation='nearest',weekday=2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.FY5253(n=1,startingMonth=12,variation='last',weekday=2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.FY5253(n=2,startingMonth=12,variation='nearest',weekday=2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.FY5253(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.FY5253(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.FY5253(2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.FY5253Quarter(n=-1,startingMonth=12,variation='nearest',weekday=2,qtr_with_extra_week=4))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.FY5253Quarter(n=1,startingMonth=12,variation='nearest',weekday=2,qtr_with_extra_week=4))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.FY5253Quarter(n=1,startingMonth=12,variation='last',weekday=2,qtr_with_extra_week=4))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-15')+pandas.tseries.offsets.FY5253Quarter(n=2,startingMonth=12,variation='nearest',weekday=2,qtr_with_extra_week=4))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.FY5253Quarter(-1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.FY5253Quarter(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.FY5253Quarter(2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',dir(pandas.tseries.offsets.Nano))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',dir(pandas.tseries.offsets.Nano()))
# for e00 in [pandas.tseries.offsets.Easter,pandas.tseries.offsets.Tick,pandas.tseries.offsets.Day,pandas.tseries.offsets.Hour,pandas.tseries.offsets.Minute,pandas.tseries.offsets.Second,pandas.tseries.offsets.Milli,pandas.tseries.offsets.Micro,pandas.tseries.offsets.Nano]:
    # for a0 in dir(e00()):
        # try:
            # print(a0,getattr(e00(),a0))
        # except Exception as e:
            # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
    # listOfAttributes0=[]
    # for a0 in dir(e00()):
        # try:
            # listOfAttributes0.append(getattr(e00(),a0))
        # except Exception as e:
            # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
    # import inspect
    # methods0=filter(callable,listOfAttributes0)
    # for method0 in methods0:
        # try:
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
        # except Exception as e:
            # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for e00 in [pandas.tseries.offsets.Easter,pandas.tseries.offsets.Tick,pandas.tseries.offsets.Day,pandas.tseries.offsets.Hour,pandas.tseries.offsets.Minute,pandas.tseries.offsets.Second,pandas.tseries.offsets.Milli,pandas.tseries.offsets.Micro,pandas.tseries.offsets.Nano]:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10 13:13:13.131313131')+e00())
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.frequencies.to_offset('10S'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.frequencies.to_offset('10s'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.frequencies.to_offset('2W'))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.frequencies.to_offset('2Week'))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.frequencies.to_offset(numpy.timedelta64(2,'W')))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.frequencies.to_offset(pandas.Timedelta(weeks=2)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.frequencies.to_offset('5min'))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.frequencies.to_offset('13BYS1D13min13ms13us'))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.tseries.frequencies.to_offset('1D13min13ms13us'))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.Tick(5,unit='5D'))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.Timestamp('2023-02-10')+pandas.tseries.offsets.Tick(5,freq='5D'))#seems like this Tick is being deprecated / removed..
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# # import scikits.timeseries#obsolete library
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',scikits.timeseries)
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',dir(scikits.timeseries))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.to_datetime(['2023-01-18',numpy.datetime64('2023-01-18'),datetime.date(2023,1,18)]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.date_range('2023-01-18','2023-01-28',freq='3D'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.date_range('2023-01-18','2023-01-28',periods=3))
# for inclusive0 in ['both','neither','left','right']:
    # for normalize0 in [False,True]:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',inclusive0,normalize0,pandas.date_range('2023-01-18 02:02:02','2023-01-28 02:02:02',periods=3,tz='US/Eastern',normalize=normalize0,name='DatetimeIndex0',inclusive=inclusive0))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',inclusive0,normalize0,pandas.date_range('2023-01-18','2023-01-28',periods=3,tz='US/Eastern').tz_convert(None))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',inclusive0,normalize0,pandas.date_range('2023-01-18','2023-01-28',periods=3,tz='US/Eastern').tz_convert('US/Central'))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',inclusive0,normalize0,pandas.date_range('2023-01-18','2023-01-28',periods=3,tz='US/Eastern').tz_localize('US/Central'))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',inclusive0,normalize0,pandas.date_range('2023-01-18','2023-01-28',periods=3).tz_localize('US/Central'))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',inclusive0,normalize0,pandas.date_range('2023-01-18','2023-01-28',periods=3).tz_convert('US/Central'))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.date_range(start='2023-01-18',freq='W',periods=3))#returns W-SUN
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.date_range(end='2023-01-18',freq=pandas.tseries.offsets.Week(),periods=3))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.date_range(end='2023-01-18',freq=pandas.tseries.offsets.Week(),periods=3).index)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.period_range('2023BQ1','2023BQ4',freq='BQ'))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.period_range('2023Q1','2023Q4',freq='Q'))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.period_range('2023Q1','2023Q4',freq='Q').index)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame([datetime.timedelta(days=d0) for d0 in range(10,50,10)]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame([datetime.timedelta(days=d0) for d0 in range(10,50,10)]).index)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.date_range('2023-01-01 00:00:30','2023-01-03 00:00:30',freq='D').asfreq(freq='H',method='ffill',normalize=False,how=None))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# df0=pandas.DataFrame(numpy.arange(pandas.date_range('2023-01-01 00:00:30','2023-01-03 00:00:30',freq='D').shape[0]),index=pandas.date_range('2023-01-01 00:00:30','2023-01-03 00:00:30',freq='D'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.arange(pandas.date_range('2023-01-01 00:00:30','2023-01-03 00:00:30',freq='D').shape[0]),index=pandas.date_range('2023-01-01 00:00:30','2023-01-03 00:00:30',freq='D')))
# for method0 in ['pad','ffill','bfill','backfill']:
    # for how0 in ['end','start']:
        # for normalize0 in [False,True]:
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,how0,normalize0,pandas.DataFrame(numpy.arange(pandas.date_range('2023-01-01 00:00:30','2023-01-03 00:00:30',freq='D').shape[0]),index=pandas.date_range('2023-01-01 00:00:30','2023-01-03 00:00:30',freq='D')).asfreq(freq='H',method=method0,normalize=normalize0,how=how0))
# for fill_value0 in [None,42]:
    # for how0 in ['end','start']:
        # for normalize0 in [False,True]:
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',fill_value0,how0,normalize0,pandas.DataFrame(numpy.arange(pandas.date_range('2023-01-01 00:00:30','2023-01-03 00:00:30',freq='D').shape[0]),index=pandas.date_range('2023-01-01 00:00:30','2023-01-03 00:00:30',freq='D')).asfreq(freq='H',fill_value=fill_value0,normalize=normalize0,how=how0))
# for how0 in ['end','start']:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',how0,pandas.DataFrame(numpy.arange(pandas.period_range('2023-01-01 00:00:30','2023-01-03 00:00:30',freq='D').shape[0]),index=pandas.period_range('2023-01-01 00:00:30','2023-01-03 00:00:30',freq='D')).asfreq(freq='H',how=how0))
# for how0 in ['end','start']:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',how0,pandas.period_range(start='2023-01-01 00:00:30',periods=3,freq='D',name='PeriodIndex0'))
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',how0,pandas.period_range('2023-01-01 00:00:30','2023-01-03 00:00:30',freq='D').asfreq(freq='H',how=how0))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3, 4, numpy.nan, 1],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3, 4, numpy.nan, 1],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")).fillna(value=42,method=method0,limit=1))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for method0 in ['pad','ffill','bfill','backfill']:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3, 4, numpy.nan, 1],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")).fillna(method=method0,limit=1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3, 4, numpy.nan, 1],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")).fillna(value=42))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3., 4., numpy.nan, 1.],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")).fillna(value=dict((('A',42),('B',42),('D',42),('E',42))),downcast='infer',axis=0))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3., 4., numpy.nan, 1.],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")).fillna(value={0:42},axis=1))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3., 4., numpy.nan, 1.],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")).fillna(value=pandas.DataFrame([[57, 2, 57, 0],[3, 4, 57, 1],[57, 57, 57, 57],[57, 3, 57, 4]]),axis=1))#axis=1 is either NotImplemented or, if no error, doesn't seem to do anything
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3., 4., numpy.nan, 1.],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")).fillna(value=42,inplace=True,limit=1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3., 4., numpy.nan, 1.],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")).fillna(value=42,limit=1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3., 4., numpy.nan, 1.],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")).fillna(method='ffill',axis=None,inplace=False,downcast=None))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3., 4., numpy.nan, 1.],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")).ffill())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3., 4., numpy.nan, 1.],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")).fillna(method='bfill',axis=None,inplace=False,downcast=None))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame([[numpy.nan, 2, numpy.nan, 0],[3., 4., numpy.nan, 1.],[numpy.nan, numpy.nan, numpy.nan, numpy.nan],[numpy.nan, 3, numpy.nan, 4]],columns=list("ABCD")).bfill())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.MultiIndex.from_product([pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0'),['morning0','afternoon0']]).shape[0]).tolist(),index=pandas.MultiIndex.from_product([pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0'),['morning0','afternoon0']])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.MultiIndex.from_product([pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0'),['morning0','afternoon0']]).shape[0]).tolist(),index=pandas.MultiIndex.from_product([pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0'),['morning0','afternoon0']])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.MultiIndex.from_product([pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0'),['morning0','afternoon0']]).shape[0]),index=pandas.MultiIndex.from_product([pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0'),['morning0','afternoon0']])).resample('D',level=0).sum())
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0').shape[0]),index=pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0')).resample('29min',axis=0,origin='start_day',offset='-1min',on='DatetimeIndex0',label='left',closed='left'))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0').shape[0]),index=pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0')).resample('29min',axis=0,origin='start_day',offset='-1min',label='left',closed='left'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0').shape[0]),index=pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0')).resample('29min',axis=0,origin='start_day',offset='-1min',label='right',closed='right'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0').shape[0]),index=pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0')).resample('M',kind='timestamp'))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0').shape[0]),index=pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0')).resample('M',kind='timestamp').resample('M',kind='period'))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0').shape[0]),index=pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0')).resample('M',kind='timestamp'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0').shape[0]),index=pandas.date_range('2023-01-19',periods=3,freq='M',name='DatetimeIndex0')).resample('M',kind='period'))
# for convention0 in ['start','s','end','e']:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',convention0,pandas.DataFrame(numpy.ones(pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0').shape[0]),index=pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0')).resample('12H',convention=convention0))
# for origin0 in ['epoch','start','start_day','end','end_day','2023-01-18 19:00:00']:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',origin0,pandas.DataFrame(numpy.ones(pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0').shape[0]),index=pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0')).resample('12H',origin=origin0))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0').shape[0]),index=pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0')).resample('29min',axis=0,origin='start_day',offset='-1min',label='left',closed='left').sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0').shape[0]),index=pandas.date_range('2023-01-19',periods=3,freq='D',name='DatetimeIndex0')).resample('29min',axis=0,origin='start_day',offset='-1min',label='right',closed='right').sum())
# df1 = pandas.DataFrame({'a': range(6)},index=pandas.date_range("2021-01-01", periods=6, freq="8H"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',df1.resample("D",group_keys=True).apply(lambda x:x))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',df1.resample("D",group_keys=False).apply(lambda x:x))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',df1.resample("D").apply(lambda x:x))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',df1.resample("D").apply(lambda x:x.reset_index()))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.date_range('2023-01-19',periods=3,freq='W',name='DatetimeIndex0').shape[0]),index=pandas.date_range('2023-01-19',periods=3,freq='W',name='DatetimeIndex0')).resample('D',kind='timestamp',group_keys=False).apply(lambda x:x))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n', pandas.DataFrame({'col0':range(pandas.date_range('2023-01-19',periods=3,freq='W',name='DatetimeIndex0').shape[0])},index=pandas.date_range('2023-01-19',periods=3,freq='W')).resample('D',group_keys=True).apply(lambda x:x))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n', pandas.DataFrame({'col0':range(pandas.date_range('2023-01-19',periods=3,freq='8H',name='DatetimeIndex0').shape[0])},index=pandas.date_range('2023-01-19',periods=3,freq='8H')).resample('D',group_keys=True).apply(lambda x:x))#group_keys=True only works/groups if you go down in freq (downsample) / up in periodCoverage (e.g. hours resampled to days, grouped by days)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n', pandas.Series(range(pandas.date_range('2023-01-19',periods=3,freq='8H',name='DatetimeIndex0').shape[0]),index=pandas.date_range('2023-01-19',periods=3,freq='8H')).resample('D',group_keys=True).apply(lambda x:x))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n', pandas.DataFrame(numpy.ones(pandas.date_range('2023-01-19',periods=3,freq='W',name='DatetimeIndex0').shape[0]),index=pandas.date_range('2023-01-19',periods=3,freq='W',name='DatetimeIndex0')).resample('D',kind='timestamp',group_keys=True).apply(lambda x:x))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.period_range('2023-01-19',periods=3,freq='W',name='PeriodIndex0').shape[0]),index=pandas.period_range('2023-01-19',periods=3,freq='W',name='PeriodIndex0')).resample('D',kind='timestamp',group_keys=False).apply(lambda x:x))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n', pandas.DataFrame(numpy.ones(pandas.period_range('2023-01-19',periods=3,freq='W',name='PeriodIndex0').shape[0]),index=pandas.period_range('2023-01-19',periods=3,freq='W',name='PeriodIndex0')).resample('D',kind='timestamp',group_keys=True).apply(lambda x:x))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0').shape[0]),index=pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0')).resample('M',kind='timestamp').sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame(numpy.ones(pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0').shape[0]),index=pandas.date_range('2023-01-19',periods=3,freq='M',name='DatetimeIndex0')).resample('M',kind='period').sum())
# for convention0 in ['start','s','end','e']:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',convention0,pandas.DataFrame(numpy.ones(pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0').shape[0]),index=pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0')).resample('12H',convention=convention0).sum())
# for origin0 in ['epoch','start','start_day','end','end_day','2023-01-18 19:00:00']:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',origin0,pandas.DataFrame(numpy.ones(pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0').shape[0]),index=pandas.period_range('2023-01-19',periods=3,freq='M',name='PeriodIndex0')).resample('12H',origin=origin0).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame({'a':range(2)}))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame({'a':range(1,4,1),'b':range(4,7,1)}))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,4,1),'b':range(4,7,1)}),copy=True,join='outer',broadcast_axis=None,fill_axis=None,fill_value=numpy.nan,method=None,limit=1,axis=None))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,4,1),'b':range(4,7,1)}),copy=True,join='outer',broadcast_axis=None,fill_axis=None,fill_value=numpy.nan,method=None,limit=1,axis=None)[0],'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,4,1),'b':range(4,7,1)}),copy=True,join='outer',broadcast_axis=None,fill_axis=None,fill_value=numpy.nan,method=None,limit=1,axis=None)[1])
# for axis0 in [0,1,None]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',axis0,'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,4,1),'b':range(4,7,1)}),copy=True,join='outer',broadcast_axis=None,fill_axis=None,fill_value=numpy.nan,method=None,limit=1,axis=axis0)[0],'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,4,1),'b':range(4,7,1)}),copy=True,join='outer',broadcast_axis=None,fill_axis=None,fill_value=numpy.nan,method=None,limit=1,axis=axis0)[1])
# for join0 in ['inner','left','right','outer']:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,4,1),'b':range(4,7,1)}),copy=True,join=join0,broadcast_axis=None,fill_axis=None,fill_value=numpy.nan,method=None,limit=1,axis=None)[0],'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,4,1),'b':range(4,7,1)}),copy=True,join=join0,broadcast_axis=None,fill_axis=None,fill_value=numpy.nan,method=None,limit=1,axis=None)[1])
# for fill_axis0 in [0,1,None]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,4,1),'b':range(4,7,1)}),copy=True,join='outer',broadcast_axis=None,fill_axis=fill_axis0,fill_value=numpy.nan,method='ffill',limit=1,axis=None)[0],'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,4,1),'b':range(4,7,1)}),copy=True,join='outer',broadcast_axis=None,fill_axis=fill_axis0,fill_value=numpy.nan,method='ffill',limit=1,axis=None)[1])
# for fill_axis0 in [0,1,None]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,4,1),'b':range(4,7,1)}),copy=True,join='outer',broadcast_axis=None,fill_axis=fill_axis0,method='ffill',limit=1,axis=None)[0],'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,4,1),'b':range(4,7,1)}),copy=True,join='outer',broadcast_axis=None,fill_axis=fill_axis0,method='ffill',limit=1,axis=None)[1])
# for fill_axis0 in [0,1,None]:
    # for method0 in ['pad','ffill','bfill','backfill']:
        # for broadcast_axis0 in [0,1,None]:
            # for fill_value0 in [42,None]:
                # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),globals(),'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,5,1),'b':range(5,9,1),'c':range(9,13,1)}),copy=True,join='outer',broadcast_axis=broadcast_axis0,fill_axis=fill_axis0,method=method0,limit=1,axis=None)[0],'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,5,1),'b':range(5,9,1),'c':range(9,13,1)}),copy=True,join='outer',broadcast_axis=broadcast_axis0,fill_axis=fill_axis0,method=method0,limit=1,axis=None)[1])
# for fill_axis0 in [0,1,None]:
    # for method0 in ['pad','ffill','bfill','backfill',None]:
        # for broadcast_axis0 in [0,1,None]:
            # for fill_value0 in [42,None]:
                # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),globals(),'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,5,1),'b':range(5,9,1),'c':range(9,13,1)}),copy=True,join='outer',broadcast_axis=broadcast_axis0,fill_axis=fill_axis0,fill_value=fill_value0,limit=1,axis=None)[0],'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,5,1),'b':range(5,9,1),'c':range(9,13,1)}),copy=True,join='outer',broadcast_axis=broadcast_axis0,fill_axis=fill_axis0,fill_value=fill_value0,limit=1,axis=None)[1])
# for broadcast_axis0 in [0,1,None]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,4,1),'b':range(4,7,1)}),copy=True,join='outer',broadcast_axis=broadcast_axis0,fill_axis=None)[0],'\n',pandas.DataFrame({'a':range(2)}).align(pandas.DataFrame({'a':range(1,4,1),'b':range(4,7,1)}),copy=True,join='outer',broadcast_axis=broadcast_axis0,fill_axis=None,method='ffill',limit=1)[1])
# for broadcast_axis0 in [0,1,None]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame(numpy.zeros((2,2))).align(pandas.DataFrame(numpy.ones((4,4))),copy=True,join='outer',broadcast_axis=broadcast_axis0)[0],'\n',pandas.DataFrame(numpy.zeros((2,2))).align(pandas.DataFrame(numpy.ones((4,4))),copy=True,join='outer',broadcast_axis=broadcast_axis0)[1])
# for broadcast_axis0 in [0,1,None]:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1,2,3,4,5,6],[3,4,5,6,7,8],[4,5,6,7,8,9],[4,5,6,7,8,9]]).align(pandas.Series([1,2]),copy=True,join='outer',broadcast_axis=broadcast_axis0)[0],'\n',pandas.DataFrame([[1,2,3,4,5,6],[3,4,5,6,7,8],[4,5,6,7,8,9],[4,5,6,7,8,9]]).align(pandas.Series([1,2]),copy=True,join='outer',broadcast_axis=broadcast_axis0)[1])
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for axis0 in [0,1,None]:
    # for broadcast_axis0 in [0,1,None]:
        # try:
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1,2,3,4,5,6],[3,4,5,6,7,8],[4,5,6,7,8,9],[4,5,6,7,8,9]]).align(pandas.Series([1,2]),copy=True,join='outer',broadcast_axis=broadcast_axis0,axis=axis0)[0],'\n',pandas.DataFrame([[1,2,3,4,5,6],[3,4,5,6,7,8],[4,5,6,7,8,9],[4,5,6,7,8,9]]).align(pandas.Series([1,2]),copy=True,join='outer',broadcast_axis=broadcast_axis0,axis=axis0)[1])
        # except Exception as e:
            # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1,2,3,4,5,6],[3,4,5,6,7,8],[4,5,6,7,8,9],[4,5,6,7,8,9]]).align(pandas.Series([1,2],index=pandas.MultiIndex.from_product([['c0'],['c1','c2']])),copy=True,join='outer',level='c0'))#must have axis (which makes sense given similar to broadcast_axis requirements)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1,2,3,4,5,6],[3,4,5,6,7,8],[4,5,6,7,8,9],[4,5,6,7,8,9]]).align(pandas.Series([1,2],index=pandas.MultiIndex.from_product([['c0'],['c1','c2']])),copy=True,join='outer',level='c0',axis=1))#can't be Series for MultiIndex
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for axis0 in [0,1]:
    # for level0 in ['c0','c1']:
        # try:
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1,2,3,4,5,6],[3,4,5,6,7,8],[4,5,6,7,8,9],[4,5,6,7,8,9]]).align(pandas.DataFrame([1,2],index=pandas.MultiIndex.from_product([['c0'],['c1','c2']])),copy=True,join='outer',level=level0,axis=axis0))
        # except Exception as e:
            # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby("A").sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby(pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),})["A"]).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby(["A","B"]).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby(["B","A"]).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby(["B"]).sum())
# df2=pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),})
# df2=df2.set_index(["A","B"])
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby(level=df2.index.names.difference(["B"])).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby(level=df2.index.names.difference(["A"])).sum())
# def columnName0(columnName0arg0):
    # if columnName0arg0=='one':
        # return 2
    # else:
        # return 5
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby(columnName0).sum())
# def columnName0(columnName0arg0):
    # if columnName0arg0=='foo':
        # return 2
    # else:
        # return 5
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby(columnName0).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby({"A":'output0'}).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby({"A":'foo'}).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby({"foo":'one'}).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby({"A":'one'}).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby({"foo":'one'}).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'}))
# grouped3=df2.groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'})
# for group_name0,data0 in grouped3:
    # print(group_name0)
    # print('---------')
    # print(data0)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(df2.groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'})))
# # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(df2.drop("A").groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'})))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(df2.set_index("B").groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'})))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n','\n','\n','\n')
# df2=pandas.Series(numpy.arange(10)+10,numpy.tile(numpy.arange(5),2))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby(level=0).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby(level=0).first())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby(level=0).last())
# df2=pandas.Series(numpy.arange(15)+10,numpy.tile(numpy.arange(5),3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby(level=0).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby(level=0).first())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby(level=0).last())
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby(level=0)[0])
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# df2=pandas.Series(numpy.arange(15)+10,numpy.tile(numpy.arange(5),3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df2.groupby(lambda x: x+100).sum())#applies function then groups by whatever index is there
# df2=pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),})
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(df2.drop("A",axis=1).set_index("B").groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'})))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(df2.set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'})))#groupby(dict0) currently either only supported for one index (if you have 2 indices, the output will be an empty DataFrameGroupBy (only columns present; no data)  or  only supported for where all the indices coincide / map from keys to 1 value (in other words, key a with value 1 and key a1 with value 1 all are together, key b with value 2 and key b2 with value 2 are all together, no overlap; tested this below
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(df2.set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup','foo':'otherGroup','bar':'otherGroup'})))#same as above, returns empty list..
# df2=pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),})
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(df2.drop("A",axis=1).set_index("B").groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'})))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(df2.set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'})))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(df2.set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup','foo':'oneGroup','bar':'otherGroup'})))#3 lines here and below: no matter what the combination, if it's more than 1 index, returns empty DataFrameGroupBy 
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(df2.set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup','foo':'fooGroup','bar':'barGroup'})))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(df2.set_index(["A","B"]).groupby([{"one":'oneGroup','two':'otherGroup','three':'otherGroup'},{'foo':'fooGroup','bar':'barGroup'}])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).drop("A",axis=1).set_index("B").groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'})))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'})))#groupby(dict0) currently either only supported for one index (if you have 2 indices, the output will be an empty DataFrameGroupBy (only columns present; no data)  or  only supported for where all the indices coincide / map from keys to 1 value (in other words, key a with value 1 and key a1 with value 1 all are together, key b with value 2 and key b2 with value 2 are all together, no overlap; tested this below
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","bar","foo","bar","foo","bar","foo","foo"],"B":["one","one","two","three","two","two","one","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup','foo':'otherGroup','bar':'otherGroup'})))#same as above, returns empty list..
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).drop("A",axis=1).set_index("B").groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'})))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup'})))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup','foo':'oneGroup','bar':'otherGroup'})))#3 lines here and below: no matter what the combination, if it's more than 1 index, returns empty DataFrameGroupBy 
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index(["A","B"]).groupby({"one":'oneGroup','two':'otherGroup','three':'otherGroup','foo':'fooGroup','bar':'barGroup'})))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index(["A","B"]).groupby([{"one":'oneGroup','two':'otherGroup','three':'otherGroup'},{'foo':'fooGroup','bar':'barGroup'}])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).groupby("A",sort=False).sum()))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).groupby("A",sort=True).sum()))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).groupby("A").sum()))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).groupby("A",sort=False).get_group("foo").sum()))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).groupby("A",sort=True).get_group("foo").sum()))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).groupby("A").get_group("foo").sum()))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).groupby("A",sort=False)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).groupby("A",sort=True)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).groupby("A")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).groupby("A",sort=False).get_group("foo")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).groupby("A",sort=True).get_group("foo")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).groupby("A").get_group("foo")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).set_index("A").groupby("A",sort=False)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).set_index("A").groupby("A",sort=True)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).set_index("A").groupby("A")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).set_index("A").groupby("A",sort=False).get_group("foo")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).set_index("A").groupby("A",sort=True).get_group("foo")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8)}).set_index("A").groupby("A").get_group("foo")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby("A",sort=False).sum()))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby("A",sort=True).sum()))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby("A").sum()))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby("A",sort=False).get_group("foo").sum()))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby("A",sort=True).get_group("foo").sum()))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby("A").get_group("foo").sum()))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby("A",sort=False)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby("A",sort=True)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby("A")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby("A",sort=False).get_group("foo")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby("A",sort=True).get_group("foo")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).groupby("A").get_group("foo")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index("A").groupby("A",sort=False)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index("A").groupby("A",sort=True)))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index("A").groupby("A")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index("A").groupby("A",sort=False).get_group("foo")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index("A").groupby("A",sort=True).get_group("foo")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',list(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.randn(8),"D":numpy.random.randn(8),}).set_index("A").groupby("A").get_group("foo")))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).groupby("A",sort=False).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).groupby("A",sort=True).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).groupby("A").sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).groupby("A",sort=False).get_group("foo").sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).groupby("A",sort=True).get_group("foo").sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).groupby("A").get_group("foo").sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).groupby("A",sort=False))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).groupby("A",sort=True))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).groupby("A"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).groupby("A",sort=False).get_group("foo"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).groupby("A",sort=True).get_group("foo"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).groupby("A").get_group("foo"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).set_index("A").groupby("A",sort=False))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).set_index("A").groupby("A",sort=True))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).set_index("A").groupby("A"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).set_index("A").groupby("A",sort=False).get_group("foo"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).set_index("A").groupby("A",sort=True).get_group("foo"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).set_index("A").groupby("A").get_group("foo"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).groupby("A",sort=False).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).groupby("A",sort=True).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).groupby("A").sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).groupby("A",sort=False).get_group("foo").sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).groupby("A",sort=True).get_group("foo").sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).groupby("A").get_group("foo").sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).groupby("A",sort=False))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).groupby("A",sort=True))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).groupby("A"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).groupby("A",sort=False).get_group("foo"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).groupby("A",sort=True).get_group("foo"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).groupby("A").get_group("foo"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).set_index("A").groupby("A",sort=False).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).set_index("A").groupby("A",sort=True).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).set_index("A").groupby("A").sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).set_index("A").groupby("A",sort=False).get_group("foo").sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).set_index("A").groupby("A",sort=True).get_group("foo").sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.randn(8),}).set_index("A").groupby("A").get_group("foo").sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).set_index("A").groupby("A",sort=False))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).set_index("A").groupby("A",sort=True))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).set_index("A").groupby("A"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).set_index("A").groupby("A",sort=False).get_group("foo"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.default_rng(8).random(8),}).set_index("A").groupby("A",sort=True).get_group("foo"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.randn(8),}).set_index("A").groupby("A").get_group("foo"))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo",numpy.nan,"foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.randn(8),}).set_index("A").groupby("A",dropna=False).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo",numpy.nan,"foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.randn(8),}).set_index("A").groupby("A",dropna=True).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo",numpy.nan,"foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8),"D":numpy.random.randn(8),}).set_index("A").groupby("A").sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).set_index("A").groupby("A").groups)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).set_index("A").groupby("A").ngroups)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',len(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"C":numpy.random.default_rng(8).random(8)}).set_index("A").groupby("A").groups))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).set_index("A").groupby("A").groups)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).set_index("A").groupby("A").ngroups)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',len(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).set_index("A").groupby("A").groups))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).groupby(["A","B"]).groups)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).groupby(["A","B"]).ngroups)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',len(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).groupby(["A","B"]).groups))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).groupby(["A","B"]).groups)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).groupby(["A","B"]).ngroups)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',len(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).groupby(["A","B"]).groups))
# for a0 in dir(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).groupby(["A","B"])):
    # try:
        # print(a0,getattr(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).groupby(["A","B"]),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).groupby(["A","B"])):
    # try:
        # listOfAttributes0.append(getattr(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).groupby(["A","B"]),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',method0,'\n',e)
# # for a0 in dir(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).groupby(["A","B"]).diff):
    # # try:
        # # print(a0,getattr(pandas.DataFrame({"A":["foo","foo","foo","foo","bar","bar","bar","bar"],"B":["one","one","one","one","two","two","three","three"],"C":numpy.random.default_rng(8).random(8)}).groupby(["A","B"]).diff,a0))
    # # except Exception as e:
        # # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# t0='2010-01-01'
# t1='2019-01-01'
# ti0='AAPL'
# import pandas_datareader
# d0=pandas_datareader.get_data_yahoo(ti0,start=t0,end=t1)
# print(d0)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.vstack([numpy.repeat("f",8),numpy.repeat("g",8)]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.vstack([numpy.repeat("h",4),numpy.repeat("i",4),numpy.repeat("j",4),numpy.repeat("k",4)]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.MultiIndex.from_arrays([numpy.hstack([numpy.repeat("f",8),numpy.repeat("g",8)]),numpy.hstack([numpy.repeat("h",4),numpy.repeat("i",4),numpy.repeat("j",4),numpy.repeat("k",4)])]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']]))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']]).shape[0])
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']])).groupby(level=0).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby(level='a').sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby(level=[0,1]).sum())
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby([0,1]).sum())
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',sys.exc_info(),'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby(['a','b']).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby(['a','col0']).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby([pandas.Grouper(level=0),'col0']).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby([pandas.Grouper(level='a'),'col0']).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby('col1')['col0'].sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c']))['col0'].groupby(pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c']))['col1']).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby('col0')['col1'].sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c']))['col1'].groupby(pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c']))['col0']).sum())
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c']))['col0'].groupby(pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c']))['a']).sum())
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# for name0,group0 in pandas.DataFrame({'col0':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby('a'):
    # print(name0,group0,sep='\n----\n',end='\n\n\n\n')
# for name0,group0 in pandas.DataFrame({'col0':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby(['a','b']):
    # print(name0,group0,sep='\n----\n',end='\n\n\n\n')
# import itertools
# for name0,group0 in itertools.groupby([1,1,1,1,2,2,3,3,3,4],key=None):
    # print(name0,group0,sep='\n----\n',end='\n\n\n\n')
# for name0,group0 in itertools.groupby([1,1,1,1,2,2,3,3,3,4],key=None):
    # print(name0,list(group0),sep='\n----\n',end='\n\n\n\n')
# for name0,group0 in itertools.groupby([1,1,1,1,2,2,3,3,3,4,1,1,2,2,2,3,3,3,3],key=None):
    # print(name0,list(group0),sep='\n----\n',end='\n\n\n\n')
# def key0(n0):
    # return n0-1
# for name0,group0 in itertools.groupby([1,1,1,1,2,2,3,3,3,4,1,1,2,2,2,3,3,3,3],key=key0):
    # print(name0,list(group0),sep='\n----\n',end='\n\n\n\n')
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.Series(numpy.arange(5),index=pandas.date_range('2023-01-21',periods=5,freq='2W')))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.Series(numpy.arange(5),index=pandas.date_range('2023-01-21',periods=5,freq='2W')).resample('M'))
# for name0,group0 in pandas.Series(numpy.arange(5),index=pandas.date_range('2023-01-21',periods=5,freq='2W')).resample('M'):
    # print(name0,list(group0),sep='\n----\n',end='\n\n\n\n')
# import pandas_profiling
# print(pandas_profiling.ProfileReport(pandas.DataFrame({'col0':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']]))))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby(['a']).get_group('f'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby(['a']).get_group('g'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby(['a','b']).get_group(('f','h')))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.random.default_rng(8).random(32)},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby(['a','b']).get_group(('f')))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':(('a'*16)+('b'*16)),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).aggregate is pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).agg)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).agg('prod'))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).agg(numpy.sum))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).agg([numpy.sum,numpy.prod,'count',lambda s0:s0.std()]))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).agg({'f0':numpy.sum,'f1':numpy.prod,'f2':['min','max']}))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).agg({'col0':numpy.sum,'col1':numpy.prod,'col2':['min','max'],'col3':numpy.sum}))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).dtypes)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).agg({'col0':numpy.sum}))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).groupby('col2').expanding().sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).rolling(window=2))
# for window0 in pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).rolling(window=2):
    # print(window0)
# for window0 in pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).rolling(window=3):
    # print(window0)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).rolling(window=2).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).rolling(window=3).sum())
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame({'col0':numpy.arange(32),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c'])).rolling(window=3).count())
# df0=pandas.DataFrame({'col0':numpy.arange(32,dtype=numpy.int_),'col1':numpy.random.default_rng(8).random(32),'col2':numpy.hstack([numpy.repeat('a',17),numpy.repeat('b',15)]),'col3':pandas.date_range('2023-01-21',periods=32,freq='D')},index=pandas.MultiIndex.from_product([['f','g'],['h','i','j','k'],['l','m','n','o']],names=['a','b','c']))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df0.dtypes)
# df0.loc[2:5,:]=numpy.nan
# for numeric_only0 in [True,False]:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df0.rolling(window=3).count(numeric_only=numeric_only0))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df0.dtypes)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',df0.rolling(window=3).dtypes)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',numpy.finfo(numpy.double).eps)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',1/numpy.finfo(numpy.double).eps)
# # py -3.10 -m timeit "'|'.join(str(n0) for n0 in range(100))"
# # py -3.10 -m timeit "'|'.join(str(n0) for n0 in range(100))"
# # py -3.10 -m timeit "'|'.join([str(n0) for n0 in range(100)])"
# # py -3.10 -m timeit "'|'.join((str(n0) for n0 in range(100),))"   #this errors
# # py -3.10 -m timeit "'|'.join(map(str,range(100)))"
# print('|'.join([str(n0) for n0 in range(100)]))
# print(timeit.timeit("'|'.join(str(n0) for n0 in range(100))",number=5000))
# print(timeit.timeit("'|'.join(str(n0) for n0 in range(100))",number=5000))
# print(timeit.timeit("'|'.join([str(n0) for n0 in range(100)])",number=5000))
# print(timeit.timeit("'|'.join(map(str,range(100)))",number=5000))
# print(timeit.timeit(stmt='pass',setup='pass',timer=time.perf_counter,number=1000000))
# a=123
# print(timeit.timeit(stmt='print(a,b,c,d)',setup='b=456\nc=78;d=90',timer=time.perf_counter,number=1000000,globals=globals()))
# print(timeit.timeit(stmt='print(a,b,c,d)',setup='b=456\nc=78;d=90\nprint(20000*7109310284)',timer=time.perf_counter,number=1000000,globals=globals()))
# a=123
# # print(timeit.timeit(stmt='print(a,b,c,d)',setup='b=456\nc=78;d=90',timer=time.perf_counter,number=100,globals=globals()))
# # print(timeit.timeit(stmt='print(a,b,c,d)',setup='b=456\nc=78;d=90\nprint(20000*7109310284234)',timer=time.perf_counter,number=100,globals=globals()))
# print(timeit.Timer(stmt='print(a,b,c,d)',setup='b=456\nc=78;d=90\nprint(20000*7109310284234)',timer=time.perf_counter,globals=globals()))
# timer0=timeit.Timer(stmt='print(a,b,c,d)',setup='b=456\nc=78;d=90\nprint(20000*7109310284234)',timer=time.perf_counter,globals=globals())
# timer0.timeit(number=100)
# timer0.repeat(50,number=100)
# timer0.repeat(repeat=5,number=1000000)
# timer0.autorange(callback=None)
# def callback0(number0,time_taken0):
    # print(f'How many times timeit was called f{number0} and total number of time for all the loops done EACH timeit call f{time_taken0}')
# timer0.autorange(callback=callback0)
# timer0=timeit.Timer(stmt='print(a,b,c,d)\nprint(a/0)',setup='b=456\nc=78;d=90\nprint(20000*7109310284234)',timer=time.perf_counter,globals=globals())
# try:
    # timer0.timeit(number=5)
# except Exception as e:
    # try:
        # timer0.print_exc(file=sys.stderr)
    # except Exception as e:
        # timer0.print_exc(file=sys.stdout)
        # print(e)
# py -3.10 -m timeit -n 10000 -r 3 -s print('abc') -p -u nsec -v "'|'.join(map(str,range(100)))"
# py -3.10 -m timeit -n 100 -r 3 -s print('abc') -p -u nsec -v -h "'|'.join(map(str,range(100)))"
# py -3.10 -m timeit --number=10000 --repeat=3 --setup=print('abc') --process --unit=nsec --verbose "'|'.join(map(str,range(100)))"
# py -3.10 -m timeit --number=100 --repeat=3 --setup=print('abc') --process --unit=nsec --verbose --help "'|'.join(map(str,range(100)))"
# py -3.10 -m timeit -n 10000 -r 3 -s "print('abc')" -s "for i in range(5):" -s "    print(i)" -p -u nsec -v "'|'.join(map(str,range(100)))"
# print(timeit.default_timer)
# print(timeit.default_timer())
# print(timeit.repeat('print(x+y)',setup='x=random.random()\ny=random.random()',number=1000,globals=globals()))
# a0=numpy.random.default_rng(8).integers(0,10,(500,500,500),endpoint=False)
# a1=numpy.random.default_rng(7).integers(0,10,(500,500,500),endpoint=False)
# print(timeit.timeit('a0+a1',number=20,globals=globals()))
# @numba.jit(nopython=True,nogil=True,cache=True,parallel=True)
# def add0(a0,a1):
    # return a0+a1
# print(timeit.timeit('add0(a0,a1)',number=20,globals=globals()))#numpy is already written in c so you're not going to get almost any speedups here.. (6.632620099931955 vs 5.918772000004537 (latest is jitted))
# print(timeit.timeit('numba.prange(10000)',number=1000,globals=globals()))
# print(timeit.timeit('numpy.arange(10000)',number=1000,globals=globals()))
# print(timeit.timeit('range(10000)',number=1000,globals=globals()))#how is this the fastest..
# print(pandas.describe_option())
# print(numba.get_num_threads())
# print(numba.set_num_threads(4))
# print(numba.get_num_threads())
# a0=numpy.random.default_rng(8).integers(0,10,(50000000),endpoint=False)
# @numba.vectorize
# def double0(x):
    # return x*2
# print(timeit.timeit('a0*2',number=20,globals=globals()))
# print(timeit.timeit('double0(a0)',number=20,globals=globals()))#slower than numpy (2.4416507999412715 vs numba 2.8174000000581145)
# a0=numpy.random.default_rng(8).integers(0,10,(50000000),endpoint=False)
# @numba.jit(nopython=True,nogil=True,cache=True,parallel=True)
# def double0(x):
    # return x*2
# print(timeit.timeit('a0*2',number=20,globals=globals()))
# print(timeit.timeit('double0(a0)',number=20,globals=globals()))#faster than numpy (2.4778214999241754 vs numba 2.017695799935609)
# try:
    # print(sys.abiflags)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# sys.addaudithook(print)
# sys.audit('event0')
# def weighted_mean(x):
    # arr = numpy.ones((1, x.shape[1]))
    # print(arr)
    # arr[:, :2] = (x[:, :2] * x[:, 2]).sum(axis=0) / x[:, 2].sum()
    # return arr
# df = pandas.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]])
# # df = pandas.DataFrame([1, 2, 0.6])
# # df = 5
# print(df)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]]).rolling(2,method='table',min_periods=0).apply(weighted_mean,raw=True,engine='numba'))
# def functionToSum0(ndarray0,p0,p1='kwPrinting0'):
    # # if ndarray0.ndim!=1:
        # # raise IndexError
    # # else:
        # # print(p0)
        # # return ndarray0[:].sum()#works for both ndarray0 and series0
    # print(p0,p1)
    # return ndarray0[:].sum()#works for both ndarray0 and series0
# print(pandas.DataFrame(numpy.arange(10)))
# print(pandas.DataFrame(numpy.arange(10)).rolling(2,min_periods=0,closed='both',center=True))
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]]).rolling(2,method='table',min_periods=0).apply(functionToSum0,raw=True,engine='numba',engine_kwargs={'nopython':False,'nogil':False,'parallel':False},args=('printMe0',),kwargs={'p1':'printMe1'}))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([1, 2, 0.6,4, 5, 0.7]).rolling(2,method='table',min_periods=0).apply(functionToSum0,raw=True,engine='numba',engine_kwargs={'nopython':False,'nogil':False,'parallel':False},args=('printMe0',),kwargs={'p1':'printMe1'}))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]]).rolling(2,method='table',min_periods=0))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1, 2, 0.6,2, 3, 0.4], [3, 4, 0.2,4, 5, 0.7]]).T)
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1, 2, 0.6,2, 3, 0.4], [3, 4, 0.2,4, 5, 0.7]]).T.rolling(1))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1, 2, 0.6,2, 3, 0.4], [3, 4, 0.2,4, 5, 0.7]]).T.rolling(3))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1, 2, 0.6,2, 3, 0.4], [3, 4, 0.2,4, 5, 0.7]]).T.rolling(9))
# print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',globals(),'\n',pandas.DataFrame([[1, 2, 0.6,2, 3, 0.4], [3, 4, 0.2,4, 5, 0.7]]).T.rolling(9,min_periods=0))
# print(pandas.DataFrame([[1, 2, 3,5,7,9],[21,17,14,8,3,1]]).T)
# print('\n'*5)
# for i in pandas.DataFrame([[1, 2, 3,5,7,9],[21,17,14,8,3,1]]).T.rolling(1):
    # print(i)
# print('\n'*5)
# for i in pandas.DataFrame([[1, 2, 3,5,7,9],[21,17,14,8,3,1]]).T.rolling(3):
    # print(i)
# print('\n'*5)
# for i in pandas.DataFrame([[1, 2, 3,5,7,9],[21,17,14,8,3,1]]).T.rolling(9):
    # print(i)
# print('\n'*5)
# for i in pandas.DataFrame([[1, 2, 3,5,7,9],[21,17,14,8,3,1]]).T.rolling(9,min_periods=0):
    # print(i)
# print('\n'*5)
# for i in pandas.DataFrame([[1, 2, 3,5,7,9],[21,17,14,8,3,1]]).T.rolling(9,min_periods=3):
    # print(i)
# print('\n'*5)
# for i in pandas.DataFrame([[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T.rolling(9,min_periods=0):
    # print(i)
# print('\n'*5)
# for i in pandas.DataFrame([[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T.rolling(9,min_periods=3):
    # print(i)
# print('\n'*5)
# for i in pandas.DataFrame([[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T.rolling(9,min_periods=8):
    # print(i)
# print(pandas.DataFrame([[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T.rolling(9,min_periods=0).sum())
# print('\n'*5)
# print(pandas.DataFrame([[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T.rolling(9,min_periods=3).sum())
# print('\n'*5)
# print(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T)
# print('\n'*5)
# print(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T.rolling(4,min_periods=3,axis=1).sum())
# print('\n'*5)
# print(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T)
# print('\n'*5)
# # print(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T.rolling(4,min_periods=3,axis=1,window='gaussian').sum())
# # print(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T.rolling(4,min_periods=3,axis=1,step=2).sum())
# # print(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T.rolling(4,min_periods=3,axis=1,step=3).sum())
# # print(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T.rolling(4,min_periods=3,axis=1,center=False).sum())
# # print(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T.rolling(4,min_periods=3,axis=1,center=True).sum())
# # print(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T.rolling(4,min_periods=3,axis=1,method='table').sum(engine='numba'))#don't actually have to import numba to use numba (installed is enough)
# # for closed0 in ['right','left','neither','both']:
    # # print(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T.rolling(4,min_periods=3,axis=1,closed=closed0).sum())
# # print(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1]]).T.rolling(4,min_periods=3,axis=1,closed='both',center=True).sum())
# print(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1],pandas.date_range('2023-02-06',freq='1D',periods=6)]).T)
# # print(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1],{'dates0':pandas.date_range('2023-02-06',freq='1D',periods=6)}]).T)
# print(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1],pandas.date_range('2023-02-06',freq='1D',periods=6)],columns=[0,1,2,3,4,'dates0']).T)
# print(pandas.DataFrame(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1],pandas.date_range('2023-02-06',freq='1D',periods=6)]).T))
# print(pandas.DataFrame(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1],pandas.date_range('2023-02-06',freq='1D',periods=6)]).T,columns=[0,1,2,3,4,5,'dates0']))
# print(pandas.DataFrame(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1],pandas.date_range('2023-02-06',freq='1D',periods=6)]).T).rename(columns={6:'dates0'}))#rename works but passing 'columns' in pandas.DataFrame [constructor] doesn't..
# print(pandas.DataFrame(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1],pandas.date_range('2023-02-06',freq='1D',periods=6)]).T).rename(columns={6:'dates0'}).rolling(4,min_periods=3,axis=0,closed='both',center=True).sum())
# # print(pandas.DataFrame(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1],pandas.date_range('2023-02-06',freq='1D',periods=6)]).T).rename(columns={6:'dates0'}).rolling('2D',min_periods=3,axis=0,closed='both',center=True,on='dates0').sum())
# # print(pandas.DataFrame(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1],pandas.date_range('2023-02-06',freq='1D',periods=6)]).T).rename(columns={6:'dates0'}).rolling('4D',min_periods=3,axis=0,closed='both',center=True,on='dates0').sum())
# print(pandas.DataFrame(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1],pandas.date_range('2023-02-06',freq='1D',periods=6)]).T).rename(columns={6:'dates0'}).rolling(4,min_periods=3,axis=0,closed='both',center=True,win_type='blackman').sum())
# print(pandas.DataFrame(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1],pandas.date_range('2023-02-06',freq='1D',periods=6)]).T).rename(columns={6:'dates0'}).rolling(4,min_periods=3,axis=0,closed='both',center=True,win_type='bartlett').sum())
# print(pandas.DataFrame(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1],pandas.date_range('2023-02-06',freq='1D',periods=6)]).T).rename(columns={6:'dates0'}).rolling(4,min_periods=3,axis=0,closed='both',center=True,win_type='gaussian').sum(std=3))
# print(pandas.DataFrame(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1],pandas.date_range('2023-02-06',freq='1D',periods=6)]).T).rename(columns={6:'dates0'}).rolling(4,min_periods=3,axis=0,closed='both',center=True,win_type='blackman').prod())
# print(pandas.DataFrame(pandas.DataFrame([[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[1, 2, 3,5,7,9],[21,numpy.nan,numpy.nan,numpy.nan,numpy.nan,1],pandas.date_range('2023-02-06',freq='1D',periods=6)]).T).rename(columns={6:'dates0'}).rolling(4,min_periods=3,axis=0,closed='both',center=True,win_type='bartlett').prod())
# def functionToSum0(ndarray0,p0,p1='kwPrinting0'):
    # print(p0,p1)
    # return None
    # return numpy.sum(ndarray0,where=ndarray0!=numpy.nan)#works for both ndarray0 and series0
# print(pandas.DataFrame(numpy.arange(10)))
# print(pandas.DataFrame(numpy.arange(10)).rolling(2,min_periods=0,closed='both',center=True).apply(numpy.sum))
# print(pandas.DataFrame(numpy.arange(10)).rolling(2,min_periods=0,closed='both',center=True).apply(functionToSum0))
# def weighted_mean(x):
    # print('this is x',x)
    # arr = numpy.ones((1, x.shape[1]))
    # print('this is arr',arr)
    # print('n0',arr[:, :-1])
    # print('n0',x[:, :-1])
    # print('n0',x[:, -1])
    # print('n0',(x[:, :-1] * x[:, -1]))
    # print('n0',(x[:, :-1] * x[:, -1]).sum(axis=0))
    # print('n0',x[:, -1])
    # print('n0',x[:, -1].sum())
    # arr[:, :-1] = (x[:, :-1] * x[:, -1]).sum(axis=0) / x[:, -1].sum()
    # print('this is arr',arr)
    # return arr
# print(pandas.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]]).rolling(2,method='table',min_periods=0).apply(weighted_mean,raw=True,engine='numba'))
# def functionToSum0(ndarray0):
    # print('this is ndarray0',ndarray0)
    # arr=numpy.ones((1,ndarray0.shape[1]))
    # print('this is arr',arr)
    # print('n0',arr[:, :-1])
    # print('n0',ndarray0[:, :-1])
    # print('n0',ndarray0[:, -1])
    # print('n0',(ndarray0[:, :-1] * ndarray0[:, -1]))
    # print('n0',(ndarray0[:, :-1] * ndarray0[:, -1]).sum(axis=0))
    # print('n0',ndarray0[:, -1])
    # print('n0',ndarray0[:, -1].sum())
    # arr[:,:-1]=(ndarray0[:,:-1]*ndarray0[:,-1]).sum(axis=0)/ndarray0[:,-1].sum()
    # print('this is arr',arr)
    # return arr
# print(pandas.DataFrame(numpy.arange(10)))
# print(pandas.DataFrame(numpy.arange(28).reshape(4,7).copy('C')).rolling(2,method='table',min_periods=0).apply(functionToSum0,raw=True,engine='numba'))
# def weighted_mean(x):
    # return numpy.sum(x,axis=0)
# print(pandas.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]]).rolling(2,method='table',min_periods=0).apply(weighted_mean,raw=True,engine='numba'))#same result as below method='single' no engine='numba'
# def weighted_mean(x):
    # return numpy.sum(x.values,axis=0)
# print(pandas.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]]).rolling(2,method='single',min_periods=0).apply(weighted_mean,raw=False))
# def weighted_mean(x,p0,p1='randomPrint1'):
    # print(p0,p1)
    # return numpy.sum(x.values,axis=0)
# print(pandas.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]]).rolling(2,method='single',min_periods=0).apply(weighted_mean,raw=False,args=('printMe0',),kwargs={'p1':'printMe1'}))
# print(numpy.array([[(1,'a')],[(2,'b')]],dtype={'names':['int0','str0'],'formats':['i4','U4']}),numpy.array([[(1,'a')],[(2,'b')]],dtype={'names':['int0','str0'],'formats':['i4','U4']}).dtype)
# try:
    # print(pandas.DataFrame(numpy.array([[(1,'a')],[(2,'b')]],dtype={'names':['int0','str0'],'formats':['i4','U4']})))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(pandas.DataFrame(numpy.array([(1,'a'),(2,'b')],dtype={'names':['int0','str0'],'formats':['i4','U4']}),index=numpy.arange(numpy.array([(1,'a'),(2,'b')],dtype={'names':['int0','str0'],'formats':['i4','U4']}).size,0,-1),columns=['int0'],dtype=numpy.float_,copy=True))
# point0=dataclasses.make_dataclass("point0",[("x",'i4'),('y','i4'),('z','f4')])
# # print(pandas.DataFrame([point0(2,2,4.),point0(3,3,6.)]))
# print(pandas.DataFrame([point0(1,2,4.),point0(7,3,6.)]))
# print(pandas.DataFrame([point0(1,2,4.),point0(7,3,6.)]).at[0,'x'])
# print(pandas.DataFrame([point0(1,2,4.),point0(7,3,6.)]).at[1,'y'])
# df0=pandas.DataFrame([point0(1,2,4.),point0(7,3,6.)])
# df0.at[1,'y']=9
# print(df0)
# print(df0.at[1,'y'])
# print(pandas.DataFrame([point0(1,2,4.),point0(7,3,6.)]).loc[1].at['y'])
# print(pandas.DataFrame([point0(1,2,4.),point0(7,3,6.)]).iloc[:,1].iat[1])
# def ij0(ie0,je0):
    # for i in range(ie0):
        # for j in range(je0):
            # yield i,j#of course can't use return (will error) since iterable..
# for i,j in ij0(4,4):
    # print(i,j)
# print(pandas.DataFrame(ij0(4,4)))
# tuples = [
   # ('cobra', 'mark i'), ('cobra', 'mark ii'),
   # ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
   # ('viper', 'mark ii'), ('viper', 'mark iii')
# ]
# index = pandas.MultiIndex.from_tuples(tuples)
# values = [[12, 2], [20, 24], [10, 20],
        # [21, 34], [17, 26], [36, 56]]
# df4 = pandas.DataFrame(values, columns=['max_speed', 'shield'], index=index)
# print(df4)
# print(df4.loc[('cobra','mark i')])
# print(df4.iloc[0])
# print(df4.loc[('viper','mark iii')])
# print(df4.loc[[('viper','mark iii')]])
# print(df4.iloc[-1])
# print(df4.iloc[[-1]])
# print(df4.loc[[('cobra')]])
# print(df4.iloc[0:1])#like python indexing (UNLIKE loc)
# print(df4.iloc[0:2])
# print(df4.loc[('cobra',):('viper',)])
# print(df4.iloc[0:-1])
# print(df4.iloc[0:])
# print(df4.loc[('sidewinder','mark i'):('viper','mark ii')])
# print(df4.iloc[2:-1])
# print(df4.loc[('sidewinder','mark i'):('viper','mark ii')][::2])
# print(df4.iloc[2:-1:2])
# print(df4.loc[('sidewinder','mark i'):('viper','mark iii')][::2])
# print(df4.iloc[2::2])
# try:
    # print(df4.loc[('cobra',),('viper',)])
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(df4.loc[[('cobra',),('viper',)]])
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(df4.loc[['cobra','viper']])
# print(df4.iloc[[2,3,4,5]])
# try:
    # print(df4.loc[False,False,True,True,True,True])
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(df4.loc[[False,False,True,True,True,True]])
# try:
    # print(df4.loc[pandas.Series([False,True],index=pandas.Series(['mark i','mark ii']))])
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(pandas.Series([False,True,False,True],index=pandas.MultiIndex.from_product([['cobra','sidewinder'],['mark i','mark ii']])))
# try:
    # print(df4.loc[pandas.Series([False,True,False,True],index=pandas.MultiIndex.from_product([['cobra','sidewinder'],['mark i','mark ii']]))])
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(df4.loc[lambda dft4: dft4[:,'max_speed']>=20])
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(df4.loc[lambda dft4: dft4['max_speed']>=20])
# print(pandas.Series(numpy.arange(4),index=numpy.arange(4,8,1)).loc[pandas.Series([True,True,False,False],index=numpy.arange(4,8,1))])
# print(pandas.MultiIndex.from_product([['cobra','sidewinder'],['mark i','mark ii']]))
# print(pandas.Series([False,True,False,True],index=pandas.MultiIndex.from_product([['cobra','sidewinder'],['mark i','mark ii']])))
# print(df4.loc[pandas.Series([False,True,False,True,False,True],index=pandas.MultiIndex.from_tuples([('cobra','mark i'),('cobra','mark ii'),('sidewinder','mark i'),('sidewinder','mark ii'),('viper','mark ii'),('viper','mark iii')]))])
# try:
    # eval('''print(df4.iloc[(0,:)])''')
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(df4.iloc[(0,0):(1,1)])
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(df4.iloc[lambda dft4: dft4.iloc[:,0]>=20])
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(df4.iloc[lambda dft4: 1])
# print(df4.iloc[lambda dft4: 0 if numpy.array_equal(dft4.iloc[0,0],numpy.array([12])) else -1])
# print(df4.iloc[lambda dft4: 0 if numpy.array_equal(dft4.iloc[0,0],12) else -1])
# try:
    # print(df4.iloc[lambda dft4: dft4.iloc[1]])
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # eval('''print(df4.iloc[lambda dft4: dft4.iloc[0,0]==12 if dft4.iloc[:,1]])''')
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(df4.iloc[[0,-1],[1]])
# print(df4.iloc[[0,-1],[0,1]])
# print(df4.iloc[:,lambda dft4: 0 if numpy.all(dft4) else 1])
# print(df4.iloc[:,0])
# print(df4.iloc[:,0].at[('cobra','mark i')])
# print(df4.iloc[:,0].iat[0])
# print(df4.xs('max_speed',axis=1))
# print(df4.xs('max_speed',axis=1,drop_level=False))
# print(df4.xs('mark i',level=1,axis=0,drop_level=False))
# try:
    # print(df4.xs('mark i'))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(df4.xs('cobra'))
# def ij0(ie0,je0):
    # for i in range(ie0):
        # for j in range(je0):
            # yield i,j#of course can't use return (will error) since iterable..
# print(df4.axes)
# print(pandas.DataFrame(ij0(4,4)).axes)
# print(df4.dtypes)#column as indices (not MultiIndex)
# print(pandas.DataFrame(ij0(4,4)).dtypes)
# print(df4.empty)
# print(pandas.DataFrame(ij0(4,4)).empty)
# print(pandas.DataFrame({'col0':[],'col1':[]}).empty)
# print(pandas.Series([]).empty)
# print(pandas.Series({'col0':[]}).empty)
# print(pandas.DataFrame({'col0':[numpy.nan],'col1':[numpy.nan]}).empty)
# print(pandas.Series([numpy.nan]).empty)
# print(df4.attrs)
# print(pandas.DataFrame(ij0(4,4)).attrs)
# ijDf0=pandas.DataFrame(ij0(4,4))
# ijDf0.attrs={'info0':'dataforInfo0','info1':'dataforInfo1'}
# print(ijDf0.attrs)
# print(ijDf0.flags)
# print(df4.flags)
# ijDf0['l0']='l0v0'
# print(ijDf0.columns)
# ijDf0.flags.allows_duplicate_labels=False
# print(ijDf0.flags.allows_duplicate_labels)
# ijDf0.flags['allows_duplicate_labels']=False
# print(ijDf0.flags.allows_duplicate_labels)
# print(ijDf0.flags)
# print(ijDf0.columns)
# list0=ijDf0.columns.tolist()
# list0.append('l0')
# try:
    # ijDf0=ijDf0[list0]
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(ijDf0.columns)
# print(df4.to_numpy())
# print(pandas.DataFrame(ij0(4,4)).to_numpy())
# print(pandas.DataFrame({'col0':[],'col1':[]}).to_numpy())
# print(pandas.Series([]).to_numpy())
# print(pandas.Series({'col0':[]}).to_numpy())
# print(pandas.DataFrame({'col0':[numpy.nan],'col1':[numpy.nan]}).to_numpy())
# print(pandas.Series([numpy.nan]).to_numpy())
# print(df4.values)
# print(pandas.DataFrame(ij0(4,4)).values)
# print(pandas.DataFrame({'col0':[],'col1':[]}).values)
# print(pandas.Series([]).values)
# print(pandas.Series({'col0':[]}).values)
# print(pandas.DataFrame({'col0':[numpy.nan],'col1':[numpy.nan]}).values)
# print(pandas.Series([numpy.nan]).values)
# print(df4.size)
# print(pandas.DataFrame(ij0(4,4)).size)
# print(pandas.DataFrame({'col0':[],'col1':[]}).size)
# print(pandas.Series([]).size)
# print(pandas.Series({'col0':[]}).size)
# print(pandas.DataFrame({'col0':[numpy.nan],'col1':[numpy.nan]}).size)
# print(pandas.Series([numpy.nan]).size)
# print(df4.shape)
# print(pandas.DataFrame(ij0(4,4)).shape)
# print(pandas.DataFrame({'col0':[],'col1':[]}).shape)
# print(pandas.Series([]).shape)
# print(pandas.Series({'col0':[]}).shape)
# print(pandas.DataFrame({'col0':[numpy.nan],'col1':[numpy.nan]}).shape)
# print(pandas.Series([numpy.nan]).shape)
# print(df4.ndim)
# print(pandas.DataFrame(ij0(4,4)).ndim)
# print(pandas.DataFrame({'col0':[],'col1':[]}).ndim)
# print(pandas.Series([]).ndim)
# print(pandas.Series({'col0':[]}).ndim)
# print(pandas.DataFrame({'col0':[numpy.nan],'col1':[numpy.nan]}).ndim)
# print(pandas.Series([numpy.nan]).ndim)
# print(pandas.Series({'col0':[]}).empty)
# print(pandas.DataFrame([[1,numpy.nan],[3,4]]).to_numpy(dtype=None,copy=False).dtype)
# print(pandas.DataFrame([[1,numpy.nan],[3,4]]).to_numpy(dtype=numpy.float32,copy=True).dtype)
# try:
    # print(pandas.DataFrame([[1,numpy.nan],[3,4]]).to_numpy(dtype=numpy.float32,copy=True,na_value='str0').dtype)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(pandas.DataFrame([[1,numpy.nan],[3,4]]).to_numpy(dtype=None,copy=True,na_value='str0').dtype)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(pandas.DataFrame([[1,numpy.nan],[3,4]]).to_numpy(dtype=numpy.object_,copy=True,na_value='str0').dtype)#upcasting happens on 0th axis ? but doesn't upcast all if going to object (e.g. int -> a1 0th axis float -STOP-> go to object, so a0 0th axis is not affected and is just regular python object; no upcasting)
# print(pandas.DataFrame([[1,numpy.nan],[3,4]]).to_numpy(dtype=numpy.object_,copy=True,na_value='str0'))
# print(type(pandas.DataFrame([[1,numpy.nan],[3,4]]).to_numpy(dtype=numpy.object_,copy=True,na_value='str0')[(0,0)]))
# print(type(pandas.DataFrame([[1,numpy.nan],[3,4]]).to_numpy(dtype=numpy.object_,copy=True,na_value='str0')[(1,1)]))
# print(pandas.MultiIndex.from_tuples([('cobra','mark i'),('cobra','mark ii'),('sidewinder','mark i'),('sidewinder','mark ii'),('viper','mark ii'),('viper','mark iii')]).to_numpy())
# print(pandas.Series(pandas.Categorical(['c0','c1','c0','c0'])).array)
# print(pandas.date_range('2023',periods=3,freq='1Y').array)
# # print(pandas.date_range('2023',periods=3).array)#defaults to days, not the default of the passed date string..
# print(pandas.Series(pandas.Categorical(['c0','c1','c0','c0'])).to_numpy())
# print(pandas.date_range('2023',periods=3,freq='1Y').to_numpy())
# try:
    # print(pandas.Series(pandas.Categorical(['c0','c1','c0','c0'])).style)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# try:
    # print(pandas.date_range('2023',periods=3,freq='1Y').style)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(pandas.DataFrame([[1,numpy.nan],[3.,4]]).style)
# print(dir(pandas.DataFrame([[1,numpy.nan],[3.,4]]).style))
# for a0 in dir(pandas.DataFrame([[1,numpy.nan],[3.,4]]).style):
    # try:
        # print(a0,getattr(pandas.DataFrame([[1,numpy.nan],[3.,4]]).style,a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.DataFrame([[1,numpy.nan],[3.,4]]).style):
    # try:
        # listOfAttributes0.append(getattr(pandas.DataFrame([[1,numpy.nan],[3.,4]]).style,a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',method0,'\n',e)

# print(pandas.io.formats.style.Styler)
# print(pandas.options.styler.format.precision)
# print(pandas.options.styler.format.na_rep)
# print(pandas.options.styler.format.decimal)
# print(pandas.options.styler.format.thousands)
# print(pandas.options.styler.format.escape)
# print(pandas.options.styler.format.formatter)
# stylerto_html0=pandas.io.formats.style.Styler(pandas.DataFrame([[1,numpy.nan],[3.,4]]),precision=pandas.options.styler.format.precision).to_html()
# stylerto_html1=pandas.io.formats.style.Styler(pandas.DataFrame([['''&^#><'"''',numpy.nan],[3.,40000000]]),precision=3,table_attributes='tableAttributes0'+datetime.datetime.today().strftime('%Y%m%d'),table_styles=[{'selector':'tr','props':[('border','3px solid')]}],caption='thisIsAClosedCaption'+datetime.datetime.today().strftime('%Y%m%d'),cell_ids=True,uuid_len=32,thousands='.',decimal=',',formatter=None,escape='html',na_rep='iMNA!!!').to_html()
# stylerto_html10=pandas.io.formats.style.Styler(pandas.DataFrame([['''&^#><'"''',numpy.nan],[3.,40000000]]),precision=3,table_attributes='tableAttributes0'+datetime.datetime.today().strftime('%Y%m%d'),table_styles=[{'selector':'tr','props':[('border','3px solid')]}],caption='thisIsAClosedCaption'+datetime.datetime.today().strftime('%Y%m%d'),cell_ids=True,uuid_len=32,thousands='.',decimal=',',formatter=None,escape='latex',na_rep='iMNA!!!').to_html()
# stylerto_html10=pandas.io.formats.style.Styler(pandas.DataFrame([['''&^#><'"''',numpy.nan],[3.,40000000]]),precision=3,table_attributes='tableAttributes0'+datetime.datetime.today().strftime('%Y%m%d'),table_styles=[{'selector':'tr','props':[('border','3px solid')]}],caption='thisIsAClosedCaption'+datetime.datetime.today().strftime('%Y%m%d'),cell_ids=True,uuid_len=32,thousands=',',decimal='.',formatter={1:'{:+.4e}'},escape='latex',na_rep='iMNA!!!').to_html()
# stylerto_html10=pandas.io.formats.style.Styler(pandas.DataFrame([['''&^#><'"''',numpy.nan],[3.,40000000]]),precision=3,table_attributes='tableAttributes0'+datetime.datetime.today().strftime('%Y%m%d'),table_styles=[{'selector':'tr','props':[('border','3px solid')]}],caption='thisIsAClosedCaption'+datetime.datetime.today().strftime('%Y%m%d'),cell_ids=True,uuid_len=32,thousands=',',decimal='.',formatter={1:'this is the number: {:+.4e}'},escape='latex',na_rep='iMNA!!!').to_html()
# def formatToType0(data0):
    # if type(data0)==int:
        # return 'iMInt'
    # else:
        # return 'iMNotInt'
# stylerto_html10=pandas.io.formats.style.Styler(pandas.DataFrame([['''&^#><'"''',2],[numpy.nan,40]]),precision=3,table_attributes='tableAttributes0'+datetime.datetime.today().strftime('%Y%m%d'),table_styles=[{'selector':'tr','props':[('border','3px solid')]}],caption='thisIsAClosedCaption'+datetime.datetime.today().strftime('%Y%m%d'),cell_ids=True,uuid_len=32,thousands=',',decimal='.',formatter=formatToType0,escape='latex',na_rep='iMNA!!!').to_html()
# stylerto_html10=pandas.io.formats.style.Styler(pandas.DataFrame([['''&^#><'"''',2],[numpy.nan,40]]),precision=3,table_attributes='tableAttributes0'+datetime.datetime.today().strftime('%Y%m%d'),table_styles=[{'selector':'tr','props':[('border','3px solid')]}],caption='thisIsAClosedCaption'+datetime.datetime.today().strftime('%Y%m%d'),cell_ids=True,uuid_len=32,thousands=',',decimal='.',formatter=formatToType0,escape='latex',na_rep='iMNA!!!').to_html()
# pandas.DataFrame([['''&^#><'"''',1,1],[0,-1,40]]).style.applymap(lambda v: "number-format: 0Ãµ[Red](0)Ãµ-Ãµ@;").to_excel(r'c:\users\pdumas\Downloads\p_pd20230208.2.xlsx')
# os.system(r'start "" "c:\users\pdumas\Downloads\p_pd20230208.2.xlsx"')
# # stylerto_html2=pandas.io.formats.style.Styler(pandas.DataFrame([[1,numpy.nan],[3.,4]]),precision=3,table_attributes='tableAttributes0'+datetime.datetime.today().strftime('%Y%m%d'),table_styles=[{'selector':'tr:hover','props':[('border','3px solid')]}],caption='thisIsAClosedCaption',cell_ids=True).set_table_styles({0:[{'selector':'td','props':'background-color: green; font-size: 8;'},{'selector':'th','props':'background-color: yellow; font-size: 20;'}]},axis=1).set_table_styles({0:[{'selector':'td','props':'background-color: red;'},{'selector':'th','props':'background-color: blue;'}]},axis=1,overwrite=False,css_class_names={'row':'row0','data':'dataPoint0'}).to_html()
# stylerto_html2=pandas.io.formats.style.Styler(pandas.DataFrame([[1,numpy.nan],[3.,4]]),precision=3,table_attributes='tableAttributes0'+datetime.datetime.today().strftime('%Y%m%d'),table_styles=[{'selector':'tr:hover','props':[('border','3px solid')]}],caption='thisIsAClosedCaption',cell_ids=True).set_table_styles({0:[{'selector':'td','props':'background-color: green; font-size: 8;'},{'selector':'th','props':'background-color: yellow; font-size: 20;'}]},axis=1).set_table_styles({0:[{'selector':'td','props':'background-color: red;'},{'selector':'th','props':'background-color: blue;'}]},axis=1,overwrite=False,css_class_names={'row':'row0','data':'dataPoint0'}).to_excel(r'C:\users\pdumas\Downloads\p_pd20230208.xlsx')#to_excel does NOT translate css formatting to Excel xml formatting..
# stylerto_html3=pandas.io.formats.style.Styler(pandas.DataFrame([[100000,2.000000],[r'https://answers.sap.com/questions/12143779/rfc-system-error-in-smt1.html',numpy.nan]])).format(formatter='{:+.3e}',subset=[0],precision=2,na_rep='iAmNA',thousands='.',decimal=',',hyperlinks='html',escape='html').to_html()
# stylerto_html3=pandas.io.formats.style.Styler(pandas.DataFrame([[100000,2.000000],[r'https://answers.sap.com/questions/12143779/rfc-system-error-in-smt1.html',numpy.nan]])).format(formatter=None,subset=[0],precision=2,na_rep='iAmNA',thousands='.',decimal=',',hyperlinks='html',escape='html').to_html()
# stylerto_html3=pandas.io.formats.style.Styler(pandas.DataFrame([[100000,2.000000],[r'https://answers.sap.com/questions/12143779/rfc-system-error-in-smt1.html',numpy.nan]])).format(formatter=None,subset=None,precision=2,na_rep='iAmNA',thousands='.',decimal=',',hyperlinks='html',escape='html').to_html()
# stylerto_html3=pandas.io.formats.style.Styler(pandas.DataFrame([[100000,2.000000],[r'https://answers.sap.com/questions/12143779/rfc-system-error-in-smt1.html',numpy.nan]])).format(formatter=None,subset=None,precision=2,na_rep='iAmNA',thousands='.',decimal=',',hyperlinks='latex',escape='latex').to_html()
# stylerto_html3=pandas.io.formats.style.Styler(pandas.DataFrame([[100000,2.000000],[100000,2.000000]])).format(formatter={1:'{:+.3e}'},subset=[1],precision=2,na_rep='iAmNA',thousands='.',decimal=',',hyperlinks='html',escape='html').to_html()
# stylerto_html3=pandas.io.formats.style.Styler(pandas.DataFrame([[100000,2.000000],[100000,2.000000]])).format(formatter={1:'{:+.3e}'},subset=[0],precision=2,na_rep='iAmNA',thousands='.',decimal=',',hyperlinks='html',escape='html').to_html()#when there is conflict (subset is x; formatter is dict with key as y; x and y no overlap; nothing / no formatting happens! makes sense
# def apply0(dataFrameOrSeries0,colorForBackground0):
    # return numpy.where(dataFrameOrSeries0==numpy.nanmin(dataFrameOrSeries0),f'background-color: {colorForBackground0};',None)
# stylerto_html4=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(4,4))).style.apply(apply0,colorForBackground0='blue').to_html()
# stylerto_html5=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(4,4))).style.apply(apply0,colorForBackground0='blue',axis=0).to_html()
# stylerto_html6=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(4,4))).style.apply(apply0,colorForBackground0='blue',axis=1).to_html()
# stylerto_html7=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(4,4))).style.apply(apply0,colorForBackground0='blue',axis=None).to_html()
# stylerto_html8=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(4,4))).style.apply(apply0,colorForBackground0='blue',axis=None,subset=(slice(1,4,2),[1,3])).to_html()
# tuples = [
   # ('cobra', 'mark i'), ('cobra', 'mark ii'),
   # ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
   # ('viper', 'mark ii'), ('viper', 'mark iii')
# ]
# index = pandas.MultiIndex.from_tuples(tuples)
# values = [[12, 2], [20, 24], [10, 20],
        # [21, 34], [17, 26], [36, 56]]
# df4 = pandas.DataFrame(values, columns=['max_speed', 'shield'], index=index)
# def apply0(dataFrameOrSeries0index0,colorForBackground0):
    # # return numpy.where(dataFrameOrSeries0index0==numpy.nanmin(dataFrameOrSeries0index0),f'background-color: {colorForBackground0};',None)
    # print(dataFrameOrSeries0index0,'endTest0')
    # return numpy.where(dataFrameOrSeries0index0.str.contains('i'),f'background-color: {colorForBackground0};','')
# stylerto_html4=df4.style.apply_index(apply0,colorForBackground0='blue').to_html()
# stylerto_html5=df4.style.apply_index(apply0,colorForBackground0='blue',axis=0).to_html()
# stylerto_html6=df4.style.apply_index(apply0,colorForBackground0='blue',axis=1).to_html()
# stylerto_html7=df4.style.apply_index(apply0,colorForBackground0='blue',axis=0,level=0).to_html()
# try:
    # stylerto_html8=df4.style.apply_index(apply0,colorForBackground0='blue',axis=None,level=1).to_html()
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# stylerto_html8=df4.style.apply_index(apply0,colorForBackground0='blue',axis=0,level=1).to_html()
# def applymap0(dataFrameOrSeries0element0,colorForBackground0):
    # return f'background-color: {colorForBackground0};' if dataFrameOrSeries0element0<23 else None
# stylerto_html4=df4.style.applymap(applymap0,colorForBackground0='blue').to_html()
# stylerto_html5=df4.style.applymap(applymap0,colorForBackground0='blue',subset=['max_speed']).to_html()
# try:
    # stylerto_html6=df4.style.applymap(applymap0,colorForBackground0='blue',subset=['mark i']).to_html()
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# stylerto_html6=df4.style.applymap(applymap0,colorForBackground0='blue',subset=(slice(('cobra','mark i'),('sidewinder','mark ii'),1))).to_html()
# def applymap_index0(dataFrameOrSeries0index0,colorForBackground0):
    # return f'background-color: {colorForBackground0};' if "i" in dataFrameOrSeries0index0 else None
# stylerto_html4=df4.style.applymap_index(applymap_index0,colorForBackground0='blue').to_html()
# stylerto_html5=df4.style.applymap_index(applymap_index0,colorForBackground0='blue',axis=0).to_html()
# stylerto_html6=df4.style.applymap_index(applymap_index0,colorForBackground0='blue',axis=1).to_html()
# stylerto_html7=df4.style.applymap_index(applymap_index0,colorForBackground0='blue',axis=1,level=0).to_html()#if not MultiIndex, 'level' is irrelevant/ignored; in this case, 'shield' gets background-color blue
# stylerto_html8=df4.style.applymap_index(applymap_index0,colorForBackground0='blue',axis=0,level=1).to_html()
# tuples = [
   # ('cobra', 'mark i'), ('cobra', 'mark ii'),
   # ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
   # ('viper', 'mark ii'), ('viper', 'mark iii')
# ]
# index = pandas.MultiIndex.from_tuples(tuples)
# values = [12, 2,20, 24,10, 20]
# s4 = pandas.Series(values, index=index)
# print(s4)
# stylerto_html4=df4.style.background_gradient().to_html()
# stylerto_html5=df4.style.background_gradient(cmap='YlOrRd').to_html()
# stylerto_html6=df4.style.background_gradient(vmin=15,vmax=32).to_html()
# stylerto_html7=df4.style.background_gradient(vmin=15,vmax=32,low=.5,high=.9).to_html()
# stylerto_html8=df4.style.background_gradient(vmin=15,vmax=32,low=.5,high=.9,subset=['max_speed']).to_html()
# stylerto_html9=df4.style.background_gradient(vmin=15,vmax=32,low=.5,high=.9,axis=1).to_html()
# stylerto_html0=df4.style.background_gradient(vmin=15,vmax=32,low=.5,high=.9,text_color_threshold=0).to_html()
# stylerto_html1=df4.style.background_gradient(vmin=15,vmax=32,low=.5,high=.9,text_color_threshold=1).to_html()
# stylerto_html2=df4.style.background_gradient(cmap='PuBu',vmin=15,vmax=32,low=.5,high=.9,subset=['max_speed'],gmap=[0,1,1,1,4,5]).to_html()
# stylerto_html3=df4.style.background_gradient(cmap='PuBu',vmin=15,vmax=32,low=.5,high=.9,subset=['max_speed','shield'],gmap=[0,1,16,23,32,52]).to_html()
# stylerto_html10=df4.style.background_gradient(vmin=15,vmax=32,low=.5,high=.9,axis=None).to_html()
# stylerto_html10=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.background_gradient(axis=0).to_html()
# stylerto_html11=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.background_gradient(axis=1).to_html()
# stylerto_html12=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.background_gradient(axis=None).to_html()
# stylerto_html0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=0,subset=None,vmin=None,vmax=None,width=100,height=100,cmap=None,color=None,props='width: 10em;',align='mid').to_html()
# stylerto_html1=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=1,subset=None,vmin=None,vmax=None,width=100,height=100,cmap=None,color=None,props='width: 10em;',align='mid').to_html()
# stylerto_html2=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=None,vmin=None,vmax=None,width=100,height=100,cmap=None,color=None,props='width: 10em;',align='mid').to_html()
# stylerto_html3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=([1,3],[2,4]),vmin=None,vmax=None,width=100,height=100,cmap=None,color=None,props='width: 10em;',align='mid').to_html()
# stylerto_html4=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=([1,3],[2,4]),vmin=2,vmax=8,width=100,height=100,cmap=None,color=None,props='width: 10em;',align='mid').to_html()
# stylerto_html5=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=([1,3],[2,4]),vmin=2,vmax=8,width=20,height=60,cmap=None,color=None,props='width: 10em;',align='mid').to_html()
# stylerto_html6=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=None,vmin=None,vmax=None,width=100,height=100,cmap='PuBu',color=None,props='width: 10em;',align='mid').to_html()
# stylerto_html7=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=None,vmin=None,vmax=None,width=100,height=100,cmap=None,color='blue',props='width: 10em;',align='mid').to_html()
# stylerto_html8=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=None,vmin=None,vmax=None,width=100,height=100,cmap=None,color=('blue','red'),props='width: 10em;',align='mid').to_html()
# stylerto_html9=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=None,vmin=None,vmax=None,width=100,height=100,cmap=None,color=('blue','red'),props='width: 100em; border: 5px;',align='mid').to_html()#100em didn't seem to do anything
# stylerto_html10=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=None,vmin=None,vmax=None,width=100,height=100,cmap=None,color=('blue','red'),props='width: 10em;',align='left').to_html()
# stylerto_html11=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=None,vmin=None,vmax=None,width=100,height=100,cmap=None,color=('blue','red'),props='width: 10em;',align='right').to_html()
# stylerto_html12=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=None,vmin=None,vmax=None,width=100,height=100,cmap=None,color=('blue','red'),props='width: 10em;',align='mid').to_html()
# stylerto_html13=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=None,vmin=None,vmax=None,width=100,height=100,cmap=None,color=('blue','red'),props='width: 10em;',align='zero').to_html()
# stylerto_html14=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=None,vmin=None,vmax=None,width=100,height=100,cmap=None,color=('blue','red'),props='width: 10em;',align='mean').to_html()
# stylerto_html15=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=None,vmin=None,vmax=None,width=100,height=100,cmap=None,color=('blue','red'),props='width: 10em;',align=5).to_html()
# stylerto_html16=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=None,vmin=None,vmax=None,width=100,height=100,cmap=None,color=('blue','red'),props='width: 10em;',align=8.5).to_html()
# def f0(dataFrameOrSeries0):
    # # if -2 < numpy.mean(dataFrameOrSeries0.to_numpy()) < 2:
    # if -2 < numpy.mean(dataFrameOrSeries0) < 2:
        # return 0
    # else:
        # return 5
# stylerto_html17=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.bar(axis=None,subset=None,vmin=None,vmax=None,width=100,height=100,cmap=None,color=('blue','red'),props='width: 10em;',align=f0).to_html()

# def apply0(dataFrameOrSeries0,colorForBackground0):
    # return numpy.where(dataFrameOrSeries0==numpy.nanmin(dataFrameOrSeries0),f'background-color: {colorForBackground0};',None)
# styler0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(4,4))).style.apply(apply0,colorForBackground0='blue',axis=None)
# stylerto_html7=styler0.to_html()
# styler0.clear()
# stylerto_html8=styler0.to_html()

# xn0=5
# yn0=5
# l0=['https://answers.sap.com/',numpy.nan,2340502,0.1235000,'$%#^str0']
# def formatter0(labelValue0):
    # if isinstance(labelValue0,float):
        # return '{:.3e}'.format(labelValue0)
    # else:
        # return labelValue0


# stylerto_html0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(xn0,yn0)),columns=l0,index=l0).style.format_index(formatter=formatter0,thousands=None,hyperlinks='html').to_html()
# stylerto_html0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(xn0,yn0)),columns=l0,index=l0).style.format_index(formatter=formatter0,thousands=',',decimal='.',na_rep='iMNANA',axis=0,escape='html',hyperlinks='html').to_html()
# stylerto_html1=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(xn0,yn0)),columns=l0,index=l0).style.format_index(formatter=formatter0,thousands=',',decimal='.',na_rep='iMNANA',axis=1,escape='latex',hyperlinks='latex').to_html()
# stylerto_html2=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(xn0,yn0)),columns=l0,index=l0).style.format_index(formatter=None,thousands=',,',decimal='.',na_rep='iMNA',axis=0,escape='html',hyperlinks='html').to_html()
# stylerto_html3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(xn0,yn0)),columns=l0,index=l0).style.format_index(formatter=None,thousands=',,',decimal='.',na_rep='iMNANA',axis=1,escape='latex',hyperlinks='latex').to_html()
# # stylerto_html0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(xn0,yn0)),columns=l0,index=l0).style.format_index(formatter=formatter0,thousands='.',decimal='dd',na_rep='iMNA',axis=0,escape='html',hyperlinks='html').to_html()
# stylerto_html1=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(xn0,yn0)),columns=l0,index=l0).style.format_index(formatter=formatter0,thousands='..',decimal='dddd',na_rep='iMNANA',axis=1,escape='latex',hyperlinks='latex').to_html()
# stylerto_html2=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(xn0,yn0)),columns=l0,index=l0).style.format_index(formatter=None,thousands='.',decimal='dd',na_rep='iMNA',axis=0,escape='html',hyperlinks='html').to_html()
# stylerto_html3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(xn0,yn0)),columns=l0,index=l0).style.format_index(formatter=None,thousands='..',decimal='dddd',na_rep='iMNANA',axis=1,escape='latex',hyperlinks='latex').to_html()
# def func1(e0):
    # if e0 > 5:
        # return "background-color: blue;"
    # else:
        # return None
# def func2(e0):
    # if type(e0)==numpy.int64 and e0 > 23:
        # return "background-color: purple;"
    # elif True:
        # return "background-color: yellow;"
    # else:
        # return None
# styler0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.applymap(func1)
# styler1=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).agg(["sum","mean",lambda s0: s0.dtype]).style.applymap(func2)
# styler2=styler0.concat(styler1)
# stylerto_html0=styler0.to_html()
# stylerto_html1=styler1.to_html()
# stylerto_html2=styler2.to_html()
# df0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5)))
# df1=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).agg(["sum","mean",lambda s0: s0.dtype])
# df0.style.applymap(func1)
# df1.style.applymap(func2)
# df2=pandas.concat([df0,df1])
# styler3=df2.style.to_html()

# styler2=pandas.io.formats.style.Styler(pandas.DataFrame([[1,numpy.nan],[3.,4]]),precision=3,table_attributes='tableAttributes0'+datetime.datetime.today().strftime('%Y%m%d'),table_styles=[{'selector':'tr:hover','props':[('border','3px solid')]}],caption='thisIsAClosedCaption',cell_ids=True).set_table_styles({0:[{'selector':'td','props':'background-color: green; font-size: 8;'},{'selector':'th','props':'background-color: yellow; font-size: 20;'}]},axis=1).set_table_styles({0:[{'selector':'td','props':'background-color: red;'},{'selector':'th','props':'background-color: blue;'}]},axis=1,overwrite=False,css_class_names={'row':'row0','data':'dataPoint0'}).applymap(lambda x: "color: green;" if type(x)==int else "").hide(axis=1,subset=1)
# stylerto_html2=styler2.to_html()
# styler2export0=styler2.export()
# styler3=pandas.DataFrame([[1,numpy.nan],[3.,4]]).style
# stylerto_html3=styler3.to_html()
# styler4=pandas.DataFrame([[1,numpy.nan],[3.,4]]).style
# styler5=styler4.use(styler2export0)
# stylerto_html4=styler4.to_html()
# stylerto_html5=styler5.to_html()
# print(styler2export0)
# d0=dict(table_attributes='tableAttributes0'+datetime.datetime.today().strftime('%Y%m%d'),table_styles=[{'selector':'tr:hover','props':[('border','3px solid')]}],applymap=(lambda x: "color: green;" if type(x)==int else ""),hide_index=False,hide_columns=False,hide_index_names=False,hide_column_names=False)
# styler6=styler4.use(d0)
# stylerto_html6=styler6.to_html()
# styler2=pandas.io.formats.style.Styler(pandas.DataFrame([[1,numpy.nan],[3.,4]]),precision=3,table_attributes='tableAttributes0'+datetime.datetime.today().strftime('%Y%m%d'),table_styles=[{'selector':'tr:hover','props':[('border','3px solid')]}],caption='thisIsAClosedCaption',cell_ids=True).set_table_styles({0:[{'selector':'td','props':'background-color: green; font-size: 8;'},{'selector':'th','props':'background-color: yellow; font-size: 20;'}]},axis=1).set_table_styles({0:[{'selector':'td','props':'background-color: red;'},{'selector':'th','props':'background-color: blue;'}]},axis=1,overwrite=False,css_class_names={'row':'row0','data':'dataPoint0'}).applymap(lambda x: "color: green;" if type(x)==int else "").hide(axis=1,names=True)
# stylerto_html2=styler2.to_html()
# styler2export0=styler2.export()
# styler3=pandas.DataFrame([[1,numpy.nan],[3.,4]]).style
# stylerto_html3=styler3.to_html()
# styler4=pandas.DataFrame([[1,numpy.nan],[3.,4]]).style
# styler5=styler4.use(styler2export0)
# stylerto_html4=styler4.to_html()
# stylerto_html5=styler5.to_html()
# print(styler2export0)
# d0=dict(table_attributes='tableAttributes0'+datetime.datetime.today().strftime('%Y%m%d'),table_styles=[{'selector':'tr:hover','props':[('border','3px solid')]}],applymap=(lambda x: "color: green;" if type(x)==int else ""),hide_index=False,hide_columns=False,hide_index_names=False,hide_column_names=False)
# styler6=styler4.use(d0)
# stylerto_html6=styler6.to_html()
# styler2=pandas.io.formats.style.Styler(pandas.DataFrame([[1,numpy.nan],[3.,4]]),precision=3,table_attributes='tableAttributes0'+datetime.datetime.today().strftime('%Y%m%d'),table_styles=[{'selector':'tr:hover','props':[('border','3px solid')]}],caption='thisIsAClosedCaption',cell_ids=True).set_table_styles({0:[{'selector':'td','props':'background-color: green; font-size: 8;'},{'selector':'th','props':'background-color: yellow; font-size: 20;'}]},axis=1).set_table_styles({0:[{'selector':'td','props':'background-color: red;'},{'selector':'th','props':'background-color: blue;'}]},axis=1,overwrite=False,css_class_names={'row':'row0','data':'dataPoint0'}).applymap(lambda x: "color: green;" if type(x)==int else "").hide(axis=1)
# stylerto_html2=styler2.to_html()
# styler2export0=styler2.export()
# styler3=pandas.DataFrame([[1,numpy.nan],[3.,4]]).style
# stylerto_html3=styler3.to_html()
# styler4=pandas.DataFrame([[1,numpy.nan],[3.,4]]).style
# styler5=styler4.use(styler2export0)
# print(styler5.table_attributes)
# stylerto_html4=styler4.to_html()
# stylerto_html5=styler5.to_html()
# print(styler2export0)
# d0=dict(table_attributes='tableAttributes0'+datetime.datetime.today().strftime('%Y%m%d'),table_styles=[{'selector':'tr:hover','props':[('border','3px solid')]}],applymap=(lambda x: "color: green;" if type(x)==int else ""),hide_index=False,hide_columns=False,hide_index_names=False,hide_column_names=False)
# styler6=styler4.use(d0)
# stylerto_html6=styler6.to_html()
# print(pandas.DataFrame([[1,numpy.nan],[3.,4]]))
# stylerto_string3=pandas.DataFrame([[1,numpy.nan],[3.,4]]).style.hide().to_string()
# print(stylerto_string3)
# stylerto_string3=pandas.DataFrame([[1,numpy.nan],[3.,4]]).style.hide(axis=1).to_string()
# print(stylerto_string3)
# print(pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))))
# stylerto_string3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.hide(subset=0).to_string()
# print(stylerto_string3)
# stylerto_string3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.hide(subset=1).to_string()
# print(stylerto_string3)
# stylerto_string3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.hide(subset=1,axis=1).to_string()
# print(stylerto_string3)
# stylerto_string3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.hide(subset=pandas.IndexSlice[0:2],axis=1).to_string()#since axis can only be 0 or 1, cannot subset multiple axes
# print(stylerto_string3)
# print(numpy.ma.make_mask(numpy.random.default_rng(8).integers(0,1,(5,5),endpoint=True)))
# print(type(numpy.ma.make_mask(numpy.random.default_rng(8).integers(0,1,(5,5),endpoint=True))))
# # stylerto_html3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.background_gradient(subset=numpy.ma.make_mask(numpy.random.default_rng(8).integers(0,1,(5,5),endpoint=True)))
# # stylerto_html3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.background_gradient(subset=numpy.ma.make_mask(numpy.random.default_rng(8).integers(0,1,(5,5),endpoint=True))).to_html()
# # stylerto_string3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.hide(subset=pandas.IndexSlice[0:2,1:3]).to_string()
# # stylerto_string3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.hide(subset=[0,1]).to_string()
# # print(stylerto_string3)
# tuples = [
   # ('cobra', 'mark i'), ('cobra', 'mark ii'),
   # ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
   # ('viper', 'mark ii'), ('viper', 'mark iii')
# ]
# index = pandas.MultiIndex.from_tuples(tuples,names=['bot0','version0'])
# values = [[12, 2,12, 2,12, 2], [20, 24,20, 24,20, 24], [10, 20,10, 20,10, 20],
        # [21, 34,21, 34,21, 34], [17, 26,7, 26,7, 26], [36, 56,36, 56,36, 56]]
# df4 = pandas.DataFrame(values, columns=index, index=index)
# print(df4)
# print(df4.style.hide(level=0,axis=0).to_string())
# print(df4.style.hide(level=1,axis=1).to_string())
# print(df4.style.hide(level='version0',axis=1).to_string())
# print(df4.style.hide(level='version0',axis=1,names=False).to_string())
# print(df4.style.hide(level='version0',axis=1,names=True).to_string())
# print(df4.style.hide(subset=('cobra',slice(None)),axis=1,names=True).to_string())
# print(df4.style.hide(subset=(slice(None),'mark i'),axis=1,names=True).to_string())
    # {% if col0 == 0 %}
        # {{col0}}
# template0='''
# {% for col0 in data.columns %}
    # {% for i0,v0 in enumerate(data[col0]) %}
        # {% if v0 > 4 %}
            # <td style="background-color: blue;">{{v0}}</td>
        # {% else %}
            # <td>{{v0}}</td>
        # {% endif %}
    # {% endfor %}
# {% endfor %}
# '''
# template0=r'C:\Users\pdumas\Documents\Code'
# styler0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.from_custom_template(template0,html_table='None',html_style='jinja0.jinja')
# stylerto_html0=styler0.to_html()
# # template0=r'C:\Users\pdumas\Documents\Code\jinja0.jinja'
# # styler0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.from_custom_template(template0)
# # styler0.export()
# # stylerto_html0=styler0.to_html()#errors like above line since 2 above line template0 seems to not be path but rather the contents of the path..
# template0='''
# {% for col0 in data.columns %}
    # {{col0}}
    # {% for i0,v0 in enumerate(data[col0]) %}
        # {% if v0 > 4 %}
            # <td style="background-color:blue">{{v0}}</td>
        # {% else %}
            # <td>{{v0}}</td>
        # {% endif %}
    # {% endfor %}
# {% endfor %}
# '''
# styler0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.from_custom_template(template0)(pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))))
# stylerto_html0=styler0.to_html()#does NOT work semantically (.html yes but formatting none..)
# stylerto_html0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_between(subset=([3]),color='blue',axis=1,left=3,right=6,inclusive='both',props=None).to_html()
# stylerto_html1=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_between(axis=1,left=3,right=6,inclusive='left',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html2=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_between(axis=0,left=3,right=6,inclusive='left',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_between(axis=None,left=3,right=6,inclusive='left',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html4=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_between(axis=None,left=3,right=6,inclusive='right',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html5=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_between(axis=None,left=3,right=6,inclusive='neither',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html6=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_between(axis=0,left=[3,4,5,6,7],right=[5,6,7,8,9],inclusive='both',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html7=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_between(axis=1,left=[3,4,5,6,7],right=[5,6,7,8,9],inclusive='both',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html8=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_between(axis=None,left=numpy.random.default_rng(7).integers(0,5,(5,5)),right=9,inclusive='both',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html9=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_between(axis=None,right=5,inclusive='both',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html10=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_between(axis=None,left=5,inclusive='both',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_min(subset=None,axis=0,color='blue',props=None).to_html()
# stylerto_html1=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_min(subset=None,axis=1,color='blue',props=None).to_html()
# stylerto_html2=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_min(subset=None,axis=None,color='blue',props=None).to_html()
# stylerto_html3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_min(subset=pandas.IndexSlice[3:,2:],axis=None,props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html4=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_min(subset=pandas.IndexSlice[3:],axis=1,props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html5=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_max(subset=None,axis=0,color='blue',props=None).to_html()
# stylerto_html6=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_max(subset=None,axis=1,color='blue',props=None).to_html()
# stylerto_html7=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_max(subset=None,axis=None,color='blue',props=None).to_html()
# stylerto_html8=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_max(subset=pandas.IndexSlice[3:,2:],axis=None,props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html9=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5))).style.highlight_max(subset=pandas.IndexSlice[3:],axis=1,props='font-weight:bold;background-color:blue;').to_html()
# # # numpy.where(numpy.equal(numpy.make_mask(numpy.random.default_rng(8).integers(0,1,(5,5),endpoint=True)),numpy.ones((5,5).dtype=numpy.int_)),
# a0=numpy.random.default_rng(8).integers(0,1,(5,5),endpoint=True).astype(numpy.float_)
# a0[a0==0]=numpy.nan
# print(a0)
# stylerto_html10=pandas.DataFrame(a0).style.highlight_null(subset=None,color='blue',props=None).to_html()
# stylerto_html11=pandas.DataFrame(a0).style.highlight_null(subset=pandas.IndexSlice[3:,2:],props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html12=pandas.DataFrame(a0).style.highlight_null(subset=pandas.IndexSlice[3:],props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html10=pandas.DataFrame(pandas.date_range('2023-02-12',periods=25).to_numpy().reshape(5,5).copy('C')).style.highlight_between(axis=None,left=pandas.to_datetime('2023-02-22'),right=pandas.to_datetime('2023-02-28'),inclusive='both',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(subset=([3]),color='blue',axis=1,q_left=.3,q_right=.6,inclusive='both',props=None).to_html()
# stylerto_html1=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(axis=1,q_left=.3,q_right=.6,inclusive='left',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html2=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(axis=0,q_left=.3,q_right=.6,inclusive='left',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html3=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(axis=None,q_left=.3,q_right=.6,inclusive='left',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html4=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(axis=None,q_left=.3,q_right=.6,inclusive='right',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html5=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(axis=None,q_left=.3,q_right=.6,inclusive='neither',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html6=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(axis=0,q_left=.3,q_right=.6,interpolation='linear',inclusive='both',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html61=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(axis=0,q_left=.3,q_right=.6,interpolation='lower',inclusive='both',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html62=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(axis=0,q_left=.3,q_right=.6,interpolation='higher',inclusive='both',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html63=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(axis=0,q_left=.3,q_right=.6,interpolation='midpoint',inclusive='both',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html64=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(axis=0,q_left=.3,q_right=.6,interpolation='nearest',inclusive='both',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html9=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(axis=None,q_right=.5,inclusive='both',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html10=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(axis=None,q_left=.5,inclusive='both',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html01=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(subset=pandas.IndexSlice[2:4],color='blue',axis=1,q_left=.3,q_right=.6,inclusive='both',props=None).to_html()
# stylerto_html02=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(subset=pandas.IndexSlice[2:4],color='blue',axis=0,q_left=.3,q_right=.6,inclusive='both',props=None).to_html()
# stylerto_html03=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(subset=pandas.IndexSlice[:,2:4],color='blue',axis=0,q_left=.3,q_right=.6,inclusive='both',props=None).to_html()
# stylerto_html51=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(axis=None,q_left=.3,q_right=.6,inclusive='both',props='font-weight:bold;background-color:blue;').to_html()
# stylerto_html020=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10))).style.highlight_quantile(subset=pandas.IndexSlice[2:5],color='blue',axis=0,q_left=.3,q_right=.6,inclusive='both',props=None).to_html()
# tuples = [
   # ('cobra', 'mark i'), ('cobra', 'mark ii'),
   # ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
   # ('viper', 'mark ii'), ('viper', 'mark iii')
# ]
# index = pandas.MultiIndex.from_tuples(tuples,names=['bot0','version0'])
# values = [[12, 2,12, 2,12, 2], [20, 24,20, 24,20, 24], [10, 20,10, 20,10, 20],
        # [21, 34,21, 34,21, 34], [17, 26,7, 26,7, 26], [36, 56,36, 56,36, 56]]
# df4 = pandas.DataFrame(values, columns=index, index=index)
# print(df4)
# print(df4.loc[pandas.IndexSlice['cobra',:],:])
# print(df4.loc[pandas.IndexSlice[:,'mark i'],:])
# print(df4.loc[:,pandas.IndexSlice['cobra',:]])
# print(df4.loc[:,pandas.IndexSlice[:,'mark i']])
# print(df4.loc[pandas.IndexSlice[:,'mark i'],pandas.IndexSlice[:,'mark i']])
# print(df4.loc[pandas.IndexSlice[:,'mark i'],pandas.IndexSlice['cobra',:]])
# print(df4.loc[pandas.IndexSlice['cobra',:],pandas.IndexSlice[:,'mark i']])
# print(df4.loc[pandas.IndexSlice['cobra',:],pandas.IndexSlice['cobra',:]])
# print('iloc0')
# # print(df4.iloc[pandas.IndexSlice[0,:],:])
# # print(df4.iloc[pandas.IndexSlice[0,:],:])
# # print(df4.iloc[pandas.IndexSlice[:,0],:])
# # print(df4.iloc[:,pandas.IndexSlice[0,:]])
# # print(df4.iloc[:,pandas.IndexSlice[:,0]])
# # print(df4.iloc[pandas.IndexSlice[:,0],pandas.IndexSlice[:,0]])
# # print(df4.iloc[pandas.IndexSlice[:,0],pandas.IndexSlice[0,:]])
# # print(df4.iloc[pandas.IndexSlice[0,:],pandas.IndexSlice[:,0]])
# # print(df4.iloc[pandas.IndexSlice[0,:],pandas.IndexSlice[0,:]])
# df4=pandas.DataFrame(numpy.random.default_rng(8).integers(0,9,(6,6),endpoint=True),columns=pandas.MultiIndex.from_product([[0,1],[0,1,2]]),index=pandas.MultiIndex.from_product([[0,1],[0,1,2]]))
# print(df4)
# print(df4.loc[pandas.IndexSlice[0,:],:])
# print(df4.loc[pandas.IndexSlice[:,0],:])
# print(df4.loc[:,pandas.IndexSlice[0,:]])
# print(df4.loc[:,pandas.IndexSlice[:,0]])
# print(df4.loc[pandas.IndexSlice[:,0],pandas.IndexSlice[:,0]])
# print(df4.loc[pandas.IndexSlice[:,0],pandas.IndexSlice[0,:]])
# print(df4.loc[pandas.IndexSlice[0,:],pandas.IndexSlice[:,0]])
# print(df4.loc[pandas.IndexSlice[0,:],pandas.IndexSlice[0,:]])
# df4=pandas.DataFrame(numpy.random.default_rng(8).integers(0,9,(6,6),endpoint=True))
# print(df4)
# # # df4[2:4,1:3]=numpy.nan
# # df4[2:4]=numpy.nan
# # df4[2:4][1:3]=numpy.nan
# df4.loc[2:4,1:2]=numpy.nan
# print(df4)
# print(df4.isna())
# print(df4.any())
# print(df4.isna().any())
# print(df4[df4==7])
# print(df4[df4==7].any())

# def highlightIndexIfDataContains7(styler0):
    # return styler0.apply_index(lambda series0: numpy.where(styler0.data[styler0.data==7].any(),"color:red",""),axis=1)
# def highlightIndexIfDataContains4(styler0,print0,backgroundColor0='blue'):
    # print(print0)
    # return styler0.apply_index(lambda series0: numpy.where(styler0.data[styler0.data==4].any(),f"background-color:{backgroundColor0}",""),axis=1)
# print(df4.style.pipe(highlightIndexIfDataContains7).pipe(highlightIndexIfDataContains4,'printMe0',backgroundColor0='yellow'))
# stylerto_html0=df4.style.pipe(highlightIndexIfDataContains7).pipe(highlightIndexIfDataContains4,'printMe0',backgroundColor0='yellow').to_html()

# df5=pandas.DataFrame([0,1,2],index=['d','e','f'])
# print(df5)
# print(df5.style.relabel_index(['g','h','i']).to_string())
# df5=pandas.DataFrame([[0,1],[0,1]],columns=['ca','cb'],index=['d','e'])
# print(df5)
# print(df5.style.relabel_index(['g','h'],axis=1).to_string())
# print(df5.style.relabel_index(['g','h'],axis=1).data)
# print(df5.style.relabel_index([f'this is column {i} called {{}}' for i in range(2)],axis=1).to_string())
# print(df5.style.hide(subset=['cb'],axis=1).relabel_index([f'this is column {i} called {{}}' for i in range(1)],axis=1).to_string())

# df4=pandas.DataFrame(numpy.random.default_rng(8).integers(0,9,(6,6),endpoint=True),columns=pandas.MultiIndex.from_product([[0,1],[0,1,2]]),index=pandas.MultiIndex.from_product([[0,1],[0,1,2]]))
# print(df4)
# # # print(df4.style.relabel_index(numpy.arange(6,12,1)).to_string())
# # print(df4.style.relabel_index([1,2,3,4,5,6]).to_string())
# # print(df4.style.relabel_index(numpy.arange(6,14,1),axis=0).to_string())
# print(df4.style.relabel_index(numpy.arange(6,12,1),axis=0,level=1).to_string())
# print(df4.style.relabel_index(numpy.arange(6,12,1),axis=0,level=0).to_string())
# print(df4.style.relabel_index(numpy.arange(6,18,1).reshape(6,2).copy('C'),axis=0,level=None).to_string())
# print(df4.style.relabel_index(numpy.arange(6,18,1).reshape(6,2).copy('C'),axis=1,level=None).to_string())

# df4=pandas.DataFrame(numpy.random.default_rng(8).integers(0,9,(6,6),endpoint=True),columns=pandas.MultiIndex.from_product([[0,1],[0,1,2]]),index=pandas.MultiIndex.from_product([[0,1],[0,1,2]]))
# print(df4)
# stylerto_html4=df4.style.set_caption(('htmlDisplayCaptionOrLatexFullCaption0','latexShortCaption0')).to_html()
# stylerto_html4=df4.style.set_properties(**{'color':'white','background-color':'black'}).to_html()
# stylerto_html5=df4.style.set_properties(subset=[[0,0]],**{'color':'white','background-color':'black'}).to_html()
# stylerto_html4=df4.style.set_properties(subset=pandas.IndexSlice[(0,0),(0,0)],**{'color':'white','background-color':'black'}).to_html()
# stylerto_html5=df4.style.set_properties(subset=pandas.IndexSlice[(0,0),(0,1)],**{'color':'white','background-color':'black'}).to_html()
# stylerto_html4=df4.style.set_properties(subset=pandas.IndexSlice[(0,0),:],**{'color':'white','background-color':'black'}).to_html()
# stylerto_html5=df4.style.set_properties(subset=pandas.IndexSlice[(0,1),:],**{'color':'white','background-color':'black'}).to_html()


# df4=pandas.DataFrame(numpy.random.default_rng(8).integers(0,9,(60,60),endpoint=True),columns=pandas.MultiIndex.from_product([[0,1],list(range(30))]),index=pandas.MultiIndex.from_product([[0,1],list(range(30))]))
# print(df4)
# stylerto_html4=df4.style.to_html()
# stylerto_html5=df4.style.set_sticky().to_html()
# stylerto_html4=df4.style.set_sticky(axis=1,pixel_size=25,levels=0).to_html()
# stylerto_html5=df4.style.set_sticky(axis=1,pixel_size=125,levels=1).to_html()
# stylerto_html4=df4.style.set_sticky(axis=1,pixel_size=125,levels=[0,1]).to_html()
# stylerto_html5=df4.style.set_sticky(axis=0,pixel_size=125,levels=1).to_html()
# stylerto_html4=df4.style.set_sticky(axis=1,pixel_size=125,levels=[0,1]).to_html()
# stylerto_html5=df4.style.set_sticky(axis=0,pixel_size=125,levels=0).to_html()
# stylerto_html5=df4.style.set_table_attributes('''class="pure-table" border="1"''').to_html()
# stylerto_html4=df4.style.set_table_styles([
# {'selector':'td:hover','props':'background-color: black; color: white;'},
# {'selector':'th','props':'background-color: blue; color: yellow;'}
# ],overwrite=True,css_class_names={'row':'row0','col':'col0','row_heading':'row_heading0','col_heading':'col_heading0','data':'data0','blank':'blank0','foot':'foot0','row_trim':'row_trim0','col_trim':'col_trim0','index_name':'index_name0','level':'level0'}).to_html()
# stylerto_html5=df4.style.set_table_styles({(1,0):[
# {'selector':'td:hover','props':'background-color: black; color: white;'},
# {'selector':'th','props':'background-color: blue; color: yellow;'}
# ]},axis=0,overwrite=False,css_class_names={'row':'row0','col':'col0','row_heading':'row_heading0','col_heading':'col_heading0','data':'data0','blank':'blank0','foot':'foot0','row_trim':'row_trim0','col_trim':'col_trim0','index_name':'index_name0','level':'level0'}).to_html()
# stylerto_html5=df4.style.set_table_styles({(1,0):[
# {'selector':'td:hover','props':'background-color: black; color: white;'},
# {'selector':'th','props':'background-color: blue; color: yellow;'}
# ]},axis=1,overwrite=False,css_class_names={'row':'row0','col':'col0','row_heading':'row_heading0','col_heading':'col_heading0','data':'data0','blank':'blank0','foot':'foot0','row_trim':'row_trim0','col_trim':'col_trim0','index_name':'index_name0','level':'level0'}).to_html()

# df6=pandas.DataFrame([[1,2,3],[4,5,6]],columns=['a','b','c'])
# df7=pandas.DataFrame([['min-val red','','blue'],['red',None,'max-val yellow']],index=df6.index,columns=df6.columns)
# stylerto_html0=df6.style.set_td_classes(df7).to_html()
# stylerto_html0=df6.style.set_tooltips(df7).to_html()
# # stylerto_html0=df6.style.set_tooltips(df7,props=['visibility: hidden; position: absolute; z-index: 1; transform: translate(-20px,-20px); background-color: yellow; color: blue;'],css_class='pd-t').to_html()
# stylerto_html0=df6.style.set_tooltips(df7,props='visibility: hidden; position: relative; z-index: 2; transform: translate(-40px,-40px); background-color: yellow; color: blue;',css_class='tt-add0').to_html()
# stylerto_html0=df6.style.set_tooltips(df7,props='visibility: hidden; position: absolute; z-index: 2; transform: translate(-40px,-40px); background-color: yellow; color: blue;',css_class='tt-add0').to_html()
# stylerto_html1=df6.style.set_tooltips(df7,props='visibility: hidden; position: absolute; z-index: 3; transform: translate(-40px,-40px); background-color: yellow; color: blue;',css_class='tt-add0').to_html()
# stylerto_html2=df6.style.set_tooltips(df7,props='visibility: hidden; position: absolute; z-index: 3; transform: translate(-80px,-80px); background-color: yellow; color: blue;',css_class='tt-add0').to_html()
# stylerto_html0=df6.style.set_uuid('uuid123').to_html()
# tuples = [
   # ('cobra', 'mark i'), ('cobra', 'mark ii'),
   # ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
   # ('viper', 'mark ii'), ('viper', 'mark iii')
# ]
# index = pandas.MultiIndex.from_tuples(tuples)
# values = [[12, 2], [20, 24], [10, 20],
        # [21, 34], [17, 26], [36, 56]]
# df4 = pandas.DataFrame(values, columns=['max_speed', 'shield'], index=index)
# stylerto_html4=df4.style.text_gradient().to_html()
# stylerto_html5=df4.style.text_gradient(cmap='YlOrRd').to_html()
# stylerto_html6=df4.style.text_gradient(vmin=15,vmax=32).to_html()
# stylerto_html7=df4.style.text_gradient(vmin=15,vmax=32,low=.5,high=.9).to_html()
# stylerto_html8=df4.style.text_gradient(vmin=15,vmax=32,low=.5,high=.9,subset=['max_speed']).to_html()
# stylerto_html9=df4.style.text_gradient(vmin=15,vmax=32,low=.5,high=.9,axis=1).to_html()
# stylerto_html2=df4.style.text_gradient(cmap='PuBu',vmin=15,vmax=32,low=.5,high=.9,subset=['max_speed'],gmap=[0,1,1,1,4,5]).to_html()
# stylerto_html3=df4.style.text_gradient(cmap='PuBu',vmin=15,vmax=32,low=.5,high=.9,subset=['max_speed','shield'],gmap=[0,1,16,23,32,52]).to_html()
# stylerto_html10=df4.style.text_gradient(vmin=15,vmax=32,low=.5,high=.9,axis=None).to_html()
# stylerto_html13=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.text_gradient(axis=0).to_html()
# stylerto_html11=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.text_gradient(axis=1).to_html()
# stylerto_html12=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(6,6))).style.text_gradient(axis=None).to_html()
# try:
    # print(pandas.io.excel.xls.writer,pandas.io.excel.xlsx.writer,pandas.io.excel.xlsm.writer)
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# tuples = [
   # ('cobra', 'mark i'), ('cobra', 'mark ii'),
   # ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
   # ('viper', 'mark ii'), ('viper', 'mark iii')
# ]
# index = pandas.MultiIndex.from_tuples(tuples,names=['bot0','version0'])
# values = [[12, 2,12, 2,12, 2], [20, 24,20, 24,20, 24], [10, 20,10, 20,10, 20],
        # [21, 34,21, 34,21, 34], [17.3143, numpy.nan,numpy.inf, 26,7, 26], [36, 56,36, 56,36, 56]]
# df4 = pandas.DataFrame(values, columns=index, index=index)
# print(df4)

# excelFileName0=str(time.perf_counter())+'pandasStyleExcelExample0.xlsx'
# excelFileName0=r'C:\Users\pdumas\Documents\Code\63131.4440283pandasStyleExcelExample0.xlsx'
# # df4.style.to_excel(excelFileName0,sheet_name='test0',startrow=5,startcol=10,header=False,index=False,freeze_panes=(6,11),na_rep='imNan',inf_rep='imInf',float_format='{:.2f}',columns=[('cobra','mark i'),('sidewinder','mark ii')],engine='openpyxl',storage_options=None)
# # df4.style.to_excel(excelFileName0,sheet_name='test0',startrow=5,startcol=10,header=False,index=True,index_label=['index_label0','index_label1'],freeze_panes=(6,11),na_rep='imNan',inf_rep='imInf',float_format='{:.2f}',columns=[('cobra','mark i'),('sidewinder','mark ii')],engine='openpyxl',storage_options=None)
# # df4.style.to_excel(excelFileName0,sheet_name='test0',startrow=5,startcol=10,header=False,index=True,index_label=['index_label0','index_label1'],freeze_panes=(6,11),na_rep='imNan',inf_rep='imInf',float_format='%.2f',columns=[('cobra','mark i'),('sidewinder','mark ii')],engine='openpyxl',storage_options=None)
# # df4.style.to_excel(excelFileName0,sheet_name='test0',startrow=5,startcol=10,header=True,index=True,index_label=['index_label0','index_label1'],freeze_panes=(6,11),na_rep='imNan',inf_rep='imInf',float_format='%.2f',columns=[('cobra','mark i'),('cobra','mark ii'),('sidewinder','mark i'),('sidewinder','mark ii')],engine='xlsxwriter',storage_options=None)
# # df4.style.to_excel(excelFileName0,sheet_name='test0',startrow=5,startcol=10,header=True,index=True,index_label=['index_label0','index_label1'],freeze_panes=(6,11),na_rep='imNan',inf_rep='imInf',float_format='%.2f',columns=[('cobra','mark i'),('cobra','mark ii'),('sidewinder','mark i'),('sidewinder','mark ii')],engine='openpyxl',storage_options=None)
# excelWriter0=pandas.ExcelWriter(excelFileName0,engine='openpyxl',mode='a',if_sheet_exists='overlay')
# df4.style.to_excel(excelWriter0,sheet_name='test0',startrow=35,startcol=10,header=True,index=True,na_rep='imNan',inf_rep='imInf',float_format='%.2f',columns=[('cobra','mark i'),('cobra','mark ii'),('sidewinder','mark i'),('sidewinder','mark ii')],engine='openpyxl',storage_options=None)
# excelWriter0.save()
# excelWriter0.close()
# os.system(r'''start "" "'''+excelFileName0+'''"''')

# htmlFileName0=str(time.perf_counter())+'pandasStyleHtmlExample0.html'
# # df4.style.applymap(lambda e0: 'background-color: yellow;').to_html(htmlFileName0,sparse_index=False,sparse_columns=False,max_rows=5,max_columns=5,doctype_html=True,exclude_styles=True,encoding='utf-16',bold_headers=True,caption='caption0',table_attributes={'row':'row0'},table_uuid='table_uuid0')
# # df4.style.applymap(lambda e0: 'background-color: yellow;').to_html(htmlFileName0,sparse_index=True,sparse_columns=True,max_rows=None,max_columns=None,doctype_html=False,exclude_styles=False,encoding='utf-32',bold_headers=False,caption=None,table_attributes={'row':'row0'},table_uuid='table_uuid0')
# # df4.style.applymap(lambda e0: 'background-color: yellow;').to_html(htmlFileName0,sparse_index=True,sparse_columns=True,max_rows=None,max_columns=None,doctype_html=False,exclude_styles=False,encoding='utf-8',bold_headers=False,caption=None,table_attributes={'row':'row0'},table_uuid='table_uuid0')
# df4.style.applymap(lambda e0: 'background-color: yellow;').to_html(htmlFileName0,sparse_index=True,sparse_columns=True,max_rows=None,max_columns=None,doctype_html=True,exclude_styles=False,encoding='utf-8',bold_headers=False,caption=None,table_attributes='border="1"',table_uuid='table_uuid0')
# os.system(r'''"C:\Program Files\Notepad++\notepad++.exe" '''+htmlFileName0+'''''')
# os.system(r'''start "" "'''+htmlFileName0+'''"''')
# print(pandas.options.styler.render.encoding)
# print(pandas.options.styler.render.max_rows)
# print(pandas.options.styler.render.max_columns)
# print(pandas.options.styler.sparse.index)
# print(pandas.options.styler.sparse.columns)
# print(df4.style.to_latex())
# print(pandas.options.styler.latex.multirow_align)
# print(pandas.options.styler.latex.multicol_align)
# print(pandas.options.styler.latex.environment)
# print(pandas.options.styler.latex.hrules)


# chromeExecutablePath0 = r'C:\Users\pdumas\AppData\Local\Google\Chrome\Application\chrome.exe'
# webbrowser.register('chrome',None,webbrowser.BackgroundBrowser(chromeExecutablePath0))
# wb0=webbrowser.get('chrome')
# # for f0 in [stylerto_html10,stylerto_html11,stylerto_html12]:
# # for f0 in [stylerto_html0, stylerto_html1, stylerto_html2, stylerto_html3, stylerto_html4, stylerto_html5, stylerto_html6, stylerto_html7, stylerto_html8]:
# # for f0 in [stylerto_html0, stylerto_html1, stylerto_html2, stylerto_html3, stylerto_html4, stylerto_html5, stylerto_html6, stylerto_html7, stylerto_html8, stylerto_html9, stylerto_html10, stylerto_html11, stylerto_html12, stylerto_html13, stylerto_html14, stylerto_html15, stylerto_html16, stylerto_html17]:
# for f0 in [stylerto_html4, stylerto_html5, stylerto_html6, stylerto_html7, stylerto_html8, stylerto_html9, stylerto_html2, stylerto_html3, stylerto_html13, stylerto_html11, stylerto_html12]:
# # for f0 in [stylerto_html0,stylerto_html1,stylerto_html2,stylerto_html3,stylerto_html4,stylerto_html5,stylerto_html6,stylerto_html61,stylerto_html62,stylerto_html63,stylerto_html64,stylerto_html9,stylerto_html10,stylerto_html01,stylerto_html02,stylerto_html03]:
# # for f0 in [stylerto_html4,stylerto_html5,stylerto_html6,stylerto_html7,stylerto_html8]:
# # for f0 in [stylerto_html4,stylerto_html5,stylerto_html6]:
# # for f0 in [stylerto_html0,stylerto_html1,stylerto_html2]:
# # for f0 in [stylerto_html2,stylerto_html3,stylerto_html4,stylerto_html5,stylerto_html6]:
# # for f0 in [stylerto_html9,stylerto_html10]:
# # for f0 in [stylerto_html0,stylerto_html1,stylerto_html2]:
# # for f0 in [stylerto_html0]:
    # with open(str(time.perf_counter())+'hExample0.html','w+') as f00:
        # f00.write(f0)
        # filePath0=os.path.join(os.getcwd(),f00.name)
        # os.system(r'''"C:\Program Files\Notepad++\notepad++.exe" '''+filePath0+'''''')
        # wb0.open(filePath0,new=2,autoraise=True)

# tuples = [
   # ('cobra', 'mark i'), ('cobra', 'mark ii'),
   # ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
   # ('viper', 'mark ii'), ('viper', 'mark iii')
# ]
# index = pandas.MultiIndex.from_tuples(tuples,names=['bot0','version0'])
# values = [[12, 2,12, 2,12, 2], [20, 24,20, 24,20, 24], [10, 20,10, 20,10, 20],
        # [21, 34,21, 34,21, 34], [17.3143, numpy.nan,numpy.inf, 26,7, 26], [36, 56,36, 56,36, 56]]
# df4 = pandas.DataFrame(values, columns=index, index=index)
# print(df4)
# df4.style.to_string(file0,encoding='iso-8859-1',sparse_index=False,sparse_columns=False,max_rows=5,max_columns=5,delimiter=',')
# df4.style.to_string(file0,encoding='utf-8',sparse_index=False,sparse_columns=False,max_rows=5,max_columns=5,delimiter=',')
# file1=r'C:\Users\pdumas\Documents\Code\pandas2output1.txt'
# df4.style.to_string(file1,encoding='iso-8859-1',sparse_index=False,sparse_columns=False,max_rows=5,max_columns=5,delimiter=',')
# os.startfile(file1)
# df8=pandas.DataFrame({'a':[4,80,9],'b':[3.23,4.56,8.90]})
# print(df8)
# # print(df8.abs())
# # print(df8.loc[(df8.a-41).abs().argsort()])
# # print(df8.loc[(df8.b-41).abs().argsort()])
# df9=pandas.DataFrame({'b':[3.23,4.56,8.90],'a':[4,80,9]})
# print(df9)
# df10=pandas.DataFrame({'b':[3.23,4.56,8.90],'a':[4,80,9],'c':[5,120.,12.]})
# df11=pandas.DataFrame({'b':[3.23,4.56,8.90],'a':[4,80,9],'c':[numpy.nan,120.,12.]})
# df12=pandas.DataFrame({'b':[3.23,4.56,8.90],'a':[4,80,9],'c':[numpy.nan,120.,12.]})
# tuples = [
   # (0, 'mark i'), (0, 'mark ii'),
   # (1, 'mark i'), (1, 'mark ii'),
   # (2, 'mark i'), (2, 'mark ii')
# ]
# index = pandas.MultiIndex.from_tuples(tuples,names=['bot0','version0'])
# values = [[12, 2,12, 2,12, 2], [20, 24,20, 24,20, 24], [10, 20,10, 20,10, 20],
        # [21, 34,21, 34,21, 34], [17.3143, numpy.nan,numpy.inf, 26,7, 26], [36, 56,36, 56,36, 56]]
# df4 = pandas.DataFrame(values, columns=index, index=index)
# print(df8.add(df9))
# print(df8.add(df9).add(df10))
# print(df8.add(df9).add(df10,fill_value=10))
# print(df8.add(df9).add(df10,axis=0,fill_value=10).add(df11))
# print(df8.add(df9).add(df10,axis=0,fill_value=10).add(df11,fill_value=2.3))
# print(df8.add(df9).add(df10,axis=0,fill_value=10).add(df11).add(df12))
# print(df8.add(df9).add(df10,axis=0,fill_value=10).add(df11).add(df12,fill_value=2.3))
# print(df4)
# print(df4.add(df8['a'],level=0))
# print(df4.add(df8['a'],level=1))
# print(df4.add(df8['a'],level=0,axis=0))
# print(df4.add(df8['a'],level=1,axis=0))
# print(df4.add(df8['a'],level='bot0',axis=0))
# print(df4.add(df8['a'],level=0))
# print(df8.radd(df9))#begin
# print(df8.radd(df9).radd(df10))
# print(df8.radd(df9).radd(df10,fill_value=10))
# print(df8.radd(df9).radd(df10,axis=0,fill_value=10).radd(df11))
# print(df8.radd(df9).radd(df10,axis=0,fill_value=10).radd(df11,fill_value=2.3))
# print(df8.radd(df9).radd(df10,axis=0,fill_value=10).radd(df11).radd(df12))
# print(df8.radd(df9).radd(df10,axis=0,fill_value=10).radd(df11).radd(df12,fill_value=2.3))
# print(df4)
# print(df4.radd(df8['a'],level=0))
# print(df4.radd(df8['a'],level=1))
# print(df4.radd(df8['a'],level=0,axis=0))
# print(df4.radd(df8['a'],level=1,axis=0))
# print(df4.radd(df8['a'],level='bot0',axis=0))
# print(df4.radd(df8['a'],level=0))#end
# print(df8.sub(df9))#begin
# print(df8.sub(df9).sub(df10))
# print(df8.sub(df9).sub(df10,fill_value=10))
# print(df8.sub(df9).sub(df10,axis=0,fill_value=10).sub(df11))
# print(df8.sub(df9).sub(df10,axis=0,fill_value=10).sub(df11,fill_value=2.3))
# print(df8.sub(df9).sub(df10,axis=0,fill_value=10).sub(df11).sub(df12))
# print(df8.sub(df9).sub(df10,axis=0,fill_value=10).sub(df11).sub(df12,fill_value=2.3))
# print(df4)
# print(df4.sub(df8['a'],level=0))
# print(df4.sub(df8['a'],level=1))
# print(df4.sub(df8['a'],level=0,axis=0))
# print(df4.sub(df8['a'],level=1,axis=0))
# print(df4.sub(df8['a'],level='bot0',axis=0))
# print(df4.sub(df8['a'],level=0))#end
# print(df8.rsub(df9))#begin
# print(df8.rsub(df9).rsub(df10))
# print(df8.rsub(df9).rsub(df10,fill_value=10))
# print(df8.rsub(df9).rsub(df10,axis=0,fill_value=10).rsub(df11))
# print(df8.rsub(df9).rsub(df10,axis=0,fill_value=10).rsub(df11,fill_value=2.3))
# print(df8.rsub(df9).rsub(df10,axis=0,fill_value=10).rsub(df11).rsub(df12))
# print(df8.rsub(df9).rsub(df10,axis=0,fill_value=10).rsub(df11).rsub(df12,fill_value=2.3))
# print(df4)
# print(df4.rsub(df8['a'],level=0))
# print(df4.rsub(df8['a'],level=1))
# print(df4.rsub(df8['a'],level=0,axis=0))
# print(df4.rsub(df8['a'],level=1,axis=0))
# print(df4.rsub(df8['a'],level='bot0',axis=0))
# print(df4.rsub(df8['a'],level=0))#end
# print(df8.mul(df9))#begin
# print(df8.mul(df9).mul(df10))
# print(df8.mul(df9).mul(df10,fill_value=10))
# print(df8.mul(df9).mul(df10,axis=0,fill_value=10).mul(df11))
# print(df8.mul(df9).mul(df10,axis=0,fill_value=10).mul(df11,fill_value=2.3))
# print(df8.mul(df9).mul(df10,axis=0,fill_value=10).mul(df11).mul(df12))
# print(df8.mul(df9).mul(df10,axis=0,fill_value=10).mul(df11).mul(df12,fill_value=2.3))
# print(df4)
# print(df4.mul(df8['a'],level=0))
# print(df4.mul(df8['a'],level=1))
# print(df4.mul(df8['a'],level=0,axis=0))
# print(df4.mul(df8['a'],level=1,axis=0))
# print(df4.mul(df8['a'],level='bot0',axis=0))
# print(df4.mul(df8['a'],level=0))#end
# print(df8.rmul(df9))#begin
# print(df8.rmul(df9).rmul(df10))
# print(df8.rmul(df9).rmul(df10,fill_value=10))
# print(df8.rmul(df9).rmul(df10,axis=0,fill_value=10).rmul(df11))
# print(df8.rmul(df9).rmul(df10,axis=0,fill_value=10).rmul(df11,fill_value=2.3))
# print(df8.rmul(df9).rmul(df10,axis=0,fill_value=10).rmul(df11).rmul(df12))
# print(df8.rmul(df9).rmul(df10,axis=0,fill_value=10).rmul(df11).rmul(df12,fill_value=2.3))
# print(df4)
# print(df4.rmul(df8['a'],level=0))
# print(df4.rmul(df8['a'],level=1))
# print(df4.rmul(df8['a'],level=0,axis=0))
# print(df4.rmul(df8['a'],level=1,axis=0))
# print(df4.rmul(df8['a'],level='bot0',axis=0))
# print(df4.rmul(df8['a'],level=0))#end
# print(df8.div(df9))#begin
# print(df8.div(df9).div(df10))
# print(df8.div(df9).div(df10,fill_value=10))
# print(df8.div(df9).div(df10,axis=0,fill_value=10).div(df11))
# print(df8.div(df9).div(df10,axis=0,fill_value=10).div(df11,fill_value=2.3))
# print(df8.div(df9).div(df10,axis=0,fill_value=10).div(df11).div(df12))
# print(df8.div(df9).div(df10,axis=0,fill_value=10).div(df11).div(df12,fill_value=2.3))
# print(df4)
# print(df4.div(df8['a'],level=0))
# print(df4.div(df8['a'],level=1))
# print(df4.div(df8['a'],level=0,axis=0))
# print(df4.div(df8['a'],level=1,axis=0))
# print(df4.div(df8['a'],level='bot0',axis=0))
# print(df4.div(df8['a'],level=0))#end
# print(df8.rdiv(df9))#begin
# print(df8.rdiv(df9).rdiv(df10))
# print(df8.rdiv(df9).rdiv(df10,fill_value=10))
# print(df8.rdiv(df9).rdiv(df10,axis=0,fill_value=10).rdiv(df11))
# print(df8.rdiv(df9).rdiv(df10,axis=0,fill_value=10).rdiv(df11,fill_value=2.3))
# print(df8.rdiv(df9).rdiv(df10,axis=0,fill_value=10).rdiv(df11).rdiv(df12))
# print(df8.rdiv(df9).rdiv(df10,axis=0,fill_value=10).rdiv(df11).rdiv(df12,fill_value=2.3))
# print(df4)
# print(df4.rdiv(df8['a'],level=0))
# print(df4.rdiv(df8['a'],level=1))
# print(df4.rdiv(df8['a'],level=0,axis=0))
# print(df4.rdiv(df8['a'],level=1,axis=0))
# print(df4.rdiv(df8['a'],level='bot0',axis=0))
# print(df4.rdiv(df8['a'],level=0))#end
# print(df8.truediv(df9))#begin
# print(df8.truediv(df9).truediv(df10))
# print(df8.truediv(df9).truediv(df10,fill_value=10))
# print(df8.truediv(df9).truediv(df10,axis=0,fill_value=10).truediv(df11))
# print(df8.truediv(df9).truediv(df10,axis=0,fill_value=10).truediv(df11,fill_value=2.3))
# print(df8.truediv(df9).truediv(df10,axis=0,fill_value=10).truediv(df11).truediv(df12))
# print(df8.truediv(df9).truediv(df10,axis=0,fill_value=10).truediv(df11).truediv(df12,fill_value=2.3))
# print(df4)
# print(df4.truediv(df8['a'],level=0))
# print(df4.truediv(df8['a'],level=1))
# print(df4.truediv(df8['a'],level=0,axis=0))
# print(df4.truediv(df8['a'],level=1,axis=0))
# print(df4.truediv(df8['a'],level='bot0',axis=0))
# print(df4.truediv(df8['a'],level=0))#end
# print(df8.rtruediv(df9))#begin
# print(df8.rtruediv(df9).rtruediv(df10))
# print(df8.rtruediv(df9).rtruediv(df10,fill_value=10))
# print(df8.rtruediv(df9).rtruediv(df10,axis=0,fill_value=10).rtruediv(df11))
# print(df8.rtruediv(df9).rtruediv(df10,axis=0,fill_value=10).rtruediv(df11,fill_value=2.3))
# print(df8.rtruediv(df9).rtruediv(df10,axis=0,fill_value=10).rtruediv(df11).rtruediv(df12))
# print(df8.rtruediv(df9).rtruediv(df10,axis=0,fill_value=10).rtruediv(df11).rtruediv(df12,fill_value=2.3))
# print(df4)
# print(df4.rtruediv(df8['a'],level=0))
# print(df4.rtruediv(df8['a'],level=1))
# print(df4.rtruediv(df8['a'],level=0,axis=0))
# print(df4.rtruediv(df8['a'],level=1,axis=0))
# print(df4.rtruediv(df8['a'],level='bot0',axis=0))
# print(df4.rtruediv(df8['a'],level=0))#end
# print(df8.floordiv(df9))#begin
# print(df8.floordiv(df9).floordiv(df10))
# print(df8.floordiv(df9).floordiv(df10,fill_value=10))
# print(df8.floordiv(df9).floordiv(df10,axis=0,fill_value=10).floordiv(df11))
# print(df8.floordiv(df9).floordiv(df10,axis=0,fill_value=10).floordiv(df11,fill_value=2.3))
# print(df8.floordiv(df9).floordiv(df10,axis=0,fill_value=10).floordiv(df11).floordiv(df12))
# print(df8.floordiv(df9).floordiv(df10,axis=0,fill_value=10).floordiv(df11).floordiv(df12,fill_value=2.3))
# print(df4)
# print(df4.floordiv(df8['a'],level=0))
# print(df4.floordiv(df8['a'],level=1))
# print(df4.floordiv(df8['a'],level=0,axis=0))
# print(df4.floordiv(df8['a'],level=1,axis=0))
# print(df4.floordiv(df8['a'],level='bot0',axis=0))
# print(df4.floordiv(df8['a'],level=0))#end
# print(df8.rfloordiv(df9))#begin
# print(df8.rfloordiv(df9).rfloordiv(df10))
# print(df8.rfloordiv(df9).rfloordiv(df10,fill_value=10))
# print(df8.rfloordiv(df9).rfloordiv(df10,axis=0,fill_value=10).rfloordiv(df11))
# print(df8.rfloordiv(df9).rfloordiv(df10,axis=0,fill_value=10).rfloordiv(df11,fill_value=2.3))
# print(df8.rfloordiv(df9).rfloordiv(df10,axis=0,fill_value=10).rfloordiv(df11).rfloordiv(df12))
# print(df8.rfloordiv(df9).rfloordiv(df10,axis=0,fill_value=10).rfloordiv(df11).rfloordiv(df12,fill_value=2.3))
# print(df4)
# print(df4.rfloordiv(df8['a'],level=0))
# print(df4.rfloordiv(df8['a'],level=1))
# print(df4.rfloordiv(df8['a'],level=0,axis=0))
# print(df4.rfloordiv(df8['a'],level=1,axis=0))
# print(df4.rfloordiv(df8['a'],level='bot0',axis=0))
# print(df4.rfloordiv(df8['a'],level=0))#end
# print(df8.mod(df9))#begin
# print(df8.mod(df9).mod(df10))
# print(df8.mod(df9).mod(df10,fill_value=10))
# print(df8.mod(df9).mod(df10,axis=0,fill_value=10).mod(df11))
# print(df8.mod(df9).mod(df10,axis=0,fill_value=10).mod(df11,fill_value=2.3))
# print(df8.mod(df9).mod(df10,axis=0,fill_value=10).mod(df11).mod(df12))
# print(df8.mod(df9).mod(df10,axis=0,fill_value=10).mod(df11).mod(df12,fill_value=2.3))
# print(df4)
# print(df4.mod(df8['a'],level=0))
# print(df4.mod(df8['a'],level=1))
# print(df4.mod(df8['a'],level=0,axis=0))
# print(df4.mod(df8['a'],level=1,axis=0))
# print(df4.mod(df8['a'],level='bot0',axis=0))
# print(df4.mod(df8['a'],level=0))#end
# print(df8.rmod(df9))#begin
# print(df8.rmod(df9).rmod(df10))
# print(df8.rmod(df9).rmod(df10,fill_value=10))
# print(df8.rmod(df9).rmod(df10,axis=0,fill_value=10).rmod(df11))
# print(df8.rmod(df9).rmod(df10,axis=0,fill_value=10).rmod(df11,fill_value=2.3))
# print(df8.rmod(df9).rmod(df10,axis=0,fill_value=10).rmod(df11).rmod(df12))
# print(df8.rmod(df9).rmod(df10,axis=0,fill_value=10).rmod(df11).rmod(df12,fill_value=2.3))
# print(df4)
# print(df4.rmod(df8['a'],level=0))
# print(df4.rmod(df8['a'],level=1))
# print(df4.rmod(df8['a'],level=0,axis=0))
# print(df4.rmod(df8['a'],level=1,axis=0))
# print(df4.rmod(df8['a'],level='bot0',axis=0))
# print(df4.rmod(df8['a'],level=0))#end
# print(df8.pow(df9))#begin
# print(df8.pow(df9).pow(df10))
# print(df8.pow(df9).pow(df10,fill_value=10))
# print(df8.pow(df9).pow(df10,axis=0,fill_value=10).pow(df11))
# print(df8.pow(df9).pow(df10,axis=0,fill_value=10).pow(df11,fill_value=2.3))
# print(df8.pow(df9).pow(df10,axis=0,fill_value=10).pow(df11).pow(df12))
# print(df8.pow(df9).pow(df10,axis=0,fill_value=10).pow(df11).pow(df12,fill_value=2.3))
# print(df4)
# print(df4.pow(df8['a'],level=0))
# print(df4.pow(df8['a'],level=1))
# print(df4.pow(df8['a'],level=0,axis=0))
# print(df4.pow(df8['a'],level=1,axis=0))
# print(df4.pow(df8['a'],level='bot0',axis=0))
# print(df4.pow(df8['a'],level=0))#end
# print(df8.rpow(df9))#begin
# print(df8.rpow(df9).rpow(df10))
# print(df8.rpow(df9).rpow(df10,fill_value=10))
# try:
    # print(df8.rpow(df9).rpow(df10,axis=0,fill_value=10).rpow(df11))
# except Exception as e:
    # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# # print(df8.rpow(df9).rpow(df10,axis=0,fill_value=10).rpow(df11,fill_value=2.3))
# # print(df8.rpow(df9).rpow(df10,axis=0,fill_value=10).rpow(df11).rpow(df12))
# # print(df8.rpow(df9).rpow(df10,axis=0,fill_value=10).rpow(df11).rpow(df12,fill_value=2.3))
# print(df4)
# print(df4.rpow(df8['a'],level=0))
# print(df4.rpow(df8['a'],level=1))
# print(df4.rpow(df8['a'],level=0,axis=0))
# print(df4.rpow(df8['a'],level=1,axis=0))
# print(df4.rpow(df8['a'],level='bot0',axis=0))
# print(df4.rpow(df8['a'],level=0))#end
# print(df8.lt(df9))#begin
# print(df8.lt(df9).lt(df10))
# print(df4)
# print(df4.lt(df8['a'],level=0))
# print(df4.lt(df8['a'],level=1))
# print(df4.lt(df8['a'],level=0,axis=0))
# print(df4.lt(df8['a'],level=1,axis=0))
# print(df4.lt(df8['a'],level='bot0',axis=0))
# print(df4.lt(df8['a'],level=0))#end
# print(df8.le(df9))#begin
# print(df8.le(df9).le(df10))
# print(df4)
# print(df4.le(df8['a'],level=0))
# print(df4.le(df8['a'],level=1))
# print(df4.le(df8['a'],level=0,axis=0))
# print(df4.le(df8['a'],level=1,axis=0))
# print(df4.le(df8['a'],level='bot0',axis=0))
# print(df4.le(df8['a'],level=0))#end
# print(df8.gt(df9))#begin
# print(df8.gt(df9).gt(df10))
# print(df4)
# print(df4.gt(df8['a'],level=0))
# print(df4.gt(df8['a'],level=1))
# print(df4.gt(df8['a'],level=0,axis=0))
# print(df4.gt(df8['a'],level=1,axis=0))
# print(df4.gt(df8['a'],level='bot0',axis=0))
# print(df4.gt(df8['a'],level=0))#end
# print(df8.ge(df9))#begin
# print(df8.ge(df9).ge(df10))
# print(df4)
# print(df4.ge(df8['a'],level=0))
# print(df4.ge(df8['a'],level=1))
# print(df4.ge(df8['a'],level=0,axis=0))
# print(df4.ge(df8['a'],level=1,axis=0))
# print(df4.ge(df8['a'],level='bot0',axis=0))
# print(df4.ge(df8['a'],level=0))#end
# print(df8.eq(df9))#begin
# print(df8.eq(df9).eq(df10))
# print(df4)
# print(df4.eq(df8['a'],level=0))
# print(df4.eq(df8['a'],level=1))
# print(df4.eq(df8['a'],level=0,axis=0))
# print(df4.eq(df8['a'],level=1,axis=0))
# print(df4.eq(df8['a'],level='bot0',axis=0))
# print(df4.eq(df8['a'],level=0))#end
# print(df8.ne(df9))#begin
# print(df8.ne(df9).ne(df10))
# print(df4)
# print(df4.ne(df8['a'],level=0))
# print(df4.ne(df8['a'],level=1))
# print(df4.ne(df8['a'],level=0,axis=0))
# print(df4.ne(df8['a'],level=1,axis=0))
# print(df4.ne(df8['a'],level='bot0',axis=0))
# print(df4.ne(df8['a'],level=0))#end
# df8=pandas.DataFrame({'a':[4,80,9],'b':[3.23,4.56,8.90]})
# print(df8)
# # print(df8.abs())
# # print(df8.loc[(df8.a-41).abs().argsort()])
# # print(df8.loc[(df8.b-41).abs().argsort()])
# df9=pandas.DataFrame({'b':[3.23,4.56,8.90],'a':[4,80,9]})
# print(df9)
# df10=pandas.DataFrame({'b':[3.23,4.56,8.90],'a':[4,80,9],'c':[5,120.,12.]})
# df11=pandas.DataFrame({'b':[3.23,4.56,8.90],'a':[4,80,9],'c':[numpy.nan,120.,12.]})
# df12=pandas.DataFrame({'b':[3.23,4.56,8.90],'a':[4,80,9],'c':[numpy.nan,120.,12.]})
# tuples = [
   # (0, 'mark i'), (0, 'mark ii'),
   # (1, 'mark i'), (1, 'mark ii'),
   # (2, 'mark i'), (2, 'mark ii')
# ]
# index = pandas.MultiIndex.from_tuples(tuples,names=['bot0','version0'])
# values = [[12, 2,12, 2,12, 2], [20, 24,20, 24,20, 24], [10, 20,10, 20,10, 20],
        # [21, 34,21, 34,21, 34], [17.3143, numpy.nan,numpy.inf, 26,7, 26], [36, 56,36, 56,36, 56]]
# df4 = pandas.DataFrame(values, columns=index, index=index)
# print('prefix_'+pandas.DataFrame([['a','b','c'],['d','e','f'],['g',2,'j']]).applymap(str))
# print(pandas.DataFrame([['a','b','c'],['d','e','f'],['g',2,'j']]).applymap(str)+'_suffix')
# tuples = [
   # ('cobra', 'mark i'), ('cobra', 'mark ii'),
   # ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
   # ('viper', 'mark ii'), ('viper', 'mark iii')
# ]
# index = pandas.MultiIndex.from_tuples(tuples,names=['bot0','version0'])
# values = [[12, 2,12, 2,12, 2], [20, 24,20, 24,20, 24], [10, 20,10, 20,10, 20],
        # [21, 34,21, 34,21, 34], [17, 26,7, 26,7, 26], [36, 56,36, 56,36, 56]]
# df4 = pandas.DataFrame(values, columns=index, index=index)
# s4=pandas.Series(values[0],index=index)
# print(df4)
# print(df4.add_prefix('keyPrefix0_'))
# print(df4.add_suffix('_nonkeySuffix0'))
# print(s4)
# print(s4.add_prefix('keyPrefix0_'))
# print(s4.add_suffix('_nonkeySuffix0'))
# def popA0(s0):
    # s0=s0.copy()
    # s0.pop('A')
    # return s0
# df0=pandas.DataFrame([['a','b','c'],['d','e','f'],['g',2,'j']],columns=['A','B','C'])
# print(df0)
# print(popA0(df0))

# tuples = [
   # ('cobra', 'mark i'), ('cobra', 'mark ii'),
   # ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
   # ('viper', 'mark ii'), ('viper', 'mark iii')
# ]
# index = pandas.MultiIndex.from_tuples(tuples,names=['bot0','version0'])
# values = [[12, 2,12, 2,12, 2], [20, 24,20, 24,20, 24], [10, 20,10, 20,10, 20],
        # [21, 34,21, 34,21, 34], [17, 26,7, 26,7, 26], [36, 56,36, 56,36, 56]]
# df4 = pandas.DataFrame(values, columns=index, index=index)
# s4=pandas.Series(values[0],index=index)
# tuples = [
   # ('cobra', 'mark i'), ('cobra', 'mark ii'),
   # ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
   # ('viper', 'mark ii'), ('viper', 'mark iii')
# ]
# index = pandas.MultiIndex.from_tuples(tuples,names=['bot0','version0'])
# values = [[12, 2,12, 0,numpy.nan, 2],
        # [20, 24,20, 24,-2, 24],
        # [10, 20,10, 20,10, 20],
    # # [21, 34,21, 34,21, 34], [17.23, numpy.nan,numpy.inf, 26,7, 26], [36, 56,36, 56,36, 56]]
        # [21, 34,21, 34,21, 34],
        # [17.23, numpy.nan,numpy.inf, 26,7, 26],
        # [0, numpy.nan,numpy.nan, numpy.nan,numpy.nan, numpy.nan]]
# df5 = pandas.DataFrame(values, columns=index, index=index)
# s5=pandas.Series(values[0],index=index)
# df6=pandas.DataFrame(numpy.random.default_rng(8).integers(-50,100,(50,50)))
# s6=pandas.Series(df6[0])
# # # # print(df4.agg('all',axis=0))
# # # # print(df4.agg('all',axis=1))
# # # # print(df5.agg('all',axis=0))
# # # # print(df5.agg('all',axis=1))
# # # # print(df5.agg('all',skipna=False,axis=0))
# # # # print(df5.agg('all',skipna=True,axis=1))
# # # # print(df4.agg('any',axis=0))
# # # # print(df4.agg('any',axis=1))
# # # # print(df5.agg('any',axis=0))
# # # # print(df5.agg('any',axis=1))
# # # # print(df5.agg('any',skipna=False,axis=0))
# # # # print(df5.agg('any',skipna=True,axis=1))
# # # # print(s4.agg('all',axis=0))
# # # # print(s5.agg('all',axis=0))
# # # # print(s5.agg('all',skipna=False,axis=0))
# # # # print(s4.agg('any',axis=0))
# # # # print(s5.agg('any',axis=0))
# # # # print(s5.agg('any',skipna=False,axis=0))
# # print(df4.agg('all',axis=0))#begin
# # print(df4.agg('all',axis=1))
# # print(df5.agg('all',axis=0))
# # print(df5.agg('all',axis=1))
# # print(df5.agg('all',skipna=False,axis=0))
# # print(df5.agg('all',skipna=True,axis=1))
# # print(df4.agg('any',axis=0))
# # print(df4.agg('any',axis=1))
# # print(df5.agg('any',axis=0))
# # print(df5.agg('any',axis=1))
# # print(df5.agg('any',skipna=False,axis=0))
# # print(df5.agg('any',skipna=True,axis=1))
# # print(s4.agg('all',axis=0))
# # print(s5.agg('all',axis=0))
# # print(s5.agg('all',skipna=False,axis=0))
# # print(s4.agg('any',axis=0))
# # print(s5.agg('any',axis=0))
# # print(s5.agg('any',skipna=False,axis=0))#end
# # print(df4.agg('bfill',limit=1))#begin
# # print(df4.agg('bfill',limit=None))
# # print(df5.agg('bfill',limit=1))
# # print(df5.agg('bfill',limit=None))
# # print(df4.agg('ffill',limit=1))
# # print(df4.agg('ffill',limit=None))
# # print(df5.agg('ffill',limit=1))
# # print(df5.agg('ffill',limit=None))
# # print(s4.agg('bfill',limit=1))
# # print(s5.agg('bfill',limit=1))
# # print(s4.agg('ffill',limit=1))
# # print(s5.agg('ffill',limit=1))#end

# for func0 in ['all','any','bfill','ffill','fillna','corr','cov','corrwith','count','cumcount','value_counts','mean','median','std','sem','var','size','sum','max','min','nlargest','nsmallest','cummax','cummin','idxmax','idxmin','cumprod','cumsum','ohlc','describe','diff','filter','hist','ngroup','nth','unique','nunique','pct_change','plot','quantile','rank','resample','sample','shift','skew','take','is_monotonic_increasing','is_monotonic_decreasing','boxplot','head','tail','first','last']:
    # try:
        # print(df5.agg(func0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
        # try:
            # print(df5.agg(func0,5))=
        # except Exception as e:
            # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
            # try:
                # print(df5.agg(func0,5,2))
            # except Exception as e:
                # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
    # try:
        # print(df6.agg(func0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
        # try:
            # print(df6.agg(func0,5))
        # except Exception as e:
            # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
            # try:
                # print(df6.agg(func0,5,2))
            # except Exception as e:
                # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
    # try:
        # print(s5.agg(func0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
        # try:
            # print(s5.agg(func0,5))
        # except Exception as e:
            # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
            # try:
                # print(s5.agg(func0,5,2))
            # except Exception as e:
                # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
    # try:
        # print(s6.agg(func0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
        # try:
            # print(s6.agg(func0,5))
        # except Exception as e:
            # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
            # try:
                # print(s6.agg(func0,5,2))
            # except Exception as e:
                # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)

# print(pandas.period_range('2023-01-01','2023-12-31',freq='M'))
# for a0 in dir(pandas.period_range('2023-01-01','2023-12-31',freq='M')):
    # try:
        # print(a0,getattr(pandas.period_range('2023-01-01','2023-12-31',freq='M'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.period_range('2023-01-01','2023-12-31',freq='M')):
    # try:
        # listOfAttributes0.append(getattr(pandas.period_range('2023-01-01','2023-12-31',freq='M'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# print(pandas.period_range('2023-01-01','2024-12-31',freq='Y'))
# for a0 in dir(pandas.period_range('2023-01-01','2024-12-31',freq='Y')):
    # try:
        # print(a0,getattr(pandas.period_range('2023-01-01','2024-12-31',freq='Y'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.period_range('2023-01-01','2024-12-31',freq='Y')):
    # try:
        # listOfAttributes0.append(getattr(pandas.period_range('2023-01-01','2024-12-31',freq='Y'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)

# print(pandas.date_range('2023-01-01','2023-12-31',freq='M'))
# for a0 in dir(pandas.date_range('2023-01-01','2023-12-31',freq='M')):
    # try:
        # print(a0,getattr(pandas.date_range('2023-01-01','2023-12-31',freq='M'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.date_range('2023-01-01','2023-12-31',freq='M')):
    # try:
        # listOfAttributes0.append(getattr(pandas.date_range('2023-01-01','2023-12-31',freq='M'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # if '_inherit_from_data.<locals>.method' in repr(method0):
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),method0.__doc__,sep='     ')
        # else:
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)

# print(pandas.date_range('2023-01-01','2024-12-31',freq='Y'))
# for a0 in dir(pandas.date_range('2023-01-01','2024-12-31',freq='Y')):
    # try:
        # print(a0,getattr(pandas.date_range('2023-01-01','2024-12-31',freq='Y'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.date_range('2023-01-01','2024-12-31',freq='Y')):
    # try:
        # listOfAttributes0.append(getattr(pandas.date_range('2023-01-01','2024-12-31',freq='Y'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # if '_inherit_from_data.<locals>.method' in repr(method0):
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),method0.__doc__,sep='     ')
        # else:
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)

# # # # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')     
     # # # # <bound method _inherit_from_data.<locals>.method of DatetimeIndex(['2023-01-31', '2023-02-28', '2023-03-31', '2023-04-30',
               # # # # '2023-05-31', '2023-06-30', '2023-07-31', '2023-08-31',
               # # # # '2023-09-30', '2023-10-31', '2023-11-30', '2023-12-31'],
              # # # # dtype='datetime64[ns]', freq='M')>     [datetime.datetime(2023, 1, 31, 0, 0) datetime.datetime(2023, 2, 28, 0, 0) datetime.datetime(2023, 3, 31, 0, 0) datetime.datetime(2023, 4, 30, 0, 0) datetime.datetime(2023, 5, 31, 0, 0) datetime.datetime(2023, 6, 30, 0, 0) datetime.datetime(2023, 7, 31, 0, 0) datetime.datetime(2023, 8, 31, 0, 0) datetime.datetime(2023, 9, 30, 0, 0) datetime.datetime(2023, 10, 31, 0, 0) datetime.datetime(2023, 11, 30, 0, 0) datetime.datetime(2023, 12, 31, 0, 0)]

# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-03T00:00:00.000000',freq='H'))
# for a0 in dir(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-03T00:00:00.000000',freq='H')):
    # try:
        # print(a0,getattr(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-03T00:00:00.000000',freq='H'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-03T00:00:00.000000',freq='H')):
    # try:
        # listOfAttributes0.append(getattr(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-03T00:00:00.000000',freq='H'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # if '_inherit_from_data.<locals>.method' in repr(method0):
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),method0.__doc__,sep='     ')
        # else:
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)

# print(pandas.timedelta_range(start='1 day',periods=5))
# print(pandas.period_range('2023-01-01','2023-01-05',freq='D'))
# print(pandas.timedelta_range(start='1 day',periods=5)+pandas.period_range('2023-01-01','2023-01-05',freq='D'))
# print(pandas.timedelta_range(start='1 day',end='10 days',periods=5))
# print(pandas.timedelta_range(start='1 day',end='10 days',freq='12H'))
# for closed0 in ['left','right',None]:
    # print(pandas.timedelta_range(start='1 day',end='10 days',periods=5,closed=closed0,name=f'{closed0}'))
# print(pandas.timedelta_range(start='1 day',periods=5))
# for a0 in dir(pandas.timedelta_range(start='1 day',periods=5)):
    # try:
        # print(a0,getattr(pandas.timedelta_range(start='1 day',periods=5),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.timedelta_range(start='1 day',periods=5)):
    # try:
        # listOfAttributes0.append(getattr(pandas.timedelta_range(start='1 day',periods=5),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # if '_inherit_from_data.<locals>.method' in repr(method0):
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),method0.__doc__,sep='     ')
        # else:
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)

# print(pandas.Timedelta(weeks=4,days=4,hours=4,minutes=4,seconds=4,milliseconds=4,microseconds=4,nanoseconds=4))
# for a0 in dir(pandas.Timedelta(weeks=4,days=4,hours=4,minutes=4,seconds=4,milliseconds=4,microseconds=4,nanoseconds=4)):
    # try:
        # print(a0,getattr(pandas.Timedelta(weeks=4,days=4,hours=4,minutes=4,seconds=4,milliseconds=4,microseconds=4,nanoseconds=4),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.Timedelta(weeks=4,days=4,hours=4,minutes=4,seconds=4,milliseconds=4,microseconds=4,nanoseconds=4)):
    # try:
        # listOfAttributes0.append(getattr(pandas.Timedelta(weeks=4,days=4,hours=4,minutes=4,seconds=4,milliseconds=4,microseconds=4,nanoseconds=4),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # if '_inherit_from_data.<locals>.method' in repr(method0):
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),method0.__doc__,sep='     ')
        # else:
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)

# print(pandas.Timestamp(datetime.datetime.today(),tz='US/Central',freq='ms'))
# for a0 in dir(pandas.Timestamp(datetime.datetime.today(),tz='US/Central',freq='ms')):
    # try:
        # print(a0,getattr(pandas.Timestamp(datetime.datetime.today(),tz='US/Central',freq='ms'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.Timestamp(datetime.datetime.today(),tz='US/Central',freq='ms')):
    # try:
        # listOfAttributes0.append(getattr(pandas.Timestamp(datetime.datetime.today(),tz='US/Central',freq='ms'),a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # if '_inherit_from_data.<locals>.method' in repr(method0):
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),method0.__doc__,sep='     ')
        # else:
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)

# print(pandas.tseries.holiday)
# for a0 in dir(pandas.tseries.holiday):
    # try:
        # print(a0,getattr(pandas.tseries.holiday,a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.holiday):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.holiday,a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # if '_inherit_from_data.<locals>.method' in repr(method0):
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),method0.__doc__,sep='     ')
        # else:
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)

# print(pandas.tseries.holiday.USFederalHolidayCalendar)
# for a0 in dir(pandas.tseries.holiday.USFederalHolidayCalendar):
    # try:
        # print(a0,getattr(pandas.tseries.holiday.USFederalHolidayCalendar,a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# listOfAttributes0=[]
# for a0 in dir(pandas.tseries.holiday.USFederalHolidayCalendar):
    # try:
        # listOfAttributes0.append(getattr(pandas.tseries.holiday.USFederalHolidayCalendar,a0))
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)
# import inspect
# methods0=filter(callable,listOfAttributes0)
# for method0 in methods0:
    # try:
        # if '_inherit_from_data.<locals>.method' in repr(method0):
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),method0.__doc__,sep='     ')
        # else:
            # print(inspect.getframeinfo(inspect.currentframe()).code_context[0].strip(),'\n',method0,method0(),sep='     ')
    # except Exception as e:
        # print(inspect.getsourcelines(inspect.currentframe())[0][sys.exc_info()[2].tb_lineno-1],'\n',e)

# print(pandas.tseries.holiday.USFederalHolidayCalendar())
# print(pandas.tseries.holiday.USFederalHolidayCalendar().holidays)
# print(pandas.tseries.holiday.USFederalHolidayCalendar().holidays(start='2023-01-01',end='2023-12-31'))
# print(pandas.tseries.holiday.USFederalHolidayCalendar().holidays(start=pandas.Timestamp('2023-01-01'),end=pandas.Timestamp('2023-12-31')))

import pyautogui,pytesseract
pytesseract.pytesseract.tesseract_cmd=r'C:\Users\pdumas\AppData\Local\Tesseract-OCR\tesseract.exe'
if 'Nickname' in pytesseract.image_to_string(pyautogui.screenshot()):
    x,y=pyautogui.locateCenterOnScreen(r'C:\Users\pdumas\Downloads\extendNicknameImageForOCR.png',confidence=)
    print(x,y)

sys.stdout.close()
os.system(r'''start "" "'''+file0+'''"''')
#py -3.10 C:\Users\pdumas\Documents\Code\pandas20230331.py







from __future__ import annotations
import numpy,pandas,pandas.tseries.holiday,matplotlib,matplotlib.pyplot,sys,os,requests,pickle,time,timeit,pytz,datetime,string#,sklearn,torch,torch.nn#,torch.optim#,jinja2#,mayavi.mlab
sys.stdout = open(r'C:\Users\pdumas\Documents\SAP\SAP GUI\numpy0output1.txt','w+')
sys.stdout.reconfigure(encoding='utf-8')
# print(numpy.version)
print(sys.version)
print(numpy.version.version)
print(pandas.__version__)
# print(torch.__version__)
print(pandas.options.display.max_columns)
pandas.options.display.width=1500
pandas.options.display.max_columns=250
pandas.options.display.max_rows=250
pandas.options.display.expand_frame_repr=False

# rng0int0 = numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(3,4))
# print(rng0int0)
# print(numpy.multiply.reduceat(rng0int0,[2],dtype=numpy.int32,axis=0))
# print(numpy.multiply.reduceat(rng0int0,[0,2,1],dtype=numpy.int32,axis=0))
# print(numpy.multiply.reduceat(rng0int0,[0,2,1],dtype=numpy.int32,axis=0).shape)
# out0 = numpy.empty(shape=(3,4))
# print(numpy.multiply.reduceat(rng0int0,[0,2,1],dtype=numpy.int32,axis=0,out=out0))
# print(out0)
# print(numpy.multiply.reduceat(rng0int0,[0,2,1],dtype=numpy.int32,axis=1))
# rng0int1 = numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,3))
# rng0int2 = numpy.random.default_rng(seed=3).integers(low=0,high=5,size=(3,2))
# print(rng0int1)
# print(rng0int2)
# print(numpy.multiply.outer(rng0int1,rng0int2,dtype=numpy.float64))
# rng0int3 = numpy.random.default_rng(seed=3).integers(low=0,high=5,size=(2,3))
# print(rng0int3)
# print(numpy.multiply.outer(rng0int1,rng0int3,dtype=numpy.float64))
# ndarray0 = numpy.arange(60.).reshape(3,4,5)
# ndarray1 = numpy.arange(24.).reshape(4,3,2)
# try:
    # ndarray2 = numpy.tensordot(ndarray0,ndarray1,axes=1)
# except Exception as e:
    # print(e)
# ndarray2 = numpy.tensordot(ndarray0,ndarray1,axes=([1,0],[0,1]))
# print(ndarray2.shape)
# print(ndarray2)
# ndarray3 = numpy.array([1,2,3,4])
# ndarray4 = numpy.array([1,2,3,4])
# ndarray3.shape = (2,2)
# ndarray4 = ndarray4.reshape(2,2)
# print(ndarray3)
# print(ndarray4)
# print(ndarray3.shape == ndarray4.shape)
# ndarray5 = numpy.array([1,2])
# ndarray6 = numpy.array([4,5])
# print(numpy.tensordot(ndarray5,ndarray6,0))
# print(numpy.tensordot(ndarray5,ndarray6,1))
# try:
    # print(numpy.tensordot(ndarray5,ndarray6,2))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.tensordot(ndarray5,ndarray6,(1,0)))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.tensordot(ndarray5,ndarray6,(0,1)))
# except Exception as e:
    # print(e)
# ndarray7 = numpy.array([1,2,3,4]).reshape(2,2)
# ndarray8 = numpy.array([4,5,6,7]).reshape(2,2)
# print(ndarray7)
# print(ndarray8)
# print(numpy.tensordot(ndarray7,ndarray8,0))
# print('\r\n')
# print(numpy.tensordot(ndarray7,ndarray8,1))
# print('\r\n')
# print(numpy.tensordot(ndarray7,ndarray8,2))
# print('\r\n')
# print(numpy.tensordot(ndarray7,ndarray8,(1,0)))
# print('\r\n')
# print(numpy.tensordot(ndarray7,ndarray8,(0,1)))
# print('\r\n'*4)
# ndarray7 = numpy.array([1,2,3,4]).reshape(2,2)
# ndarray8 = numpy.array([100,5,6,7]).reshape(2,2)
# print(ndarray7)
# print(ndarray8)
# print(numpy.tensordot(ndarray7,ndarray8,0))
# print('\r\n')
# print(numpy.tensordot(ndarray7,ndarray8,1))
# print('\r\n')
# print(numpy.tensordot(ndarray7,ndarray8,2))
# print('\r\n')
# print(numpy.tensordot(ndarray7,ndarray8,(1,0)))
# print('\r\n')
# print(numpy.tensordot(ndarray7,ndarray8,(0,1)))
# try:
    # print(numpy.tensordot(ndarray7,ndarray8,(2,0)))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.tensordot(ndarray7,ndarray8,(0,2)))
# except Exception as e:
    # print(e)
# print('\r\n')
# print(numpy.tensordot(ndarray7,ndarray8,(0,0)))
# print('\r\n')
# print(numpy.tensordot(ndarray7,ndarray8,(1,1)))
# try:
    # print(numpy.dot(numpy.arange(1,4,1)))
# except Exception as e:
    # print(e)
# ndarray9 = numpy.array([1,2,3,4])
# ndarray10 = numpy.array([4,5,6,7])
# print(numpy.dot(ndarray9,ndarray10))
# ndarray11 = numpy.array([1j,2j,3j,4])
# ndarray12 = numpy.array([4j,5j,6j,7])
# print(numpy.dot(ndarray11,ndarray12))
# print(numpy.dot(ndarray7,ndarray8))
# a = numpy.array([1, 0, 0, 1]).reshape(2,2)
# b = numpy.array([4, 1, 2, 2]).reshape(2,2)
# print(a)
# print(b)
# print(numpy.dot(a,b))
# print(numpy.matmul(a,b))
# print((a@b))
# a=100
# print(numpy.dot(a,b))
# print(numpy.multiply(a,b))
# print((a*b))
# try:
    # print(numpy.matmul(a,b))
# except Exception as e:
    # print(e)
# try:
    # print((a@b))
# except Exception as e:
    # print(e)
# out0 = numpy.empty(shape=(2,2))
# numpy.dot(a,b,out=out0)
# print(out0)
# # print(a.dtype)
# print(b.dtype)
# out0 = numpy.empty(shape=(2,2),dtype=numpy.int32)
# print(numpy.dot(a,b,out=out0))
# print(out0)
# print(2*2*8*2)
# ndarray13 = numpy.arange(64).reshape(2,2,8,2)
# ndarray14 = numpy.arange(64).reshape(2,2,2,8)
# print(numpy.dot(ndarray13,ndarray14))
# ndarray13 = numpy.arange(64).reshape(2,2,16,1)
# ndarray14 = numpy.arange(64).reshape(2,2,2,8)
# try:
    # print(numpy.dot(ndarray13,ndarray14))
# except Exception as e:
    # print(e)
# ndarray13 = numpy.arange(64).reshape(2,2,8,2)
# print(ndarray13)
# print(numpy.dot(ndarray13,[1000,2000]))
# print(numpy.eye(4,M=5,k=1,dtype=numpy.complex_,order='C',like=None))
# print(numpy.eye(4,k=-1,dtype=numpy.complex_,order='C',like=None))
# print('trace')
# print(numpy.trace(numpy.eye(4,k=-1,dtype=numpy.complex_,order='C',like=None),offset=0))
# print(numpy.trace(numpy.eye(4,k=-1,dtype=numpy.complex_,order='C',like=None),offset=-1))
# print(numpy.identity(4,dtype=numpy.complex_,like=None))
# b = numpy.array([4, 1, 2, 3]).reshape(2,2)
# print(numpy.diag(b,k=0))
# print(numpy.diag(numpy.diag(b,k=0)))
# print(numpy.diag(b,k=1))
# print(numpy.diag(b,k=-1))
# a = numpy.arange(8).reshape((2,2,2))
# print(a)
# print(numpy.trace(a))
# a[1,1,1]=100
# print(a)
# print(numpy.trace(a))
# a[0,1,0]=50
# print(a)
# print(numpy.trace(a))
# a[0,0,0]=200
# print(a)
# print(numpy.trace(a))
# a = numpy.arange(16).reshape((2,2,2,2))
# print(a)
# print('\r\r\r')
# print(numpy.trace(a))
# a = numpy.arange(8).reshape((2,2,2))
# print(a)
# out0=numpy.empty(shape=2)
# print(numpy.trace(a,axis1=2,axis2=0,dtype=numpy.float32,out=out0))
# a = numpy.arange(8).reshape((2,2,2))
# a[0,0,1]=100
# print(a)
# out0=numpy.empty(shape=2)
# print(numpy.trace(a,axis1=2,axis2=0,dtype=numpy.float32,out=out0))
# a = numpy.arange(8).reshape((2,2,2))
# a[0,0,1]=100
# a[1,1,1]=200
# print(a)
# out0=numpy.empty(shape=2)
# print(numpy.trace(a,axis1=2,axis2=0,dtype=numpy.float32,out=out0))
# print(numpy.trace(a,axis1=0,axis2=2,dtype=numpy.float32,out=out0))
# print(out0)
# try:
    # numpy.matrix(a)
# except Exception as e:
    # print(e)
# print(numpy.matrix(numpy.array([[1,2],[3,4]]),dtype=numpy.complex_,copy=False))
# matrix0 = numpy.matrix(numpy.array([[1,2],[3,4]]),dtype=numpy.complex_,copy=False)
# matrix0[0,0]=100
# print(matrix0)
# print(numpy.matrix(numpy.array([[1,2],[3,4]]),dtype=numpy.complex_))
# matrix1 = numpy.matrix(numpy.array([[1,2],[3,4]]),dtype=numpy.complex_)
# matrix1[0,0]=100
# print(matrix1)
# print(numpy.matrix(numpy.array([[1,2],[3,4]]),dtype=numpy.complex_,copy=True))
# matrix1 = numpy.matrix(numpy.array([[1,2],[3,4]]),dtype=numpy.complex_,copy=True)
# matrix1[0,0]=100
# print(matrix1)
# print(numpy.array([[1,2],[3,4]]))
# print(numpy.diagonal(numpy.array([[1,2],[3,4]])))
# print(numpy.diagonal(numpy.array([[1,2],[3,4]]),offset=1))
# print(numpy.diagonal(numpy.array([[1,2],[3,4]]),offset=-1))
# try:
    # print(numpy.fliplr(numpy.diagonal(numpy.array([[1,2],[3,4]]))))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.fliplr(numpy.diagonal(numpy.array([[1,2,3],[3,4,5]]))))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.fliplr(numpy.diagonal(numpy.array([[1,2,3],[3,4,5],[5,6,7]]))))
# except Exception as e:
    # print(e)
# print(numpy.fliplr(numpy.array([[1,2,3],[3,4,5],[5,6,7]])))
# print(numpy.flip(numpy.array([[1,2,3],[3,4,5],[5,6,7]]),axis=1))
# print(numpy.flipud(numpy.array([[1,2,3],[3,4,5],[5,6,7]])))
# print(numpy.flip(numpy.array([[1,2,3],[3,4,5],[5,6,7]]),axis=0))
# print(numpy.flip(numpy.array([[1,2,3],[3,4,5],[5,6,7]])))
# print(numpy.flip(numpy.array([[1,2,3],[3,4,5],[5,6,7]]),axis=None))
# print(numpy.flip(numpy.array([[1,2,3],[3,4,5],[5,6,7]]),axis=(0,1)))
# print(numpy.diagonal(numpy.fliplr(numpy.array([[1,2,3],[3,4,5],[5,6,7]]))))
# print(numpy.diagonal(numpy.flipud(numpy.array([[1,2,3],[3,4,5],[5,6,7]]))))
# print(numpy.flipud(numpy.diagonal(numpy.array([[1,2],[3,4]]))))
# print(numpy.diagonal(numpy.array([[[1,2],[3,4]],[[5,6],[7,8]]]),axis1=1,axis2=2))
# print(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,2,2,2)))
# default_rng1 = numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,2,2,2))
# print(default_rng1[...,0])
# print(default_rng1[0,...])
# print(default_rng1[0,...,0])
# try:
    # print(default_rng1[...,0,0,...])
# except Exception as e:
    # print(e)
# print('rot90')
# print(numpy.array([[1,2,3],[3,4,5],[5,6,7]]))
# print(numpy.rot90(numpy.array([[1,2,3],[3,4,5],[5,6,7]]),1,axes=(0,1)))
# print(numpy.rot90(numpy.array([[1,2,3],[3,4,5],[5,6,7]]),))
# print(numpy.rot90(numpy.array([[1,2,3],[3,4,5],[5,6,7]]),-1,axes=(0,1)))
# print(numpy.rot90(numpy.array([[1,2,3],[3,4,5],[5,6,7]]),1,axes=(1,0)))
# print(numpy.rot90(numpy.array([[1,2,3],[3,4,5],[5,6,7]]),2,axes=(0,1)))
# print(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,2,2,2)))
# print(numpy.rot90(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,2,2,2)),1,axes=(2,3)))
# print(numpy.rot90(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,2,2,2)),1,axes=(3,0)))
# print(numpy.diagflat(numpy.array([[1,2,3],[3,4,5],[5,6,7]])))
# print(numpy.diagflat(numpy.array([[1,2,3],[3,4,5],[5,6,7]]),k=1))
# print(numpy.diagflat(numpy.array([[1,2,3],[3,4,5],[5,6,7]]),k=-1))
# print(numpy.tri(4,M=5,k=1,dtype=numpy.complex_,like=None))
# print(numpy.tri(4,k=-1,dtype=numpy.complex_,like=None))
# print(numpy.tri(4,dtype=numpy.complex_,like=None))
# print(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,2,2,2)))
# print(numpy.triu(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,2,2,2))))
# print(numpy.triu(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,2,2,2)),k=1))
# print(numpy.tril(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,2,2,2))))
# print(numpy.tril(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,2,2,2)),k=1))
# print(numpy.tril(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,2,2,2)),k=-1))
# print()
# print(numpy.full((2,2,2,2),[5,100],dtype=numpy.float64,order='C',like=None))
# print(numpy.full_like(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,2,2,2)),[5,100],dtype=numpy.int64,order='K',subok=True,shape=None))
# print(numpy.full_like(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,2,2,2)),[5,100,200,205],dtype=numpy.float64,order='C',subok=False,shape=(4,4)))
# print('vdot')
# a0array = numpy.array([1+2j])
# b0array = numpy.array([5+6j])
# a0arrayBeforeConjugation = numpy.array([1-2j])
# print(numpy.vdot(a0arrayBeforeConjugation,b0array))
# a0 = complex(1,2)
# b0 = complex(5,6)
# print(a0)
# print(b0)
# print(sum([a0.real*b0.real,-(a0.imag*b0.imag)]),sum([a0.real*b0.imag,a0.imag*b0.real]))
# a0 = complex(3,4)
# b0 = complex(7,8)
# print(a0)
# print(b0)
# print(sum([a0.real*b0.real,-(a0.imag*b0.imag)]),sum([a0.real*b0.imag,a0.imag*b0.real]))
# a = numpy.array([1-2j,3-4j])
# b = numpy.array([5+6j,7+8j])
# print(numpy.vdot(a,b))
# print(numpy.vdot(numpy.array([[1,2,3],[3,4,5],[5,6,7]]),numpy.array([[1,2,3],[3,4,5],[5,6,7]])))
# sum0=0
# for i in range(numpy.array([[1,2,3],[3,4,5],[5,6,7]]).size):
    # sum0 += sum(x**2 for x in numpy.array([[1,2,3],[3,4,5],[5,6,7]])[::1])
    # print(x**2 for x in numpy.array([[1,2,3],[3,4,5],[5,6,7]])[::1])
    # print(numpy.array([[1,2,3],[3,4,5],[5,6,7]])[::1])
    # print(numpy.array([[1,2,3],[3,4,5],[5,6,7]])[::1]**2)
    # print(numpy.sum(numpy.array([[1,2,3],[3,4,5],[5,6,7]])[::1]**2))
# print(sum0)
# import math
# # a = numpy.arange(math.prod(2,2,3,2)).reshape((2,2,3,2))
# a = numpy.arange(2*2*3*2).reshape((2,2,2,3))
# b = numpy.arange(2*2*3*2).reshape((2,2,3,2))
# print(a)
# print(b)
# out0=numpy.empty((2,2,2,2))
# print(numpy.matmul(a,b,out=out0))
# print(out0)
# print(numpy.matmul(a,b,out=out0,dtype=numpy.float32,subok=False,casting='unsafe',order='C'))
# print(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,3)))
# print(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(3,2)))
# print(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,4)))
# print(numpy.linalg.multi_dot(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,3))))
# print(numpy.linalg.multi_dot([numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,3)),numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(3,2)),numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,4))]).dtype)
# try:
    # out0 = numpy.empty((2,4),dtype=numpy.int32)
    # print(numpy.linalg.multi_dot([numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,3)),numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(3,2)),numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,4))],out=out0))
# except Exception as e:
    # print(e)
# out0 = numpy.empty((2,4),dtype=numpy.int64)
# print(numpy.linalg.multi_dot([numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,3)),numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(3,2)),numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,4))],out=out0))
# print(out0)
# matmul0 = numpy.matmul(numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,3)),numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(3,2)))
# print(numpy.matmul(matmul0,numpy.random.default_rng(seed=2).integers(low=0,high=5,size=(2,4))))
# import site
# print(site.getsitepackages())
# print(numpy.atleast_2d(numpy.array([1,2])))
# print(numpy.transpose(numpy.atleast_2d(numpy.array([1,2]))))
# print(numpy.atleast_1d(1,numpy.array([1]),numpy.array([1,2]),numpy.array([[1,2],[3,4]]),numpy.array([[[1,2,3],[3,4,5],[5,6,7]]])))
# print(numpy.atleast_2d(1,numpy.array([1]),numpy.array([1,2]),numpy.array([[1,2],[3,4]]),numpy.array([[[1,2,3],[3,4,5],[5,6,7]]])))
# print(numpy.atleast_3d(1,numpy.array([1]),numpy.array([1,2]),numpy.array([[1,2],[3,4]]),numpy.array([[[1,2,3],[3,4,5],[5,6,7]]])))
# try:
    # a = numpy.arange(2*2*3*2).reshape((2,2,2,3),order='K')
# except Exception as e:
    # print(e)
# a = numpy.arange(2*2).reshape((2,2),order='C')
# print(a)
# print(a.transpose())
# print(a.T)
# print(a.transpose(1,0))
# print(a.transpose(0,1))
# print(numpy.transpose(a))
# print(numpy.transpose(a,(1,0)))
# print(numpy.transpose(a,(0,1)))
# a = numpy.arange(2*2*3*2).reshape((2,2,2,3),order='F')
# a = numpy.arange(4*3*2*1).reshape((4,3,2,1),order='C')
# a = numpy.arange(1*2*3*4).reshape((1,2,3,4),order='C')
# print(a)
# print(a.transpose())
# print(a.T)
# print(a.transpose(3,2,1,0))
# print(a.transpose(2,3,0,1))
# print(numpy.transpose(a))
# print(numpy.transpose(a,(3,2,1,0)))
# print(numpy.transpose(a,(2,3,0,1)))
# print('outer')
# out0 = numpy.empty((4,4),dtype=numpy.int32)
# print(numpy.outer(numpy.arange(2*2).reshape(2,2),numpy.arange(2*2).reshape(2,2)).dtype)
# print(numpy.outer(numpy.arange(2*2).reshape(2,2),numpy.arange(2*2).reshape(2,2),out=out0))
# print(out0)
# print(numpy.multiply.outer(numpy.ravel(numpy.arange(2*2).reshape(2,2)),numpy.ravel(numpy.arange(2*2).reshape(2,2))))
# print(numpy.einsum('i,j->ij',numpy.ravel(numpy.arange(2*2).reshape(2,2)),numpy.ravel(numpy.arange(2*2).reshape(2,2))))
# print(numpy.tensordot(numpy.ravel(numpy.arange(2*2).reshape(2,2)),numpy.ravel(numpy.arange(2*2).reshape(2,2)),axes=((),())))
# print(numpy.tensordot(numpy.ravel(numpy.arange(2*2).reshape(2,2)),numpy.ravel(numpy.arange(2*2).reshape(2,2)),axes=(0,0)))
# try:
    # print(numpy.array([[0,1],[2,3]]).reshape(1))
# except Exception as e:
    # print(e)
# print(numpy.array([[0,1],[2,3]]).reshape(-1))
# print(numpy.ravel(numpy.array([[0,1],[2,3]],order='C'),order='K'))
# print(numpy.ravel(numpy.array([[0,1],[2,3]],order='C'),order='F'))
# print(numpy.ravel(numpy.array([[0,1],[2,3]],order='F'),order='F'))
# print(numpy.ravel(numpy.array([[0,1],[2,3]],order='F'),order='C'))
# x = numpy.array([[1, 2, 3], [4, 5, 6]])
# print(numpy.ravel(x))
# print(numpy.ravel(x, order='F'))
# x = numpy.array([[1, 2], [3,4]])
# print(numpy.ravel(x))
# print(numpy.ravel(x, order='F'))
# print('swapaxes')
# print(numpy.arange(8).reshape((2,2,2)))
# print(numpy.swapaxes(numpy.arange(8).reshape((2,2,2)),0,2))
# print(numpy.swapaxes(numpy.arange(8).reshape((2,2,2)),2,0))
# print(numpy.swapaxes(numpy.arange(8).reshape((2,2,2)),0,1))
# print(numpy.ravel(numpy.swapaxes(numpy.arange(8).reshape((2,2,2)),0,2),order='C'))
# print(numpy.ravel(numpy.swapaxes(numpy.arange(8).reshape((2,2,2)),0,2),order='K'))
# print(type(numpy.arange(8).reshape((2,2,2)).flat))
# print(numpy.flatiter)
# print(type(type(numpy.arange(8).reshape((2,2,2)).flat)))
# print(type(numpy.flatiter))
# print(type(numpy.arange(8).reshape((2,2,2)).flatten()))
# print(numpy.arange(8).reshape((2,2,2)).flatten(order='C'))
# print(numpy.arange(8).reshape((2,2,2)).flat)
# print(numpy.arange(8).reshape((2,2,2)).flatten(order='F'))
# x=numpy.arange(8).reshape((2,2,2))
# x1=x.flatten()
# x2=x.flat
# x3=numpy.ravel(x)
# print(x1.base)
# try:
    # for i in range(x1.size):
        # print(x1.coords)
        # next(x1)
# except Exception as e:
    # print(e)
# try:
    # for i in range(x1.size):
        # print(x1.index)
        # next(x1)
# except Exception as e:
    # print(e)
# x10 = x1.copy()
# print(x2.base)
# try:
    # for i in range(x2.size):
        # print(x2.coords)
        # next(x2)
# except Exception as e:
    # print(e)
# for i in range(x.size):
    # print(x2.coords)
    # next(x2)
# for i in range(x.size):
    # print(x2.index)
    # try:
        # next(x2)
    # except Exception as e:
        # print(e)
# x2=x.flat
# for i in range(x.size):
    # print(x2.index)
    # next(x2)
# x20 = x2.copy()
# x1[7]=100
# print(x)
# x3[7]=100
# print(x)
# print('inner')
# a = numpy.array([1-2j,3-4j])
# b = numpy.array([5+6j,7+8j])
# print(numpy.inner(a,b))
# a = numpy.array([1+2j,3+4j])
# b = numpy.array([5+6j,7+8j])
# print(numpy.vdot(a,b))
# print(numpy.inner([1,2,3,4],[1,2,3,4]))
# print(numpy.array([[1,2,3],[3,4,5],[5,6,7]]))
# print(numpy.array([[1,2,3],[3,4,5],[5,6,7]]))
# print(numpy.inner(numpy.array([[1,2,3],[3,4,5],[5,6,7]]),numpy.array([[1,2,3],[3,4,5],[5,6,7]])))
# print(numpy.inner(numpy.array([[[1,2,3],[3,4,5],[5,6,7]],[[1,2,3],[3,4,5],[5,6,7]]]),numpy.array([[1,2,3],[3,4,5],[5,6,7]])))
# print(numpy.random.rand(10, 10, 10, 10))
# print('moveaxis')
# print(numpy.arange(8).reshape((2,2,2)))
# print(numpy.moveaxis(numpy.arange(8).reshape((2,2,2)),0,2))
# print(numpy.moveaxis(numpy.arange(8).reshape((2,2,2)),2,0))
# print(numpy.moveaxis(numpy.arange(8).reshape((2,2,2)),0,1))
# print(numpy.moveaxis(numpy.arange(8).reshape((2,2,2)),[0,1],[-1,-2]))
# print('einsum')
# a = numpy.arange(8).reshape((2,2,2))
# print(a)
# print(numpy.einsum('ijk,abc',a,a))
# print(numpy.einsum('ijk,',a,10))
# print(numpy.einsum(a,[...],10,[]))
# a = numpy.arange(4).reshape((2,2))
# print(a)
# print(numpy.einsum('ij,jk',a,a))
# print(numpy.einsum('ij,ji',a,a))
# a = numpy.array([[0,1],[2,3]])
# print(numpy.einsum('ij,ji',a,a))
# a = numpy.array([[0,1],[2,30]])
# print(a)
# print(a.T)
# print(numpy.einsum('ij,ji',a,a))
# print(numpy.einsum('ij,ji->j',a,a))
# print(numpy.einsum('ij,ji->i',a,a))
# a = numpy.array([[0,10],[2,3]])
# print(a)
# print(a.T)
# print(numpy.einsum('ij,ji',a,a))
# print(numpy.einsum('ij,ji->j',a,a))
# print(numpy.einsum('ij,ji->i',a,a))
# print(numpy.einsum('ij,ji->',a,a))
# a = numpy.array([[0,1],[2,3]])
# print('implicit')
# print(numpy.einsum('ij,jh',a,a))
# print(numpy.einsum('ij,jk->ik',a,a))
# print(numpy.einsum('ij,jk->ki',a,a))
# try:
    # print(numpy.einsum('i,i->',a,a))
# except Exception as e:
    # print(e)
# print(numpy.einsum('ij,ij->',a,a))
# print(numpy.einsum('ii->i',a))
# print(numpy.einsum('ii->',a))
# try:
    # print(numpy.einsum('i->',a))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.einsum('->',a))
# except Exception as e:
    # print(e)
# a = numpy.arange(8).reshape((2,2,2))
# try:
    # print(numpy.einsum('ii->i',a))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.einsum('iii->ii',a))
# except Exception as e:
    # print(e)
# print(numpy.einsum('iii->i',a))
# print(numpy.einsum('ijk->kji',a))
# print(numpy.einsum('ijk->kji',a))
# numpy.einsum('iii->i',a)[:]=1000
# print(a)
# a = numpy.arange(8).reshape((2,2,2))
# print(a)
# print(numpy.einsum('ijk,jik->k',a,a))
# a = numpy.arange(8).reshape((2,2,2))
# a.flat[7]=100
# print(a)
# print(numpy.einsum('ijk,jik->k',a,a))
# print(numpy.einsum('ijk,ijk->k',a,a))
# a = numpy.arange(4*2*2*3).reshape((4,2,2,3))
# try:
    # einsum_path0 = numpy.einsum_path('ijkl,jikl,ijlk->',a,a,a,optimize='optimal')
# except Exception as e:
    # print(e)
# a = numpy.arange(4*4*4*4).reshape((4,4,4,4))
# einsum_path0 = numpy.einsum_path('ijkl,jikl,ijlk->',a,a,a,optimize='optimal')
# for i in einsum_path0:
    # print(i)
# import time
# timeStart0 = time.time()
# for i in range(1000):
    # numpy.einsum('ijkl,jikl,ijlk->',a,a,a)
# timeEnd0 = time.time()
# print(timeEnd0-timeStart0)
# timeStart0 = time.time()
# for i in range(1000):
    # numpy.einsum('ijkl,jikl,ijlk->',a,a,a,optimize='greedy')
# timeEnd0 = time.time()
# print(timeEnd0-timeStart0)
# timeStart0 = time.time()
# for i in range(1000):
    # numpy.einsum('ijkl,jikl,ijlk->',a,a,a,optimize=True)
# timeEnd0 = time.time()
# print(timeEnd0-timeStart0)
# timeStart0 = time.time()
# for i in range(1000):
    # numpy.einsum('ijkl,jikl,ijlk->',a,a,a,optimize=einsum_path0[0])
# timeEnd0 = time.time()
# print(timeEnd0-timeStart0)
# timeStart0 = time.time()

# a = numpy.ones(shape=(5,1))
# print(a)
# print(a.shape)
# b = numpy.array([1,2])
# print(b)
# print(b.shape)
# print(numpy.einsum('ij,j->',a,b))
# try:
    # print(numpy.einsum('ij,i->',a,b))
# except Exception as e:
    # print(e)

# a = numpy.random.default_rng(seed=2).integers(1,5,size=(4,2,3))
# b = numpy.random.default_rng(seed=2).integers(1,5,size=(4,4))
# print(a.shape)
# # print(b.shape)
# einsum_path0 = numpy.einsum_path('ijk,ilm,njm,nlk,abc->',a,a,a,a,a,optimize='optimal')
# for i in einsum_path0:
    # print(i)
# # timeStart0 = time.time()
# # for i in range(1000):
    # # numpy.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a)
# # timeEnd0 = time.time()
# # print(timeEnd0-timeStart0)
# # timeStart0 = time.time()
# # for i in range(1000):
    # # numpy.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a,optimize='greedy')
# # timeEnd0 = time.time()
# # print(timeEnd0-timeStart0)
# # timeStart0 = time.time()
# # for i in range(1000):
    # # numpy.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a,optimize=True)
# # timeEnd0 = time.time()
# # print(timeEnd0-timeStart0)
# # timeStart0 = time.time()
# # for i in range(1000):
    # # numpy.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a,optimize=einsum_path0[0])
# # timeEnd0 = time.time()
# # print(timeEnd0-timeStart0)
# print('at')
# print(a)
# try:
    # print(numpy.multiply.at(a,[[...,2],[...,2]],2))
# except Exception as e:
    # print(e)
# print(numpy.multiply.at(a,[...,2],2))
# print(a)
# print(numpy.multiply.at(a,(...,2),2))
# print(a)
# print(numpy.multiply.at(a,(0,0,2),2))
# print(a)
# b = a.copy()
# c = a.copy()
# print(numpy.multiply.at(a,[0,0],2))  #TUPLE for multi-dimensional indexing; this is NOT TUPLE, hence, will give different behavior
# print(a)
# print(numpy.multiply.at(b,[0,0,2],2))  #TUPLE for multi-dimensional indexing; this is NOT TUPLE, hence, will give different behavior
# print(b)
# print(numpy.multiply.at(c,(...),numpy.array([0,0,2])))
# print(c)
# a = numpy.array([[0,1],[2,3]])
# print(a)
# print(numpy.sum(a,axis=0))
# print(numpy.sum(a,axis=1))
# print(numpy.random.default_rng(seed=2).integers(5,6,size=(3,3),endpoint=True))
# print(numpy.random.default_rng(seed=3).integers(5,6,size=(3,3),endpoint=True))
# print('add0')
# print(numpy.add(numpy.random.default_rng(seed=2).integers(5,6,size=(3,3),endpoint=True),numpy.random.default_rng(seed=3).integers(5,6,size=(3,3),endpoint=True)))
# print(numpy.subtract(numpy.random.default_rng(seed=2).integers(5,6,size=(3,3),endpoint=True),numpy.random.default_rng(seed=3).integers(5,6,size=(3,3),endpoint=True)))
# print(numpy.multiply(numpy.random.default_rng(seed=2).integers(5,6,size=(3,3),endpoint=True),numpy.random.default_rng(seed=3).integers(5,6,size=(3,3),endpoint=True)))
# print(numpy.divide(numpy.random.default_rng(seed=2).integers(5,6,size=(3,3),endpoint=True),numpy.random.default_rng(seed=3).integers(5,6,size=(3,3),endpoint=True)))
# print(numpy.true_divide(numpy.random.default_rng(seed=2).integers(5,6,size=(3,3),endpoint=True),numpy.random.default_rng(seed=3).integers(5,6,size=(3,3),endpoint=True)))
# print((numpy.random.default_rng(seed=2).integers(5,6,size=(3,3),endpoint=True))+(numpy.random.default_rng(seed=3).integers(5,6,size=(3,3),endpoint=True)))
# print((numpy.random.default_rng(seed=2).integers(5,6,size=(3,3),endpoint=True))-(numpy.random.default_rng(seed=3).integers(5,6,size=(3,3),endpoint=True)))
# print((numpy.random.default_rng(seed=2).integers(5,6,size=(3,3),endpoint=True))*(numpy.random.default_rng(seed=3).integers(5,6,size=(3,3),endpoint=True)))
# print((numpy.random.default_rng(seed=2).integers(5,6,size=(3,3),endpoint=True))/(numpy.random.default_rng(seed=3).integers(5,6,size=(3,3),endpoint=True)))
# # import math
# probability0,probability1=numpy.log(4e-50),numpy.log(5e-50)
# print(numpy.exp(numpy.logaddexp(probability0,probability1)))
# probability0,probability1=numpy.log2(4e-50),numpy.log2(5e-50)
# print(2**(numpy.logaddexp2(probability0,probability1)))
# print(numpy.floor_divide(numpy.random.default_rng(seed=2).integers(5,6,size=(3,3),endpoint=True),numpy.random.default_rng(seed=3).integers(5,6,size=(3,3),endpoint=True)))
# print((numpy.random.default_rng(seed=2).integers(5,6,size=(3,3),endpoint=True))//(numpy.random.default_rng(seed=3).integers(5,6,size=(3,3),endpoint=True)))
# print(numpy.random.default_rng(seed=2).integers(-6,-5,size=(3,3),endpoint=True))
# print(numpy.random.default_rng(seed=3).integers(-6,-5,size=(3,3),endpoint=True))
# print(numpy.floor_divide(numpy.random.default_rng(seed=2).integers(-6,-5,size=(3,3),endpoint=True),numpy.random.default_rng(seed=3).integers(-6,-5,size=(3,3),endpoint=True)))
# print(numpy.random.default_rng(seed=2).integers(-6,-5,size=(4,4),endpoint=True))
# print(numpy.random.default_rng(seed=3).integers(-6,-5,size=(4,4),endpoint=True))
# print(numpy.floor_divide(numpy.random.default_rng(seed=2).integers(-6,-5,size=(4,4),endpoint=True),numpy.random.default_rng(seed=3).integers(-6,-5,size=(4,4),endpoint=True)))
# print(numpy.floor_divide(-6,5))
# print(numpy.remainder(-6,5))
# print(numpy.remainder(-6,-5))
# print(numpy.remainder(3,5))
# print(numpy.remainder(5,3))
# print(numpy.remainder(-3,-5))
# print(numpy.remainder(-5,-3))
# print(numpy.remainder(3,-5))
# print(numpy.remainder(5,-3))
# print(numpy.remainder(-3,5))
# print(numpy.remainder(-5,3))
# print(numpy.remainder(-5,0))
# print(numpy.remainder(5,0))
# print(numpy.remainder(numpy.random.default_rng(seed=2).integers(-6,-5,size=(4,4),endpoint=True),numpy.random.default_rng(seed=3).integers(-6,-5,size=(4,4),endpoint=True)))
# print(numpy.mod(numpy.random.default_rng(seed=2).integers(-6,-5,size=(4,4),endpoint=True),numpy.random.default_rng(seed=3).integers(-6,-5,size=(4,4),endpoint=True)))
# print((numpy.random.default_rng(seed=2).integers(-6,-5,size=(4,4),endpoint=True))%(numpy.random.default_rng(seed=3).integers(-6,-5,size=(4,4),endpoint=True)))
# print(numpy.fmod(-6,5))
# print(numpy.fmod(-6,-5))
# print(numpy.fmod(3,5))
# print(numpy.fmod(5,3))
# print(numpy.fmod(-3,-5))
# print(numpy.fmod(-5,-3))
# print(numpy.fmod(3,-5))
# print(numpy.fmod(5,-3))
# print(numpy.fmod(-3,5))
# print(numpy.fmod(-5,3))
# print(numpy.fmod(-5,0))
# print(numpy.fmod(5,0))
numpy.set_printoptions(edgeitems=50,linewidth=100000)
# print(numpy.fmod(numpy.random.default_rng(seed=2).integers(-6,-5,size=(4,4),endpoint=True),numpy.random.default_rng(seed=3).integers(-6,-5,size=(4,4),endpoint=True)))
# print(numpy.random.default_rng(seed=2).integers(-6,-5,size=(4,4),endpoint=True))
# print(numpy.random.default_rng(seed=3).integers(-6,-5,size=(4,4),endpoint=True))
# print(numpy.divmod(numpy.random.default_rng(seed=2).integers(-6,-5,size=(4,4),endpoint=True),numpy.random.default_rng(seed=3).integers(-6,-5,size=(4,4),endpoint=True)))
# print(divmod(numpy.random.default_rng(seed=2).integers(-6,-5,size=(4,4),endpoint=True),numpy.random.default_rng(seed=3).integers(-6,-5,size=(4,4),endpoint=True)))
# print(numpy.linspace(-5,5,21))
# print('floor')
# print(numpy.floor(numpy.linspace(-5,5,21)))
# print(numpy.ceil(numpy.linspace(-5,5,21)))
# # try:
    # # from IPython import get_ipython
    # # get_ipython().run_line_magic("timeit","-o numpy.fix(numpy.linspace(-5,5,21))")
# # except Exception as e:
    # # print(e)
# # import IPython
# # from IPython.terminal.interactiveshell import TerminalInteractiveShell
# # terminalInteractiveShell0 = TerminalInteractiveShell.instance()
# # # terminalInteractiveShell0.define_macro('function0','''arg0=0''')
# # try:
    # # print(terminalInteractiveShell0.system("timeit -o numpy.fix(numpy.linspace(-5,5,21))"))
    # # out0 = terminalInteractiveShell0.system("timeit -o numpy.fix(numpy.linspace(-5,5,21))")
    # # print(out0)
    # # print(terminalInteractiveShell0.system("timeit numpy.fix(numpy.linspace(-5,5,21))"))
    # # print(terminalInteractiveShell0.system("timeit% numpy.fix(numpy.linspace(-5,5,21))"))
# # except Exception as e:
    # # print(e)
# # try:
    # # print(terminalInteractiveShell0.system("python -m IPython 'get_ipython.run_line_magic('''timeit -o numpy.fix(numpy.linspace(-5,5,21))''')'"))
    # # out0 = terminalInteractiveShell0.system("python -m IPython 'get_ipython.run_line_magic('''timeit -o numpy.fix(numpy.linspace(-5,5,21))''')'")
    # # print(out0)
    # # print(terminalInteractiveShell0.system("python -m IPython 'get_ipython.run_line_magic('''timeit numpy.fix(numpy.linspace(-5,5,21))''')'"))
# # except Exception as e:
    # # print(e)
# print(numpy.fix(numpy.linspace(-5,5,21)))
# print(numpy.trunc(numpy.linspace(-5,5,21)))
# print(numpy.rint(numpy.linspace(-5,5,21)))
# print(numpy.round_(numpy.linspace(-5,5,21),1))
# print(numpy.around(numpy.linspace(-5,5,21),1))
# print(numpy.round_(numpy.linspace(-5,5,21),0))
# print(numpy.around(numpy.linspace(-5,5,21),0))
# print(numpy.round_(numpy.linspace(-5,5,21),-1))
# print(numpy.around(numpy.linspace(-5,5,21),-1))
# out0=numpy.empty(numpy.linspace(-5,5,21).size)
# print(numpy.linspace(-5,5,21).round(0,out=out0))
# print(out0)
# print(numpy.linspace(-5-5j,5+5j,21).round(0))
# print(numpy.absolute(-1))
# print(abs(numpy.array(-1)))
# print(numpy.fabs(-1))
# print(numpy.absolute(numpy.array([1.414+1.414j,1.414+1.414j])))
# x=numpy.linspace(-10,10,num=101)
# print(x)
# xx=x+1j*x[:]
# print(xx)
# print('xx')
# print(x[numpy.newaxis,:])
# print(x[:,numpy.newaxis])
# xx=x+(1j*x[numpy.newaxis,:])
# print(xx)
# xx=x+1j*x[:,numpy.newaxis]
# print(xx)
# print(xx.size)
import matplotlib.pyplot
# # matplotlib.pyplot.imshow(numpy.abs(xx),extent=[-12,12,-12,12],cmap='Blues')
# # matplotlib.pyplot.show()
# # matplotlib.pyplot.imshow(numpy.abs(xx),extent=[-10,10,-10,10],cmap='Blues')
# print('sign')
# print(numpy.sign(numpy.linspace(-5,5,21)))
# print(numpy.sign(0-2j))
# print(numpy.sign(numpy.nan))
# print(numpy.heaviside(numpy.linspace(-5,5,21),10))
# print(numpy.heaviside(numpy.linspace(-5,5,21),numpy.linspace(5,15,21)))
# print(numpy.conj(xx[0,:]))
# print(numpy.conjugate(xx[0,:]))
# y = numpy.array([[1,2,3],[3,4,5],[5,6,7]])
# yy = y + 1j * y[:,:,numpy.newaxis]
# print(yy)
# yy = y + 1j * y[:,numpy.newaxis,:]
# print(yy)
# yy = y + 1j * y[numpy.newaxis,:,:]
# print(yy)
# yy = y + 1j * y[:,:]
# print(yy)
# print(numpy.exp(numpy.linspace(-5,5,21)))
# print(numpy.exp2(numpy.linspace(-5,5,21)))
# print(numpy.expm1(numpy.linspace(-5,5,21)))
# print(numpy.expm1(1e-10))
# print(numpy.exp(1e-10)-1)
# print(numpy.expm1(numpy.nan))
# piValues0 = numpy.exp(numpy.linspace(numpy.pi*-2,numpy.pi*2,100) + 1j * numpy.linspace(numpy.pi*-2,numpy.pi*2,100)[:,numpy.newaxis])
# matplotlib.pyplot.subplot(121)
# matplotlib.pyplot.imshow(numpy.abs(piValues0),extent=[numpy.pi*-2,numpy.pi*2,numpy.pi*-2,numpy.pi*2],cmap='Greens')
# matplotlib.pyplot.subplot(122)
# matplotlib.pyplot.imshow(numpy.angle(piValues0),extent=[numpy.pi*-2,numpy.pi*2,numpy.pi*-2,numpy.pi*2],cmap='hsv')
# # matplotlib.pyplot.show()
# print(numpy.log1p(1e-88))
# print(numpy.log(1+1e-88))
# print(numpy.log1p(numpy.nan))
# print(numpy.log1p(piValues0))
# print(numpy.log1p(numpy.log(piValues0)))
# print(numpy.log(numpy.linspace(-5,5,21)))
# print(numpy.log2(numpy.linspace(-5,5,21)))
# print(numpy.log10(numpy.linspace(-5,5,21)))
# try:
    # print(numpy.log(complex(numpy.linspace(-5,5,21),numpy.linspace(-5,5,21))))
# except Exception as e:
    # print(e)
# print((1+1j)*numpy.linspace(-5,5,21))
# print(numpy.log((1+1j)*numpy.linspace(-5,5,21)))
# print(numpy.log2((1+1j)*numpy.linspace(-5,5,21)))
# print(numpy.log10((1+1j)*numpy.linspace(-5,5,21)))
# print(numpy.log2(8))
# print(numpy.sqrt(numpy.linspace(-5,5,21)))
# print(numpy.cbrt(numpy.linspace(-5,5,21)))
# print(numpy.square(numpy.linspace(-5,5,21)))
# print(numpy.sqrt((1+1j)*numpy.linspace(-5,5,21)))
# try:
    # print(numpy.cbrt((1+1j)*numpy.linspace(-5,5,21),casting='unsafe'))
# except Exception as e:
    # print(e)
# print(numpy.square((1+1j)*numpy.linspace(-5,5,21)))
# print(numpy.lib.scimath.sqrt(numpy.linspace(-5,5,21)))
# print(numpy.emath.sqrt(numpy.linspace(-5,5,21)))
# print(numpy.reciprocal(numpy.linspace(-5,5,21)))
# print(numpy.reciprocal(numpy.linspace(-5,5,21,dtype=numpy.int64)))
# print(numpy.gcd.reduce(numpy.linspace(-5,5,21,dtype=numpy.int64)))
# try:
    # print(numpy.gcd.reduce(numpy.linspace(-5,5,21)))
# except Exception as e:
    # print(e)
# print(numpy.lcm.reduce(numpy.linspace(-5,5,21,dtype=numpy.int64)))
# print((numpy.geomspace(2,32,5,dtype=numpy.int64)))
# print(numpy.gcd.reduce(numpy.geomspace(2,32,5,dtype=numpy.int64)))
# print(numpy.lcm.reduce(numpy.geomspace(2,32,5,dtype=numpy.int64)))
# print((numpy.geomspace(2,32,5,dtype=numpy.float64).astype(int)))
# print(numpy.gcd.reduce(numpy.geomspace(2,32,5,dtype=numpy.float64).astype(int)))
# print(numpy.lcm.reduce(numpy.geomspace(2,32,5,dtype=numpy.float64).astype(int)))
# print((numpy.around(numpy.geomspace(2,32,5,dtype=numpy.float64)).astype(int)))
# print(numpy.gcd.reduce(numpy.around(numpy.geomspace(2,32,5,dtype=numpy.float64)).astype(int)))
# print(numpy.lcm.reduce(numpy.around(numpy.geomspace(2,32,5,dtype=numpy.float64)).astype(int)))
# print((numpy.around(numpy.geomspace(-2,-32,5,dtype=numpy.float64)).astype(int)))
# print(numpy.gcd.reduce(numpy.around(numpy.geomspace(-2,-32,5,dtype=numpy.float64)).astype(int)))
# print(numpy.lcm.reduce(numpy.around(numpy.geomspace(-2,-32,5,dtype=numpy.float64)).astype(int)))
# print((numpy.geomspace(2,32,5)))
# try:
    # print(numpy.gcd.reduce(numpy.geomspace(2,32,5)))
    # print(numpy.lcm.reduce(numpy.geomspace(2,32,5)))
# except Exception as e:
    # print(e)
# print('positive')
# print(numpy.positive(numpy.linspace(-5,5,21)))
# print(numpy.linspace(-5,5,21).copy())
# print(numpy.negative(numpy.linspace(-5,5,21)))
# print(-(numpy.linspace(-5,5,21)))
# try:
    # print(numpy.power(2,-2))
# except Exception as e:
    # print(e)
# print(numpy.power(2.,-2))
# print(numpy.power(numpy.nan,-2))
# print(numpy.power(2.,numpy.nan))
# print(numpy.power(numpy.linspace(-5,5,21),numpy.arange(-1,3,1)[:,numpy.newaxis]))
# print(numpy.power((1+1j)*numpy.linspace(-5,5,21),numpy.arange(-1,3,1)[:,numpy.newaxis]))
# print((((1+1j)*numpy.linspace(-5,5,21))**numpy.arange(-1,3,1)[:,numpy.newaxis]))
# matplotlib.pyplot.subplot(3,2,5).plot(numpy.linspace(1,5,4),numpy.linspace(1,5,4))
# try:
    # matplotlib.pyplot.imshow(numpy.linspace(1,5,4))
# except Exception as e:
    # print(e)
# try:
    # matplotlib.pyplot.imshow(numpy.linspace(1,5,4),numpy.linspace(1,5,4))
# except Exception as e:
    # print(e)
# matplotlib.pyplot.subplot(3,2,(1,3)).plot(numpy.linspace(1,5,4),numpy.linspace(1,5,4))
# # matplotlib.pyplot.show()
# print(numpy.float_power(2.,-2))
# print(numpy.float_power(2.5,-2))
# print(numpy.float_power(2,-2.5))
# print(numpy.float_power(-2,2.5))
# print(numpy.float_power(numpy.nan,-2))
# print(numpy.float_power(2.,numpy.nan))
# print(numpy.float_power(numpy.linspace(-5,5,21),numpy.arange(-1,3,1)[:,numpy.newaxis]))
# print(numpy.float_power((1+1j)*numpy.linspace(-5,5,21),numpy.arange(-1,3,1)[:,numpy.newaxis]))
# print('sin')
# matplotlib.pyplot.subplot(2,3,1).plot(numpy.linspace(0,numpy.pi*2,100),numpy.sin(numpy.linspace(0,numpy.pi*2,100)))
# matplotlib.pyplot.subplot(2,3,2).plot(numpy.linspace(0,numpy.pi*2,100),numpy.cos(numpy.linspace(0,numpy.pi*2,100)))
# matplotlib.pyplot.subplot(2,3,3).plot(numpy.linspace(0,numpy.pi*2,100),numpy.tan(numpy.linspace(0,numpy.pi*2,100)))
# matplotlib.pyplot.subplot(2,3,4).plot(numpy.linspace(-numpy.pi/2,numpy.pi/2,100),numpy.arcsin(numpy.linspace(-numpy.pi/2,numpy.pi/2,100)))
# matplotlib.pyplot.subplot(2,3,5).plot(numpy.linspace(0,numpy.pi,100),numpy.arccos(numpy.linspace(0,numpy.pi,100)))
# matplotlib.pyplot.subplot(2,3,6).plot(numpy.linspace(-numpy.pi/2,numpy.pi/2,100),numpy.arctan(numpy.linspace(-numpy.pi/2,numpy.pi/2,100)))
# print((numpy.pi*3)/2)
# # matplotlib.pyplot.show()
# # matplotlib.pyplot.cla()
# matplotlib.pyplot.clf()
# matplotlib.pyplot.plot(numpy.linspace(-numpy.pi,numpy.pi,100),numpy.arctan2(numpy.linspace(-numpy.pi,numpy.pi,100),numpy.linspace(-numpy.pi,numpy.pi,100)))
# # matplotlib.pyplot.show()
# print((numpy.pi*3)/4)
# matplotlib.pyplot.clf()
# matplotlib.pyplot.plot(numpy.linspace(0,numpy.pi*2,100),numpy.arctan2(numpy.sign(numpy.sin(numpy.linspace(0,numpy.pi*2,100))),numpy.sign(numpy.cos(numpy.linspace(0,numpy.pi*2,100)))))
# # matplotlib.pyplot.show()
# print(numpy.arctan2(numpy.inf,numpy.inf))
# matplotlib.pyplot.clf()
# matplotlib.pyplot.plot(numpy.linspace(1,10,10),numpy.hypot(numpy.linspace(1,10,10),numpy.linspace(1,10,10)))
# # matplotlib.pyplot.show()
# print(numpy.angle([1,1j,1+1j,0]))
# matplotlib.pyplot.clf()
# matplotlib.pyplot.subplot(121).plot((1+1j)*numpy.linspace(-5,5,21),numpy.angle((1+1j)*numpy.linspace(-5,5,21)))
# matplotlib.pyplot.subplot(122).plot((1+1j)*numpy.linspace(-5,5,21),numpy.angle((1+1j)*numpy.linspace(-5,5,21),deg=True))
# # matplotlib.pyplot.show()
# print(numpy.arange(13)*30)
# print(numpy.deg2rad(numpy.arange(13)*30))
# print(numpy.radians(numpy.arange(13)*30))
# print(numpy.rad2deg(numpy.radians(numpy.arange(13)*30)))
# print(numpy.degrees(numpy.radians(numpy.arange(13)*30)))
# print(numpy.arcsin(numpy.pi))
# print(numpy.arcsin(1.5))
# print(numpy.arccos(1.5))
# print(numpy.arctan(0+0j))
# print(numpy.arctan2(0,0))
# print(numpy.arctan2(0,+0))
# print(numpy.arctan2(0,-0))
# print(numpy.arctan2(0.,0.))
# print(numpy.arctan2(0.,+0.))
# print(numpy.arctan2(0.,-0.))
# print(numpy.arctan2(-0.,-0.))
# matplotlib.pyplot.clf()
# matplotlib.pyplot.subplot(2,3,1).plot(numpy.linspace(-5,5,100),numpy.sinh(numpy.linspace(-5,5,100)))
# matplotlib.pyplot.subplot(2,3,2).plot(numpy.linspace(-5,5,100),numpy.cosh(numpy.linspace(-5,5,100)))
# matplotlib.pyplot.subplot(2,3,3).plot(numpy.linspace(-5,5,100),numpy.tanh(numpy.linspace(-5,5,100)))
# matplotlib.pyplot.subplot(2,3,4).plot(numpy.linspace(-numpy.pi/2,numpy.pi/2,100),numpy.arcsinh(numpy.linspace(-numpy.pi/2,numpy.pi/2,100)))
# matplotlib.pyplot.subplot(2,3,5).plot(numpy.linspace(-numpy.pi,numpy.pi,100),numpy.arccosh(numpy.linspace(-numpy.pi,numpy.pi,100)))
# matplotlib.pyplot.subplot(2,3,6).plot(numpy.linspace(-numpy.pi/2,numpy.pi/2,100),numpy.arctanh(numpy.linspace(-numpy.pi/2,numpy.pi/2,100)))
# matplotlib.pyplot.show()
# print(numpy.arange(25,dtype=numpy.int64).reshape(5,5))
# try:
    # print(numpy.binary_repr(numpy.arange(25,dtype=numpy.int64).reshape(5,5)))
# except Exception as e:
    # print(e)
# binary_repr0vectorized = numpy.vectorize(numpy.binary_repr)
# print(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5)))
# print(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),5))
# print(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5))))
# print(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None))
# print(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=2))
# print(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=5))
# print(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=8))
# base_repr0vectorized = numpy.vectorize(numpy.base_repr)
# print(base_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5)))
# print(base_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),2,5))
# print(base_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5))))
# print(base_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),base=2,padding=None))
# print(base_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),base=2,padding=2))
# print(base_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),base=2,padding=5))
# print(base_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),base=2,padding=8))
# try:
    # print(base_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),base=37,padding=8))
# except Exception as e:
    # print(e)
# sys.path.append(r'C:\Users\pdumas\Documents\SAP\SAP GUI\pythonPackages0\factorization_python')
# import factorization
# print(factorization.get_factor_list(38))
# print(base_repr0vectorized(numpy.negative(numpy.arange(2*19,dtype=numpy.int64).reshape(2,19)),base=36,padding=8))
# for i in list(range(25)):
    # print(bin(i))
# print(numpy.sinh([0j,1j*numpy.pi/2,1j*numpy.pi,1j*(numpy.pi*2*3/4)]))
# print(numpy.cosh([0j,1j*numpy.pi/2,1j*numpy.pi,1j*(numpy.pi*2*3/4)]))
# print(numpy.tanh([0j,1j*numpy.pi/2,1j*numpy.pi,1j*(numpy.pi*2*3/4)]))
# print(numpy.cosh([1j*numpy.pi/2*.99,1j*numpy.pi/2*.98,1j*numpy.pi/2*.90,1j*numpy.pi/2*.50,1j*numpy.pi/2*.10]))
# print(numpy.linspace(-5,5,41))
# print(numpy.modf(numpy.linspace(-5,5,41)))
# try:
    # print(numpy.bitwise_and('00010','00110'))
# except Exception as e:
    # print(e)
# int0vectorized = numpy.vectorize(int)
# print(int0vectorized(['00010','00011'],2))
# print(binary_repr0vectorized(numpy.bitwise_and(int0vectorized(['00010','00011'],2)[0],int0vectorized(['00010','00011'],2)[1]),width=5))
# print(binary_repr0vectorized(numpy.bitwise_or(int0vectorized(['00010','00011'],2)[0],int0vectorized(['00010','00011'],2)[1]),width=5))
# print(binary_repr0vectorized(numpy.bitwise_xor(int0vectorized(['00010','00011'],2)[0],int0vectorized(['00010','00011'],2)[1]),width=5))
# print('bitwise_and')
# print(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2))
# print(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5)),width=None),2))
# print(numpy.bitwise_and(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2),int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5)),width=None),2)))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5),width=None),2))
# print(numpy.bitwise_and(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2),int0vectorized(binary_repr0vectorized(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5),width=None),2)))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2)&int0vectorized(binary_repr0vectorized(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5),width=None),2))

# print('bitwise_or')
# print(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2))
# print(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5)),width=None),2))
# print(numpy.bitwise_or(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2),int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5)),width=None),2)))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5),width=None),2))
# print(numpy.bitwise_or(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2),int0vectorized(binary_repr0vectorized(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5),width=None),2)))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2)|int0vectorized(binary_repr0vectorized(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5),width=None),2))

# print('bitwise_xor')
# print(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2))
# print(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5)),width=None),2))
# print(numpy.bitwise_xor(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2),int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5)),width=None),2)))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5),width=None),2))
# print(numpy.bitwise_xor(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2),int0vectorized(binary_repr0vectorized(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5),width=None),2)))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2)^int0vectorized(binary_repr0vectorized(numpy.arange(25,50,1,dtype=numpy.int64).reshape(5,5),width=None),2))

# print('bitwise_not')
# print(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2))
# print(numpy.bitwise_not(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2)))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2))
# print(numpy.bitwise_not(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2)))
# print(~(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2)))

# print('invert')
# print(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2))
# print(numpy.invert(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2)))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2))
# print(numpy.invert(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2)))
# print(~(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2)))

# print(numpy.bitwise_and([True,False],[True,True]))
# print(numpy.bitwise_or([True,False],[True,True]))
# print(numpy.bitwise_xor([True,False,False],[True,True,False]))
# print(numpy.bitwise_not([True,False,True,True]))
# print(numpy.bitwise_xor.__doc__)
# print(numpy.bitwise_xor.__name__)

# print(numpy.logical_and([True,False],[True,True]))
# print(numpy.logical_or([True,False],[True,True]))
# print(numpy.logical_xor([True,False,False],[True,True,False]))
# print(numpy.logical_not([True,False,True,True]))

# print((numpy.array([True,False])&numpy.array([True,True])))
# print((numpy.array([True,False])|numpy.array([True,True])))
# print((numpy.array([True,False,False])^numpy.array([True,True,False])))
# print(~(numpy.array([True,False,True,True])))

# print(+numpy.arange(10))
# print(-numpy.arange(10))


# print('left_shift')
# print(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2))
# print(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(1,6,1,dtype=numpy.int64)),width=None),2))
# print(numpy.left_shift(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2),int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(1,6,1,dtype=numpy.int64)),width=None),2)))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(1,6,1,dtype=numpy.int64),width=None),2))
# print(numpy.left_shift(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2),int0vectorized(binary_repr0vectorized(numpy.arange(1,6,1,dtype=numpy.int64),width=None),2)))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2)<<int0vectorized(binary_repr0vectorized(numpy.arange(1,6,1,dtype=numpy.int64),width=None),2))

# print('right_shift')
# print(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2))
# print(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(1,6,1,dtype=numpy.int64)),width=None),2))
# print(numpy.right_shift(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2),int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(1,6,1,dtype=numpy.int64)),width=None),2)))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(1,6,1,dtype=numpy.int64),width=None),2))
# print(numpy.right_shift(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2),int0vectorized(binary_repr0vectorized(numpy.arange(1,6,1,dtype=numpy.int64),width=None),2)))
# print(int0vectorized(binary_repr0vectorized(numpy.arange(25,dtype=numpy.int64).reshape(5,5),width=None),2)>>int0vectorized(binary_repr0vectorized(numpy.arange(1,6,1,dtype=numpy.int64),width=None),2))

# print('unpackbits')
# a = numpy.array([[2], [7], [23]], dtype=numpy.uint8)
# print(a)
# b = numpy.unpackbits(a, axis=1)
# print(b)
# p = numpy.packbits(b, axis=0)
# print(p)
# p1 = numpy.packbits(b, axis=1)
# print(p1)
# print(numpy.unpackbits(p, axis=0))
# print(numpy.unpackbits(p, axis=1))
# print(numpy.unpackbits(p, axis=1).size)
# try:
    # print(numpy.unpackbits(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.int64).reshape(5,5)),width=None),2),axis=None))
# except Exception as e:
    # print(e)
# print(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)).dtype)
# print(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)),width=None).dtype)
# print(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)),width=None),2).dtype)
# print(numpy.unpackbits(numpy.array(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)),width=None),2),dtype=numpy.uint8),axis=None))
# print(numpy.unpackbits(numpy.array(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)),width=None),2),dtype=numpy.uint8),axis=None,bitorder='big'))
# print(numpy.unpackbits(numpy.array(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)),width=None),2),dtype=numpy.uint8),axis=None,bitorder='little'))
# print(numpy.unpackbits(numpy.array(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)),width=None),2),dtype=numpy.uint8),axis=0))
# print(numpy.unpackbits(numpy.array(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)),width=None),2),dtype=numpy.uint8),axis=1))
# print(numpy.unpackbits(numpy.array(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)),width=None),2),dtype=numpy.uint8),axis=1,count=-2))
# print(numpy.unpackbits(numpy.array(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)),width=None),2),dtype=numpy.uint8),axis=1,count=9))
# print(numpy.unpackbits(numpy.array(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)),width=None),2),dtype=numpy.uint8),axis=1,count=8))
# print(numpy.packbits(numpy.unpackbits(numpy.array(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)),width=None),2),dtype=numpy.uint8),axis=1,count=8),axis=1))
# print(numpy.packbits(numpy.unpackbits(numpy.array(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)),width=None),2),dtype=numpy.uint8),axis=1,count=8),axis=1,bitorder='little'))
# print(numpy.packbits(numpy.unpackbits(numpy.array(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)),width=None),2),dtype=numpy.uint8),axis=1,count=8),axis=0))
# print(numpy.packbits(numpy.unpackbits(numpy.array(int0vectorized(binary_repr0vectorized(numpy.negative(numpy.arange(25,dtype=numpy.uint8).reshape(5,5)),width=None),2),dtype=numpy.uint8),axis=1,count=8),axis=0,bitorder='little'))

# print('array_equiv')
# print(numpy.array_equiv(numpy.array([[0,1],[0,1]]),numpy.array([0,1])))
# print(numpy.array_equiv(numpy.array([[0,numpy.nan],[0,numpy.nan]]),numpy.array([0,numpy.nan])))
# print(numpy.array_equiv(numpy.array([[0,numpy.nan],[0,numpy.nan]]),numpy.array([0,numpy.nan])))
# print(numpy.array_equiv(numpy.array([[0,numpy.nan],[0,numpy.nan]]),numpy.array([0,numpy.nan])))
# print(numpy.array_equiv(numpy.array([[0,1+1j*numpy.nan],[0,numpy.nan+1j]]),numpy.array([0,numpy.nan])))
# print(numpy.array_equiv(numpy.array([[0,1+1j*numpy.nan],[1,numpy.nan+1j]]),numpy.array([0,numpy.nan])))

# print('array_equal')
# print(numpy.array_equal(numpy.array([[0,1],[0,1]]),numpy.array([0,1])))
# print(numpy.array_equal(numpy.array([0,numpy.nan]),numpy.array([0,numpy.nan])))
# print(numpy.array_equal(numpy.array([0,numpy.nan]),numpy.array([0,numpy.nan]),equal_nan=False))
# print(numpy.array_equal(numpy.array([0,numpy.nan]),numpy.array([0,numpy.nan]),equal_nan=True))
# print(numpy.array_equal(numpy.array([0,1+1j*numpy.nan]),numpy.array([0,numpy.nan+1j]),equal_nan=True))
# print(numpy.array_equal(numpy.array([1,1+1j*numpy.nan]),numpy.array([0,numpy.nan+1j]),equal_nan=True))

# print('not_equal')
# print(numpy.linspace(-5,5,21))
# print(numpy.linspace(-2,8,21))
# print(numpy.not_equal(numpy.linspace(-5,5,21),numpy.linspace(-2,8,21)))
# print(numpy.equal(numpy.linspace(-5,5,21),numpy.linspace(-2,8,21)))
# print(numpy.less(numpy.linspace(-5,5,21),numpy.linspace(-2,8,21)))
# print(numpy.less_equal(numpy.linspace(-5,5,21),numpy.linspace(-2,8,21)))
# print(numpy.greater(numpy.linspace(-5,5,21),numpy.linspace(-2,8,21)))
# print(numpy.greater_equal(numpy.linspace(-5,5,21),numpy.linspace(-2,8,21)))
# print('not_equal 2')
# print(numpy.not_equal(numpy.linspace(-5,5,21),numpy.linspace(-5,5,21)))
# print(numpy.equal(numpy.linspace(-5,5,21),numpy.linspace(-5,5,21)))
# print(numpy.less(numpy.linspace(-5,5,21),numpy.linspace(-5,5,21)))
# print(numpy.less_equal(numpy.linspace(-5,5,21),numpy.linspace(-5,5,21)))
# print(numpy.greater(numpy.linspace(-5,5,21),numpy.linspace(-5,5,21)))
# print(numpy.greater_equal(numpy.linspace(-5,5,21),numpy.linspace(-5,5,21)))
# print('not_equal 3')
# print(numpy.not_equal(numpy.linspace(-5,5,21),numpy.linspace(-6,4,21)))
# print(numpy.equal(numpy.linspace(-5,5,21),numpy.linspace(-6,4,21)))
# print(numpy.less(numpy.linspace(-5,5,21),numpy.linspace(-6,4,21)))
# print(numpy.less_equal(numpy.linspace(-5,5,21),numpy.linspace(-6,4,21)))
# print(numpy.greater(numpy.linspace(-5,5,21),numpy.linspace(-6,4,21)))
# print(numpy.greater_equal(numpy.linspace(-5,5,21),numpy.linspace(-6,4,21)))
# print('not_equal broadcast')
# print(numpy.not_equal(numpy.array([[0,1],[0,1]]),numpy.array([0,1])))
# print(numpy.equal(numpy.array([[0,1],[0,1]]),numpy.array([0,1])))
# print(numpy.less(numpy.array([[0,1],[0,1]]),numpy.array([0,1])))
# print(numpy.less_equal(numpy.array([[0,1],[0,1]]),numpy.array([0,1])))
# print(numpy.greater(numpy.array([[0,1],[0,1]]),numpy.array([0,1])))
# print(numpy.greater_equal(numpy.array([[0,1],[0,1]]),numpy.array([0,1])))
# print('not_equal broadcast 2')
# print(numpy.not_equal(numpy.array([[0,1],[0,1]]),numpy.array([0,2])))
# print(numpy.equal(numpy.array([[0,1],[0,1]]),numpy.array([0,2])))
# print(numpy.less(numpy.array([[0,1],[0,1]]),numpy.array([0,-2])))
# print(numpy.less_equal(numpy.array([[0,1],[0,1]]),numpy.array([0,-2])))
# print(numpy.greater(numpy.array([[0,1],[0,1]]),numpy.array([0,2])))
# print(numpy.greater_equal(numpy.array([[0,1],[0,1]]),numpy.array([0,2])))

# print('!=')
# print(numpy.linspace(-5,5,21))
# print(numpy.linspace(-2,8,21))
# print((numpy.linspace(-5,5,21)!=numpy.linspace(-2,8,21)))
# print((numpy.linspace(-5,5,21)==numpy.linspace(-2,8,21)))
# print((numpy.linspace(-5,5,21)<numpy.linspace(-2,8,21)))
# print((numpy.linspace(-5,5,21)<=numpy.linspace(-2,8,21)))
# print((numpy.linspace(-5,5,21)>numpy.linspace(-2,8,21)))
# print((numpy.linspace(-5,5,21)>=numpy.linspace(-2,8,21)))
# print('!= 2')
# print((numpy.linspace(-5,5,21)!=numpy.linspace(-5,5,21)))
# print((numpy.linspace(-5,5,21)==numpy.linspace(-5,5,21)))
# print((numpy.linspace(-5,5,21)<numpy.linspace(-5,5,21)))
# print((numpy.linspace(-5,5,21)<=numpy.linspace(-5,5,21)))
# print((numpy.linspace(-5,5,21)>numpy.linspace(-5,5,21)))
# print((numpy.linspace(-5,5,21)>=numpy.linspace(-5,5,21)))
# print('!= 3')
# print((numpy.linspace(-5,5,21)!=numpy.linspace(-6,4,21)))
# print((numpy.linspace(-5,5,21)==numpy.linspace(-6,4,21)))
# print((numpy.linspace(-5,5,21)<numpy.linspace(-6,4,21)))
# print((numpy.linspace(-5,5,21)<=numpy.linspace(-6,4,21)))
# print((numpy.linspace(-5,5,21)>numpy.linspace(-6,4,21)))
# print((numpy.linspace(-5,5,21)>=numpy.linspace(-6,4,21)))
# print('!= broadcast')
# print((numpy.array([[0,1],[0,1]])!=numpy.array([0,1])))
# print((numpy.array([[0,1],[0,1]])==numpy.array([0,1])))
# print((numpy.array([[0,1],[0,1]])<numpy.array([0,1])))
# print((numpy.array([[0,1],[0,1]])<=numpy.array([0,1])))
# print((numpy.array([[0,1],[0,1]])>numpy.array([0,1])))
# print((numpy.array([[0,1],[0,1]])>=numpy.array([0,1])))
# print('!= broadcast 2')
# print((numpy.array([[0,1],[0,1]])!=numpy.array([0,2])))
# print((numpy.array([[0,1],[0,1]])==numpy.array([0,2])))
# print((numpy.array([[0,1],[0,1]])<numpy.array([0,-2])))
# print((numpy.array([[0,1],[0,1]])<=numpy.array([0,-2])))
# print((numpy.array([[0,1],[0,1]])>numpy.array([0,2])))
# print((numpy.array([[0,1],[0,1]])>=numpy.array([0,2])))

# # matplotlib.pyplot.figure()
# # matplotlib.pyplot.figure().show()
# # import time
# # time.sleep(2)
# # matplotlib.pyplot.close()
# # time.sleep(2)

# print(1e-20)
# # print(1e-20*(1+1e-5))
# print(1e-20*1e-5)
# print((1e-20*1e-5)+0)
# print(1e-10)
# print(abs(1e-10-1e-20))
# print(abs(1e-10-1e-20)<=((1e-20*1e-5)+0))
# print('isclose')
# print(numpy.geomspace(1e-25,1,25))
# print(numpy.geomspace(1e-24,1,25))
# print(numpy.isclose(numpy.geomspace(1e-25,1,25),numpy.geomspace(1e-24,1,25)))
# format_float_positional0vectorized0 = numpy.vectorize(numpy.format_float_positional)
# print(numpy.geomspace(1,1000,5),format_float_positional0vectorized0(numpy.geomspace(1,10000,5)),sep='\n')
# print(numpy.isclose(numpy.geomspace(1,1000,5),numpy.geomspace(1,10000,5),rtol=0,atol=500))
# print(numpy.isclose(numpy.geomspace(1,1000,5),numpy.geomspace(1,10000,5),rtol=.5,atol=0))
# print([numpy.nan,1.3],[numpy.nan,1],sep='\n')
# print(numpy.isclose([numpy.nan,1.3],[numpy.nan,1],rtol=.5,atol=0))
# print(numpy.isclose([numpy.nan,1.3],[numpy.nan,1],rtol=.5,atol=0,equal_nan=False))
# print(numpy.isclose([numpy.nan,1.3],[numpy.nan,1],rtol=.5,atol=0,equal_nan=True))

# print('allclose')
# print(numpy.geomspace(1e-25,1,25))
# print(numpy.geomspace(1e-24,1,25))
# print(numpy.allclose(numpy.geomspace(1e-25,1,25),numpy.geomspace(1e-24,1,25)))
# format_float_positional0vectorized0 = numpy.vectorize(numpy.format_float_positional)
# print(numpy.geomspace(1,1000,5),format_float_positional0vectorized0(numpy.geomspace(1,10000,5)),sep='\n')
# print(numpy.allclose(numpy.geomspace(1,1000,5),numpy.geomspace(1,10000,5),rtol=0,atol=500))
# print(numpy.allclose(numpy.geomspace(1,1000,5),numpy.geomspace(1,10000,5),rtol=.5,atol=0))
# print([numpy.nan,1.3],[numpy.nan,1],sep='\n')
# print(numpy.allclose([numpy.nan,1.3],[numpy.nan,1],rtol=.5,atol=0))
# print(numpy.allclose([numpy.nan,1.3],[numpy.nan,1],rtol=.5,atol=0,equal_nan=False))
# print(numpy.allclose([numpy.nan,1.3],[numpy.nan,1],rtol=.5,atol=0,equal_nan=True))

# print((numpy.array([True,False])&numpy.array([True,True])))
# print((numpy.array([True,False])|numpy.array([True,True])))
# print((numpy.array([True,False,False])^numpy.array([True,True,False])))
# print(~(numpy.array([True,False,True,True])))
# try:
    # print((numpy.array([True,False]) and numpy.array([True,True])))
# except Exception as e:
    # print(e)
# try:
    # print((numpy.array([True,False]) or numpy.array([True,True])))
# except Exception as e:
    # print(e)
# try:
    # print(not(numpy.array([True,False,True,True])))
# except Exception as e:
    # print(e)
# print('maximum')
# try:
    # print(max(numpy.array([1,2,3,4,5]),numpy.array([5,4,3,2,6])))
# except Exception as e:
    # print(e)
# try:
    # print(max(numpy.array([1,2,3,4,5]),numpy.array([5,4,3,2,1])))
# except Exception as e:
    # print(e)
# print(numpy.maximum(numpy.array([1,2,3,4,5]),numpy.array([5,4,3,2,1])))
# try:
    # print(min(numpy.array([1,2,3,4,5]),numpy.array([5,4,3,2,0])))
# except Exception as e:
    # print(e)
# try:
    # print(min(numpy.array([1,2,3,4,5]),numpy.array([5,4,3,2,1])))
# except Exception as e:
    # print(e)
# print(numpy.minimum(numpy.array([1,2,3,4,5]),numpy.array([5,4,3,2,1])))
# print(max([1,2,3,4,5],[5,4,3,2,6]))
# print(max([1,2,3,4,5],[5,4,3,2,1]))
# print(max([[1],2,3,4,6],[[5],[4,3,2,1]]))
# print(min([1,2,3,4,5],[5,4,3,2,0]))
# print(min([1,2,3,4,5],[5,4,3,2,1]))
# print(min([[1],2,3,4,5],[[5],[0,3,2,1]]))

# print(numpy.linspace(-5,5,27).size)
# a0 = numpy.linspace(-5,5,27).reshape(3,3,3)
# print(a0)
# a0[0,0,2] = numpy.nan
# print(numpy.linspace(25,35,27).size)
# a1 = numpy.linspace(25,35,27).reshape(3,3,3)
# print(a1)
# a1[0,0,2] = numpy.nan
# print('numpy.maximum')
# print(numpy.maximum(a0,a1))
# print('numpy.minimum')
# print(numpy.minimum(a0,a1))
# print('numpy.fmax')
# print(numpy.fmax(a0,a1))
# print('numpy.fmin')
# print(numpy.fmin(a0,a1))
# print('numpy.amax')
# print(numpy.amax(a0))
# print('numpy.amin')
# print(numpy.amin(a0))
# print('numpy.nanmax')
# print(numpy.nanmax(a0))
# print('numpy.nanmin')
# print(numpy.nanmin(a0))

# out0 = numpy.empty((3,3,1))
# keepdims0 = [True,False]
# where0 = [True,False,True]
# axis0 = [None,0,1,2]
# initial0 = [11000,-11000]
# try:
    # print(numpy.amax(a0,axis=2,keepdims=True,out=out0))
# except Exception as e:
    # print(e)
# print(numpy.amax(a0,axis=2,keepdims=True,out=out0))
# for initial1 in initial0:
    # for axis1 in axis0:
        # for keepdims1 in keepdims0:
            # print(numpy.amax(a0,keepdims=keepdims1,where=where0,axis=axis1,initial=initial1))
            # print(numpy.amin(a0,keepdims=keepdims1,where=where0,axis=axis1,initial=initial1))
            # # print(numpy.nanmax(a0,keepdims=keepdims1,where=where0,axis=axis1,initial=initial1))  #'where' and 'initial need numpy1.22
            # # print(numpy.nanmin(a0,keepdims=keepdims1,where=where0,axis=axis1,initial=initial1))  #'where' and 'initial need numpy1.22
            # print(numpy.nanmax(a0,keepdims=keepdims1,axis=axis1))
            # print(numpy.nanmin(a0,keepdims=keepdims1,axis=axis1))
# a=numpy.array([0,1,2])
# b=numpy.array([numpy.nan,1,2])
# c=numpy.array([0,numpy.nan,2])
# b0=numpy.array([numpy.inf,1,2])
# c0=numpy.array([0,numpy.inf,2])
# try:
    # print(numpy.isfinite(a,b,c))
# except Exception as e:
    # print(e)
# print(numpy.isfinite(a,b))
# print(numpy.isfinite(c,b))
# print(b)
# print(numpy.isfinite(a,c))
# print(numpy.isfinite(a,b0))
# print(numpy.isfinite(a,c0))
# a=numpy.array([0,1,numpy.inf,numpy.PINF,numpy.NINF,numpy.nan])
# print(numpy.isfinite(a))
# print(numpy.isinf(a))
# print(numpy.isposinf(a))
# print(numpy.isneginf(a))
# print(numpy.isnan(a))
# a=numpy.array([numpy.datetime64('nat')])
# print(numpy.isnat(a))
# print(numpy.inf is numpy.PINF)
# print(numpy.signbit(numpy.linspace(-5,5,21)))
# print(numpy.copysign(numpy.linspace(-5,5,21),numpy.sin(numpy.linspace(0,numpy.pi*8,21))))
# print(numpy.signbit(numpy.copysign(numpy.linspace(-5,5,21),numpy.sin(numpy.linspace(0,numpy.pi*8,21)))))
# print(1/numpy.copysign(0,numpy.PINF))
# print(1/numpy.copysign(0,numpy.NINF))

# print('finfo')
# try:
    # for dtype0 in [numpy.float16,numpy.float32,numpy.float64,numpy.float128]:
        # pass
# except Exception as e:
    # print(e)
# for dtype0 in [numpy.float16,numpy.float32,numpy.float64,numpy.longfloat]:
    # finfo0 = numpy.finfo(dtype0)
    # print(dir(finfo0))
    # try:
        # print(dict(finfo0))
    # except Exception as e:
        # print(e)
    # for attributeIndex0 in list(range(len(dir(finfo0)))):
        # print(dir(finfo0)[attributeIndex0],getattr(finfo0,dir(finfo0)[attributeIndex0]),sep='|||')
        # if (dir(finfo0)[attributeIndex0])=='machar':
            # print(list(range(len(dir(getattr(finfo0,dir(finfo0)[attributeIndex0]))))))
            # for attributeIndex1 in list(range(len(dir(getattr(finfo0,dir(finfo0)[attributeIndex0]))))):
                # print((dir(getattr(finfo0,dir(finfo0)[attributeIndex0]))[attributeIndex1]),getattr((getattr(finfo0,dir(finfo0)[attributeIndex0])),(dir(getattr(finfo0,dir(finfo0)[attributeIndex0]))[attributeIndex1])),sep='>>>>>>>>>>>>>>>>>>>>>>>>')
    # try:
        # eval('''print(finfo0.(dir(finfo0)[attributeIndex0]))''')
    # except Exception as e:
        # print(e)
    # print(finfo0.bits)
    # try:
        # print(finfo0.bits.value)
    # except Exception as e:
        # print(e)

# print('iinfo')
# for dtype0 in [numpy.int8,numpy.int16,numpy.int32,numpy.int64,numpy.longlong]:
    # iinfo0 = numpy.iinfo(dtype0)
    # for attributeIndex0 in list(range(len(dir(iinfo0)))):
        # print(dir(iinfo0)[attributeIndex0],getattr(iinfo0,dir(iinfo0)[attributeIndex0]),sep='|||')
        # if (dir(iinfo0)[attributeIndex0])=='machar':
            # print(list(range(len(dir(getattr(iinfo0,dir(iinfo0)[attributeIndex0]))))))
            # for attributeIndex1 in list(range(len(dir(getattr(iinfo0,dir(iinfo0)[attributeIndex0]))))):
                # print((dir(getattr(iinfo0,dir(iinfo0)[attributeIndex0]))[attributeIndex1]),getattr((getattr(iinfo0,dir(iinfo0)[attributeIndex0])),(dir(getattr(iinfo0,dir(iinfo0)[attributeIndex0]))[attributeIndex1])),sep='>>>>>>>>>>>>>>>>>>>>>>>>')

# print('MachAr') #see above

# print('nextafter')
# print((1-numpy.nextafter(1,2))==(numpy.spacing(1)))
# print(numpy.nextafter(1,2))
# print('spacing')
# print(numpy.spacing(1))
# for i in [numpy.NINF,numpy.PINF,numpy.nan]:
    # print(numpy.spacing(i))

# print('frexp')
# print('ldexp')
# print(numpy.frexp(17.5))
# print(numpy.frexp(17.5)[0]*10**6)
# print(numpy.binary_repr(int(numpy.frexp(17.5)[0]*10**6))) #different base so not going to give you answer you're looking for
# print(numpy.binary_repr(numpy.frexp(17.5)[1]))
# # for i in numpy.frexp(17.5):
    # # # print(numpy.binary_repr(i))
    # # print(bin(i))
# try:
    # print(numpy.ldexp(numpy.frexp(17.5)))
# except Exception as e:
    # print(e)
# print(numpy.ldexp(*numpy.frexp(17.5)))
# print(numpy.frexp(-17.5))
# print(numpy.ldexp(*numpy.frexp(-17.5)))
# print(numpy.spacing(-1))

# x = numpy.array([[0, 3], [2, 2]])
# print(x)
# print(numpy.argsort(x,axis=None))
# print(numpy.unravel_index(numpy.argsort(x,axis=None),shape=x.shape))
# print(x[numpy.unravel_index(numpy.argsort(x,axis=None),shape=x.shape)])

# print('sort')
# print(numpy.sort(x))
# print(numpy.sort(x,axis=None))
# # import time
# # for kind0 in ['quicksort','heapsort','mergesort','stable']:
    # # timeStart0 = time.time()
    # # numpy.sort(numpy.random.default_rng(seed=3).integers(low=0,high=1000000,size=(1000,1000)),axis=None,kind=kind0)
    # # timeEnd0 = time.time()
    # # print(timeEnd0-timeStart0)
# print(numpy.sort(numpy.array([(1,1)],dtype=numpy.dtype('i4, i8'))))
# try:
    # print(numpy.sort(numpy.array([(1,2),(1,2,3,4,5)],dtype='key0 2; key1 5')))
# except Exception as e:
    # print(e)
# print(numpy.sort(numpy.array([(30.5,30.5,10),(30.5,30.5,5),(50.5,50.5,1)],dtype=[('length',float),('width',float),('height',int)]),order=['length','height']))
# try:
    # eval('''print(numpy.sort(numpy.array([(30.5,30.5,10),(30.5,30.5,5),(50.5,50.5,1)],dtype=[('length',float),('width',float),('height',int)]),order=('height','length')))''')
# except Exception as e:
    # print(e)
# print(numpy.sort(numpy.array([(30.5,30.5,10),(30.5,30.5,5),(50.5,50.5,1)],dtype=[('length',float),('width',float),('height',int)]),order=['height','length']))

# print('lexsort')
# print(numpy.lexsort(([1,2,3,4],[9,8,8,7])))
# print(numpy.random.default_rng(seed=3).integers(low=0,high=20,size=(3,3)))
# print(numpy.random.default_rng(seed=2).integers(low=0,high=20,size=(3,3)))
# print(numpy.lexsort((numpy.random.default_rng(seed=3).integers(low=0,high=20,size=(3,3)),numpy.random.default_rng(seed=2).integers(low=0,high=20,size=(3,3)))))
# print(numpy.lexsort((numpy.random.default_rng(seed=3).integers(low=0,high=20,size=(3,3)),numpy.random.default_rng(seed=2).integers(low=0,high=20,size=(3,3))),axis=0))
# try:
    # print(numpy.lexsort((numpy.random.default_rng(seed=3).integers(low=0,high=20,size=(3,3)),numpy.random.default_rng(seed=2).integers(low=0,high=20,size=(3,3))),axis=None))
# except Exception as e:
    # print(e)
# print('ndarray.sort')
# x = numpy.array([[3,0], [2, 2]])
# print(x)
# print(x.sort())
# print(x)
# try:
    # print(x.sort(axis=None))
# except Exception as e:
    # print(e)
# x = numpy.array([[3,0], [2, 2]])
# print(x.sort(axis=0,kind='heapsort',order=None))
# print(x)
# y=numpy.array([(30.5,30.5,10),(30.5,30.5,5),(50.5,50.5,1)],dtype=[('length',float),('width',float),('height',int)])
# print(y.sort(order=['height','length']))
# print(y)
# x = numpy.array([[3,0], [2, 2]])
# print(numpy.msort(x))
# print('sort_complex')
# z=numpy.array([complex(9,2),complex(8,4),complex(7,5)])
# print(numpy.sort_complex(z))
# print(numpy.sort(z))
# z=numpy.array([complex(9,2),complex(8,4),complex(7,6),complex(7,5)])
# print(numpy.sort_complex(z))
# print(numpy.sort(z))
# z=numpy.array([complex(numpy.nan,2),complex(numpy.nan,4),complex(numpy.nan,5)])
# print(numpy.sort(z))
# print(numpy.sort_complex(x))

# print('partition')
# print(numpy.arange(27,0,-1).reshape(3,3,3))
# print(numpy.partition(numpy.arange(27,0,-1).reshape(3,3,3),2))
# print(numpy.partition(numpy.arange(27,0,-1).reshape(3,3,3),kth=1,axis=-1,kind='introselect'))
# print(numpy.partition(numpy.arange(27,0,-1).reshape(3,3,3),kth=1,axis=0,kind='introselect'))
# print(numpy.partition(numpy.arange(27,0,-1).reshape(3,3,3),kth=1,axis=1,kind='introselect'))
# print(numpy.partition(numpy.arange(9,0,-1).reshape(3,3),kth=1,axis=0,kind='introselect'))
# print(numpy.partition(numpy.arange(27,0,-1).reshape(3,3,3),kth=1,axis=None,kind='introselect'))
# print(numpy.partition(numpy.array([(30.5,30.5,10),(30.5,30.5,5),(50.5,50.5,1)],dtype=[('length',float),('width',float),('height',int)]),kth=0,order=['height','length']))
# print('argpartition')
# print(numpy.argpartition(numpy.arange(27,0,-1).reshape(3,3,3),2))
# print(numpy.argpartition(numpy.arange(27,0,-1).reshape(3,3,3),kth=1,axis=-1,kind='introselect'))
# print(numpy.argpartition(numpy.arange(27,0,-1).reshape(3,3,3),kth=1,axis=0,kind='introselect'))
# print(numpy.argpartition(numpy.arange(27,0,-1).reshape(3,3,3),kth=1,axis=None,kind='introselect'))
# print(numpy.argpartition(numpy.array([(30.5,30.5,10),(30.5,30.5,5),(50.5,50.5,1)],dtype=[('length',float),('width',float),('height',int)]),kth=0,order=['height','length']))

# print('nanargmax')
# print('nanargmin')
# a=numpy.arange(27,0,-1).reshape(3,3,3)
# print(a)
# try:
    # a[(...,0)]=numpy.nan
# except Exception as e:
    # print(e)
# a=numpy.arange(27,0,-1,dtype=numpy.float64).reshape(3,3,3)
# print(a)
# a[(...,0)]=numpy.nan
# print(a)
# print(numpy.argmin(a,axis=-1))
# print(numpy.argmin(a,axis=None))
# print(numpy.nanargmin(a,axis=-1))
# print(numpy.nanargmin(a,axis=None))
# print(numpy.argmax(a,axis=-1))
# print(numpy.argmax(a,axis=None))
# print(numpy.nanargmax(a,axis=-1))
# print(numpy.nanargmax(a,axis=None))

# print('where')
# print(numpy.where(numpy.arange(27,0,-1,dtype=numpy.float64).reshape(3,3,3)<3,numpy.arange(27,0,-1,dtype=numpy.float64).reshape(3,3,3),-10))
# print(numpy.argwhere(numpy.arange(27,0,-1,dtype=numpy.float64).reshape(3,3,3)<3))
# print(numpy.argwhere(numpy.arange(27,0,-1,dtype=numpy.float64).reshape(3,3,3)<8))

# print('equal 2,2')
# print(numpy.equal(numpy.array([[1,1],[2,2]]),numpy.array([1,1])))
# print(numpy.isclose(numpy.array([[1,1],[2,2]]),numpy.array([1,1])))
# print(numpy.ogrid[1:5:2])
# print(numpy.ogrid[1:5:7])
# print(numpy.ogrid[1:5:2j])
# print(numpy.ogrid[1:5:7j])
# print(numpy.nonzero(numpy.triu(numpy.arange(9,0,-1).reshape(3,3))))
# print(numpy.flatnonzero(numpy.triu(numpy.arange(9,0,-1).reshape(3,3))))
# print(numpy.count_nonzero(numpy.triu(numpy.arange(9,0,-1).reshape(3,3))))
# print(numpy.count_nonzero(numpy.triu(numpy.arange(9,0,-1).reshape(3,3)),axis=0,keepdims=True))
# print(numpy.count_nonzero(numpy.triu(numpy.arange(9,0,-1).reshape(3,3)),axis=0,keepdims=False))

# print('compress')
# print(numpy.arange(27,0,-1,dtype=numpy.float64).reshape(3,3,3))
# for axis1 in [None,0,1,2]:
    # try:
        # print(numpy.compress(numpy.arange(27,0,-1,dtype=numpy.float64).reshape(3,3,3)<3,numpy.arange(27,0,-1,dtype=numpy.float64).reshape(3,3,3),axis=axis1))
    # except Exception as e:
        # print(e)
    # print(numpy.compress(numpy.array([True,False,False]),numpy.arange(27,0,-1,dtype=numpy.float64).reshape(3,3,3),axis=axis1))
    # print(numpy.arange(27,0,-1,dtype=numpy.float64).reshape(3,3,3).compress(numpy.array([True,False,False]),axis=axis1))
# print('extract')
# print(numpy.extract(numpy.arange(27,0,-1,dtype=numpy.float64).reshape(3,3,3)<3,numpy.arange(27,0,-1,dtype=numpy.float64).reshape(3,3,3)))

# print('choose')
# def buildNestedArrays(start0,stop0,step0,x0,y0,nesting0):
    # array0 = numpy.arange(start0,stop0,step0).reshape(x0,y0)
    # for j in range(nesting0):
        # array1 = numpy.arange(start0,stop0,step0).reshape(x0,y0).put(numpy.arange(array0.size).reshape(1,1,x0,y0),array0,mode='clip') ##array1 seems to be set to 'None' here..
        # array0 = array1
    # print(array1)
    # return array1
# # import pdb
# # pdb.set_trace()
# # from nose.tools import set_trace
# # set_trace()   
# print(buildNestedArrays(9,0,-1,3,3,1))
# try:
    # print(numpy.choose(numpy.array([0,1,4]),(numpy.linspace(200,300,3),numpy.linspace(500,600,3),numpy.linspace(800,900,3)),mode='raise'))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.choose(numpy.array([0,1,4]),(numpy.linspace(200,300,3),numpy.linspace(500,600,3),numpy.linspace(800,900,3))))
# except Exception as e:
    # print(e)
# print(numpy.choose(numpy.array([0,1,2]),(numpy.linspace(200,300,3),numpy.linspace(500,600,3),numpy.linspace(800,900,3))))
# print(numpy.choose(numpy.array([-1,1,4]),(numpy.linspace(200,300,3),numpy.linspace(500,600,3),numpy.linspace(800,900,3)),mode='wrap'))
# print(numpy.choose(numpy.array([-1,1,4]),(numpy.linspace(200,300,3),numpy.linspace(500,600,3),numpy.linspace(800,900,3)),mode='clip'))
# print(numpy.choose(numpy.array([-1,1,4]),(numpy.linspace(200,300,3),numpy.linspace(500,600,3),numpy.linspace(800,900,3)),mode='clip').shape)
# print(numpy.empty((3,)))
# out0 = numpy.empty(numpy.choose(numpy.array([-1,1,4]),(numpy.linspace(200,300,3),numpy.linspace(500,600,3),numpy.linspace(800,900,3)),mode='clip').shape,dtype=numpy.float64)
# numpy.choose(numpy.array([-1,1,4]),(numpy.linspace(200,300,3),numpy.linspace(500,600,3),numpy.linspace(800,900,3)),mode='clip',out=out0)
# print(out0)


# print('select')
# print(numpy.select([numpy.arange(9,0,-1)<5,numpy.arange(9,0,-1)>5],[numpy.arange(9,0,-1)*2,numpy.arange(9,0,-1)*4],1000))
# print(numpy.select([numpy.arange(9,0,-1)<5,numpy.arange(9,0,-1)>5],[numpy.arange(9,0,-1)*2,numpy.arange(9,0,-1)*4],default=1000))
# print(numpy.select([numpy.arange(9,0,-1)<5,numpy.arange(9,0,-1)>5],[numpy.arange(9,0,-1)*2,numpy.arange(9,0,-1)*4]))

# print('searchsorted')
# print(numpy.searchsorted(numpy.arange(27),numpy.around(numpy.linspace(0,27,7),0).astype(int)))
# print(numpy.searchsorted(numpy.arange(27),numpy.around(numpy.linspace(0,27,7),0).astype(int),side='left',sorter=None))
# print(numpy.searchsorted(numpy.arange(27),numpy.around(numpy.linspace(0,27,7),0).astype(int),side='right',sorter=None))
# print(numpy.searchsorted(numpy.arange(27),numpy.around(numpy.linspace(0,27,7),0).astype(int),side='right',sorter=None).size)
# print(numpy.searchsorted(numpy.arange(27,0,-1),numpy.around(numpy.linspace(0,27,7),0).astype(int),side='right',sorter=numpy.argsort(numpy.arange(27,0,-1))))
# print(numpy.searchsorted(numpy.arange(27,0,-1),numpy.around(numpy.linspace(0,27,7),0).astype(int),side='left',sorter=numpy.argsort(numpy.arange(27,0,-1))))
# print(numpy.searchsorted(numpy.arange(26,-1,-1),numpy.around(numpy.linspace(0,27,7),0).astype(int),side='right',sorter=numpy.argsort(numpy.arange(26,-1,-1))))
# print(numpy.searchsorted(numpy.arange(26,-1,-1),numpy.around(numpy.linspace(0,27,7),0).astype(int),side='left',sorter=numpy.argsort(numpy.arange(26,-1,-1))))
# try:
    # print(numpy.searchsorted(numpy.arange(27),numpy.around(numpy.linspace(0,27,7),0).astype(int),side='right',sorter=numpy.arange(numpy.searchsorted(numpy.arange(27),numpy.around(numpy.linspace(0,27,7),0).astype(int),side='right',sorter=None).size,0,-1)))
# except Exception as e:
    # print(e)
# print(numpy.searchsorted(numpy.arange(27),numpy.around(numpy.linspace(0,27,7),0).astype(int),side='right',sorter=numpy.arange(27)))
# print(numpy.searchsorted(numpy.arange(27),numpy.around(numpy.linspace(0,27,7),0).astype(int),side='right',sorter=numpy.arange(27)[::-1]))
# print(numpy.searchsorted(numpy.arange(27),numpy.around(numpy.linspace(0,27,7),0).astype(int),side='right',sorter=numpy.arange(26,-1,-1)))
# a0 = numpy.arange(27)[2]=4
# try:
    # print(numpy.searchsorted(a0,numpy.around(numpy.linspace(0,27,7),0).astype(int)))
# except Exception as e:
    # print(e)
# print('bisect')
# import bisect
# print(bisect.bisect_left(list(numpy.arange(27)),4))
# print(bisect.bisect_right(list(numpy.arange(27)),4))
# print(bisect.bisect(list(numpy.arange(27)),4))
# print(bisect.bisect(list(numpy.arange(27)),4,lo=6))
# print(bisect.bisect(list(numpy.arange(27)),4,hi=2))
# def key0(v0):
    # v0 = v0 + 10
    # return v0
# try:
    # print(bisect.bisect(list(numpy.arange(27)),4,key=key0)) #python3.10 needed
# except Exception as e:
    # print(e)
# list0 = list(numpy.arange(27))
# print(bisect.insort_left(list0,4))
# print(list0)
# print(bisect.insort_right(list0,4))
# print(list0)
# print(bisect.insort(list0,4))
# print(list0)
# a0 = numpy.arange(27,dtype=numpy.float64)
# a0[:-6:1]=numpy.nan
# print(a0)
# print(numpy.searchsorted(a0,numpy.around(numpy.linspace(0,27,7),0).astype(int)))
# a0 = numpy.arange(27,dtype=numpy.float64)
# a0[6::1]=numpy.nan
# print(a0)
# print(numpy.searchsorted(a0,numpy.around(numpy.linspace(0,27,7),0).astype(int)))
# a0 = 1j*numpy.arange(27,dtype=numpy.float64)
# a0[6::1]=numpy.nan
# print(a0)
# print(numpy.searchsorted(a0,numpy.around(numpy.linspace(0,27,7),0).astype(int)))
# print(numpy.searchsorted(a0,1j*numpy.around(numpy.linspace(0,27,7),0).astype(int)))

# print('histogram')
# w0 = numpy.arange(20)
# w0[:5]=3
# w0[5:7]=2
# w0[7:]=1
# print(w0)
# print(numpy.histogram(numpy.arange(20)))
# print(numpy.histogram(numpy.arange(20),weights=w0))
# print(numpy.histogram(numpy.arange(20),density=True))
# print(numpy.histogram(numpy.arange(20),weights=w0,density=True))
# print(numpy.histogram(numpy.arange(20),bins=5,weights=w0))
# print(numpy.histogram(numpy.arange(20),bins=5,weights=w0,density=True))
# print(numpy.histogram(numpy.arange(20),bins=[0,4,12,13,20],weights=w0))
# print(numpy.histogram(numpy.arange(20),bins=[0,4,12,13,20],weights=w0,density=True))
# print(numpy.histogram(numpy.arange(20),range=(12.,19.),bins=[0,4,12,13,20],weights=w0))
# print(numpy.histogram(numpy.arange(20),range=(12,19),bins=[0,4,12,13,20],weights=w0,density=True))
# print(numpy.histogram(numpy.arange(20),range=(12.,19.),weights=w0))
# print(numpy.histogram(numpy.arange(20),range=(12,19),weights=w0,density=True))

# print('histogram2d')
# w0 = numpy.arange(20)
# w0[:5]=3
# w0[5:7]=2
# w0[7:]=1
# print(w0)
# w1 = numpy.arange(20)
# w1[:5]=5
# w1[5:7]=4
# w1[7:]=2
# print(w1)
# b0=numpy.array([0,4,12,13,20,26,34])
# print(b0)
# print(b0.shape)
# b1=b0+2
# print(b1)
# print(b1.shape)
# print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1)))
# print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1),weights=w0))
# print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1),density=True))
# print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1),weights=w0,density=True))
# print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1),bins=5,weights=w0))
# print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1),bins=5,weights=w0,density=True))
# print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1),bins=[0,4,12,13,20,26,34],weights=w0))
# print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1),bins=[0,4,12,13,20,26,34],weights=w0,density=True))
# try:
    # print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1),bins=[list(b0),list(b1)],weights=[list(w0),list(w1)],density=True))
# except Exception as e:
    # print(e)
# print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1),bins=[b0,b1],weights=w1,density=True))
# print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1),range=[[12,19],[12,19]],bins=[b0,b1],weights=w1,density=True))
# print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1),range=[[12.,19.],[12.,19.]],weights=w1,density=True))
# print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1),range=[[12.,19.],[12.,19.]],density=True))
# print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1),range=[[12.,19.],[12.,19.]]))
# print(numpy.histogram2d(numpy.arange(20),numpy.arange(14,34,1),range=[[12.,19.],[12.,29.]]))

# print('histogramdd')
# w0 = numpy.arange(20)
# w0[:5]=3
# w0[5:7]=2
# w0[7:]=1
# print(w0)
# w1 = numpy.arange(20)
# w1[:5]=5
# w1[5:7]=4
# w1[7:]=2
# print(w1)
# b0=numpy.array([0,4,12,13,20,26,34])
# print(b0)
# print(b0.shape)
# b1=b0+2
# print(b1)
# print(b1.shape)
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1))))
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),weights=w0))
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),density=True))
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),weights=w0,density=True))
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),bins=5,weights=w0))
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),bins=5,weights=w0,density=True))
# try:
    # print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),bins=[0,4,12,13,20,26,34],weights=w0))
# except Exception as e:
    # print(e)
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),bins=numpy.arange(40).reshape(2,20),weights=w0))
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),bins=numpy.arange(40).reshape(2,20),weights=w0,density=True))
# try:
    # print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),bins=[list(b0),list(b1)],weights=[list(w0),list(w1)],density=True))
# except Exception as e:
    # print(e)
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),bins=[b0,b1],weights=w1,density=True))
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),range=[[12,19],[12,19]],bins=[b0,b1],weights=w1,density=True))
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),range=[[12.,19.],[12.,19.]],weights=w1,density=True))
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),range=[[12.,19.],[12.,19.]],density=True))
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),range=[[12.,19.],[12.,19.]]))
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1)),range=[[12.,19.],[12.,29.]]))
# print(numpy.histogramdd((numpy.arange(20),numpy.arange(14,34,1),numpy.arange(23,43,1)),weights=w0,density=True))
# print(numpy.random.randn(30,3))
# print(numpy.histogramdd(numpy.random.randn(30,3),bins=(4,8,16),weights=numpy.around(numpy.linspace(4,0,30)).astype(int)))

# print('bincount')
# print(numpy.arange(20).size)
# print(numpy.bincount(numpy.arange(20)).size)
# print(numpy.arange(0,20,4).size)
# print(numpy.bincount(numpy.arange(0,20,4)).size)
# print(numpy.bincount(numpy.arange(20)))
# print(numpy.bincount(numpy.arange(0,20,4)))
# print(numpy.bincount(numpy.arange(20),weights=numpy.linspace(0,10,20)).sum())
# print(numpy.sum(numpy.bincount(numpy.arange(20),weights=numpy.linspace(10,0,20))))
# print(numpy.sum(numpy.bincount(numpy.arange(20),weights=numpy.linspace(40,0,20))))
# print(numpy.bincount(numpy.arange(20),minlength=40))
# print(numpy.bincount(numpy.arange(20),minlength=10))

# print('histogram_bin_edges')
# size0=[20,2000]
# bins0=['sqrt','rice','sturges','doane','scott','stone','fd','auto']
# for bins1 in bins0:
    # for size1 in size0:
        # print('uniform',size1,bins1,numpy.histogram_bin_edges(numpy.arange(size1),bins=bins1))
        # print('normal',size1,bins1,numpy.histogram_bin_edges(numpy.random.default_rng(seed=2).normal(loc=(size1/2),scale=(numpy.sqrt(size1)),size=size1),bins=bins1))
# print(numpy.histogram_bin_edges(numpy.arange(20)))
# print(numpy.histogram_bin_edges(numpy.arange(20),weights=w0))
# print(numpy.histogram_bin_edges(numpy.arange(20),range=(12.,19.),weights=w0))

# print('digitize')
# print(numpy.digitize(numpy.arange(35),numpy.array([0,4,12,13,20,26,34])))
# print(numpy.digitize(numpy.arange(35),numpy.array([0,4,12,13,20,26,34]),right=False))
# print(numpy.digitize(numpy.arange(35),numpy.array([0,4,12,13,20,26,34]),right=True))
# print(numpy.digitize(numpy.arange(21).reshape(3,7),numpy.array([0,4,12,13,20]),right=True))
# print(numpy.digitize(numpy.arange(35),numpy.array([34,26,20,13,12,4,0])))
# print(numpy.digitize(numpy.arange(35),numpy.array([34,26,20,13,12,4,0]),right=False))
# print(numpy.digitize(numpy.arange(35),numpy.array([34,26,20,13,12,4,0]),right=True))
# try:
    # print(numpy.digitize(numpy.arange(21).reshape(3,7),numpy.array([0,4,12,20,13]),right=True))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.digitize(1j*numpy.arange(21).reshape(3,7),numpy.array([0,4,12,13,20]),right=True))
# except Exception as e:
    # print(e)

# print('unique')
# a0=numpy.array([0,0,0,9,9,2,2,5,7,7,7,1,1,1,1,1])
# print(a0.size)
# print(a0)
# print(numpy.unique(a0,return_index=True,return_inverse=True,return_counts=True))
# print(numpy.unique(a0.reshape(2,2,4),return_index=True,return_inverse=True,return_counts=True,axis=None))
# print(a0.reshape(2,2,4))
# print(numpy.unique(a0.reshape(2,2,4),return_index=True,return_inverse=True,return_counts=True,axis=0))
# print(numpy.unique(a0.reshape(2,2,4),return_index=True,return_inverse=True,return_counts=True,axis=1))
# print(numpy.unique(a0.reshape(2,2,4),return_index=True,return_inverse=True,return_counts=True,axis=2))
# try:
    # print(numpy.unique(a0.reshape(2,2,4),return_index=True,return_inverse=True,return_counts=True,axis=3))
# except Exception as e:
    # print(e)
# a0=numpy.array([0,0,0,0,0,0,1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,3,4,4,4,4,4,4,5,5,5,5,5,5])
# print(a0.size)
# print(a0)
# print(a0.reshape(6,6))
# print(numpy.unique(a0.reshape(6,6),return_index=True,return_inverse=True,return_counts=True,axis=0))
# print(numpy.unique(a0.reshape(6,6),return_index=True,return_inverse=True,return_counts=True,axis=1))

# print('repeat')
# print(numpy.repeat(numpy.arange(6),2))
# print(numpy.repeat(numpy.arange(6),3))
# try:
    # print(numpy.repeat(numpy.arange(6),2,axis=1))
# except Exception as e:
    # print(e)
# print(numpy.repeat(numpy.arange(6).reshape(2,3),3))
# print(numpy.repeat(numpy.arange(6).reshape(2,3),3,axis=None))
# print(numpy.repeat(numpy.arange(6).reshape(2,3),3,axis=0))
# print(numpy.repeat(numpy.arange(6).reshape(2,3),3,axis=1))
# print(numpy.repeat(numpy.arange(6).reshape(2,3),[4,2],axis=0))

# print('tile')
# print(numpy.tile(numpy.arange(6),2))
# print(numpy.tile(numpy.arange(6),3))
# print(numpy.tile(numpy.arange(6),[4,2]))
# print(numpy.tile(numpy.arange(6).reshape(2,3),3))
# print(numpy.tile(numpy.arange(6).reshape(2,3),[4,2]))

# print('broadcast_to')
# try:
    # print(numpy.broadcast_to(numpy.arange(6),2))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.broadcast_to(numpy.arange(6).reshape(2,3),3))
# except Exception as e:
    # print(e)
# print(numpy.broadcast_to(2,6,subok=False))
# print(numpy.broadcast_to(2,6,subok=True))
# print(numpy.broadcast_to(2,(4,4)))
# print(numpy.broadcast_to(numpy.arange(4),(4,4)))
# print(numpy.broadcast_to(numpy.arange(4).reshape(2,2),(3,2,2)))

# print('broadcast')
# a=numpy.arange(9).reshape(3,1,3)
# b=numpy.arange(9).reshape(1,3,3)
# c=numpy.arange(3).reshape(3)
# print(numpy.broadcast(a,b,c))
# abc = numpy.broadcast(a,b,c)
# for i in ['ndim','nd','numiter','shape','size']:
    # print(i,getattr(abc,i))
# for i in range(abc.size):
    # print(abc.index)
    # next(abc)
# a=numpy.arange(9).reshape(3,1,3)
# b=numpy.arange(9).reshape(1,3,3)
# c=numpy.arange(3).reshape(3)
# print(numpy.broadcast(a,b,c))
# abc = numpy.broadcast(a,b,c)
# for i in range(abc.size):
    # # print(abc.iters)
    # # print(abc.iters[0],abc.iters[1],abc.iters[2])
    # # next(abc.iters[0])
    # # next(abc.iters[1])
    # # next(abc.iters[2])
    # dim0,dim1,dim2=abc.iters
    # print(next(dim0),next(dim1),next(dim2))
# a=numpy.arange(9).reshape(3,1,3)
# b=numpy.arange(9).reshape(1,3,3)
# c=numpy.arange(3).reshape(3)
# print(numpy.broadcast(a,b,c))
# abc = numpy.broadcast(a,b,c)
# out0=numpy.empty(abc.shape)
# print(a*b*c for (a,b,c) in abc)
# out0.flat=[a*b*c for (a,b,c) in abc]
# print(out0)
# print(abc.index)
# print(abc.reset())
# print(abc.index)

# print('broadcast_arrays')
# a=numpy.arange(9).reshape(3,1,3)
# b=numpy.arange(9).reshape(1,3,3)
# c=numpy.arange(3).reshape(3)
# print(numpy.broadcast_arrays(a,b,c))
# print(numpy.array(x) for x in numpy.broadcast_arrays(a,b,c))
# print([numpy.array(x) for x in numpy.broadcast_arrays(a,b,c)])

# print('broadcast_shapes')
# a=numpy.arange(9).reshape(3,1,3)
# b=numpy.arange(9).reshape(1,3,3)
# c=numpy.arange(3).reshape(3)
# try:
    # print(numpy.broadcast_shapes(a,b,c))
# except Exception as e:
    # print(e)
# a=numpy.arange(9).reshape(3,1,3).shape
# b=numpy.arange(9).reshape(1,3,3).shape
# c=numpy.arange(3).reshape(3).shape
# print(numpy.broadcast_shapes(a,b,c))

# print('numpy.lib.arraysetops')
# print(numpy.lib.arraysetops)
# print(dir(numpy.lib.arraysetops))

# print('in1d')
# try:
    # print(numpy.in1d(numpy.arange(5),numpy.arange(5),assume_unique=True,invert=False))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.in1d(numpy.arange(4).reshape(2,2),numpy.arange(3,7,1),assume_unique=True,invert=False))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.in1d(numpy.arange(4),numpy.arange(3,7,1).reshape(2,2),assume_unique=True,invert=False))
# except Exception as e:
    # print(e)
# print(numpy.in1d(numpy.arange(5),numpy.arange(3,9,1),assume_unique=True,invert=False))
# print(numpy.in1d(numpy.arange(5),numpy.arange(3,9,1),assume_unique=False,invert=False))
# print(numpy.in1d(numpy.arange(5),numpy.arange(3,9,1),assume_unique=False,invert=True))

# print('isin')
# try:
    # print(numpy.isin(numpy.arange(5),numpy.arange(5),assume_unique=True,invert=False))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.isin(numpy.arange(4).reshape(2,2),numpy.arange(3,7,1),assume_unique=True,invert=False))
# except Exception as e:
    # print(e)
# try:
    # print(numpy.isin(numpy.arange(4),numpy.arange(3,7,1).reshape(2,2),assume_unique=True,invert=False))
# except Exception as e:
    # print(e)
# print(numpy.isin(numpy.arange(5),numpy.arange(3,9,1),assume_unique=True,invert=False))
# print(numpy.isin(numpy.arange(5),numpy.arange(3,9,1),assume_unique=False,invert=False))
# print(numpy.isin(numpy.arange(5),numpy.arange(3,9,1),assume_unique=False,invert=True))
# print(numpy.isin([1,2,3],{1,2,3}))
# print(numpy.isin([1,2,3],list({1,2,3})))
# print(numpy.isin(numpy.arange(8).reshape(2,2,2),numpy.arange(3,7,1),assume_unique=True,invert=False))

# print('intersect1d')
# import functools
# print(functools.reduce(numpy.intersect1d,(numpy.arange(6),numpy.arange(-2,4,1),numpy.arange(1,7,1))))
# print(numpy.intersect1d(numpy.arange(6),numpy.arange(-2,4,1)))
# print(numpy.intersect1d(numpy.arange(6),numpy.arange(-2,4,1),assume_unique=False,return_indices=False))
# print(numpy.intersect1d(numpy.arange(6),numpy.arange(-2,4,1),assume_unique=True,return_indices=False))
# print(numpy.intersect1d(numpy.arange(6),numpy.arange(-2,4,1),assume_unique=True,return_indices=True))
# print(numpy.intersect1d(numpy.arange(6),numpy.arange(6),assume_unique=False,return_indices=True))
# print(numpy.intersect1d(numpy.arange(6),numpy.arange(6),assume_unique=True,return_indices=True))

# print('setdiff1d')
# print(functools.reduce(numpy.setdiff1d,(numpy.arange(6),numpy.arange(-2,4,1),numpy.arange(1,7,1))))
# print(numpy.setdiff1d(numpy.arange(6),numpy.arange(-2,4,1)))
# print(numpy.setdiff1d(numpy.arange(6),numpy.arange(-2,4,1),assume_unique=False))
# print(numpy.setdiff1d(numpy.arange(6),numpy.arange(-2,4,1),assume_unique=True))
# print(numpy.setdiff1d(numpy.arange(6),numpy.arange(6),assume_unique=False))
# print(numpy.setdiff1d(numpy.arange(6),numpy.arange(6),assume_unique=True))

# print('setxor1d')
# print(functools.reduce(numpy.setxor1d,(numpy.arange(6),numpy.arange(-2,4,1),numpy.arange(1,7,1))))
# print(numpy.setxor1d(numpy.arange(6),numpy.arange(-2,4,1)))
# print(numpy.setxor1d(numpy.arange(6),numpy.arange(-2,4,1),assume_unique=False))
# print(numpy.setxor1d(numpy.arange(6),numpy.arange(-2,4,1),assume_unique=True))
# print(numpy.setxor1d(numpy.arange(6),numpy.arange(6),assume_unique=False))
# print(numpy.setxor1d(numpy.arange(6),numpy.arange(6),assume_unique=True))

# print('union1d')
# print(functools.reduce(numpy.union1d,(numpy.arange(6),numpy.arange(-2,4,1),numpy.arange(1,7,1))))
# print(numpy.union1d(numpy.arange(6),numpy.arange(-2,4,1)))
# print(numpy.union1d(numpy.arange(6),numpy.arange(6)))

# print('numpy.ma')
# print(numpy.average(numpy.ma.masked_array(numpy.arange(6),numpy.array([1,1,1,0,0,0]))))
# print(numpy.average(numpy.ma.masked_array(numpy.arange(6),numpy.array([0,0,0,0,0,0]))))
# print(numpy.average(numpy.ma.masked_array(numpy.arange(6),numpy.array([1,1,1,1,1,1]))))
# print('numpy.average')
# print(numpy.arange(8).reshape(2,2,2))
# for axis1 in [None,0,1,2]:
    # for weights1 in [None,[10,.5]]:
        # for returned1 in [False,True]:
            # try:
                # print(axis1,weights1,returned1,'\n',numpy.average(numpy.arange(8).reshape(2,2,2),axis=axis1,weights=weights1,returned=returned1),end='\n\n')
            # except Exception as e:
                # print(e)
# print(numpy.average(numpy.arange(8).reshape(2,2,2),axis=0,weights=[10+0j,.5+0j],returned=True),end='\n\n')
# print('numpy.ma.average')
# print(numpy.arange(8).reshape(2,2,2))
# for axis1 in [None,0,1,2]:
    # for weights1 in [None,[10,.5]]:
        # for returned1 in [False,True]:
            # try:
                # print(axis1,weights1,returned1,'\n',numpy.ma.average(numpy.arange(8).reshape(2,2,2),axis=axis1,weights=weights1,returned=returned1),end='\n\n')
            # except Exception as e:
                # print(e)
# print(numpy.ma.average(numpy.arange(8).reshape(2,2,2),axis=0,weights=[10+0j,.5+0j],returned=True),end='\n\n')

# print('numpy.mean')
# print(numpy.arange(8).reshape(2,2,2))
# for axis1 in [None,0,1,2]:
    # try:
        # print(axis1,weights1,returned1,'\n',numpy.mean(numpy.arange(8).reshape(2,2,2),axis=axis1),end='\n\n')
    # except Exception as e:
        # print(e)
# out0=numpy.empty((1,1,1),dtype=numpy.float32)
# print(numpy.mean(numpy.arange(8).reshape(1,1,8),axis=None,out=out0,dtype=numpy.longfloat,keepdims=True,where=[True,False,True,False,True,False,False,False]))
# print(out0)

# print('ptp')
# for axis1 in [None,0,1,2]:
    # for keepdims1 in [False,True]:
        # print(axis1,keepdims1,'\n',numpy.ptp(numpy.arange(8).reshape(2,2,2),axis=axis1,keepdims=keepdims1),end='\n\n')
# out0=numpy.empty((1,1,1),dtype=numpy.int8)
# print(numpy.mean(numpy.arange(8).reshape(1,1,8)-8,axis=None,keepdims=True,out=out0))
# print(out0)
# out0=numpy.empty((1,1,1),dtype=numpy.int8)
# print(numpy.mean(numpy.arange(140).reshape(1,1,140)-130,axis=None,keepdims=True,out=out0))
# print(out0)
# out0=numpy.empty((1,1,1),dtype=numpy.int8)
# print(numpy.mean(numpy.arange(110).reshape(1,1,110)-100,axis=None,keepdims=True,out=out0))
# print(out0)
# print((2**7)-1)

# print('percentile')
# try:
    # numpy.percentile(numpy.arange(20),10,method='hazen')
# except Exception as e:
    # print(e)

# import pandas_profiling,ftfy,datacleaner,dateparser
# print(pandas_profiling.ProfileReport(pandas.read_csv(r'C:\Users\pdumas\Downloads\company_ipo.csv')))
# # profileReport0=pandas_profiling.ProfileReport(pandas.read_csv(r'C:\Users\pdumas\Downloads\company_ipo.csv'))
# import pandas_profiling,pandas,os
# profileReport0=pandas_profiling.ProfileReport(pandas.read_csv(r'C:\Users\pdumas\Downloads\ipos.csv'))
# file0=r'C:\Users\pdumas\Documents\profileReport0.html'
# profileReport0.to_file(file0)
# os.system(r'''start "" "'''+file0+'''"''')
# s1=['the 21st of January 2023','1 hour ago','2 hours ago','1 year and 1 week ago','2 hours from now','2 hours later']
# for s0 in s1:
    # print(s0,dateparser.parse(s0),sep='        ')
# s1=['Sm"rgâ€ s','I wentttt there','w&hat do yO^^u want','give me&#x2019 1 example that &hellip works!']
# for s0 in s1:
    # print(s0,ftfy.fix_text(s0,normalization='NFKC'),sep='        ')
# print(ftfy.fix_text('The Mona Lisa doesnÃƒÆ’Ã‚Â¢ÃƒÂ¢Ã¢â‚¬Å¡Ã‚Â¬ÃƒÂ¢Ã¢â‚¬Å¾Ã‚Â¢t have eyebrows.'))
# a0=numpy.random.default_rng(8).random((10,10))
# a0[1:3]=numpy.nan
# a0[6:8]=numpy.nan
# print(a0)
# df0=pandas.DataFrame(a0)
# df0.iloc[1:3,:]=numpy.nan
# df0.iloc[6:8,:]=numpy.nan
# print(df0)
# try:
    # print(a0,datacleaner.autoclean(a0),sep='\n\n')
# except Exception as e:
    # print(e)
# print(pandas.DataFrame(df0),datacleaner.autoclean(df0),sep='\n\n')#looks like this does the same as pandas (unless more complex input is entered)
# z0=numpy.zeros((20,20,20))
# z0[4:6,2:4,2:4]=numpy.exp(numpy.random.default_rng(8).uniform(0,numpy.pi*2,(2,2,2))*1j)
# ifftn0=numpy.fft.ifftn(z0).real
# # print(z0)
# # print(z0[:,0])
# # s0=mayavi.mlab.mesh(z0[:,0],z0[0,:],z0[0,:])
# # mayavi.mlab.show()
# # ifftn0=numpy.fft.ifftn(z0).imag
# # print(z0)
# # print(z0[:,0])
# # s0=mayavi.mlab.mesh(z0[:,0],z0[0,:],z0[0,:])
# # mayavi.mlab.show()
# # ifftn0=numpy.fft.ifftn(z0)
# # print(z0)
# # print(z0[:,0])
# # s0=mayavi.mlab.mesh(z0[:,0],z0[0,:],z0[0,:])
# # mayavi.mlab.show()
# s0=mayavi.mlab.volume_slice(z0[:,2,2],z0[2,:,2],z0[2,2,:])
# mayavi.mlab.show()
# import shapely.geometry
# import geopandas
# tupleOfLongitudeAndLatitude=(-95.3623, 29.7627)
# df0=pandas.DataFrame(tupleOfLongitudeAndLatitude).T
# df0=df0.rename(columns={0:'Longitude',1:'Latitude'})
# print(df0)
# shapely.geometry.Point(...

#python -X pycache_prefix="C:\Users\pdumas\Downloads" "C:\Users\pdumas\Documents\SAP\SAP GUI\numpy0.py"
# print(sys.pycache_prefix)
# print(os.environ.get('PYTHONPYCACHEPREFIX','nothingSet0'),os.environ.setdefault('PYTHONPYCACHEPREFIX',r"C:\Users\pdumas\Documents\SAP\SAP GUI"),os.environ.get('PYTHONPYCACHEPREFIX','nothingSet0'),sys.pycache_prefix,sep='\n')

# df = pandas.DataFrame({"A": [1, 0, -1]})
# pseudo_css = "number-format: 0Â§[Red](0)Â§-Â§@;"
# df.style.applymap(lambda v: pseudo_css).to_excel("formatted_file.xlsx")

# df = pandas.DataFrame([[4, 6], [1, 9], [3, 4], [5, 5], [9,6]],
               # columns=["Mike", "Jim"],
               # index=["Mon", "Tue", "Wed", "Thurs", "Fri"])
# styler = df.style.concat(df.agg(["sum"]).style)   
# fileSystemLoader0=jinja2.FileSystemLoader(r'C:\Users\pdumas\Downloads\jinja2Templates0')
# print(fileSystemLoader0)
# environment0=jinja2.Environment(fileSystemLoader0)
# print(environment0)
# get_template0=environment0.get_template(r'test0.jinja')
# print(get_template0)
# render0=get_template0.render()
# print(render0)
# print(env0.get_template(r'test0.jinja').render())
# env0=jinja2.Environment(jinja2.FileSystemLoader(r'C:\Users\pdumas\Downloads\jinja2Templates0'))
# print(env0.get_template(r'test0.jinja').render())
# print(jinja2.Environment(jinja2.FileSystemLoader(r'C:\Users\pdumas\Downloads\jinja2Templates0')).get_template(r'C:\Users\pdumas\Downloads\jinja2Templates0\test0.jinja').render())
# names0=['cindy','beth','mary']
# print(jinja2.Environment(loader=jinja2.BaseLoader()).from_string('''
# {% for name0 in names0 %}
    # {{name0}}
# {% endfor %}
 # ''').render(names0=names0))

# import pandas as pd
# cidx = pd.MultiIndex.from_arrays([
    # ["Equity", "Equity", "Equity", "Equity",
     # "Stats", "Stats", "Stats", "Stats,ating"],
    # ["Energy", "Energy", "Consumer", "Consumer", "", "", "", "", ""],
    # ["BP", "Shell", "H&M", "Unilever",
     # "Std Dev", "Variance", "52w High", "52w Low", ""]
# ])
# iidx = pd.MultiIndex.from_arrays([
    # ["Equity", "Equity", "Equity", "Equity"],
    # ["Energy", "Energy", "Consumer", "Consumer"],
    # ["BP", "Shell", "H&M", "Unilever"]
# ])
# styler0 = pd.DataFrame([
    # [1, 0.8, 0.66, 0.72, 32.1678, 32.1678**2, 335.12, 240.89, "Buy"],
    # [0.8, 1.0, 0.69, 0.79, 1.876, 1.876**2, 14.12, 19.78, "Hold"],
    # [0.66, 0.69, 1.0, 0.86, 7, 7**2, 210.9, 140.6, "Buy"],
    # [0.72, 0.79, 0.86, 1.0, 213.76, 213.76**2, 2807, 3678, "Sell"],
# ], columns=cidx, index=iidx).style
# print(styler0.to_latex())
# styler0.to_latex(buf=sys.stdout)
# styler0.to_latex(buf=sys.stdout,column_format='lllrrrrrr')
# styler0.to_latex(buf=sys.stdout,column_format='lllrrrrrr',position='th!')
# styler0.to_latex(buf=sys.stdout,column_format='lllrrrrrr',position='th!',position_float='raggedleft')
# styler0.to_latex(buf=sys.stdout,column_format='lllrrrrrr',position='th!',position_float='raggedleft',hrules=True)
# styler0.to_latex(buf=sys.stdout,column_format='lllrrrrrr',position='th!',position_float='raggedleft',hrules=True,clines='all;data')
# for clines0 in ['all;data','all;index','skip-last;data','skip-last;index']:
    # print('\n','\n','\n','\n',clines0)
    # styler0.to_latex(buf=sys.stdout,column_format='lllrrrrrr',position='th!',position_float='raggedleft',hrules=True,clines=clines0)
# styler0.to_latex(buf=sys.stdout,column_format='lllrrrrrr',position='th!',position_float='raggedleft',hrules=True,clines='all;data',label='label0',caption=('fullCaption0','shortCaptionn0'))
# styler0.to_latex(buf=sys.stdout,column_format='lllrrrrrr',position='th!',position_float='raggedleft',hrules=True,clines='all;data',label='label0',caption=('fullCaption0','shortCaptionn0'),sparse_index=False,sparse_columns=False)
# styler0.to_latex(buf=sys.stdout,column_format='lllrrrrrr',position='th!',position_float='raggedleft',hrules=True,clines='all;data',label='label0',caption=('fullCaption0','shortCaptionn0'),sparse_index=False,sparse_columns=False,siunitx=True)
# for multirow_align0 in ['c','b','t','naive']:
    # print('\n','\n','\n','\n',multirow_align0)
    # styler0.to_latex(buf=sys.stdout,column_format='lllrrrrrr',position='th!',position_float='raggedleft',hrules=True,clines='all;data',label='label0',caption=('fullCaption0','shortCaptionn0'),siunitx=True,multirow_align=multirow_align0)
# for multicol_align0 in ['r','l','c','naive-r','naive-l','|r']:
    # print('\n','\n','\n','\n',multicol_align0)
    # styler0.to_latex(buf=sys.stdout,column_format='lllrrrrrr',position='th!',position_float='raggedleft',hrules=True,clines='all;data',label='label0',caption=('fullCaption0','shortCaptionn0'),siunitx=True,multicol_align=multicol_align0)
# styler0.to_latex(buf=sys.stdout,position='th!',hrules=True,clines='all;data',label='label0',caption=('fullCaption0','shortCaptionn0'),siunitx=True,environment='longtable')
# with open(r'C:\Users\pdumas\Downloads\latex0output0frompy0.txt','w') as f0:
    # pass
# styler0.to_latex(buf=r'C:\Users\pdumas\Downloads\latex0output0frompy0.txt',position='th!',hrules=True,clines='all;data',label='label0',caption=('fullCaption0','shortCaptionn0'),siunitx=True,environment='longtable',encoding='utf-16')
# # os.system(r'start "" "C:\Users\pdumas\Downloads\latex0output0frompy0.txt"')
# styler0.applymap(lambda e0: "background-color: blue;").to_latex(buf=sys.stdout,position='th!',hrules=True,clines='all;data',label='label0',caption=('fullCaption0','shortCaptionn0'),siunitx=True,environment='longtable',convert_css=True)

# df0 = pandas.DataFrame({
   # 'gender': ['male', 'male', 'female', 'male', 'female', 'male','female','male','female','male','female','male','female','male'],
   # 'education': ['low', 'medium', 'high', 'low', 'high', 'low','medium','low', 'high', numpy.nan, 'high', 'medium', 'high', 'medium'],
   # 'country': ['US', 'FR', 'US', 'FR', 'FR', 'FR','BR','BR','CN','CN','CN','CN','CN','CN']
# })
# print(df0.groupby('gender',as_index=True).value_counts())
# print(df0.groupby('gender',as_index=False).value_counts())
# print(df0.groupby('gender').value_counts(sort=False))
# print(df0.groupby('gender').value_counts(sort=True,ascending=False))
# print(df0.groupby('gender').value_counts(sort=True,ascending=False,normalize=True))
# try:
    # print(df0.groupby('gender').value_counts(sort=True,ascending=False,normalize=True,subset=pandas.IndexSlice[:4]))
# except Exception as e:
    # print(e)
# try:
    # print(df0.groupby('gender').value_counts(sort=True,ascending=False,normalize=True,subset=[0,1,2,3]))
# except Exception as e:
    # print(e)
# try:
    # print(df0.groupby('gender').value_counts(sort=True,ascending=False,normalize=True,subset=['gender','country']))
# except Exception as e:
    # print(e)
# print(df0.groupby('gender').value_counts(sort=True,ascending=False,normalize=True,subset=['education']))
# print(df0.groupby('gender').value_counts(sort=True,ascending=False,normalize=True,dropna=False))


import pandas as pd
import numpy as np

# # # Generate a 10x10 random number DataFrame
# df = pd.DataFrame(np.random.randint(0, 10, size=(10, 10)))
# # a0=df.to_numpy()
# # print(df)
# # print(a0[0,0])
# # print(a0[-1,-1])
# # print(df[0])
# # print(df[0][0])
# # print(df[0].loc[0])
# # df.iloc[0,0]=numpy.nan
# # df.iloc[-1,-1]=numpy.nan

# # # Count the number of occurrences of each value
# # print(df)
# # print(df.value_counts())
# # print(df.value_counts(normalize=True,sort=True,ascending=True,subset=[0,1,2,3,4],dropna=False))
# print(df.stack())
# # series0=df.stack()
# # print(series0.value_counts())
# # print(series0.value_counts(normalize=True,sort=True,ascending=True,bins=3,dropna=False))
# value_counts = df.stack().value_counts()

# # # Print the result
# print(value_counts)


# df = pd.DataFrame({'population': [59000000, 65000000, 434000,
                                  # 434000, 434000, 434000, 337000, 11300,
                                  # 11300, 11300],
                   # 'GDP': [1937894, 2583560 , 12011, 4520, 12128, 12128,
                           # 17036, 182, 183, 311],
                   # 'alpha-2': ["IT", "FR", "MT", "MV", "AR", "BN",
                               # "IS", "NR", "TV", "AI"]},
                  # index=["Italy", "France", "Malta",
                         # "Maldives", "Argentina.Province","Brunei", "Iceland",
                         # "Nauru", "Anguilla","Tuvalu"])
# print(df)
# print(df.nlargest(3,'GDP'))
# print(df.nlargest(3,'population'))
# print(df.nlargest(3,'population',keep='first'))
# print(df.nlargest(3,'population',keep='last'))
# print(df.nlargest(3,'population',keep='all'))
# print(df.nlargest(3,['GDP','population'],keep='all'))
# print(df.nlargest(3,['population','GDP'],keep='all'))
# print(df.nsmallest(3,'GDP'))
# print(df.nsmallest(2,'population'))
# print(df.nsmallest(2,'population',keep='first'))
# print(df.nsmallest(2,'population',keep='last'))
# print(df.nsmallest(2,'population',keep='all'))
# print(df.nsmallest(2,['population','GDP'],keep='all'))
# try:
    # print(df.nsmallest(2,['population','alpha-2'],keep='all'))
# except Exception as e:
    # print(e)

# pop0={'Italy':10,'Kentucky':1}
# print(pandas.Series(pop0))
# countries_population = {"Italy": 59000000, "France": 65000000,
                        # "Brunei": 434000, "Malta": 434000,
                        # "Maldives": 434000, "Iceland": 337000,
                        # "Nauru": 11300, "Tuvalu": 11300,
                        # "Anguilla": 11300, "Montserrat": 5200}
# s = pd.Series(countries_population)
# print(s)
# print(s.nlargest())
# print(s.nsmallest())
# print(s.nlargest(3))
# print(s.nlargest(2))
# print(s.nlargest(3,keep='first'))
# print(s.nlargest(3,keep='last'))
# print(s.nlargest(3,keep='all'))
# print(s.nsmallest(3))
# print(s.nsmallest(2))
# print(s.nsmallest(2,keep='first'))
# print(s.nsmallest(2,keep='last'))
# print(s.nsmallest(2,keep='all'))

# # import pandas_datareader.data
# # # dataReader0=pandas_datareader.data.DataReader('TSLA','yahoo','2009-03-15','2021-12-31')
# # dataReader0=pandas_datareader.data.get_yahoo_data('TSLA','yahoo','2009-03-15','2021-12-31')
# # print(dataReader0.head(10))

# import yfinance
# ticker0=yfinance.Ticker('TSLA')
# print(ticker0)
# print(dir(ticker0))
# for a0 in dir(ticker0):
    # print(a0,getattr(ticker0,a0),sep='\n',end='\n\n\n')#yet another decryption key error since Yahoo keeps changing it..

# import quandl#now nasdaqdatalink?
# quandl.ApiConfig.api_key=r'sSc4W21RRfHzYr6T3DKp'
# # quandl.ApiConfig.page_limit=500
# # for a0 in dir(quandl.ApiConfig):
    # # print(a0,getattr(quandl.ApiConfig,a0),sep='\n',end='\n\n\n')
# # # print(quandl.get('NSE/OIL',authtoken='sSc4W21RRfHzYr6T3DKp'))
# # # print(quandl.get('WIKI/TSLA',start_date='2009-03-15',end_date='2021-12-31'))
# # # print(quandl.get('ZACKS/FC',ticker='TSLA',start_date='2009-03-15',end_date='2021-12-31'))
# # # # print(quandl.get_table('ZACKS/FC',start_date='2009-03-15',end_date='2009-12-31'))
# print(quandl.get_table('ZACKS/FC'))
# # print(quandl.get_table('ZACKS/FC',paginate=True,ticker=['TSLA'],per_end_date={'lte':'2021-12-31'},qopts={'columns':['ticker','per_end_date']}))
# print(quandl.get_table('ZACKS/FC', paginate=True, ticker=['AAPL', 'MSFT'], per_end_date={'gte': '2015-01-01'}, qopts={'columns':['ticker', 'per_end_date']}))#giving only 10 rows for whatever reason..
# print(quandl.get_table('ZACKS/FC', paginate=True, page_size=1000, ticker=['AAPL', 'MSFT'], per_end_date={'gte': '2015-01-01'}, qopts={'columns':['ticker', 'per_end_date']}))



# key0='KD0VZR7OUMSPBDCV'
# # url = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=TSLA&apikey={}&outputsize=full'.format(key0)
# # r = requests.get(url)
# # with open(r'C:\Users\pdumas\Downloads\tsla.InceptionToDateStockPrices.20230219.pickle','wb') as f0:
    # # pickle.dump(r,f0)
# with open(r'C:\Users\pdumas\Downloads\tsla.InceptionToDateStockPrices.20230219.pickle','rb') as f0:
    # r=pickle.load(f0)
# # for a0 in dir(r):
    # # print(a0,getattr(r,a0),sep='\n',end='\n\n\n')
# data = r.json()

# # print(data)
# # print(pandas.DataFrame(data['Time Series (Daily)']))
# # print(pandas.DataFrame(data['Time Series (Daily)']).T)
# # print(pandas.DataFrame(data['Time Series (Daily)']).T.columns)
# # print(pandas.DataFrame(data['Time Series (Daily)']).T.index)
# df0=pandas.DataFrame(data['Time Series (Daily)']).T
# df0.index=pandas.DatetimeIndex(df0.index)
# df0=df0.applymap(float)
# print(df0.agg('std',axis=0))
# print(df0.agg('std',axis=1))

# print(df0)
# df0=pandas.DataFrame([numpy.arange(40),numpy.repeat(20,40)])
# print(df0)
# print(df0.agg('std',axis=0))
# print(df0.agg('std',axis=1))
# print(df0.first('1W'))
# print(df0.last('1W'))
# print(df0.first('4D'))
# print(df0.last('4D'))
# print(df0)
# print(pandas.DataFrame(data).resample('15D').ohlc())
# print(pandas.DataFrame(data['Time Series (Daily)']).T.resample('15D').ohlc())
# # print(pandas.DataFrame(data['Time Series (Daily)']).T.resample('15D',on=pandas.DataFrame(data['Time Series (Daily)']).T.index).ohlc())
# print(df0['5. adjusted close'])
# df0['5. adjusted close']=df0['5. adjusted close'].astype(numpy.float_)
# print(df0['5. adjusted close'].agg('mean'))
# print(df0['5. adjusted close'].resample('15D'))
# print(df0['5. adjusted close'].resample('15D').ohlc())
# print(df0.shift(periods=2,axis=1))
# print(df0.shift(periods=-2,axis=1))
# # print(df0.shift(periods=7,fill_value='1900-01-01'))
# # print(df0.shift(periods=-7,fill_value='1900-01-01'))
# print(df0.shift(periods=7,fill_value=1.50))
# print(df0.shift(periods=-7,fill_value=1.50))
# try:
    # print(df0.shift(periods=7,freq='infer'))
# except Exception as e:
    # print(e)
# print(df0.shift(periods=7,freq='1D'))
# print(df0.shift(periods=-7,freq='1D'))
# print(df0.shift(periods=-7,freq='1M'))
# print(df0.shift(periods=7))
# print(df0.shift(periods=-7))
# print(df0.drop(df0.filter(regex='[2-8].*').columns,axis=1))
# print(df0.drop(df0.filter(regex='[2-8].*').columns,axis=1).stack())
# print(df0.drop(df0.filter(regex='[2-8].*').columns,axis=1).stack().shift(periods=7))
# print(df0.drop(df0.filter(regex='[2-8].*').columns,axis=1).stack().shift(periods=-7))
# print(df0.drop(df0.filter(regex='[2-8].*').columns,axis=1).stack().shift(periods=7,fill_value=1.5))
# try:
    # print(df0.drop(df0.filter(regex='[2-8].*').columns,axis=1).stack().shift(periods=7,fill_value=1.5,freq='1D'))
# except Exception as e:
    # print(e)
# print(pandas.Series(df0.drop(df0.filter(regex='[2-8].*').columns,axis=1)['1. open'],index=df0.index).shift(periods=7,fill_value=1.5,freq='1D'))
# print(pandas.Series(df0.drop(df0.filter(regex='[2-8].*').columns,axis=1)['1. open'],index=df0.index).shift(periods=7,fill_value=1.5,freq='2D'))
# print(pandas.date_range('2023-02-28',periods=4,freq='BQ'))
# print(pandas.date_range('2023-02-28',periods=4,freq='BQ').shift(4))
# print(pandas.date_range('2023-02-28',periods=4,freq='BQ').shift(4,freq='15D'))


# import quandl
# quandl.ApiConfig.api_key=r'sSc4W21RRfHzYr6T3DKp'
# df=quandl.get_table('ZACKS/FC')
# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','wb') as f0:
    # pickle.dump(df,f0)
# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)

# countries_population = {"Italy": 59000000, "France": 65000000,
                        # "Brunei": 434000, "Malta": 434000,
                        # "Maldives": 434000, "Iceland": 337000,
                        # "Nauru": 11300, "Tuvalu": 11300,
                        # "Anguilla": 11300, "Montserrat": 5200}
# s = pd.Series(countries_population)

# df1 = pd.DataFrame({
    # 'length': [1.5, 0.5, 1.2, 0.9, 3],
    # 'width': [0.7, 0.2, 0.15, 0.2, 1.1]
    # }, index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])
# hist = df1.hist(bins=3)

# print(df)
# print(s)
# print(df.filter(items=['comp_name','comp_name_2']))
# print(df.filter(like='comp'))
# print(df.filter(like='div'))
# print(df.filter(regex='^comp'))
# print(df.filter(like='2',axis=0))
# print(s.filter(items=['Italy','Maldives']))
# print(s.filter(like='al'))
# print(s.filter(regex='a$'))
# print(s.filter(regex='a$',axis=None))

# print(hist)
# print(dir(hist))
# matplotlib.pyplot.cla()
# matplotlib.pyplot.clf()
# s.hist()
# matplotlib.pyplot.show()

# print(pandas.read_html(requests.get(r'https://www.worldometers.info/gdp/gdp-by-country/').content))
# df0=pandas.read_html(requests.get(r'https://www.worldometers.info/gdp/gdp-by-country/').content)[-1]
# # df0=pandas.read_html(requests.get(r'https://data.worldbank.org/indicator/NY.GDP.MKTP.CD').content)[-1]
# print(df0)
# print(df0.columns)
# # df0['GDP  (nominal, 2017)']=df0['GDP  (nominal, 2017)'].str.replace('$','').replace(',','').astype(numpy.float_)
# # df0['GDP  (nominal, 2017)']=df0['GDP  (nominal, 2017)'].str.replace('$','').replace(',','')
# df0['GDP  (nominal, 2017)']=df0['GDP  (nominal, 2017)'].str.replace('[\$,]','',regex=True).astype(numpy.float_)
# print(df0['GDP  (nominal, 2017)'])
# # df0.hist(figsize=(14.2,12.8),layout=(2,2))
# # df0.hist(figsize=(14.2,12.8),layout=(1,3))
# # df0.hist(figsize=(22.2,20.8),layout=(1,4))
# # df0.hist(column='GDP  (nominal, 2017)')
# # df0.hist(column='GDP  (nominal, 2017)',bins=100,grid=False,xlabelsize=40,xrot=90.0,ylabelsize=25,yrot=45.0,ax=matplotlib.pyplot.gca(),sharex=False,sharey=False,figsize=900,layout=(15,15),backend='matplotlib',legend=True)
# # df0.hist(column='GDP  (nominal, 2017)',bins=100,grid=False,xlabelsize=40,xrot=90.0,ylabelsize=25,yrot=45.0,ax=matplotlib.pyplot.gca(),sharex=False,sharey=False,figsize=900,layout=(15,15),backend='matplotlib',legend=True)
# df0.hist(column='GDP  (nominal, 2017)',bins=100,grid=False,xlabelsize=10,xrot=60.0,ylabelsize=5,yrot=0.0,ax=matplotlib.pyplot.gca(),sharex=False,sharey=False,layout=(7,7),backend='matplotlib',legend=True)
# print(matplotlib.rcParams)
# print(pandas.options.plotting.backend)
# df0 = pandas.DataFrame({
   # 'gender': ['male', 'male', 'female', 'male', 'female', 'male','female','male','female','male','female','male','female','male'],
   # 'education': ['low', 'medium', 'high', 'low', 'high', 'low','medium','low', 'high', numpy.nan, 'high', 'medium', 'high', 'medium'],
   # 'country': ['US', 'FR', 'US', 'FR', 'FR', 'FR','BR','BR','CN','CN','CN','CN','CN','CN'],
   # 'count': numpy.random.default_rng(8).integers(0,100,(14,))
# })
# # df0.hist(by='gender')
# # df0.hist()
# print(list(df0.itertuples(index=False)))
# s2 = pandas.Series(numpy.random.default_rng(8).integers(0,100,(12,)),index=pandas.MultiIndex.from_product([['male','female','binary'],['US','FR','BR','CN']],names=['gender','country'])
# )
# # print(s2)
# # s2.hist()
# # s2.hist(by='gender')
# s2.hist(grid=True,xlabelsize=20,xrot=65.,ylabelsize=10,yrot=65.,backend='matplotlib',ax=matplotlib.pyplot.gca(),figsize=(12,10),bins=6,legend=True)
# # df0['gender'].to_
# matplotlib.pyplot.show()


# import matplotlib.pyplot as plt
# import numpy as np

# fig, ax = plt.subplots()

# Create a scatter plot with random data
# x = np.random.rand(100)
# y = np.random.rand(100)
# sc = ax.scatter(x, y, s=50, c='r', alpha=0.5)
# sc = ax.scatter(x, y, s=50, c='r', alpha=0.99)
# sc = ax.scatter(x, y, s=50, c='r', alpha=0.01)

# # # # Define a filter function
# # # def filter_func(rgba, x, y):
    # # # # This function returns a modified RGBA color based on the given coordinates
    # # # alpha = rgba[3]
    # # # if x < 0.5 and y < 0.5:
        # # # alpha = 0.2 # make the point more transparent in the lower-left corner
    # # # return (rgba[0], rgba[1], rgba[2], alpha)

# Define a filter function
# def filter_func(rgba, dpi0):
    # # This function returns a modified RGBA color based on the given coordinates
    # print(rgba)
    # print(dpi0)
    # x=20
    # y=.5
    # return (rgba, x,y)

# Set the filter function using the agg_filter keyword argument
# sc.set_agg_filter(filter_func)
# sc.set_alpha(.2)

# x0=numpy.arange(15)
# height0=numpy.random.default_rng(8).integers(-10,20,(15,))
# width0=numpy.random.default_rng(8).integers(-10,20,(15,))/3
# bottom0=numpy.random.default_rng(8).integers(-10,20,(15,))-10
# # align0='center'
# # figure0,axis0=matplotlib.pyplot.subplots()
# # bar0=axis0.bar(x,y,angle=30.)
# # bar0=axis0.bar(x0,height0)
# # bar0=axis0.bar(x0,height0,width0)
# # bar0=axis0.bar(x0,height0,width0,bottom0)
# for align0 in ['center','edge']:
    # bar0=matplotlib.pyplot.subplots()[1].bar(x0,height0,align=align0,label=f'{align0}')#if multiple subplots at once, matplotlib will always LIFO (display last computed on top / what the user sees first)
    # bar0.axis.set_title(f'{align0}')
    # matplotlib.pyplot.legend()
    # print(bar0)
# # bar0=axis0.bar(x0,height0,width0,bottom0,align0)
# # bar0.set_angle(30.)
# matplotlib.pyplot.show()


# df0 = pandas.DataFrame({
   # 'gender': ['male', 'male', 'female', 'male', 'female', 'male','female','male','female','male','female','male','female','male'],
   # 'education': ['low', 'medium', 'high', 'low', 'high', 'low','medium','low', 'high', numpy.nan, 'high', 'medium', 'high', 'medium'],
   # 'country': ['US', 'FR', 'US', 'FR', 'FR', 'FR','BR','BR','CN','CN','CN','CN','CN','CN'],
   # 'count': numpy.random.default_rng(8).integers(0,100,(14,))
# })
# df0.iloc[0:3,3]=numpy.nan
# print(df0)
# # print(df0.groupby('education'))
# # print(df0.groupby('education').count())
# # print(df0.groupby('education').ngroup())
# # print(df0.groupby('education').ngroup(ascending=False))
# # for ngroup0 in range(df0.groupby('education').ngroups):
# for ngroup0 in range(5):
    # print(df0.groupby('education').nth(ngroup0))
# # print(df0.groupby('education').nth([0,1]))
# # print(df0.groupby('education').nth(slice(0,2)))
# print('\n\n')
# # for ngroup0 in range(df0.groupby('education').ngroups):
# for ngroup0 in range(5):
    # print(df0.groupby('education').nth(ngroup0,dropna='any'))
# print('\n\n')
# # for ngroup0 in range(df0.groupby('education').ngroups):
# # for ngroup0 in range(5):
    # # print(df0.groupby('education').nth(ngroup0,dropna='all'))
# print(df0.groupby('education').nth(0,dropna='all'))
# print(df0.groupby('education').nth(1,dropna='all'))
# print(df0.groupby('education').nth(2,dropna='all'))
# print(df0.groupby('education').nth(3,dropna='all'))
# print(df0.groupby('education').nth(4,dropna='all'))
# try:
    # print(df0.groupby('education').nth([0,1],dropna='any'))
# except Exception as e:
    # print(e)
# print(df0.groupby('education').nth(slice(0,2,dropna='any')))

# a0=numpy.random.default_rng(8).integers(0,10,(10,10))
# # a0=numpy.random.default_rng(8).integers(0,10,(10,10,10))
# a0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10)))
# # matplotlib.pyplot.scatter(df0)
# print(a0)
# matplotlib.pyplot.plot(a0)
# matplotlib.pyplot.show()
# df0=pandas.DataFrame(numpy.arange(20))
# df10=pandas.DataFrame(numpy.arange(0,40,2))
# df1=pandas.DataFrame(numpy.arange(19,-1,-1))
# df2=pandas.DataFrame(numpy.geomspace(1,1000,20))
# df3=pandas.DataFrame(numpy.geomspace(1000,1,20))
# df4=pandas.DataFrame(numpy.logspace(1,3,4))
# df5=pandas.DataFrame(numpy.logspace(3,1,4))
# df6=pandas.DataFrame(numpy.array([1000,999.9,999.8,800,500,1]))
# df7=pandas.DataFrame(numpy.array([[1000,numpy.nan,999.8,800,500,1],[1000,999.9,999.8,800,500,numpy.nan],['a','b','c','d','e','f']])).T
# print(df0)
# print(df0.skew())
# print(df10)
# print(df10.skew())
# print(df1)
# print(df1.skew())
# print(df2)
# print(df2.skew())
# print(df3)
# print(df3.skew())
# print(df4)
# print(df4.skew())
# print(df5)
# print(df5.skew())
# print(df6)
# print(df6.skew())
# print('\n\n\n')
# # df7=pandas.DataFrame(numpy.array([[1000,numpy.nan,999.8,800,500,1],[1000,999.9,999.8,800,500,numpy.nan]])).T
# # df7=pandas.DataFrame(numpy.array([[1000,numpy.nan,999.8,800,500,1],[1000,numpy.nan,999.8,800,500,1]])).T
# # df7=pandas.DataFrame(numpy.array([[1000,numpy.nan,999.8,800,500,1],[1000,999.9,999.8,800,500,1]])).T
# # df7=pandas.DataFrame(numpy.array([[1000,999.9,999.8,800,500,1],[1000,999.9,999.8,800,500,1],[1000,999.9,999.8,800,500,1]])).T
# print(df7)
# print(df7.skew())
# print(df7.skew(skipna=True))
# print(df7.skew(skipna=False))
# print(df7.skew(skipna=False,axis=1))
# print(df7.skew(skipna=True,axis=1))
# print('take0')
# print(df7.take([0,2]))
# print(df7.take([0,2],axis=0))
# print(df7.take([0,2],axis=1))
# print(df7.iloc[[0,2],:])
# print(df7.iloc[:,[0,2]])
# try:
    # print(df7.skew(skipna=False,numeric_only=False))
# except Exception as e:
    # print(e)
# df7=pandas.DataFrame(numpy.array([[1000,numpy.nan,999.8,800,500,1],[1000,999.9,999.8,800,500,numpy.nan],['1000','999.9','999.8','800','500','nan']]))#numpy.nan and na don't work but nan works..
# print(df7.skew(skipna=False,numeric_only=False))
# print(df7.skew(skipna=False,numeric_only=True))
# df0 = pandas.DataFrame({
   # 'gender': ['male', 'male', 'female', 'male', 'female', 'male','female','male','female','male','female','male','female','male'],
   # 'education': ['low', 'medium', 'high', 'low', 'high', 'low','medium','low', 'high', numpy.nan, 'high', 'medium', 'high', 'medium'],
   # 'country': ['US', 'FR', 'US', 'FR', 'FR', 'FR','BR','BR','CN','CN','CN','CN','CN','CN'],
   # 'count': numpy.random.default_rng(8).integers(0,100,(14,))
# })
# print(df0.groupby('gender')['count'].skew())
# df8=pandas.DataFrame(numpy.array([1000,numpy.nan,999.8,800,500,1]))
# print(df8)
# print(df8.skew(skipna=True))
# s8=pandas.DataFrame(numpy.array([1000,numpy.nan,999.8,800,500,1]))
# print(s8)
# print(s8.skew(skipna=True))
# print(s8.skew(skipna=False))
# s8=pandas.DataFrame(numpy.array(['1000','999.9','999.8','800','500','1']))
# print(s8.skew(skipna=False))
# print(s8.skew(skipna=False,numeric_only=False))
# print(s8.skew(skipna=False,numeric_only=True))
# print('take0')
# print(s8.take([0,2]))
# print(s8.take([0,2],axis=0))
# print(s8.iloc[[0,2],:])
# print(pandas.Series(numpy.geomspace(1,1000,20)+numpy.array([1000])).is_monotonic_increasing)
# print(pandas.Series(numpy.geomspace(1,1000,20)+numpy.array([1000])).is_monotonic_decreasing)
# print(pandas.Series(numpy.geomspace(1000,1,20)+numpy.array([1])).is_monotonic_increasing)
# print(pandas.Series(numpy.geomspace(1000,1,20)+numpy.array([1])).is_monotonic_decreasing)
# print(pandas.Series(numpy.repeat(5,20)).is_monotonic_increasing)
# print(pandas.Series(numpy.repeat(5,20)).is_monotonic_decreasing)
# print(pandas.Index(numpy.geomspace(1,1000,20)+numpy.array([1000])).is_monotonic_increasing)
# print(pandas.Index(numpy.geomspace(1,1000,20)+numpy.array([1000])).is_monotonic_decreasing)
# print(pandas.Index(numpy.geomspace(1000,1,20)+numpy.array([1])).is_monotonic_increasing)
# print(pandas.Index(numpy.geomspace(1000,1,20)+numpy.array([1])).is_monotonic_decreasing)
# print(pandas.Index(numpy.repeat(5,20)).is_monotonic_increasing)
# print(pandas.Index(numpy.repeat(5,20)).is_monotonic_decreasing)
# print(pandas.DataFrame([numpy.random.default_rng(8).integers(-10,20,(20,)),numpy.random.default_rng(7).integers(-10,20,(20,)),numpy.random.default_rng(6).integers(-10,20,(20,))]).T.boxplot())
# print(pandas.DataFrame([numpy.random.default_rng(8).integers(-10,20,(20,)),numpy.random.default_rng(7).integers(-10,20,(20,)),numpy.random.default_rng(6).integers(-10,20,(20,))]).T.boxplot(return_type=None))
# print(pandas.DataFrame([numpy.random.default_rng(8).integers(-10,20,(20,)),numpy.random.default_rng(7).integers(-10,20,(20,)),numpy.random.default_rng(6).integers(-10,20,(20,))]).T.boxplot(return_type='axes'))
# print(pandas.DataFrame([numpy.random.default_rng(8).integers(-10,20,(20,)),numpy.random.default_rng(7).integers(-10,20,(20,)),numpy.random.default_rng(6).integers(-10,20,(20,))]).T.boxplot(return_type='dict'))
# print(pandas.DataFrame([numpy.random.default_rng(8).integers(-10,20,(20,)),numpy.random.default_rng(7).integers(-10,20,(20,)),numpy.random.default_rng(6).integers(-10,20,(20,))]).T.boxplot(return_type='both'))
# print(pandas.DataFrame(numpy.array([numpy.random.default_rng(8).integers(-10,20,(20,)),numpy.random.default_rng(7).integers(-10,20,(20,)),numpy.random.default_rng(6).integers(-10,20,(20,)),numpy.random.default_rng(5).integers(-10,20,(20,))]).T,columns=['col0','col1','col2','col3']).T.boxplot(columns=[0,1],fontsize=20,rot=60.,backend='matplotlib',return_type='axes',grid=False,figsize=(14,12),layout=(2,2)))
# print(pandas.DataFrame(numpy.array([numpy.random.default_rng(8).integers(-10,20,(20,)),numpy.random.default_rng(7).integers(-10,20,(20,)),numpy.random.default_rng(6).integers(-10,20,(20,)),numpy.random.default_rng(5).integers(-10,20,(20,))]).T,columns=['col0','col1','col2','col3']).boxplot(fontsize=20,rot=60.,backend='matplotlib',return_type='axes',grid=False,figsize=(14,12)))
# print(pandas.DataFrame(numpy.array([numpy.random.default_rng(8).integers(-10,20,(20,)),numpy.random.default_rng(7).integers(-10,20,(20,)),numpy.random.default_rng(6).integers(-10,20,(20,)),numpy.random.default_rng(5).integers(-10,20,(20,))]).T,columns=['col0','col1','col2','col3']).boxplot())
# a0=numpy.hstack([numpy.repeat('group0',5),numpy.repeat('group1',5),numpy.repeat('group2',5),numpy.repeat('group3',5)])
# print(a0)
# # # print(pandas.DataFrame(numpy.array([numpy.random.default_rng(8).integers(-10,20,(20,)),numpy.random.default_rng(7).integers(-10,20,(20,)),numpy.random.default_rng(6).integers(-10,20,(20,)),numpy.random.default_rng(5).integers(-10,20,(20,))]).T,columns=['col0','col1','col2','col3']).boxplot(fontsize=20,grid=False,rot=60.,figsize=(16,12),ax=matplotlib.pyplot.gca(),backend='matplotlib',by=a0))
# df0=pandas.DataFrame(numpy.array([numpy.random.default_rng(8).integers(-10,20,(20,)),numpy.random.default_rng(7).integers(-10,20,(20,)),numpy.random.default_rng(6).integers(-10,20,(20,)),numpy.random.default_rng(5).integers(-10,20,(20,))]).T,columns=['col0','col1','col2','col3'])
# df0['groupCol0']=pandas.Series(a0)
# print(df0)
# # df0.boxplot(fontsize=20,grid=False,rot=60.,figsize=(16,12),ax=matplotlib.pyplot.gca(),backend='matplotlib',column=['col0','col2'],by='groupCol0')
# # df0.boxplot(fontsize=20,grid=False,rot=60.,figsize=(16,12),ax=matplotlib.pyplot.gca(),backend='matplotlib',by='groupCol0')
# df0.plot.box(by='groupCol0')
# # s0=pandas.Series(df0.iloc[:,0])
# # # s0.plot.box()
# # s0.index=pandas.Series(a0)
# # print(s0.index)
# # s0.plot.box(by=s0.index)#by only works for dataframes..
# matplotlib.pyplot.show()

# import pandas as pd
# i = pd.date_range('2018-04-09', periods=4, freq='2D')
# ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
# print(ts)
# print(ts.last('3D'))
# print(ts.first('3D'))
# periods0=40
# i = pd.date_range('2018-04-09', periods=periods0, freq='1D')
# df0 = pd.DataFrame({'A': numpy.arange(periods0),'B': numpy.arange(periods0)}, index=i)
# s0 = pd.Series(numpy.arange(periods0), index=i)
# print(df0)
# print(df0.last('5D'))
# print(df0.first('5D'))
# print(df0.last('1W'))
# print(df0.first('1W'))
# print(df0.last('1M'))
# print(df0.first('1M'))
# print(s0)
# print(s0.last('5D'))
# print(s0.first('5D'))
# print(s0.last('1W'))
# print(s0.first('1W'))
# print(s0.last('1M'))
# print(s0.first('1M'))
# df0 = pandas.DataFrame(
    # [[1, 2, 3, 4], [6, 7, 8, 9], [6, 7, 8, 10], [6, 7, 8, 10]], columns=["D", "B", "E", "A"], index=[1, 2,5,6]
# )
# df1 = pandas.DataFrame(
    # [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900]],
    # columns=["A", "B", "C", "D"],
    # index=[2, 3, 4],
# )
# print(df0)
# print(df1)
# print(df0.align(df1))
# print(df0.align(df1,axis=0))
# print(df0.align(df1,axis=1))
# print(df0.align(df1,axis=1,fill_value=42.))
# print(df0.align(df1,axis=0,method='bfill'))
# print(df0.align(df1,axis=0,method='ffill'))
# print(df0.align(df1,axis=1,fill_axis=0,method='bfill',limit=1))#does it really make sense for fill_axis and axis to differ (fill values will always just be fill_value..)
# print(df0.align(df1,axis=1,fill_axis=1,method='bfill',limit=1))
# # df0 = pandas.DataFrame([1, 2, 3, 4], columns=["D"],index=[1,2,5,6])
# df0 = pandas.DataFrame([42], columns=["D"],index=[1])
# df1 = pandas.DataFrame(
    # [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900],[600, 700, 800, 900]],
    # columns=["A", "B", "C", "D"],
    # index=[2, 3, 4,5],
# )
# print(df0.align(df1,broadcast_axis=0))
# print(df0.align(df1,broadcast_axis=1))
# print(df1.align(df0,broadcast_axis=0))
# print(df1.align(df0,broadcast_axis=1))
# df2=pandas.DataFrame([6,7,8,9],index=pandas.MultiIndex.from_product([[0,1],[0,1]],names=['level0','level1']))
# print(df2.align(df0,level='level0'))
# print(df2.align(df0,level='level1',copy=False))

# # aligned1, aligned2 = df1.align(df2, axis=1, broadcast_axis=1)
# # print(aligned1)
# # print(aligned2)
# # aligned1, aligned2 = df1.align(df2, axis=1, broadcast_axis=0)
# # print(aligned1)
# # print(aligned2)
# # aligned1, aligned2 = df1.align(df2, axis=0, broadcast_axis=0)
# # print(aligned1)
# # print(aligned2)


# s0 = pandas.Series(
    # [1, 2, 3, 4], index=[1, 2,5,6]
# )
# s1 = pandas.Series(
    # [10, 20, 30, 40],
    # index=[2, 3, 4,5],
# )
# print(s0)
# print(s1)
# print(s0.align(s1))
# print(s0.align(s1,axis=0))
# print(s0.align(s1,axis=0,method='bfill'))
# print(s0.align(s1,axis=0,method='ffill'))
# s0 = pandas.Series([42],index=[1])
# s1 = pandas.Series(
    # [10, 20, 30, 40],
    # index=[2, 3, 4,5]
# )
# print(s0.align(s1,broadcast_axis=0))
# print(s1.align(s0,broadcast_axis=0))
# s2=pandas.Series([6,7,8,9],index=pandas.MultiIndex.from_product([[0,1],[0,1]],names=['level0','level1']))
# print(s2.align(s0,level='level0'))
# print(s2.align(s0,level='level1',copy=False))

# aligned1, aligned2 = s1.align(s2, axis=0, broadcast_axis=0)
# print(aligned1)
# print(aligned2)

# df0=pandas.DataFrame([[True,numpy.nan,False],[True,0,False],[True,0,False]])
# print(df0)
# print(df0.all())
# print(df0.all(axis=0))
# print(df0.all(axis=1))
# print(df0.all(axis=None))
# print(df0.all(axis=0,bool_only=None))
# print(df0.all(axis=0,bool_only=True))
# print(df0.all(axis=0,bool_only=False))
# print(df0.all(axis=0,skipna=True))
# print(df0.all(axis=0,skipna=False))
# print(df0)
# print(df0.any())
# print(df0.any(axis=0))
# print(df0.any(axis=1))
# print(df0.any(axis=None))
# print(df0.any(axis=0,bool_only=None))
# print(df0.any(axis=0,bool_only=True))
# print(df0.any(axis=0,bool_only=False))
# print(df0.any(axis=0,skipna=True))
# print(df0.any(axis=0,skipna=False))

# s0=pandas.Series([True,numpy.nan,0])
# print(s0)
# print(s0.all())
# print(s0.all(axis=0))
# print(s0.all(axis=None))
# print(s0.all(axis=0,bool_only=None))
# try:
    # print(s0.all(axis=0,bool_only=True))
# except Exception as e:
    # print(e)
# print(s0.all(axis=0,bool_only=False))
# print(s0.all(axis=0,skipna=True))
# print(s0.all(axis=0,skipna=False))
# print(s0)
# print(s0.any())
# print(s0.any(axis=0))
# print(s0.any(axis=None))
# print(s0.any(axis=0,bool_only=None))
# try:
    # print(s0.any(axis=0,bool_only=True))
# except Exception as e:
    # print(e)
# print(s0.any(axis=0,bool_only=False))
# print(s0.any(axis=0,skipna=True))
# s0=pandas.Series([False,numpy.nan,0])
# print(s0.any(axis=0,skipna=True))
# print(s0.any(axis=0,skipna=False))

# df0 = pandas.DataFrame([[4, 9]] * 2, columns=['A', 'B'],index=[42,43])
# print(df0)
# for result_type0 in ['reduce','expand','broadcast',None]:
    # print(result_type0)
    # print(df0.apply(lambda s0: [1,2],axis=1,result_type=result_type0))
    # print(df0.apply(lambda s0: pandas.Series([1,2]),axis=1,result_type=result_type0))
    # print(df0.apply(lambda s0: [1,2],axis=0,result_type=result_type0))
    # print(df0.apply(lambda s0: pandas.Series([1,2]),axis=0,result_type=result_type0))
    # print('\n\n')
# for func0 in [numpy.mean,numpy.var]:
    # for raw0 in [False,True]:
        # print(func0,raw0,timeit.repeat('df0.apply(func0,raw=raw0)',repeat=3,number=1000,globals=globals()),sep='\n',end='\n\n')#2.5-3 times speed up using raw=True
# for func0 in [numpy.mean,numpy.var]:
    # for axis0 in [0,1]:
        # print(df0.apply(func0,axis=axis0))
# # print(df0.apply(numpy.power,raw=True,axis=1,args=(2,2)))
# # def addAndPrint0(s0,argToAdd0,kwargToPrint0='printDefault0'):
    # # print(kwargToPrint0)
    # # return s0+argToAdd0
# # print(pandas.DataFrame([[4, 9]] * 2, columns=['A', 'B'],index=[42,43]).apply(addAndPrint0,axis=0,args=(42,)))
# # print(pandas.DataFrame([[4, 9]] * 2, columns=['A', 'B'],index=[42,43]).apply(numpy.add,raw=True,axis=1,args=(2,2)))
# # print(pandas.DataFrame([[4, 9]] * 2, columns=['A', 'B'],index=[42,43]).apply(numpy.add,axis=1,args=(2,)))
# # print(df0.apply(lambda x,arg0: np.add(x, arg0),args=(2,),axis=1))#if you go through lambda it works but a straight numpy.add doesn't even though it also takes 2 positional arguments. weird..
# # print(df0.apply(lambda x,arg0: numpy.power(x, arg0),args=(2,),axis=1))
# s0 = pandas.Series([4, 9.] * 2,index=[42,43,44,45])
# print(s0)
# print(s0.apply(numpy.mean))
# print(s0.apply(numpy.mean,convert_dtype=True))
# print(s0.apply(numpy.mean,convert_dtype=False))
# def addAndPrint0(s0,argToAdd0,kwargToPrint0='printDefault0'):
    # print(kwargToPrint0)
    # return s0+argToAdd0
# print(s0.apply(addAndPrint0,args=(42,)))
# def func1(e0,kwarg0='printDefault1'):
    # print(kwarg0)
    # return str(e0)+str(e0)
# df0.iloc[1,1]=numpy.nan
# print(df0)
# print(df0.applymap(lambda e0: str(e0)+str(e0),na_action=None))
# print(df0.applymap(func1,na_action=None))
# print(df0.applymap(func1,na_action='ignore'))

# print(pandas.period_range(start='2023-01-01',end='2024-12-31',freq='M'))
# print(pandas.period_range(start='2023-01-01',end='2024-12-31',freq='M').asfreq('W'))
# print(pandas.period_range(start='2023-01-01',end='2024-12-31',freq='M').asfreq('W',how='E'))
# print(pandas.period_range(start='2023-01-01',end='2024-12-31',freq='M').asfreq('W',how='S'))
# print(pandas.period_range(start='2023-01-01',end='2024-12-31',freq='M').asfreq('A',how='E'))
# print(pandas.period_range(start='2023-01-01',end='2024-12-31',freq='M').asfreq('A',how='S'))
# print(pandas.period_range(start='2023-01-01',end='2024-12-31',freq='M').asfreq('D',how='E'))
# print(pandas.period_range(start='2023-01-01',end='2024-12-31',freq='M').asfreq('D',how='S'))
# print(pandas.period_range(start='2023-01-01',end='2024-12-31',freq='M').asfreq('2D',how='S'))
# print(pandas.period_range(start='2023-01-01',periods=24,freq='M'))
# print(pandas.period_range(end='2024-12-31',periods=24,freq='M'))
# print(pandas.period_range(end='2024-12-31',periods=24,freq='M',name='2023Through2024.Months'))
# print(pandas.PeriodIndex(['2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12'],freq='M'))
# print(pandas.PeriodIndex(['2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12'],freq='M',ordinal=True))
# print(pandas.PeriodIndex(['2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12'],freq='M',ordinal=False))
# print(pandas.PeriodIndex(['2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12'],freq='M',copy=True))
# print(pandas.PeriodIndex(year=2023,month=numpy.arange(12),freq='M'))
# print(pandas.PeriodIndex(year=2023,month=numpy.arange(1,13,1),freq='M'))
# try:
    # print(pandas.PeriodIndex(year=[2023,2024],month=numpy.arange(1,13,1),freq='M'))
# except Exception as e:
    # print(e)
# print(pandas.PeriodIndex(year=2023,month=numpy.arange(1,13,1),freq='M',dtype=pandas.PeriodDtype(freq='D')))
# print(pandas.PeriodIndex(year=2023,month=numpy.arange(1,13,1),freq='D',dtype=pandas.PeriodDtype(freq='D')))
# print(pandas.PeriodIndex(year=2023,quarter=numpy.arange(1,5,1),freq='Q'))
# # print(pandas.PeriodIndex(year=2023,month=1,day=1,freq=pandas.PeriodDtype(freq='D')))
# # print(pandas.PeriodIndex(year=2023,month=1,day=1,freq='D'))
# print(pandas.PeriodIndex(year=2023,hour=1,freq='H'))
# print(pandas.PeriodIndex(year=2023,minute=1,freq='min'))
# print(pandas.PeriodIndex(year=2023,second=1,freq='sec'))

# print(pandas.period_range('2023-01','2024-12',freq='Y'))
# print(pandas.period_range('2023-01','2024-12',freq='M').strftime('%Y%m%d'))
# print(pandas.period_range('2023-01','2024-12',freq='M').to_timestamp())
# print(pandas.period_range('2023-01','2024-12',freq='M').to_timestamp('M'))
# print(pandas.period_range('2023-01','2024-12',freq='M').to_timestamp('M',how='E'))#asfreq and to_timestamp don't actually up/down sample (keep same samples just different format 'D' vs 'M')
# print(pandas.Period('2023'))
# try:
    # print(pandas.Period('2023',dtype=pandas.PeriodDtype('M')))
# except Exception as e:
    # print(e)
# print(pandas.Period('2023',freq='M'))
# print(pandas.Period('2023',freq='D'))
# print(pandas.Period(ordinal=300,freq='D'))
# try:
    # print(pandas.Period(year=2023))
# except Exception as e:
    # print(e)
# print(pandas.Period(year=2023,freq='M'))
# print(pandas.Period(year=2023,quarter=2,freq='D'))
# print(pandas.Period(year=2023,month=2,day=2,hour=2,minute=2,second=2,freq='s'))
# print(pandas.Period(year=2023,month=2,day=2,hour=2,minute=2,second=2,freq='ns'))
# try:
    # print(pandas.Period(year=2023,month=2,day=2,hour=2,minute=2,second=2,freq='D').now())
# except Exception as e:
    # print(e)
# print(pandas.Period('2023',freq='D').now())

# print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03']))
# try:
    # print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03'],freq='D'))
# except Exception as e:
    # print(e)
# print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03'],freq='infer'))
# try:
    # print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03'],freq='infer',tz='US/EST'))
# except Exception as e:
    # print(e)
# print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03'],freq='infer',tz='EST'))
# print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03'],freq='infer',tz='EST',normalize=True))
# print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03'],freq='infer',tz='EST',normalize=True,closed='left'))
# print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03'],freq='infer',tz='EST',normalize=True,closed='right'))
# print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer'))
# print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer',dayfirst=True))
# print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer',yearfirst=True))
# try:
    # print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer',yearfirst=True,dtype='datetime64[ns]'))
# except Exception as e:
    # print(e)
# print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03'],freq='infer',normalize=True,closed='left',ambiguous='infer',yearfirst=True,dtype='datetime64[ns]'))
# print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer',yearfirst=True,copy=True))

# print('\n\n')
# print(pandas.DatetimeIndex(['2023-01-01T00:00:00.000000','2023-02T00:00:00.000000','2023-03T23:23:23.000023']))
# try:
    # print(pandas.DatetimeIndex(['2023-01-01T00:00:00.000000','2023-02T00:00:00.000000','2023-03T23:23:23.000023'],freq='D'))
# except Exception as e:
    # print(e)
# print(pandas.DatetimeIndex(['2023-01-01T00:00:00.000000','2023-02T00:00:00.000000','2023-03T23:23:23.000023'],freq='infer'))
# try:
    # print(pandas.DatetimeIndex(['2023-01-01T00:00:00.000000','2023-02T00:00:00.000000','2023-03T23:23:23.000023'],freq='infer',tz='US/EST'))
# except Exception as e:
    # print(e)
# print(pandas.DatetimeIndex(['2023-01-01T00:00:00.000000','2023-02T00:00:00.000000','2023-03T23:23:23.000023'],freq='infer',tz='EST'))
# print(pandas.DatetimeIndex(['2023-01-01T00:00:00.000000','2023-02T00:00:00.000000','2023-03T23:23:23.000023'],freq='infer',tz='EST',normalize=True))
# print(pandas.DatetimeIndex(['2023-01-01T00:00:00.000000','2023-02T00:00:00.000000','2023-03T23:23:23.000023'],freq='infer',tz='EST',normalize=True,closed='left'))
# print(pandas.DatetimeIndex(['2023-01-01T00:00:00.000000','2023-02T00:00:00.000000','2023-03T23:23:23.000023'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer'))
# print(pandas.DatetimeIndex(['2023-01-01T00:00:00.000000','2023-02T00:00:00.000000','2023-03T23:23:23.000023'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer',dayfirst=True))
# print(pandas.DatetimeIndex(['2023-01-01T00:00:00.000000','2023-02T00:00:00.000000','2023-03T23:23:23.000023'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer',yearfirst=True))
# try:
    # print(pandas.DatetimeIndex(['2023-01-01T00:00:00.000000','2023-02T00:00:00.000000','2023-03T23:23:23.000023'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer',yearfirst=True,dtype='datetime64[ns]'))
# except Exception as e:
    # print(e)
# print(pandas.DatetimeIndex(['2023-01-01T00:00:00.000000','2023-02T00:00:00.000000','2023-03T23:23:23.000023'],freq='infer',normalize=True,closed='left',ambiguous='infer',yearfirst=True,dtype='datetime64[ns]'))
# print(pandas.DatetimeIndex(['2023-01-01T00:00:00.000000','2023-02T00:00:00.000000','2023-03T23:23:23.000023'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer',yearfirst=True,copy=True))
# print(pandas.DatetimeIndex(['2023-01-01T00:00:00.000000','2023-02T00:00:00.000000','2023-03T23:23:23.000023'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer',yearfirst=True,copy=True,name='DatetimeIndex0'))
# print(pandas.DatetimeIndex(['1/1/2023T00:00:00.000000','2/1/2023T00:00:00.000000','3/1/2023T23:23:23.000023'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer',dayfirst=True,copy=True,name='DatetimeIndex0'))
# print(pandas.DatetimeIndex(['1/1/2023T00:00:00.000000','2/1/2023T00:00:00.000000','3/1/2023T23:23:23.000023'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer',dayfirst=False,copy=True,name='DatetimeIndex0'))
# print(pandas.DatetimeIndex(['1/1/2023T00:00:00.000000','2/1/2023T00:00:00.000000','3/1/2023T23:23:23.000023'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer',yearfirst=True,copy=True,name='DatetimeIndex0'))
# print(pandas.DatetimeIndex(['1/1/2023T00:00:00.000000','2/1/2023T00:00:00.000000','3/1/2023T23:23:23.000023'],freq='infer',tz='EST',normalize=True,closed='left',ambiguous='infer',yearfirst=False,copy=True,name='DatetimeIndex0'))
# print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03']).month_name())
# print(pandas.DatetimeIndex(['2023-01','2023-02','2023-03']).month_name)
# print(dir(pandas.DatetimeIndex(['2023-01','2023-02','2023-03']).month_name))
# for a0 in dir(pandas.DatetimeIndex(['2023-01','2023-02','2023-03']).month_name):
    # print(a0,'      ',getattr(pandas.DatetimeIndex(['2023-01','2023-02','2023-03']).month_name,a0))
# print(str(pandas.DatetimeIndex(['2023-01','2023-02','2023-03']).month_name))
# if '_inherit_from_data.<locals>.method' in repr(pandas.DatetimeIndex(['2023-01','2023-02','2023-03']).to_julian_date):
    # print('1')
# print(pandas.date_range('2023-01','2024-12',freq='M').strftime('%Y%m%d'))
# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T00:00:00.000010',freq='ns'))
# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T00:00:00.000010',freq='ns').snap(freq='S'))
# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T00:00:00.000010',freq='ns').snap(freq='D'))
# print(pandas.date_range('2023-01-01','2023-01-03',freq='D').snap(freq='H'))
# for ambiguous0 in ['infer','NaT','raise',[True,True,True,True,False,False,False]]:
    # try:
        # print(pandas.DatetimeIndex(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00'],ambiguous=ambiguous0).tz_localize('Europe/Warsaw',ambiguous=ambiguous0))#DatetimeIndex ambiguous doesn't work / always raises so must instantiate via other means
    # except Exception as e:
        # print(sys.exc_info())
# for ambiguous0 in ['infer','NaT','raise',[True,True,True,True,False,False,False]]:
    # try:
        # print(pandas.DatetimeIndex(['2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00'],ambiguous=ambiguous0))
    # except Exception as e:
        # print(sys.exc_info())
# for ambiguous0 in ['infer','NaT','raise',[True,True,True,True,False,False,False]]:
    # try:
        # print(pandas.DatetimeIndex(['2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00'],ambiguous=ambiguous0).tz_localize('Europe/Warsaw',ambiguous=ambiguous0))#DatetimeIndex ambiguous doesn't work / always raises so must instantiate via other means
    # except Exception as e:
        # print(sys.exc_info())
# for ambiguous0 in ['infer','NaT','raise',[True,True,True,True,False,False,False]]:
    # try:
        # print(pandas.to_datetime(pandas.Series(['2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00'])).dt.tz_localize('Europe/Warsaw',ambiguous=ambiguous0))
    # except Exception as e:
        # print(sys.exc_info())
# for nonexistent0 in ['shift_forward','shift_backward','NaT',pandas.Timedelta('42H'),'raise']:
    # try:
        # print(pandas.to_datetime(pandas.Series(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00'])).dt.tz_localize('Europe/Warsaw',nonexistent=nonexistent0))
    # except Exception as e:
        # print(sys.exc_info())
# print(pandas.to_datetime(pandas.Series(['2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00'])).dt.tz_localize('Europe/Warsaw',ambiguous='infer').dt.tz_localize(None))
# print(pandas.to_datetime(pandas.Series(['2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00'])).dt.tz_localize('Europe/Warsaw',ambiguous='infer').dt.tz_convert('US/Central'))
# print(pandas.to_datetime(pandas.Series(['2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00'])).dt.tz_localize('Europe/Warsaw',ambiguous='infer').dt.tz_convert(None))
# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T00:00:00.000010',freq='ns').round(freq='S'))
# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T00:00:00.000010',freq='ns').round(freq='D'))
# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T00:00:00.000010',freq='ns').round(freq='H'))
# print(pandas.date_range('2023-01-01','2023-01-03',freq='D').round(freq='H'))
# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T02:00:00.000010',freq='min'))
# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T02:00:00.000010',freq='min').round(freq='H'))
# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T02:00:00.000010',freq='min').round(freq='D'))
# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T02:00:00.000010',freq='min').round(freq='D'))
# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T00:00:00.000010',freq='N').round(freq='H'))
# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T02:00:00.000010',freq='min').snap(freq='H'))
# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T02:00:00.000010',freq='min').snap(freq='D'))
# print(pandas.date_range('2023-01-01T00:00:00.000000','2023-01-01T02:00:00.000010',freq='min').snap(freq='D'))
# for ambiguous0 in ['infer','NaT','raise',[True,True,True,True,False,False,False]]:
    # for nonexistent0 in ['shift_forward','shift_backward','NaT',pandas.Timedelta('42H'),'raise']:
        # print(ambiguous0,nonexistent0,sep='\n')
        # try:
            # print(pandas.to_datetime(pandas.Series(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00','2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00'])).dt.round(freq='H',ambiguous=ambiguous0,nonexistent=nonexistent0))
            # print(pandas.to_datetime(pandas.Series(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00','2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00'])).dt.floor(freq='H',ambiguous=ambiguous0,nonexistent=nonexistent0))
            # print(pandas.to_datetime(pandas.Series(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00','2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00'])).dt.ceil(freq='H',ambiguous=ambiguous0,nonexistent=nonexistent0))
        # except Exception as e:
            # print(sys.exc_info())
        # print('\n')
# print(pandas.date_range('2023-01-01','2023-01-03',freq='D').to_period())
# print(pandas.date_range('2023-01-01','2023-01-03',freq='D').to_period('H'))
# print(pandas.date_range('2023-01-01','2023-01-03',freq='D').to_perioddelta('H'))
# print(pandas.date_range('2023-01-01','2023-01-03',freq='D')-pandas.date_range('2023-01-01','2023-01-03',freq='D').to_period('H').to_timestamp())
# print(pandas.date_range('2023-01-01','2023-02-01',freq='D').to_perioddelta('H'))
# print(pandas.date_range('2023-01-01','2023-02-01',freq='D')-pandas.date_range('2023-01-01','2023-02-01',freq='D').to_period('H').to_timestamp())
# print(pandas.date_range('2023-01-01','2023-02-01',freq='D').to_perioddelta('D'))
# print(pandas.date_range('2023-01-01','2023-02-01',freq='D')-pandas.date_range('2023-01-01','2023-02-01',freq='D').to_period('D').to_timestamp())
# print(pandas.date_range('2023-01-01','2023-02-01',freq='D').to_perioddelta('M'))
# print(pandas.date_range('2023-01-01','2023-02-01',freq='D')-pandas.date_range('2023-01-01','2023-02-01',freq='D').to_period('M').to_timestamp())
# print(pandas.date_range('2023-01-01','2023-02-01',freq='D').to_perioddelta('Y'))
# print(pandas.date_range('2023-01-01','2023-02-01',freq='D')-pandas.date_range('2023-01-01','2023-02-01',freq='D').to_period('Y').to_timestamp())
# print(pandas.date_range('2023-01-01','2023-02-01',freq='D').to_pydatetime())
# print(pandas.date_range('2023-01-01','2023-02-01',freq='H').to_pydatetime())
# print(pandas.date_range('2023-01-01','2023-02-01',freq='D').to_series(index=None,name=None))
# print(pandas.date_range('2023-01-01','2023-02-01',freq='D').to_series(index=numpy.arange(pandas.date_range('2023-01-01','2023-02-01',freq='D').size),name='to_series0withIndexDifferent0'))
# print(pandas.date_range('2023-01-01','2023-02-01',freq='D').to_frame())
# print(pandas.date_range('2023-01-01','2023-02-01',freq='D').to_frame(index=True,name=None))
# print(pandas.date_range('2023-01-01','2023-02-01',freq='D').to_frame(index=False,name='to_frame0withIndexDifferent0'))
# try:
    # print(pandas.TimedeltaIndex(['2 days','2 days'],unit='D',freq='infer',copy=True,name='TimedeltaIndex0'))
# except Exception as e:
    # print(e)
# print(pandas.TimedeltaIndex(['2 days','2 days'],freq='infer',copy=True,name='TimedeltaIndex0'))
# print(pandas.TimedeltaIndex(['2 days','2 days'],freq='infer',copy=True,name='TimedeltaIndex0')+pandas.period_range('2023-01-01','2023-01-02',freq='D'))
# try:
    # print(pandas.Timedelta('2',unit='D'))
# except Exception as e:
    # print(e)
# print(pandas.Timedelta(2,unit='D'))
# print(pandas.Timedelta(3,unit='h'))
# print(pandas.Timedelta(4,unit='s'))
# print(pandas.Timedelta(4,unit='ms'))
# print(pandas.Timedelta(4,unit='us'))
# print(pandas.Timedelta(4,unit='ns'))
# print(pandas.Timedelta(weeks=4,days=4,hours=4,minutes=4,seconds=4,milliseconds=4,microseconds=4,nanoseconds=4))
# print(type(pandas.DataFrame({'a':[1,2],'b':[2,3]})['a']))
# print(type(pandas.to_datetime(500)))
# print(type(pandas.to_datetime(pandas.to_datetime('2023-01-01').to_numpy())))
# # print(type(pandas.to_datetime(pandas.DataFrame({'year':[2022,2023],'month':[2,3]}).to_numpy())))
# try:
    # print(type(pandas.to_datetime(pandas.DataFrame({'year':[2022,2023],'month':[2,3]}))))
# except Exception as e:
    # print(e)
# print(type(pandas.to_datetime(pandas.DataFrame({'year':[2022,2023],'month':[2,3],'day':[23,24]}))))
# print(type(pandas.to_datetime(pandas.DataFrame({'year':[2022,2023],'month':[2,3],'day':[23,24]})['year'])))
# print(type(pandas.to_datetime(pandas.DataFrame({'year':[2022,2023],'month':[2,3],'day':[23,24],'hour':[5,6],'minute':[1,2],'second':[1,2],'millisecond':[1,2],'microsecond':[1,2],'nanosecond':[1,2]}))))
# print(pandas.to_datetime(pandas.DataFrame({'year':[2022,2023],'month':[2,3],'day':[23,24],'hour':[5,6],'minute':[1,2],'second':[1,2],'millisecond':[1,2],'microsecond':[1,2],'nanosecond':[1,2]})))
# print(pandas.to_datetime(pandas.date_range('2023-01-01','2023-01-05',freq='D')))
# for errors0 in ['raise','coerce','ignore']:
    # print(errors0)
    # try:
        # print(pandas.to_datetime(pandas.Series(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00','2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00','1300-03-27T01:20:00 -0500','1300-03-27T01:20:00','13000301','919191','11/12/11',1490000000,1490000000000000]),errors=errors0))#if part of larger, takes most loose which is 'ignore' (rather than 'coerce')
        # print(pandas.to_datetime('919191',errors=errors0))#if alone, same rule applies (this time taking 'coerce')
    # except Exception as e:
        # print(sys.exc_info())
    # print('\n')
# for dayfirst0 in [False,True]:
    # print(dayfirst0)
    # try:
        # print(pandas.to_datetime(pandas.Series(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00','2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00','1300-03-27T01:20:00 -0500','1300-03-27T01:20:00','13000301','919191','11/12/11',1490000000,1490000000000000]),errors='ignore',dayfirst=dayfirst0))
        # print(pandas.to_datetime('11/12/11',dayfirst=dayfirst0))
    # except Exception as e:
        # print(sys.exc_info())
    # print('\n')
# for yearfirst0 in [False,True]:
    # print(yearfirst0)
    # try:
        # print(pandas.to_datetime(pandas.Series(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00','2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00','1300-03-27T01:20:00 -0500','1300-03-27T01:20:00','13000301','919191','11/12/11',1490000000,1490000000000000]),errors='ignore',yearfirst=yearfirst0))
        # print(pandas.to_datetime('11/12/11',yearfirst=yearfirst0))
    # except Exception as e:
        # print(sys.exc_info())
    # print('\n')
# for utc0 in [False,True]:
    # print(utc0)
    # try:
        # print(pandas.to_datetime(pandas.Series(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00','2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00','2018-03-27T01:20:00 -0500','2018-03-27T01:20:00']),errors='ignore',utc=utc0))
        # print(pandas.to_datetime('11/12/11',utc=utc0))
    # except Exception as e:
        # print(sys.exc_info())
    # print('\n')
# for infer_datetime_format0 in [False,True]:
    # print('infer_datetime_format0',infer_datetime_format0)
    # try:
        # print(pandas.to_datetime(pandas.Series(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00','2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00','2018-03-27T01:20:00 -0500','2018-03-27T01:20:00']),errors='ignore',infer_datetime_format=infer_datetime_format0))
        # print(timeit.repeat('''pandas.to_datetime(pandas.Series(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00','2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00','2018-03-27T01:20:00 -0500','2018-03-27T01:20:00']),errors='ignore',infer_datetime_format=infer_datetime_format0)''',repeat=3,number=100,globals=globals()))
        # print(pandas.to_datetime(pandas.Series(['2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00']),errors='ignore',infer_datetime_format=infer_datetime_format0))
        # print(timeit.repeat('''pandas.to_datetime(pandas.Series(['2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00']),errors='ignore',infer_datetime_format=infer_datetime_format0)''',repeat=3,number=100,globals=globals()))#unless you have a lot (100000+ ?), then usually 'False' (the default) is quickest and best
    # except Exception as e:
        # print(sys.exc_info())
    # print('\n')
# for origin0 in ['unix','julian']:
    # print('origin0',origin0)
    # try:
        # # print(pandas.to_datetime(pandas.Series(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00','2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00','2018-03-27T01:20:00 -0500','2018-03-27T01:20:00']),errors='ignore',origin=origin0))
        # try:
            # print(pandas.to_datetime(pandas.Series([1490000000,1490000000000000]),errors='coerce',unit='D',origin=origin0))
        # except Exception as e:
            # print(e)
        # try:
            # print(pandas.to_datetime(1490000000,errors='ignore',unit='D',origin=origin0))
        # except Exception as e:
            # print(e)
        # try:
            # print(pandas.to_datetime(1490000000000000,errors='ignore',unit='D',origin=origin0))
        # except Exception as e:
            # print(e)
        # print(pandas.to_datetime(10,errors='ignore',unit='D',origin=origin0))
        # print(pandas.to_datetime(365*6000,errors='ignore',unit='D',origin=origin0))
    # except Exception as e:
        # print(sys.exc_info())
    # print('\n')
# for format0 in ['%y%m%d','%d%m%y']:
    # for exact0 in [True,False]:
        # print('format0,exact0',format0,exact0)
        # try:
            # print(pandas.to_datetime(pandas.Series(['101112',' 101112','101112 ']),errors='ignore',format=format0,exact=exact0))
        # except Exception as e:
            # print(sys.exc_info())
        # print('\n')
# for cache0 in [True,False]:
    # print('cache0',cache0)
    # try:
        # print(pandas.to_datetime(pandas.Series(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00','2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00','2018-03-27T01:20:00 -0500','2018-03-27T01:20:00']),errors='ignore',cache=cache0))
        # print(timeit.repeat('''pandas.to_datetime(pandas.Series(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00','2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00','2018-03-27T01:20:00 -0500','2018-03-27T01:20:00']),errors='ignore',cache=cache0)''',repeat=3,number=100,globals=globals()))
    # except Exception as e:
        # print(sys.exc_info())
    # print('\n')
# print(pandas.to_datetime(pandas.Series(['2015-03-29T01:20:00','2015-03-29T01:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T02:20:00','2015-03-29T02:40:00','2015-03-29T03:20:00','2018-10-28T01:20:00','2018-10-28T01:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T02:20:00','2018-10-28T02:40:00','2018-10-28T03:20:00',numpy.nan,'2018-03-27T01:20:00']),errors='ignore',cache=cache0))
# print(pandas.to_datetime([223453.5,223454.5,223455.5],unit='D',origin='julian'))#must be within 1900-20* range?
# print(pandas.to_datetime([2458347.2,2458347.5,2458347.9],unit='D',origin='julian'))
# print(pandas.Series(pandas.date_range("2000-01-01", periods=3, freq="q")))
# print(pandas.Series(pandas.date_range("2000-01-01", periods=3, freq="q")).dt)
# print(type(pandas.Series(pandas.date_range("2000-01-01", periods=3, freq="q")).dt))
# print(pandas.Series(pandas.date_range("2000-01-01", periods=3, freq="q")).dt.quarter)
# print(pandas.Series(pandas.date_range("2000-01-01", periods=3, freq="q")).dt.tz_localize('UTC',nonexistent='NaT',ambiguous='infer'))
# print(pandas.Series(pandas.date_range("2000-01-01", periods=3, freq="q")).dt.tz_localize('US/Eastern',nonexistent='NaT',ambiguous='infer'))
# print(pandas.to_timedelta(2,'d'))
# print(pandas.to_timedelta(2))
# print(pandas.to_timedelta([2,3,4],'d'))
# print(pandas.to_timedelta(['1ns','2us','2ms'],errors='coerce'))
# print(pandas.to_timedelta(['1 days','2 dayss'],errors='coerce'))
# print(pandas.to_timedelta(['1 days','2 dayss'],errors='ignore'))
# try:
    # print(pandas.to_timedelta(['1 days','2 dayss']))
# except Exception as e:
    # print(e)
# print(pandas.DataFrame({'filename0':['bgp','bgp','bep'],'data0':[1,2,3]}))
# print(pandas.DataFrame({'filename0':['bgp','bgp','bep'],'data0':[1,2,3]})['filename0'].str.contains('bgp'))
# print(pandas.DataFrame({'filename0':['bgp','bgp','bep'],'data0':[1,2,3]})['filename0'][pandas.DataFrame({'filename0':['bgp','bgp','bep'],'data0':[1,2,3]})['filename0'].str.contains('bgp')])
# df0=pandas.DataFrame({'filename0':['bgp','bgp','bep'],'data0':[1,2,3]})
# df0['filename0'][df0['filename0'].str.contains('bgp')]='BGP'
# print(df0)
# print(pandas.Series([]))
# print(pandas.Series([]).empty)
# print(pandas.Series([]).any())
# print(pandas.Series([]).all())
# print(pandas.Timestamp(pandas.NaT))
# print(pandas.Timedelta(pandas.NaT))
# print(pandas.Period(pandas.NaT))
# try:
    # print(pandas.tseries.offsets.DateOffset(pandas.NaT))
# except Exception as e:
    # print(e)
# print(pandas.tseries.offsets.DateOffset(2))
# print(pandas.NaT==pandas.NaT)
# print(pandas.Timestamp(datetime.datetime.today()))
# print(pandas.Timestamp('2023-02-27T10:12:59.050505'))
# print(pandas.Timestamp(2023,2,27,10,12,59,5,5))
# print(pandas.Timestamp(datetime.datetime.today(),tz='US/Central'))
# print(pandas.Timestamp(datetime.datetime.today(),tzinfo=datetime.timezone.utc))
# print(pandas.Timestamp(datetime.datetime.today(),tz=datetime.timezone.utc))
# print(pandas.Timestamp(datetime.datetime.today(),freq='D'))
# print(pandas.Timestamp(datetime.datetime.today(),unit='D'))
# print(pandas.Timestamp(149,freq='D'))
# print(pandas.Timestamp(149,freq='s'))
# print(pandas.Timestamp(149,unit='D'))
# print(pandas.Timestamp(149,unit='s'))
# try:
    # print(pandas.Timestamp('2018-10-28T02:20:00',fold=0))
# except Exception as e:
    # print(e)
# try:
    # print(pandas.Timestamp(2018,10,28,2,20,fold=0))
# except Exception as e:
    # print(e)
# print(pandas.Timestamp(datetime.datetime(2018,10,28,2,20),fold=0))
# print(pandas.Timestamp(datetime.datetime(2018,10,28,2,20),fold=1))
# print(pandas.Timestamp(datetime.datetime.today(),tz='Asia/Tokyo'))
# print(pandas.Timestamp(datetime.datetime.today(),tz='UTC').astimezone('Asia/Tokyo'))
# print(pandas.Timestamp(datetime.datetime.today(),tz='US/Central'))
# print(pandas.Timestamp(datetime.datetime.today(),tz='US/Central').astimezone('Asia/Tokyo'))
# for ambiguous0 in ['infer','NaT','raise',True,False]:
    # for nonexistent0 in ['shift_forward','shift_backward','NaT',pandas.Timedelta('42H'),'raise']:
        # print('ambiguous0,nonexistent0',ambiguous0,nonexistent0,sep='\n')
        # try:
            # print(pandas.Timestamp('2018-10-28T02:20:00').round(freq='H',ambiguous=ambiguous0,nonexistent=nonexistent0))
            # print(pandas.Timestamp('2015-03-29T01:20:00').round(freq='H',ambiguous=ambiguous0,nonexistent=nonexistent0))
            # print(pandas.Timestamp('2018-10-28T02:20:00').ceil(freq='H',ambiguous=ambiguous0,nonexistent=nonexistent0))
            # print(pandas.Timestamp('2015-03-29T01:20:00').ceil(freq='H',ambiguous=ambiguous0,nonexistent=nonexistent0))
            # print(pandas.Timestamp('2018-10-28T02:20:00').floor(freq='H',ambiguous=ambiguous0,nonexistent=nonexistent0))
            # print(pandas.Timestamp('2015-03-29T01:20:00').floor(freq='H',ambiguous=ambiguous0,nonexistent=nonexistent0))
        # except Exception as e:
            # print(sys.exc_info())
        # print('\n')
# print(pandas.Timestamp(datetime.datetime.today(),tz='US/Central').combine(datetime.date(2023,2,27),datetime.time(10,59,59)))
# print(pandas.Timestamp(datetime.datetime.today(),tz='US/Central').replace(2001,10,11))
# print(pandas.Timestamp(datetime.datetime.today(),tz='US/Central').replace(2001,10,11,tzinfo=pytz.timezone('US/Eastern')))
# print(time.time())
# print(pandas.to_datetime(time.time()))
# print(pandas.to_datetime(time.time(),unit='ms'))
# print(pandas.to_datetime(time.time(),unit='s'))
# print(pandas.Timestamp(time.time(),unit='s'))
# print(pandas.Timestamp(time.time(),unit='s',tz='US/Central'))
# print(pandas.DatetimeIndex([time.time()],tz='US/Central'))
# print(pandas.DatetimeIndex([pandas.Timestamp(time.time(),unit='s')],tz='US/Central'))
# try:
    # print(pandas.DatetimeIndex(time.time(),unit='s',tz='US/Central'))
# except Exception as e:
    # print(e)
# print(pandas.Timestamp(time.time(),unit='s').tz_localize('US/Central'))
# print(pandas.to_datetime(1490195805.433502912,unit='s'))
# print(pandas.to_datetime(1490195805433502912,unit='ns'))
# print((pandas.to_datetime(['2012-10-08 18:15:05', '2012-10-09 18:15:05', '2012-10-10 18:15:05', '2012-10-11 18:15:05'])-pandas.to_datetime('1970-01-01T00:00:00'))//pandas.Timedelta('1s'))
# print(pandas.to_datetime([1349720105, 1349806505, 1349892905, 1349979305],unit='s'))
# print(pandas.to_datetime([1,3,5,7],unit='D',origin='unix'))
# try:
    # print(pandas.to_datetime([1,3,5,7],unit='D',origin='julian'))
# except Exception as e:
    # print(e)
# print(pandas.to_datetime([1,3,5,7],unit='D',origin=pandas.Timestamp('1950-01-01')))
# print(pandas.Series([1,11,21],[pandas.Timestamp('2023-01'),pandas.Timestamp('2023-02'),pandas.Timestamp('2023-03')]))
# print(pandas.Series([1,11,21],[pandas.Timestamp('2023-01'),pandas.Timestamp('2023-02'),pandas.Timestamp('2023-03')]).index)
# print(pandas.Series([1,11,21],[pandas.Period('2023-01'),pandas.Period('2023-02'),pandas.Period('2023-03')]))
# print(pandas.Series([1,11,21],pandas.Index(['2023-01','2023-02','2023-03'])))
# print(pandas.Series([1,11,21],pandas.Index(['2023-01','2023-02','2023-03'])).index)
# print(pandas.Series([1,11,21],pandas.Index([datetime.datetime(2023,1,1),datetime.datetime(2023,2,1),datetime.datetime(2023,3,1)])))
# print(pandas.Series([1,11,21],pandas.Index([datetime.datetime(2023,1,1),datetime.datetime(2023,2,1),datetime.datetime(2023,3,1)])).index)
# print(pandas.tseries.holiday)
# print(dir(pandas.tseries.holiday))
# for inclusive0 in ['both','left','right','neither']:
    # print('inclusive0',inclusive0)
    # # print(pandas.bdate_range(start='2023-01-01',end='2023-12-31',freq='B',name='bdate_range0',inclusive=inclusive0,weekmask='1111000',holidays=pandas.tseries.holiday.USFederalHolidayCalendar().holidays(start='2023-01-01',end='2023-12-31')))
    # print(pandas.bdate_range(start='2023-01-01',end='2023-12-31',freq='C',name='bdate_range0',inclusive=inclusive0,weekmask='1111000',holidays=pandas.tseries.holiday.USFederalHolidayCalendar().holidays(start='2023-01-01',end='2023-12-31')))
    # # print(pandas.bdate_range(start='2023-01-01',end='2023-12-31',freq='B',name='bdate_range0',inclusive=inclusive0,weekmask='1111000'))
    # print(pandas.bdate_range(start='2023-01-01',end='2023-12-31',freq='C',name='bdate_range0',inclusive=inclusive0,weekmask='1111000'))
    # # print(pandas.bdate_range(start='2023-01-01',end='2023-12-31',periods=20,name='bdate_range0',inclusive=inclusive0,weekmask='1111000'))
    # print(pandas.bdate_range(start='2023-01-01',end='2023-12-31',freq='D'))
    # print('\n')
# print(pandas.bdate_range(start='2023-01-01',end='2023-01-31',freq='C',tz='Europe/London',normalize=True,name='bdate_range1',holidays=pandas.tseries.holiday.USFederalHolidayCalendar().holidays(start='2023-01-01',end='2023-12-31')))
# print(pandas.bdate_range(start='2023-01-01',end='2023-01-31',freq='C',tz='Europe/Paris',normalize=True,name='bdate_range1',holidays=pandas.tseries.holiday.USFederalHolidayCalendar().holidays(start='2023-01-01',end='2023-12-31')))
# print(pandas.bdate_range(start='2023-01-01',end='2023-01-31',freq='C',tz='Europe/Paris',normalize=True,name='bdate_range1',holidays=pandas.tseries.holiday.USFederalHolidayCalendar().holidays(start='2023-01-01',end='2023-12-31'),closed='right'))
# # print(pandas.bdate_range(start='2023-01-01',end='2023-01-31',freq='CH',tz='Europe/Paris',normalize=True,name='bdate_rangeCBH',holidays=pandas.tseries.holiday.USFederalHolidayCalendar().holidays(start='2023-01-01',end='2023-12-31')))#normalize would only work if you built your own custom business hour frequency..
# print(pandas.bdate_range(start='2023-01-01',periods=5,freq='CBMS',name='bdate_rangeCBMS',weekmask='1000000'))
# print(pandas.DataFrame({'c0':numpy.arange(30),'c1':numpy.arange(30,60,1)},pandas.date_range(start='2023-01-01',periods=30,freq='12H')))
# print(pandas.DataFrame({'c0':numpy.arange(30),'c1':numpy.arange(30,60,1)},pandas.date_range(start='2023-01-01',periods=30,freq='12H')).asof('2023-01-04T09:00:00'))
# df0=pandas.DataFrame({'c0':numpy.arange(30),'c1':numpy.arange(30,60,1)},pandas.date_range(start='2023-01-01',periods=30,freq='12H'))
# df0.iloc[6,1]=numpy.nan
# print(df0)
# print(df0.asof('2023-01-04T09:00:00'))
# print(df0.asof('2023-01-04T09:00:00',subset='c1'))
# print(df0.asof('2023-01-04T09:00:00',subset='c0'))
# print(df0['c1'].asof('2023-01-04T09:00:00'))
# print(df0['c0'].asof('2023-01-04T09:00:00'))
# print(df0['2023-01-10':'2023-01-13'])
# print(df0['2023-01-10T00:00:00':'2023-01-13T00:13:00'])
# print(df0['2023-01-10T00:00:00':'2023-01-13T13:00:00'])
# print(df0.loc['2023-01-10T00:00:00'])
# print(df0['c0']['2023-01-10T00:00:00'])
# df0=pandas.DataFrame({'c0':numpy.arange(30),'c1':numpy.arange(30,60,1)},pandas.MultiIndex.from_product([pandas.date_range(start='2023-01-01',periods=15,freq='12H'),['1st6Hours','2nd6Hours']]))
# print(df0)
# print(df0.loc[('2023-01-05','1st6Hours')])
# print(df0.loc[('2023-01-05','2nd6Hours')])
# print(df0.loc[pandas.IndexSlice['2023-01-05',:]])
# print(df0.loc[pandas.IndexSlice[:,:]])
# # print(df0.loc[pandas.IndexSlice[:,'2nd6Hours']])#this will error; below won't; reason is you have to specify ''',:]''' to end to avoid ambiguity / having system guess whether IndexSlice is referring to 1st part or 1st,2nd parts of [1st,2nd]
# print(df0.loc[pandas.IndexSlice[:,'2nd6Hours'],:])
# df0=pandas.DataFrame({'c0':numpy.arange(30),'c1':numpy.arange(30,60,1)},pandas.date_range(start='2023-01-01',periods=30,freq='12H',tz='US/Central'))
# print(df0)
# print(df0.loc['2023-01-05T01:00:00-05:00'])
# print(df0.loc['2023-01-05T01:00:00-05:00':])
# print(df0.loc['2023-01-05T05:00:00-05:00':])

# s0 = pandas.Series(
    # [1, 2, 3],
    # pd.DatetimeIndex(
        # ["2011-12-31 23:59:00", "2012-01-01 00:00:00", "2012-01-01 00:02:00"]
    # ),
# )
# # print(s0.index.resolution)
# # print(s0['2011-12-31 23'])
# # print(s0['2011-12-31 23:59'])
# # print(s0['2011-12-31 23:59:00'])
# # s0 = pandas.Series(
    # # [1, 2, 3],
    # # pd.DatetimeIndex(
        # # ["2011-12", "2012-01","2012-02"]
    # # ),
# # )
# # print(s0.index.resolution)
# # print(s0['2012-01-01'])
# # print(s0['2012-01'])
# # print(s0['2012'])
# print(s0[pandas.Timestamp('2012')])
# print(s0[pandas.Timestamp('2012-01')])
# print(s0[pandas.Timestamp('2012-01-01')])
# try:
    # print(s0[datetime.datetime(2012,1)])
# except Exception as e:
    # print(e)
# print(s0[datetime.datetime(2012,1,1)])

# df0=pandas.DataFrame({'c0':numpy.arange(30),'c1':numpy.arange(30,60,1),'c2':numpy.arange(60,90,1)},pandas.date_range(start='2023-01-01',periods=30,freq='4H',tz='US/Central'))
# df0=pandas.DataFrame({'c0':numpy.arange(30),'c1':numpy.arange(30,60,1),'c2':numpy.arange(60,90,1)},pandas.date_range(start='2023-01-01',periods=30,freq='4H'))
# df1=pandas.DataFrame({'c0':numpy.arange(30),'c1':numpy.arange(30,60,1),'c2':pandas.date_range(start='2023-01-01',periods=30,freq='4H')})
# df2=pandas.DataFrame({'c0':numpy.arange(30),'c1':numpy.arange(30,60,1),'c2':pandas.timedelta_range(start='3 minutes',periods=30,freq='1 min')})
# print(df0.truncate())
# print(df0.truncate(before='c0',after='c0',axis=1,copy=True))
# print(df0.truncate(before='c1',after='c2',axis=1,copy=False))
# print(df0.truncate(before='c1',after='c2',axis=1,copy=False).to_numpy().base)
# print(df0.truncate(before='2023-01-02',after='2023-01-03',axis=0,copy=True))
# print(df0['c0'].truncate(before='2023-01-02',after='2023-01-03',axis=0,copy=True))
# print(df0['c0'].truncate(before='2023-01-02T00:00:00',after='2023-01-03T04:00:00',axis=0,copy=True))
# print(df0['c0'].loc['2023-01-02':'2023-01-03'])
# print(df0['c0'].tz_localize('US/Central'))
# try:
    # print(df1['c2'].tz_localize('US/Central'))
# except Exception as e:
    # print(e)
# print(df1['c2'].dt.tz_localize('US/Central'))
# try:
    # print(df1.dt.tz_localize('US/Central'))
# except Exception as e:
    # print(e)
# try:
    # print(df1['c2'].dt.components)
# except Exception as e:
    # print(e)
# print(df1['c2'].dt.year)
# print(df1['c2'].dt.day)
# print(df1['c2'].dt.hour)
# print(df1['c2'].dt.isocalendar())
# print(dir(df1['c2'].dt))
# print(df1['c2'].dt.strftime('%Y%m%d%H%M%S%%f'))
# print(df1['c2'].dt.strftime('%Y%m%d%H%M%S%f'))
# print(df2['c2'].dt.components)

# print(pandas.tseries.offsets.BusinessHour(start='09:00').rollforward(pandas.Timestamp('2023-02-25T00:00:00')))
# print(pandas.tseries.offsets.BusinessHour(start='09:00')+pandas.Timestamp('2023-02-25T00:00:00'))
# print(pandas.tseries.offsets.BusinessHour(2,start='09:00')+pandas.Timestamp('2023-02-25T00:00:00'))

# df2=pandas.DataFrame({'c0':numpy.arange(30),'c1':numpy.arange(30,60,1),'c2':pandas.timedelta_range(start='3 minutes',periods=30,freq='1 min')})
# df3=pandas.DataFrame({'c2':pandas.timedelta_range(start='3 minutes',periods=30,freq='1 min'),'c3':pandas.timedelta_range(start='4 minutes',periods=30,freq='1 min')})
# print(pandas.date_range(start='2023-03-01',periods=30,freq='D'))
# print(pandas.date_range(start='2023-03-03',periods=30,freq='D'))
# # df4=pandas.DataFrame({'c2':pandas.date_range(start=pandas.Timestamp('2023-03=01'),periods=30,freq='D'),'c3':pandas.date_range(start=pandas.Timestamp('2023-03=03'),periods=30,freq='D')})
# df4=pandas.DataFrame({'c2':pandas.date_range(start='2023-03-01',periods=30,freq='D'),'c3':pandas.date_range(start='2023-03-03',periods=30,freq='D')})
# print(df4)
# s0=df2['c2']
# print(s0)
# print(pandas.tseries.offsets.Hour(2)+s0)
# print(pandas.tseries.offsets.Hour(2)+-s0)
# print(s0-pandas.tseries.offsets.Minute(1))
# print(df3-pandas.tseries.offsets.Minute(1))
# print(df4['c3']-df4['c2'])
# print(df4['c3']-df4['c2']+s0)
# print(pandas.date_range('2023-03-01','2023-03-05',freq='D')+pandas.tseries.offsets.CustomBusinessDay(holidays=['2023-03-02'],weekmask='1101101'))
# print(pandas.Series(pandas.date_range('2023-03-01','2023-03-05',freq='D').weekday,pandas.date_range('2023-03-01','2023-03-05',freq='D')))
# print(pandas.Series(pandas.date_range('2023-03-01','2023-03-05',freq='D').weekday,pandas.date_range('2023-03-01','2023-03-05',freq='D')).map(pandas.Series('Mon Tue Wed Thu Fri Sat Sun'.split())))
# customBusinessDay0=pandas.tseries.offsets.CustomBusinessDay(holidays=['2023-03-02'],weekmask='1101101')
# print(pandas.Series(pandas.date_range('2023-03-01','2023-03-05',freq=customBusinessDay0).weekday,pandas.date_range('2023-03-01','2023-03-05',freq=customBusinessDay0)))
# print(pandas.Series(pandas.date_range('2023-03-01','2023-03-05',freq=customBusinessDay0).weekday,pandas.date_range('2023-03-01','2023-03-05',freq=customBusinessDay0)).map(pandas.Series('Mon Tue Wed Thu Fri Sat Sun'.split())))
# print(pandas.Series(pandas.date_range('2023-03-01',periods=5,freq=customBusinessDay0).weekday,pandas.date_range('2023-03-01',periods=5,freq=customBusinessDay0)))
# print(pandas.Series(pandas.date_range('2023-03-01',periods=5,freq=customBusinessDay0).weekday,pandas.date_range('2023-03-01',periods=5,freq=customBusinessDay0)).map(pandas.Series('Mon Tue Wed Thu Fri Sat Sun'.split())))
# print(pandas.Timestamp('2023-12-15')+pandas.tseries.offsets.CustomBusinessMonthBegin(calendar=pandas.tseries.holiday.USFederalHolidayCalendar()))
# print(pandas.Timestamp('2023-03-01T15:30:00')+pandas.tseries.offsets.BusinessHour(1))
# print(pandas.Timestamp('2023-03-01T16:30:00')+pandas.tseries.offsets.BusinessHour(1))
# print(pandas.Timestamp('2023-03-01T16:30:00')+pandas.tseries.offsets.BusinessHour(1))
# print(pandas.Timestamp('2023-03-01T16:30:00')+pandas.tseries.offsets.BusinessHour(2))
# try:
    # customBusinessHour0=pandas.tseries.offsets.CustomBusinessHour(start='20:00:00',end='05:00:00')
# except Exception as e:
    # print(e)
# customBusinessHour0=pandas.tseries.offsets.CustomBusinessHour(start='20:00',end='05:00')
# print(customBusinessHour0)
# print(pandas.date_range('2023-03-03T17:00:00',freq='4H',periods=7))
# print(pandas.date_range('2023-03-03T17:00:00',freq='4H',periods=7)+customBusinessHour0)
# print(pandas.date_range('2023-03-15','2023-05-20',freq='BMS')+customBusinessHour0)
# print(pandas.date_range('2023-03-15','2023-05-20',freq='W'))
# print(pandas.date_range('2023-03-15','2023-05-20',freq='W-SUN'))
# print(pandas.date_range('2023-03-15','2023-05-20',freq='W-SAT'))
# print(pandas.date_range('2023-03-15','2023-05-20',freq='BQS'))
# print(pandas.date_range('2023-03-15','2023-05-20',freq='Q'))
# print(pandas.date_range('2023-03-15','2023-05-20',freq='Q-DEC'))
# print(pandas.date_range('2023-03-15','2023-05-20',freq='Q-MAR'))
# class calendar0(pandas.tseries.holiday.AbstractHolidayCalendar):
    # rules=[
        # pandas.tseries.holiday.Holiday('July 4th',month=7,day=4,observance=pandas.tseries.holiday.nearest_workday)
    # ]
# calendar0instance0=calendar0()
# print(pandas.Timestamp('2023-07-03T10:00')+pandas.tseries.offsets.CustomBusinessDay(holidays=calendar0instance0.holidays()))
# print(pandas.Timestamp('2023-07-03T10:00')+pandas.tseries.offsets.CustomBusinessDay(calendar=calendar0instance0))
# print(calendar0instance0.holidays())
# calendar0.start_date='2023-01-01'
# calendar0.end_date='2023-12-31'
# # pandas.tseries.holiday.AbstractHolidayCalendar.start_date=datetime.datetime(2023,1,1)
# # pandas.tseries.holiday.AbstractHolidayCalendar.end_date=datetime.datetime(2023,12,31)
# pandas.tseries.holiday.AbstractHolidayCalendar.start_date='2023-01-01'
# pandas.tseries.holiday.AbstractHolidayCalendar.end_date='2023-12-31'
# # calendar0instance0=calendar0()
# print(calendar0instance0.holidays())
# print(pandas.date_range('2023-07-03','2023-07-05',freq=pandas.offsets.CDay(calendar=calendar0instance0)).to_series())
# class calendar1(pandas.tseries.holiday.AbstractHolidayCalendar):
    # rules=[
        # pandas.tseries.holiday.Holiday('July 5th',month=7,day=5,observance=pandas.tseries.holiday.next_monday),
        # pandas.tseries.holiday.Holiday('July 6th',month=7,day=6,observance=pandas.tseries.holiday.previous_friday),
        # pandas.tseries.holiday.Holiday('July 7th',month=7,day=7,observance=pandas.tseries.holiday.next_monday_or_tuesday),
        # pandas.tseries.holiday.Holiday('July 8th',month=7,day=8,observance=pandas.tseries.holiday.sunday_to_monday)
    # ]
# # uUSFederalHolidayCalendar0instance0=pandas.tseries.holiday.get_calendar(pandas.tseries.holiday.USFederalHolidayCalendar)
# uUSFederalHolidayCalendar0instance0=pandas.tseries.holiday.get_calendar("USFederalHolidayCalendar")
# ucalendar10instance0=pandas.tseries.holiday.get_calendar("calendar1")
# print(uUSFederalHolidayCalendar0instance0.rules)
# print(ucalendar10instance0.rules)
# calendar2instance0=pandas.tseries.holiday.HolidayCalendarFactory("calendar2",ucalendar10instance0,pandas.tseries.holiday.USFederalHolidayCalendar().holidays())
# print(calendar2instance0.rules)
# calendar2instance0=pandas.tseries.holiday.HolidayCalendarFactory("calendar2",ucalendar10instance0,pandas.tseries.holiday.USFederalHolidayCalendar().rules)
# print(calendar2instance0.rules)
# print(pandas.date_range('2023-01-01','2023-04-01',freq='D'))
# for freq0 in ['D','B','MS','BQ']:
    # print(freq0)
    # print(pandas.date_range('2023-01-01','2023-04-01',freq='D').shift(7,freq=freq0))
    # print('\n')
# df0=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(30,30)))
# print(df0)
# for col0 in df0:
    # sampled0Index0=df0.sample(frac=.4,random_state=8).index
    # df0.loc[sampled0Index0,col0]=numpy.nan
# print(df0)
# for method0 in ['pad','ffill','backfill','bfill','nearest','zero','index','values','time','linear','slinear','barycentric','krogh','akima','quadratic','cubic','polynomial','spline','cubicspline','pchip']:
    # print(method0)
    # print(df0)
    # try:
        # print(df0.interpolate(method=method0))
    # except Exception as e:
        # print(e)
        # try:
            # print(df0.interpolate(method=method0,order=3))
        # except Exception as e:
            # print(e)
    # try:
        # print(df0[0].interpolate(method=method0))
    # except Exception as e:
        # print(e)
        # try:
            # print(df0[0].interpolate(method=method0,order=2))
        # except Exception as e:
            # print(e)
# df0=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(30,30)),index=pandas.date_range('2023-01-01',periods=30,freq='W'))
# print(df0)
# for col0 in df0:
    # sampled0Index0=df0.sample(frac=.4,random_state=8).index
    # df0.loc[sampled0Index0,col0]=numpy.nan
# print(df0)
# for method0 in ['pad','ffill','backfill','bfill','nearest','zero','index','values','time','linear','slinear','barycentric','krogh','akima','quadratic','cubic','polynomial','spline','cubicspline','pchip','piecewise_polynomial','from_derivatives']:
    # print(method0)
    # print(df0)
    # try:
        # print(df0.interpolate(method=method0))
    # except Exception as e:
        # print(e)
        # try:
            # print(df0.interpolate(method=method0,order=3))
        # except Exception as e:
            # print(e)
    # try:
        # print(df0[0].interpolate(method=method0))
    # except Exception as e:
        # print(e)
        # try:
            # print(df0[0].interpolate(method=method0,order=2))
        # except Exception as e:
            # print(e)
# df0=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(30,30)))
# print(df0)
# for col0 in df0:
    # sampled0Index0=df0.sample(frac=.4,random_state=8).index
    # df0.loc[sampled0Index0,col0]=numpy.nan
# print(df0)
# for method0 in ['linear']:
    # for limit0 in [1,2]:
        # for limit_area0 in ['inside','outside',None]:
            # for limit_direction0 in ['forward','backward','both']:
                # for downcast0 in ['infer',None]:
                    # print('method0,limit0,limit_area0,limit_direction0,downcast0',method0,limit0,limit_area0,limit_direction0,downcast0)
                    # print(df0)
                    # try:
                        # print(df0.interpolate(method=method0,limit=limit0,limit_area=limit_area0,limit_direction=limit_direction0,downcast=downcast0))
                    # except Exception as e:
                        # print(e)
                    # try:
                        # print(df0[0].interpolate(method=method0,limit=limit0,limit_area=limit_area0,limit_direction=limit_direction0,downcast=downcast0))
                    # except Exception as e:
                        # print(e)
# df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(10,10)))
# df1.iloc[:,[4,6,7]]=numpy.nan
# print(df1)
# print(df1.interpolate(axis=1,limit=1))
# print(df1.interpolate(axis=1))
# df0=pandas.DataFrame(numpy.array([numpy.random.default_rng(8).integers(-10,20,(20,)),numpy.random.default_rng(7).integers(-10,20,(20,)),numpy.random.default_rng(6).integers(-10,20,(20,)),numpy.random.default_rng(5).integers(-10,20,(20,))]).T,columns=['col0','col1','col2','col3'])
# print(df0)
# print(df0.rename(mapper=str.title,axis=1))
# print(df0.rename(mapper=str.upper,axis=1))
# # # print(df0.rename(index=dict(map(df0.index,numpy.arange(19,0,-1)))))
# print(df0.rename(index=dict(zip(df0.index,numpy.arange(19,0,-1)))))
# print(df0.rename(index=dict(zip(df0.index,numpy.arange(19,-1,-1)))))
# print(df0.rename(index=dict(zip(df0.index,numpy.arange(19,-2,-1)))))
# print(df0.rename(index=dict(zip(df0.index,numpy.arange(19,-2,-1))),errors='raise',inplace=False,copy=True))
# try:
    # print(df0.rename(index=dict(zip(numpy.arange(23),numpy.arange(19,-2,-1))),errors='raise',inplace=False,copy=True))
# except Exception as e:
    # print(e)
# print(df0.rename(mapper=(lambda e0: str(e0)[-2:]),axis=1))
# print(df0.rename(mapper=(lambda e0: map(e0,string.ascii_lowercase))))
# print(df0.rename(mapper=(lambda e0: numpy.choose(e0,string.ascii_lowercase))))
# print('str.upper0')
# print(df0.rename(mapper=(lambda e0: numpy.choose(e0,string.ascii_lowercase))).rename(str.upper))
# print(df0.rename(mapper=(lambda e0: numpy.choose(e0,string.ascii_lowercase))).rename(index=str.upper,columns=str.upper))
# print(map([1,2,3],string.ascii_lowercase))
# print(numpy.choose([1,2,3],string.ascii_lowercase))
# print([e0 for e0 in map(str.upper,string.ascii_lowercase)])
# df0=pandas.DataFrame({'c0':numpy.arange(30),'c1':numpy.arange(30,60,1)},pandas.MultiIndex.from_product([numpy.arange(15),[0,1]],names=['super','sub']))
# print(df0.rename(mapper=(lambda e0: e0*4),level=None))
# print(df0.rename(mapper=(lambda e0: e0*4),level='super'))
# print(df0.rename(mapper=(lambda e0: e0*4),level=1))

# df0=pandas.DataFrame(numpy.array([numpy.random.default_rng(8).integers(-10,20,(20,)),numpy.random.default_rng(7).integers(-10,20,(20,)),numpy.random.default_rng(6).integers(-10,20,(20,)),numpy.random.default_rng(5).integers(-10,20,(20,))]).T,columns=['col0','col1','col2','col3'])
# print(df0)
# # # print(df0['col0'].rename(index=dict(map(df0.index,numpy.arange(19,0,-1)))))
# print(df0['col0'].rename(index=dict(zip(df0.index,numpy.arange(19,0,-1)))))
# print(df0['col0'].rename(index=dict(zip(df0.index,numpy.arange(19,-1,-1)))))
# print(df0['col0'].rename(index=dict(zip(df0.index,numpy.arange(19,-2,-1)))))
# print(df0['col0'].rename(index=dict(zip(df0.index,numpy.arange(19,-2,-1))),errors='raise',inplace=False,copy=True))
# try:
    # print(df0['col0'].rename(index=dict(zip(numpy.arange(23),numpy.arange(19,-2,-1))),errors='raise',inplace=False,copy=True))
# except Exception as e:
    # print(e)
# print(df0['col0'].rename(index=(lambda e0: map(e0,string.ascii_lowercase))))
# print(df0['col0'].rename(index=(lambda e0: numpy.choose(e0,string.ascii_lowercase))))
# df0=pandas.DataFrame({'c0':numpy.arange(30),'c1':numpy.arange(30,60,1)},pandas.MultiIndex.from_product([numpy.arange(15),[0,1]],names=['super','sub']))
# print(df0['c0'].rename(index=(lambda e0: e0*4),level=None))
# print(df0['c0'].rename(index=(lambda e0: e0*4),level='super'))
# print(df0['c0'].rename(index=(lambda e0: e0*4),level=1))
# print(df0['c0'].rename(index=(lambda e0: e0*4),level=1).name)
# print(df0['c0'].rename("seriesNewName0").name)

# df0=pandas.DataFrame({'c0':numpy.arange(30),'c1':numpy.arange(30,60,1)},pandas.MultiIndex.from_product([numpy.arange(15),[0,1]],names=['super','sub']))
# print(df0.rename_axis(index=['superNewName0','subNewName0']))
# print(df0.rename_axis(columns=['colsNewName0']))
# print(df0.rename_axis(mapper=['superNewName0','subNewName0']))
# print(df0.rename_axis(mapper=['colsNewName0'],axis=1))
# try:
    # print(df0['c0'].rename_axis(mapper=str.upper))
# except Exception as e:
    # print(e)
# print(df0['c0'].rename_axis(mapper=['sup0','su0']))
# try:
    # print(df0['c0'].rename_axis(mapper="string0",axis=0,copy=True,inplace=False))
# except Exception as e:
    # print(e)
# try:
    # print(df0['c0'].rename_axis(mapper=1,axis=0,copy=True,inplace=False))
# except Exception as e:
    # print(e)
# df0=pandas.DataFrame({'c0':numpy.arange(30),'c1':numpy.arange(30,60,1)})
# print(df0['c0'].rename_axis(mapper="string0",axis=0,copy=True,inplace=False))
# print(df0['c0'].rename_axis(mapper=1,axis=0,copy=True,inplace=False))
# try:
    # print(df0['c0'].rename_axis(index=(lambda e0: numpy.choose(e0,string.ascii_lowercase)),axis=0,copy=True,inplace=False))
# except Exception as e:
    # print(e)
# try:
    # print(df0['c0'].rename_axis(index=(lambda e0: e0*4),axis=0,copy=True,inplace=False))
# except Exception as e:
    # print(e)
# print(df0['c0'].rename_axis(index='index0',axis=0,copy=True,inplace=False))
# print(df0['c0'].rename_axis(index='index0',axis=0,copy=True,inplace=False).rename_axis(index=str.upper))
# # # print(df0['c0'].rename_axis(index=(lambda e0: numpy.choose(e0,string.ascii_lowercase)),axis=0,copy=True,inplace=False).rename_axis(index=str.upper))

#______________________________
# df0=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(30,2)),index=pandas.MultiIndex.from_product([pandas.date_range('2023-01-01',periods=15,freq='W'),[0,1]]))
# # df0=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(30,2)),index=pandas.MultiIndex.from_product([pandas.date_range('2023-04-10',periods=15,freq='D'),[0,1]]))
# df1=pandas.DataFrame(numpy.random.default_rng(7).integers(-10,100,(30,2)),index=pandas.MultiIndex.from_product([pandas.date_range('2023-04-01',periods=15,freq='D'),[1,2]]))
# df2=pandas.DataFrame(numpy.random.default_rng(7).integers(-10,100,(30,2)),numpy.arange(30,60,1))
# print(df0)
# print(df1)
# print(df2)
# print(df2.reindex())
# print(df2.reindex(copy=True))
# print(df0.reindex(df1.index))
# print('tolerance0')
# df0=df0.reset_index(level=1,drop=True)
# df1=df1.reset_index(level=1,drop=True)
# print(df0)
# print(df1)
# # print('duplicated')
# # print(df0.index.duplicated(keep='first'))
# # print(df0.index.duplicated(keep='last'))
# # print(df0.index.duplicated(keep=False))
# # # print(df0.index.set_index(0,append=True))
# # # print(df0.set_index(0,append=True).duplicated(keep=False,subset=0))
# df0=df0[df0.index.duplicated(keep='last')]
# df1=df1[df1.index.duplicated(keep='last')]
# # df0.index=df0.index.drop_duplicates()
# # df1.index=df1.index.drop_duplicates()
# print(df0)
# print(df1)
# print(df0.reindex(df1.index,method='ffill',tolerance='2 days'))
# print(df0.reindex(df1.index,method='ffill',tolerance='2W'))
# print(df0.reindex(df1.index,method='ffill',limit=2))
# print(df0.reindex(df1.index,method='nearest',limit=2,fill_value=678.89))
# print('duplicated2')
# print(df0.reindex(df1.index,method='ffill',tolerance='2W').duplicated(keep=False,subset=0))
# print(df0.reindex(df1.index,method='ffill',tolerance='2W')[0].duplicated(keep='first'))
# print(df0.reindex(df1.index,method='ffill',tolerance='2W')[0].duplicated(keep='last'))
# print(df0.reindex(df1.index,method='ffill',tolerance='2W')[0].duplicated(keep=False))
#______________________________
# print(df0.reindex(df1.index,tolerance='2W'))
# print(df0.reset_index(level=0,drop=True))
# print(df1.reset_index(level=0,drop=True))
# df0=df0.reset_index(level=0,drop=True)
# df1=df1.reset_index(level=0,drop=True)
# print(df0.reindex(df1.index,level=0))
# print(df0.reindex(df1.index,level=1))

# import pandas as pd
# t1 = pd.DataFrame(data={'a1':[0,0,1,1,2,2],
                        # 'a2':[0,1,0,1,0,1],
                        # 'x':[1.,2.,3.,4.,5.,6.]})
# t1.set_index(['a1','a2'], inplace=True)
# t1.sort_index(inplace=True)
# t2 = pd.DataFrame(data={'b1':[0,1,2],
                        # 'y':[20.,40.,60.]})
# t2.set_index(['b1'], inplace=True)
# t2.sort_index(inplace=True)
# print(t1)
# print(t2)
# print(t1.reset_index('a2',drop=False))
# print(t1.reset_index('a2',drop=False).join(t2))
# print(t1.reset_index('a2',drop=False).join(t2).rename_axis('a1'))
# print(t1.reset_index('a2',drop=False).join(t2).rename_axis('a1').set_index('a2',append=True))

# t1.reset_index('a2', drop=False).join(t2
    # ).rename_axis('a1').set_index('a2', append=True)

# df0 = pandas.DataFrame([('bird', 389.0),
                   # ('bird', 24.0),
                   # ('mammal', 80.5),
                   # ('mammal', np.nan)],
                  # index=['falcon', 'parrot', 'lion', 'monkey'],
                  # columns=('class', 'max_speed'))
# print(df0)
# index = pd.MultiIndex.from_tuples([('bird', 'falcon'),
                                   # ('bird', 'parrot'),
                                   # ('mammal', 'lion'),
                                   # ('mammal', 'monkey')],
                                  # names=['class', 'name'])
# columns = pd.MultiIndex.from_tuples([('speed', 'max'),
                                     # ('species', 'type')])
# df0 = pandas.DataFrame([(389.0, 'fly'),
                   # ( 24.0, 'fly'),
                   # ( 80.5, 'run'),
                   # (np.nan, 'jump')],
                  # index=index,
                  # columns=columns)
# print(df0)
# print(df0.reset_index())
# print(df0.reset_index(names=['name1','name2']))
# print(df0.reset_index(level=0,names=['name1']))
# print(df0.reset_index(level=0,names=['name1','name2']))
# print(df0.reset_index(col_fill='col_fill1'))
# print(df0.reset_index(col_fill='col_fill0',col_level=1))
# print(df0.reset_index(level=1,drop=True))
# print(df0.reset_index(level=1))
# print(df0.reset_index(level='name'))
# print(df0.reset_index(level=1,names=['speed','speeds'],allow_duplicates=True,inplace=False))
# print(df0.reset_index(level=1,names=['speed','speed'],allow_duplicates=True,inplace=False))
# try:
    # print(df0.reset_index(level=1,names=['speed'],allow_duplicates=False))
# except Exception as e:
    # print(e)
# print(df0.reset_index(level=1,names=['speed','speed'],allow_duplicates=False))
# print(df0.reset_index(level=1,names=['speed','speed'],col_fill='max',allow_duplicates=True))
# try:
    # print(df0.reset_index(level=1,names=['speed','speed'],col_fill='max',allow_duplicates=False))
# except Exception as e:
    # print(e)

# arrays = [np.array(['bar', 'bar', 'baz', 'baz']),
          # np.array(['one', 'two', 'one', 'two'])]
# s0 = pandas.Series(
    # range(4), name='foo',
    # index=pd.MultiIndex.from_arrays(arrays,
                                    # names=['a', 'b']))
# print(s0)
# print(s0.reset_index())
# print(s0.reset_index(drop=True))
# print(s0.reset_index(level=0,drop=True))
# print(s0.reset_index(level='a',drop=True))
# print(s0.reset_index(level='a',name='a0'))
# print(s0.reset_index(name=('a0','b0')))
# print(s0.reset_index(name='name0'))
# try:
    # print(s0.reset_index(name=['a0','b0']))
# except Exception as e:
    # print(e)
# print(s0.reset_index(level='a',name='b').reset_index(allow_duplicates=True))
# try:
    # print(s0.reset_index(level='a',name='b').reset_index(allow_duplicates=False))
# except Exception as e:
    # print(e)
# df0 = pandas.DataFrame({'month': [1, 4, 7, 10],
                   # 'year': [2012, 2014, 2013, 2014],
                   # 'sale': [55, 40, 3, 3],
                   # 'sale1': [56, 42, 3, 3]})
# print(df0)
# print(df0.set_index(['sale','month']))
# print(df0.set_index(['sale','month'],append=True))
# print(df0.set_index('sale'))
# print(df0.set_index('sale',drop=False))
# print(df0.set_index('sale',drop=False,inplace=False))
# print(df0.set_index('sale',append=True))
# print(df0.set_index('sale',append=True,verify_integrity=True))
# print(df0.set_index('sale').set_index('sale1',verify_integrity=False))
# try:
    # print(df0.set_index('sale').set_index('sale1',append=True,verify_integrity=True))
# except Exception as e:
    # print(e)
# try:
    # print(df0.set_index('sale').set_index('sale1',verify_integrity=True))
# except Exception as e:
    # print(e)

# df0 = pandas.DataFrame({
    # 'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],
    # 'style': ['cup', 'cup', 'cup', 'pack', 'pack'],
    # 'rating': [4, 4, 3.5, 15, 4]
# },index=numpy.arange(5,10,1))
# print(df0)
# print(df0.drop_duplicates())
# print(df0.drop_duplicates(subset='rating'))
# print(df0.drop_duplicates(subset=['style','rating']))
# print(df0.drop_duplicates(ignore_index=True))
# print(df0.drop_duplicates(ignore_index=True,inplace=False))
# for keep0 in ['first','last',False]:
    # print(keep0)
    # print(df0.drop_duplicates(ignore_index=True,subset='brand',keep=keep0))
    # print('\n')
    # print(df0.drop_duplicates(ignore_index=True,keep=keep0))
    # print('\n\n')

# s0 = pandas.Series(['lama', 'cow', 'lama', 'beetle', 'lama', 'hippo'],
              # name='animal')
# print(s0)
# print(s0.drop_duplicates(inplace=False))
# for keep0 in ['first','last',False]:
    # print(keep0)
    # print(s0.drop_duplicates(keep=keep0))
    # print('\n\n')

# df0=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(30,2)),index=pandas.MultiIndex.from_product([pandas.date_range('2023-01-01',periods=15,freq='W'),[0,1]]))
# df1=pandas.DataFrame(numpy.random.default_rng(7).integers(-10,100,(30,2)),index=pandas.MultiIndex.from_product([pandas.date_range('2023-04-01',periods=15,freq='D'),[1,2]]))
# df2=pandas.DataFrame(numpy.random.default_rng(7).integers(-10,100,(30,2)),numpy.arange(30,60,1))
# print(df0[1])
# print(df1[1])
# print(df2[1])
# print(df2[1].reindex())
# print(df2[1].reindex(copy=True))
# print(df0[1].reindex(df1[1].index))
# print('tolerance0')
# df0=df0.reset_index(level=1,drop=True)
# df1=df1.reset_index(level=1,drop=True)
# print(df0[1])
# print(df1[1])
# df0=df0[df0.index.duplicated(keep='last')]
# df1=df1[df1.index.duplicated(keep='last')]
# print(df0[1])
# print(df1[1])
# print(df0[1].reindex(df1[1].index,method='ffill',tolerance='2 days'))
# print(df0[1].reindex(df1[1].index,method='ffill',tolerance='2W'))
# print(df0[1].reindex(df1[1].index,method='ffill',limit=2))
# print(df0[1].reindex(df1[1].index,method='nearest',limit=2,fill_value=678.89))

# print(df0[1].reindex_like(df1,method='ffill',tolerance='2 days',copy=True))
# print(df0[1].reindex_like(df1,method='ffill',tolerance='2W'))
# print(df0[1].reindex_like(df1,method='ffill',limit=2))
# print(df0[1].reindex_like(df1,method='nearest',limit=2))
# print(df0[1].reindex_like(df1[1],method='ffill',tolerance='2 days',copy=True))
# print(df0[1].reindex_like(df1[1],method='ffill',tolerance='2W'))
# print(df0[1].reindex_like(df1[1],method='ffill',limit=2))
# print(df0[1].reindex_like(df1[1],method='nearest',limit=2))

# l0=5
# df0=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(l0,2)),index=pandas.date_range('2023-01-01',periods=l0,freq='W'))
# df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(l0,2)),index=pandas.period_range('2023-01-01',periods=l0,freq='W'))
# print(df0)
# print(df0.asfreq('5D'))
# print(df0.asfreq('3D',fill_value=42))
# print(df0.asfreq('3D',fill_value=42,method='ffill'))
# print(df0.asfreq('12H',fill_value=42,method='bfill'))
# try:
    # print(df1.asfreq('1M',fill_value=42,method='bfill'))
# except Exception as e:
    # print(e)
# print(df1)
# print(df1.asfreq('1M',fill_value=42))
# print(df1.asfreq('1M',fill_value=42,how='start'))

# l0=5
# df0=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(l0,2)),index=pandas.date_range('2023-01-01',periods=l0,freq='W'))
# df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(l0,2)),index=pandas.period_range('2023-01-01',periods=l0,freq='W'))
# print(df0[1])
# print(df0[1].asfreq('5D'))
# print(df0[1].asfreq('3D',fill_value=42))
# print(df0[1].asfreq('3D',fill_value=42,method='ffill'))
# print(df0[1].asfreq('12H',fill_value=42,method='bfill'))
# try:
    # print(df1[1].asfreq('1M',fill_value=42,method='bfill'))
# except Exception as e:
    # print(e)
# print(df1[1])
# print(df1[1].asfreq('1M',fill_value=42))
# print(df1[1].asfreq('1M',fill_value=42,how='start'))

# df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(10,10)))
# df1.iloc[[4,6,7],:]=numpy.nan
# # # print(df1.fillna(42,downcast=True))
# print(df1)
# print(df1.fillna(42))
# print(df1.fillna(42,downcast='float'))
# print(df1.fillna(42,downcast='int'))
# print(df1.fillna(downcast='int',method='ffill'))
# print(df1.fillna(downcast='int',method='ffill',limit=1))
# print(df1.fillna(downcast='int',method='ffill',limit=2,inplace=False))
# df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(10,10)))
# df1.iloc[:,[4,6,7]]=numpy.nan
# print(df1)
# print(df1.fillna(42,axis=1))
# print(df1.fillna(42,downcast='int',axis=1))
# print(df1.fillna(downcast='int',method='ffill',axis=1))
# print(df1.fillna(downcast='int',method='ffill',limit=1,axis=1))
# print(df1.fillna(downcast='int',method='ffill',limit=2,inplace=False,axis=1))

# df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(10,10)))
# df1.iloc[[4,6,7],:]=numpy.nan
# # # print(df1.fillna(42,downcast=True))
# print(df1[1])
# print(df1[1].fillna(42))
# print(df1[1].fillna(42,downcast='float'))
# print(df1[1].fillna(42,downcast='int'))
# print(df1[1].fillna(downcast='int',method='ffill'))
# print(df1[1].fillna(downcast='int',method='ffill',limit=1))
# print(df1[1].fillna(downcast='int',method='ffill',limit=2,inplace=False))

# dff = pandas.DataFrame(numpy.random.randn(10, 3), columns=list("ABC"))
# dff.iloc[3:5, 0] = pandas.NaT
# dff.iloc[4:6, 1] = numpy.nan
# dff.iloc[5:8, 2] = numpy.nan
# dff.iloc[0:3, 2] = None
# print(dff)
# print(dff.notnull())
# print(dff["A"].notnull())
# print(dff["C"].notnull())
# print(dff.notna())
# print(dff["A"].notna())
# print(dff["C"].notna())
# print(dff.isna())
# print(dff["A"].isna())
# print(dff["C"].isna())
# print(dff.isnull())
# print(dff["A"].isnull())
# print(dff["C"].isnull())
# print(dff.fillna(dff.mean()["A":"B"]))


# s = pandas.Series(range(5))
# t = pandas.Series([True, False])
# print(s.shape,t.shape,sep='\n')
# print(s.where(t, 99))
# print(s.mask(t, 99))

# df0=pandas.DataFrame(numpy.arange(5))
# m0=numpy.ma.make_mask(numpy.arange(5))
# print(df0,m0,sep='\n')
# print(m0.shape,df0.shape,sep='\n')
# # # m0=numpy.array(m0,numpy.newaxis
# m0=numpy.expand_dims(m0,1)#must be same dims   unless you Series (then it truncates..)
# print(m0.shape,df0.shape,sep='\n')
# print(df0.where(m0,df0**2+1))
# print(df0.where(~m0,df0**2+1))
# m0=m0[:2]
# m0=pandas.Series(numpy.squeeze(m0,1))
# print(m0)
# print(df0.where(m0,df0**2+1))
# print(df0.where(~m0,df0**2+1))
# print(df0.where(~m0,df0**2+1,inplace=False,axis=0,level=None))

# df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(10,10)))
# df1.iloc[[4,6,7],:]=numpy.nan
# print(df1)
# print(df1.sum(axis=0))
# print(df1.where(df1.sum(axis=0)>300,'<=300'))
# df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(10,10)))
# df1.iloc[:,[4,6,7]]=numpy.nan
# # print(df1.where(df1.sum(axis=1)>50,'<=50',axis=1))#axis=1 doesn't take nans..

# df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(10,10)),pandas.MultiIndex.from_product([numpy.arange(5),numpy.arange(2)]))
# # df2=pandas.DataFrame(numpy.random.default_rng(8).integers(100,200,(5,10)))
# df2=pandas.DataFrame(numpy.random.default_rng(8).integers(100,200,(10,10)))
# df3=pandas.DataFrame(numpy.random.default_rng(8).integers(100,200,(20,10)),pandas.MultiIndex.from_product([numpy.arange(10),numpy.arange(2)]))
# # print(df1.where(df1.sum(axis=0)>50,df2,axis=1))#ValueError: operands could not be broadcast together with shapes (10,10) (10,10) (5,10)
# print(df1.sum(axis=1))
# print(df1.where(df1.sum(axis=1)>50,df2,axis=1))
# print(df1.where(df1.sum(axis=1)>400,df2,axis=1))#ValueError: operands could not be broadcast together with shapes (10,10) (10,10) (5,10)
# # print(df1.where(df1.sum(axis=1)>50,df2,axis=0))#ValueError: cannot join with no overlapping index names
# # print(df1.where(df1.sum(axis=1)>50,df3,level=0))#TypeError: Join on level between two MultiIndex objects is ambiguous
# # print(df1.where(df2.sum(axis=0)>50,df3,level=0))#TypeError: Join on level between two MultiIndex objects is ambiguous even though there's only 1 MultiIndex object involved..

# df0=pandas.DataFrame(numpy.arange(5))
# m0=numpy.ma.make_mask(numpy.arange(5))
# print(df0[0],m0,sep='\n')
# print(m0.shape,df0[0].shape,sep='\n')
# # # m0=numpy.array(m0,numpy.newaxis
# # m0=numpy.expand_dims(m0,1)#must be same dims   unless you Series (then it truncates..)
# print(m0.shape,df0[0].shape,sep='\n')
# print(df0[0].where(m0,df0[0]**2+1))
# print(df0[0].where(~m0,df0[0]**2+1))
# m0=m0[:2]
# m0=pandas.Series((m0))
# print(m0)
# print(df0[0].where(m0,df0[0]**2+1))
# print(df0[0].where(~m0,df0[0]**2+1))
# print(df0[0].where(~m0,df0[0]**2+1,inplace=False,axis=0,level=None))

# df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(10,10)))
# df1.iloc[[4,6,7],:]=numpy.nan
# df1.iloc[:,0]=numpy.nan
# print(df1)
# print(df1.dropna(axis=0,how='any',inplace=False))
# print(df1.dropna(axis=0,how='all'))
# print(df1.dropna(axis=1,how='any'))
# print(df1.dropna(axis=1,how='all'))
# print('subset0')
# print(df1.dropna(axis=0,how='any',subset=[0,1,2]))
# print(df1.dropna(axis=0,how='all',subset=[0,1,2]))
# print(df1.dropna(axis=1,how='any',subset=[0,1,2]))
# print(df1.dropna(axis=1,how='all',subset=[0,1,2]))
# print(df1.dropna(thresh=1))
# print(df1.dropna(thresh=2))
# print(df1.dropna(thresh=22))
# print(df1.dropna(thresh=1,axis=1))
# print(df1.dropna(thresh=2,axis=1))
# print(df1.dropna(thresh=2,axis=1,subset=[0,1,2]))
# print(df1.dropna(thresh=22,axis=1,subset=[0,1,2]))

# print('\n\n\n\n')
# df1=pandas.DataFrame(numpy.random.default_rng(8).integers(-10,100,(10,10)))
# df1.iloc[:,[4,6,7]]=numpy.nan
# df1.iloc[0,:]=numpy.nan
# print(df1)
# print(df1.dropna(axis=0,how='any',inplace=False))
# print(df1.dropna(axis=0,how='all'))
# print(df1.dropna(axis=1,how='any'))
# print(df1.dropna(axis=1,how='all'))
# print('subset0')
# print(df1.dropna(axis=0,how='any',subset=[0,1,2]))
# print(df1.dropna(axis=0,how='all',subset=[0,1,2]))
# print(df1.dropna(axis=1,how='any',subset=[0,1,2]))
# print(df1.dropna(axis=1,how='all',subset=[0,1,2]))
# print(df1.dropna(thresh=1))
# print(df1.dropna(thresh=2))
# print(df1.dropna(thresh=3))
# print(df1.dropna(thresh=22))
# print(df1.dropna(thresh=1,axis=1))
# print(df1.dropna(thresh=2,axis=1))
# print(df1.dropna(thresh=2,axis=1,subset=[0,1,2]))
# print(df1.dropna(thresh=3,axis=1,subset=[0,1,2]))
# print(df1.dropna(thresh=22,axis=1,subset=[0,1,2]))


# ser = pandas.Series([np.NaN, 2, pd.NaT, '', None, 'I stay'])
# print(ser)
# print(ser.dropna())

# pandas.options.display.max_rows=999999
# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)
# print(df)
# # print(df.replace('V',10))
# # print(df.replace('V','10'))
# # print(df.replace('.*V.*','10'))
# # print(df.replace('.*V.*','10',regex=True))
# # print(df.replace('(.*)V(.*)','(\1)10(\2)',regex=True))
# print(df.replace(r'(.*)V(.*)',r'(\1)10(\2)',regex=True))
# print(df.replace(r'(.*)V(.*)',r'\110\2',regex=True))
# print(df.replace('(.*)V(.*)','\110\2',regex=True))
# print(df.replace(r'(Company)',r'The Coolest \1',regex=True))
# print(df.replace(r'(Company)|(The)',r'The Coolest \1',regex=True))
# print(df.replace(r'(The)|(Company)',r'The Coolest \1',regex=True))
# print(df.replace('(.*)V(.*)','\g<1>10\2',regex=True))
# print(df.replace('(.*)V(.*)','\g<1>10\g<2>',regex=True))
# print(df.replace({'m_ticker':['PFE','MSFT'],'ticker':['PFE','MSFT']},{'m_ticker':['PFE0','MSFT0'],'ticker':['PFE1','MSFT1']}))
# print(df.replace(['PFE','MSFT'],['PFE00','MSFT00']))
# print(df.replace(['PFE','MSFT'],'PPEPrecedent'))
# print(df.replace(['PFE','MSFT'],method='ffill'))
# print(df.replace(['PFE','MSFT'],method='bfill',limit=1,inplace=False))
# print(df.replace({'PFE':'PFE2','MSFT':'MSFT2'}))
# print(df.replace({'m_ticker':{'PFE':'PFE0'},'ticker':{'PFE':'PFE1'}}))
# print(df['m_ticker'])
# print(df['m_ticker'].replace('V',10))
# print(df['m_ticker'].replace('V','10'))
# print(df['m_ticker'].replace('.*V.*','10'))
# print(df['m_ticker'].replace('.*V.*','10',regex=True))
# print(df['m_ticker'].replace('(.*)V(.*)','(\1)10(\2)',regex=True))
# print(df['m_ticker'].replace('(.*)V(.*)','\g<1>10\2',regex=True))
# print(df['m_ticker'].replace('(.*)V(.*)','\g<1>10\g<2>',regex=True))
# print(df['m_ticker'].replace(['PFE','MSFT'],['PFE00','MSFT00']))
# print(df['m_ticker'].replace(['PFE','MSFT'],'PPEPrecedent'))
# print(df['m_ticker'].replace(['PFE','MSFT'],method='ffill'))
# print(df['m_ticker'].replace(['PFE','MSFT'],method='bfill',limit=1,inplace=False))
# print(df['m_ticker'].replace({'PFE':'PFE2','MSFT':'MSFT2'}))

# i0=pandas.Index([0,1,2,3,4,7,8,9,10,11])
# print(len(i0))
# df0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,100,10),i0)
# print(df0)
# figure0,axes0=matplotlib.pyplot.subplots(nrows=1,ncols=2)
# # df0.plot()
# df0.plot(ax=axes0[0],subplots=True)
# # matplotlib.pyplot.show()
# i1=df0.index.union(pandas.Index([5,6]))
# print(i1)
# df1=df0.reindex(i1).interpolate('akima')
# print(df1)
# # df1.plot()
# df1.plot(ax=axes0[1],subplots=True)
# matplotlib.pyplot.show()

# df = pandas.DataFrame(np.random.randn(10, 2))
# print(df)
# print(numpy.random.rand(df.shape[0]))
# print(False*3)
# print([False*3])
# print([False]*3)
# try:
    # pandas.arrays.IntegerArray([1,2,None,3],[False,False,False,True],copy=True)
# except Exception as e:
    # print(e)
# try:
    # pandas.arrays.IntegerArray(numpy.array([1,2,numpy.nan,3],dtype=numpy.int_),[False,False,False,True],copy=True)
# except Exception as e:
    # print(e)
# print(pandas.arrays.IntegerArray(numpy.array([1,2,42,3],dtype=numpy.int_),numpy.array([False,False,False,True],dtype=numpy.bool_),copy=True))
# print(pandas.array([1,2,None,3],'Int32',copy=True))
# print(pandas.array([1,2,None,3],pandas.Int32Dtype(),copy=True))
# print(pandas.array([1,2,None,3],'UInt32',copy=True))

# import pandas.api.extensions
# @pandas.api.extensions.register_extension_dtype
# class ex0(pandas.api.extensions.ExtensionDtype):
    # name='ex0name0'
# print(ex0)
# print(pandas.array(pandas.Series([1,2,3])).dtype)
# print(pandas.array(pandas.Index([1,2,3])).dtype)
# print(pandas.array(pandas.Index([1,2,3])).dtype)



# import operator
# import re
# from typing import Any, Sequence

# import numpy as np
# import pandas as pd


# @pd.api.extensions.register_extension_dtype
# class AngleDtype(pd.core.dtypes.dtypes.PandasExtensionDtype):
    # """
    # An ExtensionDtype for unit-aware angular data.
    # """
    # # Required for all parameterized dtypes
    # _metadata = ('unit',)
    # _match = re.compile(r'(A|a)ngle\[(?P<unit>.+)\]')

    # def __init__(self, unit=None):
        # if unit is None:
            # unit = 'rad'

        # if unit not in ['rad', 'deg']:
            # msg = f"'{type(self).__name__}' only supports 'rad' and 'deg' units"
            # raise ValueError(msg)

        # self._unit = unit

    # def __str__(self) -> str:
        # return f'angle[{self.unit}]'

    # # TestDtypeTests
    # def __hash__(self) -> int:
        # return hash(str(self))

    # # TestDtypeTests
    # def __eq__(self, other: Any) -> bool:
        # if isinstance(other, str):
            # return self.name == other
        # else:
            # return isinstance(other, type(self)) and self.unit == other.unit

    # # Required for pickle compat (see GH26067)
    # def __setstate__(self, state) -> None:
        # self._unit = state['unit']

    # # Required for all ExtensionDtype subclasses
    # @classmethod
    # def construct_array_type(cls):
        # """
        # Return the array type associated with this dtype.
        # """
        # return AngleArray

    # # Recommended for parameterized dtypes
    # @classmethod
    # def construct_from_string(cls, string: str) -> AngleDtype:
        # """
        # Construct an AngleDtype from a string.

        # Example
        # -------
        # >>> AngleDtype.construct_from_string('angle[deg]')
        # angle['deg']
        # """
        # if not isinstance(string, str):
            # msg = f"'construct_from_string' expects a string, got {type(string)}"
            # raise TypeError(msg)

        # msg = f"Cannot construct a '{cls.__name__}' from '{string}'"
        # match = cls._match.match(string)

        # if match:
            # d = match.groupdict()
            # try:
                # return cls(unit=d['unit'])
            # except (KeyError, TypeError, ValueError) as err:
                # raise TypeError(msg) from err
        # else:
            # raise TypeError(msg)

    # # Required for all ExtensionDtype subclasses
    # @property
    # def type(self):
        # """
        # The scalar type for the array (e.g., int).
        # """
        # return np.generic

    # # Required for all ExtensionDtype subclasses
    # @property
    # def name(self) -> str:
        # """
        # A string representation of the dtype.
        # """
        # return str(self)

    # @property
    # def unit(self) -> str:
        # """
        # The angle unit.
        # """
        # return self._unit

# class AngleArray(pd.api.extensions.ExtensionArray):
    # """
    # An ExtensionArray for unit-aware angular data.
    # """
    # # Include `copy` param for TestInterfaceTests
    # def __init__(self, data, unit='rad', copy: bool=False):
        # self._data = np.array(data, copy=copy)
        # self._unit = unit

    # # Required for all ExtensionArray subclasses
    # def __getitem__(self, index: int) -> AngleArray | Any:
        # """
        # Select a subset of self.
        # """
        # if isinstance(index, int):
            # return self._data[index]
        # else:
            # # Check index for TestGetitemTests
            # index = pd.core.indexers.check_array_indexer(self, index)
            # return type(self)(self._data[index])

    # # TestSetitemTests
    # def __setitem__(self, index: int, value: np.generic) -> None:
        # """
        # Set one or more values in-place.
        # """
        # # Check index for TestSetitemTests
        # index = pd.core.indexers.check_array_indexer(self, index)

        # # Upcast to value's type (if needed) for TestMethodsTests
        # if self._data.dtype < type(value):
            # self._data = self._data.astype(type(value))

        # # TODO: Validate value for TestSetitemTests
        # # value = self._validate_setitem_value(value)

        # self._data[index] = value

    # # Required for all ExtensionArray subclasses
    # def __len__(self) -> int:
        # """
        # Length of this array.
        # """
        # return len(self._data)

    # # TestUnaryOpsTests
    # def __invert__(self) -> AngleArray:
        # """
        # Element-wise inverse of this array.
        # """
        # data = ~self._data
        # return type(self)(data, unit=self.dtype.unit)

    # def _ensure_same_units(self, other) -> AngleArray:
        # """
        # Helper method to ensure `self` and `other` have the same units.
        # """
        # if isinstance(other, type(self)) and self.dtype.unit != other.dtype.unit:
            # return other.asunit(self.dtype.unit)
        # else:
            # return other

    # def _apply_operator(self, op, other, recast=False) -> np.ndarray | AngleArray:
        # """
        # Helper method to apply an operator `op` between `self` and `other`.

        # Some ops require the result to be recast into AngleArray:
        # * Comparison ops: recast=False
        # * Arithmetic ops: recast=True
        # """
        # f = operator.attrgetter(op)
        # data, other = np.array(self), np.array(self._ensure_same_units(other))
        # result = f(data)(other)
        # return result if not recast else type(self)(result, unit=self.dtype.unit)

    # def _apply_operator_if_not_series(self, op, other, recast=False) -> np.ndarray | AngleArray:
        # """
        # Wraps _apply_operator only if `other` is not Series/DataFrame.
        
        # Some ops should return NotImplemented if `other` is a Series/DataFrame:
        # https://github.com/pandas-dev/pandas/blob/e7e7b40722e421ef7e519c645d851452c70a7b7c/pandas/tests/extension/base/ops.py#L115
        # """
        # if isinstance(other, (pd.Series, pd.DataFrame)):
            # return NotImplemented
        # else:
            # return self._apply_operator(op, other, recast=recast)

    # # Required for all ExtensionArray subclasses
    # @pd.core.ops.unpack_zerodim_and_defer('__eq__')
    # def __eq__(self, other):
        # return self._apply_operator('__eq__', other, recast=False)

    # # TestComparisonOpsTests
    # @pd.core.ops.unpack_zerodim_and_defer('__ne__')
    # def __ne__(self, other):
        # return self._apply_operator('__ne__', other, recast=False)

    # # TestComparisonOpsTests
    # @pd.core.ops.unpack_zerodim_and_defer('__lt__')
    # def __lt__(self, other):
        # return self._apply_operator('__lt__', other, recast=False)

    # # TestComparisonOpsTests
    # @pd.core.ops.unpack_zerodim_and_defer('__gt__')
    # def __gt__(self, other):
        # return self._apply_operator('__gt__', other, recast=False)

    # # TestComparisonOpsTests
    # @pd.core.ops.unpack_zerodim_and_defer('__le__')
    # def __le__(self, other):
        # return self._apply_operator('__le__', other, recast=False)

    # # TestComparisonOpsTests
    # @pd.core.ops.unpack_zerodim_and_defer('__ge__')
    # def __ge__(self, other):
        # return self._apply_operator('__ge__', other, recast=False)
    
    # # TestArithmeticOpsTests
    # @pd.core.ops.unpack_zerodim_and_defer('__add__')
    # def __add__(self, other) -> AngleArray:
        # return self._apply_operator_if_not_series('__add__', other, recast=True)

    # # TestArithmeticOpsTests
    # @pd.core.ops.unpack_zerodim_and_defer('__sub__')
    # def __sub__(self, other) -> AngleArray:
        # return self._apply_operator_if_not_series('__sub__', other, recast=True)

    # # TestArithmeticOpsTests
    # @pd.core.ops.unpack_zerodim_and_defer('__mul__')
    # def __mul__(self, other) -> AngleArray:
        # return self._apply_operator_if_not_series('__mul__', other, recast=True)

    # # TestArithmeticOpsTests
    # @pd.core.ops.unpack_zerodim_and_defer('__truediv__')
    # def __truediv__(self, other) -> AngleArray:
        # return self._apply_operator_if_not_series('__truediv__', other, recast=True)

    # # Required for all ExtensionArray subclasses
    # @classmethod
    # def _from_sequence(cls, data, dtype=None, copy: bool=False):
        # """
        # Construct a new AngleArray from a sequence of scalars.
        # """
        # if dtype is None:
            # dtype = AngleDtype()

        # if not isinstance(dtype, AngleDtype):
            # msg = f"'{cls.__name__}' only supports 'AngleDtype' dtype"
            # raise ValueError(msg)
        # else:
            # return cls(data, unit=dtype.unit, copy=copy)

    # # TestParsingTests
    # @classmethod
    # def _from_sequence_of_strings(cls, strings, *, dtype=None, copy: bool=False) -> AngleArray:
        # """
        # Construct a new AngleArray from a sequence of strings.
        # """
        # scalars = pd.to_numeric(strings, errors='raise')
        # return cls._from_sequence(scalars, dtype=dtype, copy=copy)

    # # Required for all ExtensionArray subclasses
    # @classmethod
    # def _from_factorized(cls, uniques: np.ndarray, original: AngleArray):
        # """
        # Reconstruct an AngleArray after factorization.
        # """
        # return cls(uniques, unit=original.dtype.unit)

    # # Required for all ExtensionArray subclasses
    # @classmethod
    # def _concat_same_type(cls, to_concat: Sequence[AngleArray]) -> AngleArray:
        # """
        # Concatenate multiple AngleArrays.
        # """
        # # ensure same units
        # counts = pd.value_counts([array.dtype.unit for array in to_concat])
        # unit = counts.index[0]

        # if counts.size > 1:
            # to_concat = [a.asunit(unit) for a in to_concat]

        # return cls(np.concatenate(to_concat), unit=unit)

    # # Required for all ExtensionArray subclasses
    # @property
    # def dtype(self):
        # """
        # An instance of AngleDtype.
        # """
        # return AngleDtype(self._unit)

    # # Required for all ExtensionArray subclasses
    # @property
    # def nbytes(self) -> int:
        # """
        # The number of bytes needed to store this object in memory.
        # """
        # return self._data.nbytes

    # @property
    # def unit(self):
        # return self.dtype.unit

    # # Test*ReduceTests
    # def all(self) -> bool:
        # return all(self)

    # def any(self) -> bool:  # Test*ReduceTests
        # return any(self)

    # def sum(self) -> np.generic:  # Test*ReduceTests
        # return self._data.sum()

    # def mean(self) -> np.generic:  # Test*ReduceTests
        # return self._data.mean()

    # def max(self) -> np.generic:  # Test*ReduceTests
        # return self._data.max()

    # def min(self) -> np.generic:  # Test*ReduceTests
        # return self._data.min()

    # def prod(self) -> np.generic:  # Test*ReduceTests
        # return self._data.prod()

    # def std(self) -> np.generic:  # Test*ReduceTests
        # return pd.Series(self._data).std()

    # def var(self) -> np.generic:  # Test*ReduceTests
        # return pd.Series(self._data).var()

    # def median(self) -> np.generic:  # Test*ReduceTests
        # return np.median(self._data)

    # def skew(self) -> np.generic:  # Test*ReduceTests
        # return pd.Series(self._data).skew()

    # def kurt(self) -> np.generic:  # Test*ReduceTests
        # return pd.Series(self._data).kurt()

    # # Test*ReduceTests
    # def _reduce(self, name: str, *, skipna: bool=True, **kwargs):
        # """
        # Return a scalar result of performing the reduction operation.
        # """
        # f = operator.attrgetter(name)
        # return f(self)()

    # # Required for all ExtensionArray subclasses
    # def isna(self):
        # """
        # A 1-D array indicating if each value is missing.
        # """
        # return pd.isnull(self._data)

    # # Required for all ExtensionArray subclasses
    # def copy(self):
        # """
        # Return a copy of the array.
        # """
        # copied = self._data.copy()
        # return type(self)(copied, unit=self.unit)

    # # Required for all ExtensionArray subclasses
    # def take(self, indices, allow_fill=False, fill_value=None):
        # """
        # Take elements from an array.
        # """
        # if allow_fill and fill_value is None:
            # fill_value = self.dtype.na_value

        # result = pd.core.algorithms.take(self._data, indices, allow_fill=allow_fill,
                                         # fill_value=fill_value)
        # return self._from_sequence(result)

    # # TestMethodsTests
    # def value_counts(self, dropna: bool=True):
        # """
        # Return a Series containing descending counts of unique values (excludes NA values by default).
        # """
        # return pd.core.algorithms.value_counts(self._data, dropna=dropna)

    # def asunit(self, unit: str) -> AngleArray:
        # """
        # Cast to an AngleDtype unit.
        # """
        # if unit not in ['rad', 'deg']:
            # msg = f"'{type(self.dtype).__name__}' only supports 'rad' and 'deg' units"
            # raise ValueError(msg)
        # elif self.dtype.unit == unit:
            # return self
        # else:
            # rad2deg = self.dtype.unit == 'rad' and unit == 'deg'
            # data = np.rad2deg(self._data) if rad2deg else np.deg2rad(self._data)
            # return type(self)(data, unit)


# object0=AngleArray([1,2.2,5.6],unit='rad',copy=True)
# for a0 in dir(object0):
    # try:
        # print(a0,'    ',getattr(object0,a0))
    # except Exception as e:
        # print(e,sys.exc_info())
# listOfAttributes0=[]
# for a0 in dir(object0):
    # try:
        # listOfAttributes0.append(getattr(object0,a0))
    # except Exception as e:
        # print(e,sys.exc_info())
# listOfMethods0=filter(callable,listOfAttributes0)
# print('methods0',end='\n\n\n\n\n')
# for method0 in listOfMethods0:
    # try:
        # print(method0,method0(),sep='\n',end='\n\n')
    # except Exception as e:
        # print(e,sys.exc_info())

# object0=AngleArray([1,2.2,5.6,numpy.nan],unit='rad',copy=True)
# for a0 in dir(object0):
    # try:
        # print(a0,'    ',getattr(object0,a0))
    # except Exception as e:
        # print(e,sys.exc_info())
# listOfAttributes0=[]
# for a0 in dir(object0):
    # try:
        # listOfAttributes0.append(getattr(object0,a0))
    # except Exception as e:
        # print(e,sys.exc_info())
# listOfMethods0=filter(callable,listOfAttributes0)
# print('methods0',end='\n\n\n\n\n')
# for method0 in listOfMethods0:
    # try:
        # print(method0,method0(),sep='\n',end='\n\n')
    # except Exception as e:
        # print(e,sys.exc_info())




# object0=AngleDtype()
# for a0 in dir(object0):
    # try:
        # print(a0,'    ',getattr(object0,a0))
    # except Exception as e:
        # print(e,sys.exc_info())
# listOfAttributes0=[]
# for a0 in dir(object0):
    # try:
        # listOfAttributes0.append(getattr(object0,a0))
    # except Exception as e:
        # print(e,sys.exc_info())
# listOfMethods0=filter(callable,listOfAttributes0)
# print('methods0',end='\n\n\n\n\n')
# for method0 in listOfMethods0:
    # try:
        # # print(method0,method0(),method0.__doc__,sep='\n',end='\n\n\n\n')
        # print(method0,method0(),sep='\n',end='\n\n')
    # except Exception as e:
        # print(e,sys.exc_info())
# print(object0.is_dtype(numpy.void))
# print(object0.is_dtype(numpy.float_))
# print(AngleDtype.is_dtype(object0))
# print(AngleDtype.construct_from_string('angle[deg]'))
# print(type(AngleDtype.construct_from_string('angle[deg]')))
# print(object0.empty((2,)))


# print(pandas.array(AngleArray([1,2.2,5.6],unit='rad',copy=True)).dtype)
# print(pandas.array([None,numpy.nan,pandas.NA,1,2,3],'Int32'))
# print(pandas.array([None,numpy.nan,pandas.NA,1,2,3]))
# print(pandas.Series([None,numpy.nan,pandas.NA,1,2,3],dtype='Int32'))
# print(pandas.Series([None,numpy.nan,pandas.NA,1,2,3]))
# print(pandas.Series([1.0,None,numpy.nan,pandas.NA,1,2,3]))
# pa0=pandas.array([None,numpy.nan,pandas.NA,1,2,3],'Int32')
# pa1=pandas.array([1.0,numpy.nan,pandas.NA,1,2,3],'Int32')
# pa2=pandas.array([1.0,numpy.nan,pandas.NA,1,2,3.2])
# print(pa0+pa1)
# print((pa0+pa1).dtype)
# print(pa0+pa2)
# print((pa0+pa2).dtype)
# try:
    # print(pandas.concat([pa0,pa2]).dtype)
# except Exception as e:
    # print(e)
# print(pandas.concat([pandas.DataFrame(pa0),pandas.DataFrame(pa2)]))
# print(pandas.concat([pandas.DataFrame(pa0),pandas.DataFrame(pa2)]).dtypes)
# print(pandas.concat([pandas.DataFrame(pa0),pandas.DataFrame(pa2)],axis=1))
# print(pandas.concat([pandas.DataFrame(pa0),pandas.DataFrame(pa2)],axis=1).dtypes)
# print(pandas.concat([pandas.DataFrame(pa0),pandas.DataFrame(pa2)],axis=1).iloc[:,0].astype('Float64'))

# m0=numpy.ma.make_mask([1,0,0])
# m1=pandas.array([True,False,pandas.NA],dtype='boolean')
# a0=numpy.arange(3)
# s0=pandas.Series(numpy.arange(3))
# print(a0[m0])
# print(s0[m1])
# print(pandas.DataFrame(numpy.repeat(numpy.nan,3)).any())
# print(pandas.DataFrame(numpy.repeat(numpy.nan,3)).all())#for Series distinguishing only
# a0=numpy.array([True,False,numpy.nan],dtype=numpy.bool_)
# s0=pandas.Series(numpy.array([True,False,numpy.nan],dtype=numpy.bool_))#numpy.nan as True
# s0=pandas.Series(numpy.array([True,False,numpy.nan],dtype=numpy.bool_),dtype='object')#numpy.nan as True
# # s0=pandas.Series([True,False,numpy.nan],dtype='object')#numpy.nan as False
# pa0=pandas.array([True,False,pandas.NA],dtype='boolean')
# print(a0|True)
# print(a0&False)
# print(pa0|True)
# print(pa0&False)
# print(a0&True)
# print(a0|False)
# print(pa0&True)
# print(pa0|False)
# print(s0|True)
# print(s0&False)
# print(s0&True)
# print(s0|False)
# print(pandas.options.mode.string_storage)
# print(repr(pandas.StringDtype()))
# print(repr(pandas.StringDtype(storage='python')))
# print(repr(pandas.StringDtype(storage='pyarrow')))
# print(pandas.StringDtype())
# print(pandas.StringDtype(storage='python'))
# print(pandas.StringDtype(storage='pyarrow'))
# print(type(pandas.StringDtype()))
# print(pandas.StringDtype(storage='python').type)
# print(pandas.StringDtype(storage='pyarrow').type)

# s0=pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse'],dtype='string')
# df0=pandas.DataFrame([['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse'],['lower0','UPPER0','title To a Movie sehr groÃŸ0','SwApCAse0']],dtype="string").T
# numpyArray0=df0.to_numpy()
# print(df0)
# for r0 in [s0.str.lower(),s0.str.upper(),s0.str.capitalize(),s0.str.title(),s0.str.swapcase(),s0.str.casefold()]:
    # print(r0)
# s1=pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse'],dtype='string')[::-1]
# s1[2]=pandas.NA
# s2=pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse'],dtype='string')[::-2]
# s3=pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse'],dtype='string')[::2]
# s4=pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse','swapCase2'],dtype='string')
# print(s0)
# print(s1)
# print(s2)
# print(s3)
# print(s4)
# print(s0.str.cat())
# print(s0.str.cat(s1))
# print(s0.str.cat(s1,na_rep='imNa'))
# print(s0.str.cat(s1,sep=';'))
# for join0 in ['left','right','outer','inner']:
    # print(s0.str.cat(s4,sep=';',join=join0))#worth mentioning that even on join='right' this will still give <NA> for index=4 (in other words, if caller is long, will include; but if others is long, will output <NA>; if short, both behave like SQL inner joins)
    # print(s0.str.cat(s1,sep=';',join=join0))
    # print(pandas.Index(s0).str.cat(pandas.Index(s1),sep=';',na_rep='imNa',join=join0))
    # print(pandas.Index(s0).str.cat([s2,s3],sep=';',na_rep='imNa',join=join0))
    # try:
        # print(pandas.Index(s0).str.cat(pandas.Index(s2),sep=';',na_rep='imNa',join=join0))#join is not None; caller is Index; others is Index; yet errors since different size
    # except Exception as e:
        # print(e)
    # print(s0.str.cat(s2,sep=';',na_rep='imNa',join=join0))#join is not None; caller is Series; others is Series; works!
    # print(s0.str.cat(df0,sep=';',na_rep='imNa',join=join0))
    # # # print(s0.str.cat([numpyArray0,['t0','t1','t2','t3'],df0],sep=';',na_rep='imNa',join=join0))
    # # # print(s0.str.cat([numpyArray0,pandas.Series(['t0','t1','t2','t3'])],sep=';',na_rep='imNa',join=join0))
    # # # print(s0.str.cat([pandas.Series(['t0','t1','t2','t3'],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),df0.to_numpy()],sep=';',na_rep='imNa',join=join0))#won't work since '''df0.to_numpy()''' is not 1-dim
    # print(s0.str.cat([pandas.Series(['t0','t1','t2','t3'],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),numpy.array(['t5','t6','t7','t8'])],sep=';',na_rep='imNa',join=join0))
    # print('noJoinPassed0',s0.str.cat(s1))
    # print('noJoinPassed1',s0.str.cat(s2))
# print(pandas.Index(pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','SwApCAse','swapCase2'],dtype='string')))

# print('center0')
# for f0 in [s0.str.center,s0.str.ljust,s0.str.rjust]:
    # for width0 in [1,10,100]:
        # for fillchar0 in ['',' ','|']:
            # print('f0,width0,fillchar0',f0,width0,fillchar0)
            # try:
                # print(f0(width0,fillchar=fillchar0))
            # except Exception as e:
                # print(e)
            # print('\n')

# import re
# reCompile0=re.compile(r'v.*a',re.DOTALL)
# print(reCompile0)
# print(re.findall(r'v.*a','string to v find things\n in a',re.DOTALL))
# print(re.findall(r'v.*a','string to v find things\n in a'))
# print(re.findall(r'gro[a-ÃŸ]','groÃŸ',re.ASCII))
# print(re.findall(r'gro[a-ÃŸ]','groÃŸ'))
# print(re.findall(r'\w+','groÃŸ',re.ASCII))
# print(re.findall(r'\w+','groÃŸ'))
# print(re.findall(r'Ã¤hn[a-z]+',u'Ã¤hnl Ã¤hnlich',re.ASCII))
# print(re.findall(r'Ã¤hn[a-z]+',u'Ã¤hnl Ã¤hnlich'))
# print(re.findall(r'\w+[a-z]+',u'Ã¤hnl Ã¤hnlich',re.ASCII))
# print(re.findall(r'\w+[a-z]+',u'Ã¤hnl Ã¤hnlich'))
# print(re.findall(r'^newLine$','newLine\nnewLine\nnewLine\n',re.MULTILINE))
# print(re.findall(r'^newLine$','newLine\nnewLine\nnewLine\n'))
# print(re.findall(r'^newLine$','newLine\nnewLine\nnewLine',re.MULTILINE))
# print(re.findall(r'^newLine$','newLine\nnewLine\nnewLine'))
# # def f0(s0,fl0=re.NOFLAG):
    # # print(findall('findThis[a-z]+',s0,flags=re.NOFLAG))
    # # print(findall('findThis[a-z]+',s0,flags=0))
    # # print(findall('findThis[a-z]+',s0))
# # f0('this is findThisabcde\n\nfindThisasdf\n')
# print(re.findall(r'cAsEsEnSiTiVe','cAsEsEnSiTiVe CASESENSITIVE casesensitive',re.IGNORECASE))
# print(re.findall(r'cAsEsEnSiTiVe','cAsEsEnSiTiVe CASESENSITIVE casesensitive'))
# import locale
# print(locale.getlocale())
# # locale.setlocale(locale.LC_ALL,'en_US.ISO8859-1')
# # locale.setlocale(locale.LC_ALL, 'en_US.ISO8859-1')
# locale.setlocale(locale.LC_ALL, 'de_DE')
# print(locale.getlocale())
# # # print(re.findall(b'Ã¤hn[a-z]+',b'Ã¤hnl Ã¤hnlich',re.LOCALE))#not encouraged plus not that much value unless you're lower level and can write bytes as unicode as most locale differences are accented, etc. ?
# # # print(re.findall(b'Ã¤hn[a-z]+',b'Ã¤hnl Ã¤hnlich'))
# print(re.findall('''this
                    # \sis #midpoint
                    # \smatched''','this is matched  \nthis is matched   this is  matched',re.VERBOSE))
# print(re.findall('''this
                    # \sis #midpoint
                    # \smatched''','this is matched  \nthis is matched   this is  matched'))

# s0=pandas.Series(['lower','UPPER','title To a Movie sehr groÃŸ','title To123 A Movie sehr groÃŸ','title\sTo123 A Movie sehr groÃŸ','SwApCAse',None,numpy.nan,pandas.NA],dtype='string')
# print(s0)
# # print(re.findall(r'v.*a','string to v find things\n in a',re.DOTALL))
# # print(re.findall(r'gro[a-ÃŸ]','groÃŸ',re.ASCII))
# # print(re.findall(r'\w+','groÃŸ',re.ASCII))
# # print(re.findall(r'Ã¤hn[a-z]+',u'Ã¤hnl Ã¤hnlich',re.ASCII))
# # print(re.findall(r'\w+[a-z]+',u'Ã¤hnl Ã¤hnlich',re.ASCII))
# # print(re.findall(r'^newLine$','newLine\nnewLine\nnewLine\n',re.MULTILINE))
# # print(re.findall(r'^newLine$','newLine\nnewLine\nnewLine',re.MULTILINE))
# # print(re.findall(r'cAsEsEnSiTiVe','cAsEsEnSiTiVe CASESENSITIVE casesensitive',re.IGNORECASE))
# print(s0.str.contains(' To'))
# print(s0.str.contains('\sTo'))
# print(s0.str.contains('\\sTo',regex=False))
# print(s0.str.contains('\sto',regex=True,flags=0,case=True))
# print(s0.str.contains('\sto',regex=True,flags=0,case=False))
# print(s0.str.contains('\sto',regex=True,flags=0,case=False,na=' To'))
# s0=pandas.Series(["'string to v find things\\n in a'", "'groÃŸ'", "u'Ã¤hnl Ã¤hnlich'",
       # # "'newLine\\nnewLine\\nnewLine\\n'",
       # 'newLine\\nnewLine\\nnewLine\\n'
       # "'newLine\\nnewLine\\nnewLine'",
       # "'cAsEsEnSiTiVe CASESENSITIVE casesensitive'",None,numpy.nan,pandas.NA],dtype='string')
# import re
# for flags0 in [re.DOTALL, re.ASCII, re.MULTILINE, re.IGNORECASE]:#re.DOTALL, re.ASCII, re.MULTILINE don't seem to have any effect; re.IGNORECASE works!
    # for pat0 in ['v.*a','gro[a-ÃŸ]','\\w+','Ã¤hn[a-z]+','\\w+[a-z]+','^newLine$','cAsEsEnSiTiVe']:
        # # print('flags0,pat0',flags0,pat0,'\n',s0)
        # # print(s0.str.contains(pat0,flags=flags0))
        # # print(s0.str.count(pat0,flags=flags0))
        # print(s0.str.count(pat0,flags=flags0))
        # print('\n')
# print(s0.str.encode('ISO8859-1'))
# print(s0.str.encode('ISO8859-1').str.decode('ISO8859-1'))
# print(s0.str.encode('ASCII',errors='ignore'))
# print(s0.str.encode('ASCII',errors='ignore').str.decode('ASCII',errors='ignore'))
# s0=pandas.Series(['boat','bob','bat','bear','cat','car','cot','vet','vea',None,numpy.nan,pandas.NA],dtype='string')
# for f0 in [s0.str.startswith,s0.str.endswith]:
    # for na0 in [None,'vga']:
        # # for pat0 in ['v.*a','b[ao]','b[a-o]','bo','t']:
        # for pat0 in [('ba','bo'),('t','r'),'bo','t']:
            # print('f0,na0,pat0',f0,na0,pat0,'\n',s0)
            # print(f0(pat0,na=na0))
            # print('\n')
# import re
# s0=pandas.Series(['a a a a d d','b b b','c','42',42])#Series.str doesn't automatically convert all to str first (numeric will return NaN or NA depending if object or pandas.StringDtype is used, respectively); use Series.apply(str) or DataFrame.applymap(str) to convert all to str first if needed
# for f0 in [s0.str.extract,s0.str.extractall,s0.str.findall]:
    # for pat0 in ['([A-C\s])([D\s])','(?P<digitCol0>\d\d)']:
        # for expand0 in [True,False]:
            # print('f0,pat0,expand0',f0,pat0,expand0)
            # try:
                # print(f0(pat0,expand=expand0,flags=re.IGNORECASE))
            # except Exception as e:
                # print(e)
                # print(f0(pat0,flags=re.IGNORECASE))

# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)
# # print(df)
# s0=df['comp_url']
# print(s0)
# for f0 in [s0.str.find,s0.str.rfind,s0.str.index,s0.str.rindex]:
    # print(f0)
    # try:
        # print(f0('.co'))
    # except Exception as e:
        # print(e)
    # try:
        # print(f0('.co',start=11,end=15))
    # except Exception as e:
        # print(e)
# for f0 in print(df['comp_name_2'].)
# shape0 = (3,4,)
# for f0 in [torch.rand,torch.ones,torch.zeros]:
    # print(f0(shape0))
# t0z0=torch.from_numpy(numpy.array([[1,1+1j],[1-1j,-1]]))
# for a0 in dir(t0z0):
    # try:
        # print(a0,'    ',getattr(t0z0,a0))
    # except Exception as e:
        # print(e)

# # Create a sparse tensor
# indices = torch.tensor([[0, 1, 1],
                        # [2, 0, 2]])
# values = torch.tensor([3, 4, 5])
# sparse_tensor = torch.sparse_coo_tensor(indices, values, size=(3, 3))

# # Get the dimensions of the index and value tensors
# print(sparse_tensor)
# print(sparse_tensor[0])
# print(sparse_tensor[1])
# print(sparse_tensor[2])
# print(sparse_tensor._dimI())  # 2
# print(sparse_tensor._dimV())  # 1
# print(sparse_tensor._nnz())

# indices = torch.tensor([[0, 1],
                        # [2, 0]])
# values = torch.tensor([3, 4])
# sparse_tensor = torch.sparse_coo_tensor(indices, values, size=(3, 3))

# # Get the dimensions of the index and value tensors
# print(sparse_tensor)
# print(torch.tensor(sparse_tensor))
# # print(sparse_tensor.clone().detach().requires_grad_(True))
# print(sparse_tensor.clone().detach())
# print(sparse_tensor[0])
# print(sparse_tensor[1])
# print(sparse_tensor[2])
# print(sparse_tensor._dimI())  # 2
# print(sparse_tensor._dimV())  # 1
# print(sparse_tensor._nnz())

# indices = torch.tensor([[0, 1,0],
                        # [4, 0,2]])
# values = torch.tensor([3, 4, 5])
# sparse_tensor = torch.sparse_coo_tensor(indices, values, size=(3, 5))

# # Get the dimensions of the index and value tensors
# print(sparse_tensor)
# print(torch.tensor(sparse_tensor))
# # print(sparse_tensor.clone().detach().requires_grad_(True))
# print(sparse_tensor.clone().detach())
# print(sparse_tensor[0])
# print(sparse_tensor[1])
# print(sparse_tensor[2])
# print(sparse_tensor._dimI())  # 2
# print(sparse_tensor._dimV())  # 1
# print(sparse_tensor._nnz())

# indices = torch.tensor([[0, 1,0],
                        # [4, 0,4]])
# values = torch.tensor([3, 4, 5])
# sparse_tensor = torch.sparse_coo_tensor(indices, values, size=(3, 5))

# # Get the dimensions of the index and value tensors
# print(sparse_tensor)
# print(torch.tensor(sparse_tensor))
# # print(sparse_tensor.clone().detach().requires_grad_(True))
# print(sparse_tensor.clone().detach())
# print(sparse_tensor[0])
# print(sparse_tensor[1])
# print(sparse_tensor[2])
# print(sparse_tensor._dimI())  # 2
# print(sparse_tensor._dimV())  # 1
# print(sparse_tensor._nnz())
# print(sparse_tensor.coalesce())

# print(torch.tensor([1+1j,1-2j,1+3j]))
# print(torch.tensor([1+1j,1-2j,1+3j]).is_conj())
# print(torch.tensor([1+1j,1-2j,1+3j])._conj())
# print(torch.tensor([1+1j,1-2j,1+3j])._conj().is_conj())
# print(torch.tensor([1+1j,1-2j,1+3j])._conj_physical())
# print(torch.tensor([1+1j,1-2j,1+3j])._conj_physical().is_conj())
# print(torch.tensor([1+1j,1-2j,1+3j]).resolve_conj())
# print(torch.tensor([1+1j,1-2j,1+3j])._conj().resolve_conj())
# print(torch.tensor([1+1j,1-2j,1+3j])._conj()==torch.tensor([1+1j,1-2j,1+3j])._conj_physical())
# print(torch.tensor([1,2,3]))
# print(torch.tensor([1,2,3]).is_conj())
# # print(torch.tensor([1,2,3])._conj())
# # print(torch.tensor([1,2,3])._conj().is_conj())
# print(torch.tensor([1,2,3])._conj_physical())
# print(torch.tensor([1,2,3])._conj_physical().is_conj())
# print(torch.tensor([1,2,3]).resolve_conj())
# # print(torch.tensor([1,2,3])._conj().resolve_conj())
# # print(torch.tensor([1,2,3])._conj()==torch.tensor([1,2,3])._conj_physical())



# torch.manual_seed(6)
# x=torch.randn(4,4,requires_grad=True)
# y=torch.randn(4,4,requires_grad=True)
# z=x*y
# l=z.sum()
# # l=z.prod()
# # l.backward(retain_graph=True)#if you retain graph the 2nd pass won't be the same as the 1st, which makes sense since it'll be the 2nd time gradients (of loss function with respect to input(s)) are calculated and applied
# l.backward()
# print(x)
# print(x.grad)
# print(x.grad_fn)
# print(y)
# print(y.grad)
# print(y.grad_fn)
# print(z)
# print(z.grad)
# print(z.grad_fn)
# print(l)
# print(l.grad)
# print(l.grad_fn)

# torch.manual_seed(6)
# x=torch.randn(4,4,requires_grad=True)
# print(x)
# y=torch.randn(4,4,requires_grad=True)
# with torch.no_grad():
    # z=x*y
    # print(x.requires_grad)
    # print(z)
# print(x.detach())
# print(x)
# print(x.requires_grad_(False))
# print(x)
# l=z.sum()
# l.backward(create_graph=True)
# print(x)
# print(x.grad)
# print(x.grad_fn)
# print(y)
# print(y.grad)
# print(y.grad_fn)
# print(z)
# print(z.grad)
# print(z.grad_fn)
# print(l)
# print(l.grad)
# print(l.grad_fn)
# l.backward()
# print(x)
# print(x.grad)
# print(x.grad_fn)
# print(y)
# print(y.grad)
# print(y.grad_fn)
# print(z)
# print(z.grad)
# print(z.grad_fn)
# print(l)
# print(l.grad)
# print(l.grad_fn)




# torch.manual_seed(6)
# x=torch.randn(4,4,requires_grad=True)
# y=torch.randn(4,4,requires_grad=True)
# z=x*y
# l=z.sum()
# l.backward(inputs=[y])
# print(x)
# print(x.grad)
# print(x.grad_fn)
# print(y)
# print(y.grad)
# print(y.grad_fn)
# print(z)
# print(z.grad)
# print(z.grad_fn)
# print(l)
# print(l.grad)
# print(l.grad_fn)


# torch.manual_seed(6)
# x=torch.randn(4,4,requires_grad=True)
# y=torch.randn(4,4,requires_grad=True)
# z=x*y
# l=z.sum()
# l.backward(gradient=torch.tensor(3.))
# print(x)
# print(x.grad)
# print(x.grad_fn)
# print(y)
# print(y.grad)
# print(y.grad_fn)
# print(z)
# print(z.grad)
# print(z.grad_fn)
# print(l)
# print(l.grad)
# print(l.grad_fn)

# torch.manual_seed(6)
# x=torch.randn(4,4,requires_grad=True)
# y=torch.randn(4,4,requires_grad=True)
# z=x*y
# l=z.sum()
# l.backward(gradient=torch.tensor(1.))
# print(x)
# print(x.grad)
# print(x.grad_fn)
# print(y)
# print(y.grad)
# print(y.grad_fn)
# print(z)
# print(z.grad)
# print(z.grad_fn)
# print(l)
# print(l.grad)
# print(l.grad_fn)

# torch.manual_seed(6)
# x=torch.randn(4,4,requires_grad=True)
# y=torch.randn(4,4,requires_grad=True)
# z=x*y
# l=z.sum()
# l.backward(gradient=torch.tensor(.5))
# print(x)
# print(x.grad)
# print(x.grad_fn)
# print(y)
# print(y.grad)
# print(y.grad_fn)
# print(z)
# print(z.grad)
# print(z.grad_fn)
# print(l)
# print(l.grad)
# print(l.grad_fn)

# torch.manual_seed(6)
# x=torch.randn(4,4,requires_grad=True)
# y=torch.randn(4,4,requires_grad=True)
# z=x*y
# l=z.sum()
# # # l.backward()
# dl=torch.tensor(1.)
# # dl=torch.tensor(2.4706)
# print(dl)
# backSum0=l.grad_fn
# print(backSum0)
# dz=backSum0(dl)
# print(dz)
# backMul0=backSum0.next_functions[0][0]
# print(backMul0)
# dx,dy=backMul0(dz)
# print(dx)
# print(dy)
# backX0=backMul0.next_functions[0][0]
# backY0=backMul0.next_functions[1][0]
# print(backX0)
# print(backY0)
# # print(x)
# print(backX0(dx))
# print(backY0(dy))
# print(x.grad)
# print(y.grad)
# print(x)
# print(y)

# print(torch.cuda)
# print(torch.cuda.is_available())
# if torch.cuda.is_available():
    # device0=torch.device("cuda:0")
    # x=torch.tensor([2,2],dtype=torch.float16,device=device0)
    # y=torch.tensor([1,1])
    # y.to(device0)
    # print(x)
    # print(y)
    # y.to('cpu')
    
# tensor0=torch.ones((4,),requires_grad=True)
# for epoch0 in range(3):
    # modelOutput0=(tensor0*3).sum()
    # modelOutput0.backward()
    # print(tensor0)
    # print(tensor0.grad)
    # # tensor0.grad.zero_()
    # print(tensor0.grad)
# # optimSGD0=torch.optim.SGD(tensor0,lr=.01)
# optimSGD0.step()
# optimSGD0.zero_grad_()




# x=torch.tensor(1.)
# print(x)
# w=torch.tensor(1.,requires_grad=True)
# print(w)
# yActual=torch.tensor(2.)
# print(yActual)
# yEstimate=x*w
# print(yEstimate)
# loss0=(yEstimate-yActual)**2
# print(loss0)
# loss0.backward()
# print(w.grad)

# x=numpy.array([1,2,3,4])
# y=numpy.array([2,4,6,8])
# w=0
# def cP(x):
    # return x*w
# def cL(pY,y):
    # return ((pY-y)**2).mean()
# def cG(x,pY,y):
    # return numpy.dot(2*x,pY-y).mean()
# nI=20
# lR=.01
# for lR in [.001,.1,.01]:
    # w=0
    # for e in range(nI):
        # pY=cP(x)
        # l=cL(pY,y)
        # dw=cG(x,pY,y)
        # w-=lR*dw
        # print(lR,x,y,pY,l,dw,w)



# x=torch.tensor([1,2,3,4],dtype=torch.float16)
# y=torch.tensor([2,4,6,8],dtype=torch.float16)
# w=torch.tensor(0.,dtype=torch.float16,requires_grad=True)
# def cP(x):
    # return x*w
# def cL(pY,y):
    # return ((pY-y)**2).mean()
# nI=20
# lR=.01
# for lR in [.001,.1,.01]:
    # w=torch.tensor(0.,dtype=torch.float16,requires_grad=True)
    # for e in range(nI):
        # pY=cP(x)
        # l=cL(pY,y)
        # l.backward()
        # with torch.no_grad():
            # w-=lR*w.grad
        # print(lR,x,y,pY,l,w.grad,w)
        # w.grad.zero_()


# x=torch.tensor([1,2,3,4],dtype=torch.float32)
# y=torch.tensor([2,4,6,8],dtype=torch.float32)
# w=torch.tensor(0.,dtype=torch.float32,requires_grad=True)
# cL=torch.nn.MSELoss()
# def cP(x):
    # return x*w
# lR=.01
# for lR in [.001,.1,.01]:
    # w=torch.tensor(0.,dtype=torch.float32,requires_grad=True)
    # for e in range(nI):
        # pY=cP(x)
        # l=cL(pY,y)
        # l.backward()
        # with torch.no_grad():
            # w-=lR*w.grad
        # print(lR,x,y,pY,l,w.grad,w,sep='\n',end='\n\n\n')
        # w.grad.zero_()
        
# x=torch.tensor([1,2,3,4],dtype=torch.float32)
# y=torch.tensor([2,4,6,8],dtype=torch.float32)
# w=torch.tensor(0.,dtype=torch.float32,requires_grad=True)
# cL=torch.nn.MSELoss(reduction='sum')
# def cP(x):
    # return x*w
# lR=.01
# for lR in [.001,.1,.01]:
    # w=torch.tensor(0.,dtype=torch.float32,requires_grad=True)
    # for e in range(nI):
        # pY=cP(x)
        # l=cL(pY,y)
        # l.backward()
        # with torch.no_grad():
            # w-=lR*w.grad
        # print(lR,x,y,pY,l,w.grad,w,sep='\n',end='\n\n\n')
        # w.grad.zero_()

# df = pandas.DataFrame([
    # [1, 2, 3, 4,21,22],
    # [5, 6, 7, 8,21,22],
    # [9, 10, 11, 12,21,22],
# ]).set_index([0,1],append=True).rename_axis(['l0','l1','l2'])
# print(df)
# df=df.T.set_index(pandas.MultiIndex.from_product([[0,1],[10,11]],names=['l0','l1']),append=True).T
# # df.columns=pandas.MultiIndex.from_product([[0,1],[10,11]],names=['l0','l1'])
# print(df)
# print(df.droplevel('l0'))
# print(df.droplevel('l0',axis=1))
# print(df.droplevel(0))
# print(df.droplevel(0,axis=1))
# print(df.droplevel([0,1]))
# print(df.droplevel([0,1],axis=1))

# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)
# # print(df)
# # s0=df['comp_url']
# s0=df['comp_name_2']
# print(s0)
# print(s0.str.replace('inc.','INCORPORATED',case=False))
# print(s0.str.replace('inc.','INCORPORATED'))
# import re
# print(s0.str.replace('inc.','INCORPORATED',case=False,flags=re.IGNORECASE))#'flags' overrides 'case'
# print('n=2')
# print(s0.str.replace('Inc.','INCORPORATED',n=2))
# s0=df['officer_name_2']
# print(s0)
# compile0=re.compile('\.\W\w+')
# print('compile0')
# print(s0.str.replace(compile0,' LastName0'))
# print(s0.str.replace('\.\W\w+',' LastName0'))
# print(s0.str.replace('J.','MiddleInitialJ0',regex=False))
# def printingLastNameInReverse0(match0):
    # print(f'{match0.group(0)} is being printed in reverse')
    # return '. '+match0.group(0)[::-1]
# print(s0.str.replace('\.\W\w+',printingLastNameInReverse0))
# print(s0.str.replace('\.\W\w+',printingLastNameInReverse0,n=5))

# nI=20
# lR=.01
# x=torch.tensor([1,2,3,4],dtype=torch.float32)
# y=torch.tensor([2,4,6,8],dtype=torch.float32)
# w=torch.tensor(0.,dtype=torch.float32,requires_grad=True)
# cL=torch.nn.MSELoss(reduction='sum')
# o0=torch.optim.SGD([w],lr=lR)
# # o0=torch.nn.SGD([w],lr=.01,weight_decay=.2,momentum=.5,dampening=.1,nesterov=True,maximize=True,foreach=True,differentiable=True)
# def cP(x):
    # return x*w
# for e in range(nI):
    # pY=cP(x)
    # l=cL(pY,y)
    # l.backward()
    # o0.step()
    # print(lR,x,y,pY,l,w.grad,w,sep='\n',end='\n\n\n')
    # o0.zero_grad()


# nI=20
# lR=.01
# x=torch.tensor([1,2,3,4],dtype=torch.float32)
# y=torch.tensor([2,4,6,8],dtype=torch.float32)
# w=torch.tensor(0.,dtype=torch.float32,requires_grad=True)
# cL=torch.nn.MSELoss(reduction='sum')
# def cP(x):
    # return x*w
# for weight_decay0 in [0.,.2,.8]:
    # for momentum0 in [0.,.2,.8]:
        # for dampening0 in [0.,.2,.8]:
            # for nesterov0 in [False,True]:
                # for foreach0 in [False,True]:
                    # for maximize0 in [False,True]:
                        # for differentiable0 in [False,True]:
                            # print('weight_decay0,momentum0,dampening0,nesterov0,maximize0,foreach0,differentiable0')
                            # print(weight_decay0,momentum0,dampening0,nesterov0,maximize0,foreach0,differentiable0)
                            # try:
                                # listOfl0=[]
                                # o0=torch.optim.SGD([w],lr=.01,weight_decay=weight_decay0,momentum=momentum0,dampening=dampening0,nesterov=nesterov0,maximize=maximize0,foreach=foreach0)
                                # # o0=torch.optim.SGD([w],lr=lR)
                                # for e in range(nI):
                                    # pY=cP(x)
                                    # l=cL(pY,y)
                                    # l.backward()#with 'differentiable=True' (65% sure it's True not False), we get 'RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.' since it's similar to doing backward('retain_graph=False') and second pass ?
                                    # o0.step()
                                    # print(lR,x,y,pY,l,w.grad,w,sep='\n',end='\n\n\n')
                                    # o0.zero_grad()
                                    # listOfl0.append(l.item())
                                # print('weight_decay0,momentum0,dampening0,nesterov0,maximize0,foreach0,differentiable0')
                                # print(weight_decay0,momentum0,dampening0,nesterov0,maximize0,foreach0,differentiable0)
                                # print(list(range(len(listOfl0))),listOfl0)
                                # matplotlib.pyplot.plot(list(range(len(listOfl0))),listOfl0,label=str([weight_decay0,momentum0,dampening0,nesterov0,maximize0,foreach0,differentiable0]))
                            # except Exception as e:
                                # print(e,sys.exc_info())
                            # print('\n\n\n\n')
# current_fig_manager0=matplotlib.pyplot.get_current_fig_manager()
# print(dir(current_fig_manager0))
# matplotlib.pyplot.legend()
# matplotlib.pyplot.show()


# nI=20
# lR=.01
# x=torch.tensor([1,2,3,4],dtype=torch.float32)
# y=torch.tensor([2,4,6,8],dtype=torch.float32)
# w=torch.tensor(0.,dtype=torch.float32,requires_grad=True)
# w1=torch.tensor(0.,dtype=torch.float32,requires_grad=True)
# w2=torch.tensor(0.,dtype=torch.float32,requires_grad=True)
# cL=torch.nn.MSELoss(reduction='sum')
# o0=torch.optim.SGD([w],lr=lR,weight_decay=.05)
# def cP(x):
    # return x*w
# for e in range(nI):
    # state_dict0=o0.state_dict()
    # print(state_dict0)
    # # o0.add_param_group({'params':{w1:.01}})
    # # o0.add_param_group({'lr': 0.02, 'momentum': 0, 'dampening': 0, 'weight_decay': 0.05, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0]})
    # # o0.add_param_group({'lr': 0.02,'weight_decay': 0.05,'params': [w2]})
    # o0.add_param_group({'momentum':.01,'params': [w2]})
    # # o0.add_param_group({'momentum':.01,'params': w2})
    # # print(o0.state_dict())
    # # # o0.load_state_dict(state_dict0)#must have the same number of parameter groups otherwise you get 'ValueError: loaded state dict has a different number of parameter groups'
    # # print(o0.state_dict())
    # pY=cP(x)
    # l=cL(pY,y)
    # l.backward()
    # o0.step()
    # print(lR,x,y,pY,l,w.grad,w,sep='\n',end='\n\n\n')
    # print(w)
    # o0.zero_grad(set_to_none=True)
    # print(w)


# nI = 20
# lR = 0.01
# x = torch.tensor([1, 2, 3, 4], dtype=torch.float32)
# y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)
# w = torch.tensor(0., dtype=torch.float32, requires_grad=True)
# w1 = torch.tensor(0., dtype=torch.float32, requires_grad=True)
# w2 = torch.tensor(1., dtype=torch.float32, requires_grad=True)
# cL = torch.nn.MSELoss(reduction='sum')
# o0 = torch.optim.SGD([w], lr=lR, weight_decay=0.05)
# def cP(x):
    # return x * w
# o0.add_param_group({'lr': 0.05, 'params': [w1]})
# state_dict0 = o0.state_dict()
# print(state_dict0)
# print(o0.param_groups)
# o0.add_param_group({'momentum': 0.01, 'params': [w2]})
# print(o0.param_groups)
# # o0.load_state_dict(state_dict0)#must have same parameter groups otherwise get 'ValueError: loaded state dict has a different number of parameter groups'; not as value-add as thought since can't add or remove parameter groups but you CAN tweak hyperparameters (adding, changing, or removing them) for the same tensors manually and add them in mid-run, which is cool
# # param_groups0=[{'params': [tensor(0., requires_grad=True)], 'lr': 0.015, 'momentum': 0, 'dampening': 0, 'weight_decay': 0.05, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False}, {'lr': 0.05, 'params': [tensor(0., requires_grad=True)], 'momentum': 0, 'dampening': 0, 'weight_decay': 0.05, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False}, {'momentum': 0.01, 'params': [tensor(1., requires_grad=True)], 'lr': 0.01, 'dampening': 0, 'weight_decay': 0.05, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False}]
# state_dict0={'state': {}, 'param_groups': [{'params': [torch.tensor(0., requires_grad=True)], 'lr': 0.015, 'momentum': 0, 'dampening': 0, 'weight_decay': 0.05, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False}, {'lr': 0.05, 'params': [torch.tensor(0., requires_grad=True)], 'momentum': 0, 'dampening': 0, 'weight_decay': 0.05, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False}, {'momentum': 0.01, 'params': [torch.tensor(1., requires_grad=True)], 'lr': 0.01, 'dampening': 0, 'weight_decay': 0.05, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False}]}
# o0.load_state_dict(state_dict0)
# print(o0.param_groups)
# for e in range(nI):
    # # o0.add_param_group({'momentum': 0.01, 'params': [w2]})#in a loop so won't work since 1st add works but subsequent adds error
    # pY = cP(x)
    # l = cL(pY, y)
    # l.backward()
    # o0.step()
    # print(lR, x, y, pY, l, w.grad, w, sep='\n', end='\n\n\n')
    # # o0.zero_grad()
    # print('0      ',w.grad)#result with '''o0.zero_grad()''' before is '''tensor(0.),tensor(0.),...''';result without '''o0.zero_grad()''' before is '''tensor(-0.2171), tensor(-0.1116), ...'''; both give '''None''' for '''print('1      ',w.grad)''' but '''None''' doesn't seem to do anything as error still goes to [close to] 0 after 20 runs..
    # o0.zero_grad(set_to_none=True)#only 0s get None-d
    # print('1      ',w.grad)



# x=torch.tensor([1,2,3,4],dtype=torch.float32)
# print(id(x))
# print(id(x.numpy()))#different id but same underlying data's memory (maybe metadata offsets)
# print(id(x.numpy(force=True)))
# xNumpy0=x.numpy()
# xNumpy0+=2
# print(xNumpy0)
# print(x)

# x=torch.tensor([1,2,3,4],dtype=torch.float32,requires_grad=True)
# print(id(x))
# try:
    # print(id(x.numpy()))
# except Exception as e:
    # print(e)
# print(id(x.detach().numpy()))
# print(id(x.detach().cpu().resolve_conj().resolve_neg().numpy()))
# print(id(x.numpy(force=True)))
# xNumpy0=x.numpy(force=True)#same memory if possible (like numpy)
# xNumpy0+=2
# print(xNumpy0)
# print(x)

# print(dir(torch.randn((3,3))))
# print(torch.randn((3,3)).stride())
# print(torch.randn((3,3,3)).stride())
# print(torch.randn((3,3,3)).contiguous().stride())
# print(torch.randn((3,3,3,3)).stride())
# print(torch.randn((3,3,3,3)).to(memory_format=torch.channels_last).stride())
# print(torch.randn((3,3,3,3,3)).stride())
# print(torch.randn((3,3,3,3,3)).to(memory_format=torch.channels_last_3d).stride())
# print(torch.randn((3,3,3,3,3)).to(memory_format=torch.channels_last_3d).to(memory_format=torch.contiguous_format).stride())
# print(torch.randn((3,3,3,3,3)).cpu(memory_format=torch.preserve_format).stride())
# print(torch.randn((3,3,3,3,3)).stride())
# print(torch.randn((3,3,3,3,3)).clone(memory_format=torch.preserve_format).stride())


# print(torch.tensor([1+1j,1-2j,1+3j])._conj())
# print(torch.tensor([1+1j,1-2j,1+3j])._conj().imag)
# print(torch.tensor([1+1j,1-2j,1+3j])._conj().imag.is_neg())
# print(torch.tensor([1+1j,1-2j,1+3j])._conj().resolve_neg())
# print(torch.tensor([1+1j,1-2j,1+3j])._conj().resolve_neg().imag)
# print(torch.tensor([1+1j,1-2j,1+3j])._conj().resolve_neg().imag.is_neg())
# print(torch.tensor([1+1j,1-2j,1+3j])._conj().is_neg())
# print(torch.tensor([1+1j,1-2j,1+3j])._conj().resolve_neg().is_neg())

# print(torch.tensor([-1+1j,1-2j,1+3j])._conj())
# print(torch.tensor([-1+1j,1-2j,1+3j])._conj().imag)
# print(torch.tensor([-1+1j,1-2j,1+3j])._conj().imag.is_neg())
# print(torch.tensor([-1+1j,1-2j,1+3j])._conj().resolve_neg())
# print(torch.tensor([-1+1j,1-2j,1+3j])._conj().resolve_neg().imag)
# print(torch.tensor([-1+1j,1-2j,1+3j])._conj().resolve_neg().imag.is_neg())
# print(torch.tensor([-1+1j,1-2j,1+3j])._conj().is_neg())
# print(torch.tensor([-1+1j,1-2j,1+3j])._conj().resolve_neg().is_neg())

# print(torch.tensor([-1+1j,1-2j,1+3j]).conj())
# print(torch.tensor([-1+1j,1-2j,1+3j]).conj().imag)
# print(torch.tensor([-1+1j,1-2j,1+3j]).conj().imag.is_neg())
# print(torch.tensor([-1+1j,1-2j,1+3j]).conj().resolve_neg())
# print(torch.tensor([-1+1j,1-2j,1+3j]).conj().resolve_neg().imag)
# print(torch.tensor([-1+1j,1-2j,1+3j]).conj().resolve_neg().imag.is_neg())
# print(torch.tensor([-1+1j,1-2j,1+3j]).conj().is_neg())
# print(torch.tensor([-1+1j,1-2j,1+3j]).conj().resolve_neg().is_neg())


# try:
    # print(torch.signbit(torch.tensor([-1+1j,1-2j,1+3j])))
# except Exception as e:
    # print(e)
# # print(torch.signbit(torch.tensor([-1+1j,1-2j,1+3j]).conj()))
# print(torch.signbit(torch.tensor([-1,-0.,-0,0,1]))) 



# nI=200
# lR=.01
# x=torch.tensor([1,2,3,4],dtype=torch.float32)
# # print(torch.from_numpy(numpy.expand_dims(x.numpy(),1)))
# x=torch.from_numpy(numpy.expand_dims(x.numpy(),1))
# y=torch.tensor([2,4,6,8],dtype=torch.float32)
# y=torch.from_numpy(numpy.expand_dims(y.numpy(),1))
# w=torch.tensor(0.,dtype=torch.float32,requires_grad=True)
# m0=torch.nn.Linear(1,1)
# cL=torch.nn.MSELoss(reduction='sum')
# print(m0.parameters())
# o0=torch.optim.SGD(m0.parameters(),lr=lR)
# for e in range(nI):
    # pY=m0(x)
    # l=cL(pY,y)
    # l.backward()
    # o0.step()
    # print(e,lR,x,y,pY,l,str(list(m0.parameters())),sep='\n',end='\n\n\n')
    # o0.zero_grad()

# o0=torch.nn.Module
# for a0 in dir():
    # try:
        # print(a0,'    ',getattr(o0,a0))
    # except Exception as e:
        # print(e)


# nI=200
# lR=.01
# x=torch.tensor([1,2,3,4],dtype=torch.float32)
# # print(torch.from_numpy(numpy.expand_dims(x.numpy(),1)))
# x=torch.from_numpy(numpy.expand_dims(x.numpy(),1))
# y=torch.tensor([2,4,6,8],dtype=torch.float32)
# y=torch.from_numpy(numpy.expand_dims(y.numpy(),1))
# w=torch.tensor(0.,dtype=torch.float32,requires_grad=True)
# class lC0(torch.nn.Module):
    # def __init__(self,i0,o0):
        # # super(lC0,self).__init__()
        # super().__init__()
        # self.m1=torch.nn.Linear(i0,o0)
    # def forward(self,i1):
        # print('calculatingForwardPass')
        # return self.m1(i1)
# m0=lC0(1,1)
# cL=torch.nn.MSELoss(reduction='sum')
# print(m0.parameters())
# o0=torch.optim.SGD(m0.parameters(),lr=lR)
# for e in range(nI):
    # pY=m0(x)
    # l=cL(pY,y)
    # l.backward()
    # o0.step()
    # print(e,lR,x,y,pY,l,str(list(m0.parameters())),sep='\n',end='\n\n\n')
    # o0.zero_grad()

# import sklearn.datasets
# for n_samples0 in [15,100]:
    # for n_features0 in [1,100]:
        # for n_informative0 in [1,10]:
            # for n_targets0 in [1,3]:
                # for bias0 in [0.,.1]:
                    # for effective_rank0 in [None,2]:
                        # for tail_strength0 in [0.,.1]:
                            # for random_state0 in [2,None]:
                                # for coef0 in [False,True]:
                                    # for noise0 in [0.,.1]:
                                        # for shuffle0 in [False,True]:

                                            # print(f'n_samples {n_samples0}',f'n_features {n_features0}',f'n_informative {n_informative0}',f'n_targets {n_targets0}',f'bias {bias0}',f'effective_rank {effective_rank0}',f'tail_strength {tail_strength0}',f'random_state {random_state0}',f'coef {coef0}',f'noise {noise0}',f'shuffle {shuffle0}',sep='\r\n')
                                            # print(sklearn.datasets.make_regression(n_samples=n_samples0,n_features=n_features0,n_informative=n_informative0,n_targets=n_targets0,bias=bias0,effective_rank=effective_rank0,tail_strength=tail_strength0,random_state=random_state0,coef=coef0,noise=noise0,shuffle=shuffle0))


# nI=200
# lR=.01
# x=torch.tensor([1,2,3,4],dtype=torch.float32)
# # print(torch.from_numpy(numpy.expand_dims(x.numpy(),1)))
# x=torch.from_numpy(numpy.expand_dims(x.numpy(),1))
# y=torch.tensor([2,4,6,8],dtype=torch.float32)
# y=torch.from_numpy(numpy.expand_dims(y.numpy(),1))
# w=torch.tensor(0.,dtype=torch.float32,requires_grad=True)
# class lC0(torch.nn.Module):
    # def __init__(self,i0,o0):
        # # super(lC0,self).__init__()
        # super().__init__()
        # self.m1=torch.nn.Linear(i0,o0)
    # def forward(self,i1):
        # print('calculatingForwardPass')
        # return self.m1(i1)
# m0=lC0(1,1)
# cL=torch.nn.MSELoss(reduction='sum')
# print(m0.parameters())
# o0=torch.optim.SGD(m0.parameters(),lr=lR)
# for e in range(nI):
    # pY=m0(x)
    # l=cL(pY,y)
    # l.backward()
    # o0.step()
    # print(e,lR,x,y,pY,l,str(list(m0.parameters())),sep='\n',end='\n\n\n')
    # o0.zero_grad()

# y=torch.tensor([2,4,6,8],dtype=torch.float32)
# print(y)
# print(y.view((2,2)))
# print(y.view((-1,2)))
# print(y.dtype)
# print(y.view(torch.float64))
# print(y.view(torch.float16))
# y=torch.tensor([2,4,6,8,2,4,6,9],dtype=torch.float32)
# y=torch.tensor([[2,4,6,8],[2,4,6,9]],dtype=torch.float32)
# y=y.view((4,2))
# print(y)
# print(y.dtype)
# print(y.view(torch.float64))
# print(y.view(torch.float16))
# y=torch.tensor([[2,4],[6,8],[2,4],[6,9]],dtype=torch.float32)
# print(y)
# print(y.dtype)
# print(y.view(torch.float64))
# print(y.view(torch.float16))
# print(y.view(torch.cfloat))
# y1=y.clone()
# z=y.view(torch.int32)
# print(z)
# z[0,0]=10000000
# print(y)
# print('\n')
# print(y1)
# z=y1.view(torch.int32)
# z[0,0]=1000000000
# print(y1)

# 1064483442
# 1000000000


# import sklearn.datasets
# # x0,y0=sklearn.datasets.make_regression(n_samples=100,n_features=1,noise=.1,random_state=42)
# x0,y0=sklearn.datasets.make_regression(n_samples=100,n_features=1,noise=20,random_state=42)
# nI=100
# lR=.01
# x=torch.from_numpy(x0.astype(numpy.float32))
# y=torch.from_numpy(y0.astype(numpy.float32))
# y.view(y.shape[0],1)
# # y=torch.from_numpy(numpy.expand_dims(y.numpy(),1))
# # z=torch.tensor([2.,4.,6.,8.],dtype=torch.float32)
# # z=torch.from_numpy(numpy.expand_dims(z.numpy(),1))
# # print(x.shape,y.shape,z.shape)
# # class lC0(torch.nn.Module):
    # # def __init__(self,i0,o0):
        # # # super(lC0,self).__init__()
        # # super().__init__()
        # # self.m1=torch.nn.Linear(i0,o0)
    # # def forward(self,i1):
        # # print('calculatingForwardPass')
        # # return self.m1(i1)
# n_samples,n_features=x.shape
# output_size=1
# # m0=lC0(1,1)
# m0=torch.nn.Linear(n_features,output_size)
# # cL=torch.nn.MSELoss(reduction='sum')#this will drive error to infinity as we're looking for MEAN squared error as loss not SUMming the values
# cL=torch.nn.MSELoss()
# o0=torch.optim.SGD(m0.parameters(),lr=lR)
# for e in range(nI):
    # pY=m0(x)
    # l=cL(pY,y)
    # l.backward()
    # o0.step()
    # # print(e,lR,x,y,pY,l,str(list(m0.parameters())),sep='\n',end='\n\n\n')
    # print(str(e)+'   '+str(l.item()),sep='\n',)
    # o0.zero_grad()
# yNumpy0=m0(x).detach().numpy()
# matplotlib.pyplot.scatter(x0,y0)
# matplotlib.pyplot.plot(x0,yNumpy0)
# matplotlib.pyplot.show()



# import sklearn.datasets
# x0,y0=sklearn.datasets.make_regression(n_samples=100,n_features=1,noise=20,random_state=4)
# x=torch.from_numpy(x0.astype(numpy.float32))
# y=torch.from_numpy(y0.astype(numpy.float32))
# y=y.view(y.shape[0],1)
# n_samples,n_features=x.shape
# input_size=n_features
# output_size=1
# m0=torch.nn.Linear(input_size,output_size)
# lR=0.01
# cL=torch.nn.MSELoss()
# o0=torch.optim.SGD(m0.parameters(),lr=lR)
# nI=100
# for e in range(nI):
    # pY=m0(x)
    # l=cL(pY,y)
    # l.backward()
    # o0.step()
    # # print(str(e)+'   '+str(l.item()),sep='\n',)
    # o0.zero_grad()
# yNumpy0=m0(x).detach().numpy()
# matplotlib.pyplot.scatter(x0,y0)
# matplotlib.pyplot.plot(x0,yNumpy0)
# matplotlib.pyplot.show()



# import torch
# import torch.nn as nn
# import numpy as np
# from sklearn import datasets
# import matplotlib.pyplot as plt

# # 0) Prepare data
# X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)

# # cast to float Tensor
# X = torch.from_numpy(X_numpy.astype(np.float32))
# y = torch.from_numpy(y_numpy.astype(np.float32))
# y = y.view(y.shape[0], 1)

# n_samples, n_features = X.shape

# # 1) Model
# # Linear model f = wx + b
# input_size = n_features
# output_size = 1
# model = nn.Linear(input_size, output_size)

# # 2) Loss and optimizer
# learning_rate = 0.01

# criterion = nn.MSELoss()
# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  

# # 3) Training loop
# num_epochs = 100
# for epoch in range(num_epochs):
    # # Forward pass and loss
    # y_predicted = model(X)
    # loss = criterion(y_predicted, y)
    
    # # Backward pass and update
    # loss.backward()
    # optimizer.step()

    # # zero grad before new step
    # optimizer.zero_grad()

    # if (epoch+1) % 10 == 0:
        # print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')

# # Plot
# predicted = model(X).detach().numpy()

# plt.plot(X_numpy, y_numpy, 'ro')
# plt.plot(X_numpy, predicted, 'b')


# import sklearn.preprocessing
# import sklearn.datasets

# # for return_X_y0 in [False,True]:
    # # for as_frame0 in [False,True]:
        # # print(f'return_X_y {return_X_y0}',f'as_frame {as_frame0}',sep='\n')
        # # print(sklearn.datasets.load_breast_cancer(return_X_y=return_X_y0,as_frame=as_frame0))
        # # object0=sklearn.datasets.load_breast_cancer(return_X_y=return_X_y0,as_frame=as_frame0)
        # # for a0 in dir(object0):
            # # try:
                # # print(a0,'    ',getattr(object0,a0))
            # # except Exception as e:
                # # print(e,sys.exc_info())

# # load_breast_cancer0=sklearn.datasets.load_breast_cancer()
# # x0,y0=load_breast_cancer0.data,load_breast_cancer0.target
# t000=time.perf_counter()
# sample_weight0=numpy.ones((569,))*.1
# sample_weight0[0]=20
# x0,y0=sklearn.datasets.load_breast_cancer(return_X_y=True)
# for copy0 in [True,False]:
    # for with_mean0 in [True,False]:
        # for with_std0 in [True,False]:
            # print(f'copy {copy0}',f'with_mean {with_mean0}',f'with_std {with_std0}',sep='\n')
            # standardScaler0=sklearn.preprocessing.StandardScaler(copy=copy0,with_mean=with_mean0,with_std=with_std0)
            # standardScaler0.fit(x0,y0)
            # # standardScaler0.partial_fit(x0,y0)
            # # print(standardScaler0.get_feature_names_out())
            # # for deep0 in [True,False]:
                # # print(f'deep {deep0}',sep='\n')
                # # print(standardScaler0.set_params(**{'copy': False, 'with_mean': False, 'with_std': False}))
                # # print(standardScaler0.get_params(deep=deep0))
            # # for copy1 in [False,True]:
                # # print(f'copy {copy1}',sep='\n')
                # # print(standardScaler0.transform(x0,copy=copy1))
            # # for sample_weight1 in [None,sample_weight0]:
                # # print(f'sample_weight {sample_weight1}',sep='\n')
                # # print(standardScaler0.fit_transform(x0,y0,sample_weight=sample_weight0))
                # # print(standardScaler0.fit_transform(x0,sample_weight=sample_weight0))
            # print(standardScaler0.transform(x0))#without 'fit' call first, raises error!
            # # for transform0 in [None,'default','pandas']:
                # # print(f'transform {transform0}',sep='\n')
                # # print(standardScaler0.set_output(transform=transform0))
                # # print('transform0',type(standardScaler0.transform(x0)),standardScaler0.transform(x0))
                # # print('inverse_transform0',standardScaler0.inverse_transform(standardScaler0.transform(x0,copy=True),copy=True))
            # standardScaler0.fit(x0,y0,sample_weight=sample_weight0)
            # print(standardScaler0.transform(x0))
            # # object0=standardScaler0
            # # for a0 in dir(object0):
                # # try:
                    # # print(a0,'    ',getattr(object0,a0))
                # # except Exception as e:
                    # # print(e,sys.exc_info())
            # # print(standardScaler0)
# t100=time.perf_counter()
# print(t100-t000)
# t100t000=t100-t000

# t200=time.perf_counter()
# sample_weight0=numpy.ones((569,))*.1
# sample_weight0[0]=20
# x0,y0=sklearn.datasets.load_breast_cancer(return_X_y=True)
# for copy0 in [True,False]:
    # for with_mean0 in [True,False]:
        # for with_std0 in [True,False]:
            # print(f'copy {copy0}',f'with_mean {with_mean0}',f'with_std {with_std0}',sep='\n')
            # standardScaler0=sklearn.preprocessing.StandardScaler(copy=copy0,with_mean=with_mean0,with_std=with_std0)
            # standardScaler0.partial_fit(x0,y0)
            # # standardScaler0.partial_fit(x0,y0)
            # # print(standardScaler0.get_feature_names_out())
            # # for deep0 in [True,False]:
                # # print(f'deep {deep0}',sep='\n')
                # # print(standardScaler0.set_params(**{'copy': False, 'with_mean': False, 'with_std': False}))
                # # print(standardScaler0.get_params(deep=deep0))
            # # for copy1 in [False,True]:
                # # print(f'copy {copy1}',sep='\n')
                # # print(standardScaler0.transform(x0,copy=copy1))
            # # for sample_weight1 in [None,sample_weight0]:
                # # print(f'sample_weight {sample_weight1}',sep='\n')
                # # print(standardScaler0.fit_transform(x0,y0,sample_weight=sample_weight0))
                # # print(standardScaler0.fit_transform(x0,sample_weight=sample_weight0))
            # print(standardScaler0.transform(x0))#without 'fit' call first, raises error!
            # # for transform0 in [None,'default','pandas']:
                # # print(f'transform {transform0}',sep='\n')
                # # print(standardScaler0.set_output(transform=transform0))
                # # print('transform0',type(standardScaler0.transform(x0)),standardScaler0.transform(x0))
                # # print('inverse_transform0',standardScaler0.inverse_transform(standardScaler0.transform(x0,copy=True),copy=True))
            # standardScaler0.partial_fit(x0,y0,sample_weight=sample_weight0)
            # print(standardScaler0.transform(x0))
            # # object0=standardScaler0
            # # for a0 in dir(object0):
                # # try:
                    # # print(a0,'    ',getattr(object0,a0))
                # # except Exception as e:
                    # # print(e,sys.exc_info())
            # # print(standardScaler0)
# t300=time.perf_counter()
# print(t300-t200)
# t300t200=t300-t200
# print('should be positive0 ',t100t000-t300t200)#'partial_fit' is slightly faster than 'fit'


# # import sklearn.datasets,sklearn.model_selection
# from sklearn import *
# # # x0,y0=sklearn.datasets.load_breast_cancer(return_X_y=True)
# # # for test_size0 in [None,.2,100]:
    # # # for train_size0 in [None,.6,469]:
        # # # for random_state0 in [42,None]:
            # # # for shuffle0 in [False,True]:
                # # # for stratify0 in [None,y0]:
                    # # # print(f'test_size {test_size0}',f'train_size {train_size0}',f'random_state {random_state0}',f'shuffle {shuffle0}',f'stratify {stratify0}',sep='\n')
                    # # # try:
                        # # # x0Train,x0Test,y0Train,y0Test=sklearn.model_selection.train_test_split(x0,y0,test_size=test_size0,train_size=train_size0,random_state=random_state0,shuffle=shuffle0,stratify=stratify0)
                    # # # except Exception as e:
                        # # # print(e)
                    # # # print('x0Train',x0Train,'x0Test',x0Test,'y0Train',y0Train,'y0Test',y0Test,sep='\n')
                    # # # print('len0Train',len(y0Train)/len(y0),sep='\n')
                    # # # print('len0Test',len(y0Test)/len(y0),sep='\n')
                    # # # print('proportiony0Train',numpy.bincount(y0Train)/len(y0Train),sep='\n')
                    # # # print('proportiony0Test',numpy.bincount(y0Test)/len(y0Test),sep='\n')

# x0,y0=sklearn.datasets.load_breast_cancer(return_X_y=True,as_frame=True)
# x0Train,x0Test,y0Train,y0Test=sklearn.model_selection.train_test_split(x0,y0,random_state=42,stratify=y0)
# train0=pandas.concat([x0Train,y0Train],axis=1)
# test0=pandas.concat([x0Test,y0Test],axis=1)
# print(train0,test0)
# # import autogluon
# # from autogluon import *
# from autogluon.tabular import TabularDataset,TabularPredictor
# # print(TabularDataset)
# # train_data0=autogluon.tabular.TabularDataset(train0)
# # train_data0=tabular.TabularDataset(train0)
# train_data0=TabularDataset(train0)
# test_data0=TabularDataset(test0)
# tabularPredictor0=TabularPredictor(label='target').fit(train_data=train_data0)
# # predict0=tabularPredictor0.predict(test_data.drop('target',axis=1))
# predict0=tabularPredictor0.predict(test_data0.drop(columns=['target']))
# print(predict0)
# print(tabularPredictor0.evaluate(test_data0,silent=True))

# from sklearn import *
# x0,y0=sklearn.datasets.load_breast_cancer(return_X_y=True,as_frame=False)
# x0Train,x0Test,y0Train,y0Test=sklearn.model_selection.train_test_split(x0,y0,random_state=42,stratify=y0)

# # x0TestStandardScaler0,y0Train=sklearn.preprocessing.StandardScaler().fit_transform(x0Train,y0Train)
# x0TrainStandardScaler0=sklearn.preprocessing.StandardScaler().fit_transform(x0Train)
# # x0TestStandardScaler0,y0Test=sklearn.preprocessing.StandardScaler().fit_transform(x0Test,y0Test)
# x0TestStandardScaler0=sklearn.preprocessing.StandardScaler().fit_transform(x0Test)

# x0TrainTorch0=torch.from_numpy(x0TrainStandardScaler0.astype(numpy.float32))
# x0TestTorch0=torch.from_numpy(x0TestStandardScaler0.astype(numpy.float32))
# y0TrainTorch0=torch.from_numpy(y0Train.astype(numpy.float32))
# y0TestTorch0=torch.from_numpy(y0Test.astype(numpy.float32))

# print(x0TrainTorch0.shape,x0TestTorch0.shape,y0TrainTorch0.shape,y0TestTorch0.shape)
# y0TrainTorch0=y0TrainTorch0.view(y0TrainTorch0.shape[0],1)
# y0TestTorch0=y0TestTorch0.view(y0TestTorch0.shape[0],1)

# nI=200
# lR=.01
# class lR0(torch.nn.Module):
    # def __init__(self,i0,o0):
        # # super(lR0,self).__init__()
        # super().__init__()
        # self.m1=torch.nn.Linear(i0,o0)
    # def forward(self,i1):
        # print('calculatingForwardPass')
        # return torch.sigmoid(self.m1(i1))
# m0=lR0(x0TrainTorch0.shape[1],1)
# cL=torch.nn.BCELoss()
# print(m0.parameters())
# o0=torch.optim.SGD(m0.parameters(),lr=lR)
# for e in range(nI):
    # pY=m0(x0TrainTorch0)
    # l=cL(pY,y0TrainTorch0)
    # l.backward()
    # o0.step()
    # print(e,l.item(),sep='\n',end='\n\n\n')
    # o0.zero_grad()
# with torch.no_grad():
    # y0PredictedTorch0=m0(x0TestTorch0)
    # y0PredictedTorch0=y0PredictedTorch0.round()
    # # print(sum(y0PredictedTorch0==y0TestTorch0)/float(len(y0TestTorch0)))
    # print(sum(y0PredictedTorch0==y0TestTorch0)/float(len(y0TestTorch0)))

# import re
# s0=pandas.Series(['matchMe0','matchMe0 ',' matchMe0','matchme0',None],dtype=pandas.StringDtype())
# for pat0 in ['^matchMe0']:
    # for case0 in [True,False]:
        # for flags0 in [0,re.IGNORECASE]:
            # for na0 in [None,'matchMe0']:
                # print(f'pat {pat0}',f'case {case0}',f'flags {flags0}',f'na {na0}',sep='\n')
                # print(s0.str.fullmatch(pat0,case=case0,flags=flags0,na=na0))


# s = pd.Series(["String",
              # (1, 2, 3, 4),
              # ["a", "b", "c","3a"],
              # 123,
              # -456,
              # {1: "Hello","3a":"Awesome", "2": "World"}])
# for i0 in [1,2,3,0,-1,"3a"]:
    # print(f'i {i0}',sep='\n')
    # print(s.str.get(i0))

# s = pd.Series(["String",
            # (1, 2, 3, 4),
            # ["a", "b", "c","3a"],
            # [["a"],[ "b"]],
            # 123,
            # -456,
            # {1: "Hello","3a":"Awesome", "2": "World"},
            # ['lion', 'elephant', 'zebra'],
            # [1.1, 2.2, 3.3],
            # ['cat', np.nan, 'dog'],
            # ['cow', 4.5, 'goat'],
            # ['duck', ['swan', 'fish'], 'guppy']])

# for sep0 in [",","|",""," "]:
    # print(f'sep {sep0}',sep='\n')
    # print(s.str.join(sep0))


# s = pd.Series(["String",
            # (1, 2, 3, 4),
            # ["a", "b", "c","3a"],
            # [["a"],[ "b"]],
            # 123,
            # -456,
            # {1: "Hello","3a":"Awesome", "2": "World"},
            # ['lion', 'elephant', 'zebra'],
            # [1.1, 2.2, 3.3],
            # ['cat', np.nan, 'dog'],
            # ['cow', 4.5, 'goat'],
            # ['duck', ['swan', 'fish'], 'guppy']])
# print(s)
# print(s.str.len())

# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)
# print(df)
# # df=df.applymap(str).astype(pandas.StringDtype())
# df=df.applymap(str)
# # print(df.applymap(str).astype(pandas.StringDtype()).str.len())
# # for s1 in df:
    # # # print(type(s1))
    # # # print(type(df[s1]))
    # # print(df[s1].str.len())
# print(df.apply(lambda s2:s2.str.len()))
# print(df.apply(lambda s2:s2.str.len()).describe())


# s3 = pd.Series(['1. Ant.  ', '  2. Bee!\n\t', '3. Cat?\t','a3. Cat?\ta','\t\ta3. Cat?\ta', np.nan, 10, True])
# print(s3)
# for function00 in [s3.str.lstrip,s3.str.rstrip,s3.str.strip]:
    # for to_strip0 in [None,'1.\t','1.23\t\n!']:
        # print(f'function0 {function00}',f'to_strip {to_strip0}',sep='\n')
        # print(function00(to_strip=to_strip0))


# import re
# s0=pandas.Series(['matchMe0','matchMe0 ',' matchMe0','matchme0',None],dtype=pandas.StringDtype())
# for pat0 in ['matchMe0']:
    # for case0 in [True,False]:
        # for flags0 in [0,re.IGNORECASE]:
            # for na0 in [None,'matchMe0']:
                # for function00 in [s0.str.fullmatch,s0.str.match,]:
                    # print(f'function0 {function00}',f'pat {pat0}',f'case {case0}',f'flags {flags0}',f'na {na0}',sep='\n')
                    # print(function00(pat0,case=case0,flags=flags0,na=na0))


# import unicodedata
# for int00 in list(range(20)):#don't seem to have any names (0 shows up in notepad++ as NUL, 1 as SAH? ^A, ...)
# for int00 in list(range(65,86,1)):
    # print(f'int0 {int00}',f'chr(int0) {chr(int00)}',sep='\n')
    # print(unicodedata.name(chr(int00),'default0'))

# for unicodeHexString0 in ['00C7','0043','0327']:
# for unicodeHexString0 in ['00C7','0043','2160','0049']:
    # print(f'int0 {unicodeHexString0}',f'chr(int0) {chr(int(unicodeHexString0,16))}',sep='\n')#some unicodes like 0327 not supported..
    # print(unicodedata.name(chr(int(unicodeHexString0,16)),'default0'))
    # for form0 in ['NFC','NFKC','NFD','NFKD']:
        # print(f'form {form0}',sep='\n')
        # for function00 in [unicodedata.normalize,unicodedata.is_normalized]:
            # # print(unicodedata.normalize(form0,chr(int(unicodeHexString0,16))))
            # print(f'function0 {function00}',sep='\n')
            # print(function00(form0,chr(int(unicodeHexString0,16))))
# for attribute0 in [unicodedata.unidata_version,unicodedata.ucd_3_2_0]:
    # print(attribute0)

# object0=unicodedata.ucd_3_2_0
# for a0 in dir(object0):
    # try:
        # print(a0,'    ',getattr(object0,a0))
    # except Exception as e:
        # print(e,sys.exc_info())
# object0=unicodedata
# for a0 in dir(object0):
    # try:
        # print(a0,'    ',getattr(object0,a0))
    # except Exception as e:
        # print(e,sys.exc_info())
# listOfAttributes0=[]
# for a0 in dir(object0):
    # try:
        # listOfAttributes0.append(getattr(object0,a0))
    # except Exception as e:
        # print(e,sys.exc_info())
# listOfMethods0=filter(callable,listOfAttributes0)
# print('methods0',end='\n\n\n\n\n')
# for method0 in listOfMethods0:
    # for unicode0 in ['\u00C7','\u0043','\u2160','\u0049','`','0','1','2','^','%','$']:
        # print(f'unicode {unicode0}')
        # try:
            # # print(method0,method0(unicode0),method0.__doc__,sep='\n',end='\n\n\n\n')
            # print(method0,method0(unicode0),sep='\n',end='\n\n')
        # except Exception as e:
            # print(e,sys.exc_info())
# print(unicodedata.lookup('DOLLAR SIGN'))
# print(unicodedata.lookup('ROMAN NUMERAL ONE'))
# print(unicodedata.normalize('NFC','abc'))
# print(unicodedata.normalize('NFC','\u00C7\u0043'))



# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)
# print(df)
# # df=df.applymap(str).astype(pandas.StringDtype())
# df=df.applymap(str)
# # print(df.applymap(str).astype(pandas.StringDtype()).str.len())
# # for s1 in df:
    # # # print(type(s1))
    # # # print(type(df[s1]))
    # # print(df[s1].str.len())
# for form0 in ['NFC','NFKC','NFD','NFKD']:
    # print(f'form {form0}',sep='\n')
    # print(df.apply(lambda s2:s2.str.normalize(form0)))

# s0=pandas.Series(['\u00C7','\u0043','\u2160','\u0049','`','0','1','2','^','%','$'],dtype=pandas.StringDtype())
# for form0 in ['NFC','NFKC','NFD','NFKD']:
    # print(f'form {form0}',sep='\n')
    # print(s0.str.normalize(form0))


# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)
# print(df)
# s0=df['comp_name_2']
# for width0 in [13,100]:
    # for side0 in ['left','right','both']:
        # for fillchar0 in ['|']:
            # print(f'width {width0}',f'side {side0}',f'fillchar {fillchar0}',sep='\n')
            # print(s0.str.pad(width0,side=side0,fillchar=fillchar0))



# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)
# print(df)
# s0=df['eps_diluted_discont_oper'].dropna().apply(str)
# for width0 in [2,6,13]:
    # print(f'width {width0}',sep='\n')
    # print(s0.str.zfill(width0))

# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)
# print(df)
# s0=df['comp_name_2']
# i0=pandas.Index(df['comp_name_2'])
# # for sep0 in [,]:
    # # for expand0 in [,]:
        # # print(f'sep {sep0}',f'expand {expand0}',sep='\n')
        # # print(s0.str.zfill(width0))sep=sep0,expand=expand0,
# for sep0 in [' ','|']:
    # for expand0 in [True,False]:
        # for function00 in [s0.str.partition,s0.str.rpartition,i0.str.partition,i0.str.rpartition]:
            # print(f'sep {sep0}',f'expand {expand0}',f'function0 {function00}',sep='\n')
            # print(function00(sep0,expand=expand0))


# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)
# print(df)
# s0=df['comp_name_2']
# print(s0)
# for pat0 in [None,'Inc','Inc.*']:
    # for n0 in [-1,1]:
        # for expand0 in [True,False]:
            # for regex0 in [None,True,False]:
                # for function00 in [s0.str.split,s0.str.rsplit]:
                    # print(f'pat {pat0}',f'n {n0}',f'expand {expand0}',f'regex {regex0}',f'function0 {function00}',sep='\n')
                    # try:
                        # print(function00(pat=pat0,n=n0,expand=expand0,regex=regex0))
                    # except Exception as e:
                        # print(e)
                        # print(function00(pat=pat0,n=n0,expand=expand0))


# s0=pandas.Series(['abc','abcabcabc'],dtype=pandas.StringDtype())
# mapping0={97:98,98:'c',99:None}
# print(s0)
# print(s0.str.translate(mapping0))#wouldn't you just use s0.str.replace or even stronger s0.replace (seems like translate is lower-level or only value-add if know and can use only ordinals..)

# statusCounter0=0
# stringToWrap0='''   sesquicentennial celebrations are   what Dr. Feld loves to see as she exclaims "Oh the joy!" as   she \n walked by. \v Remote-robot-assisted technologies are the future \t\t as they \t can reduce costs \n \n  \n significantly. pneumonoultramicroscopicsilicovolcanoconiosis    is the longest English word?'''
# import textwrap
# for width0 in [70,10]:
    # for expand_tabs0 in [True,False]:
        # for tabsize0 in [8,24]:
            # for replace_whitespace0 in [True,False]:
                # for drop_whitespace0 in [True,False]:
                    # for initial_indent0 in ['','initialIndent0']:
                        # for subsequent_indent0 in ['','subsequentIndent0']:
                            # for fix_sentence_endings0 in [False,True]:
                                # for break_long_words0 in [True,False]:
                                    # for break_on_hyphens0 in [True,False]:
                                        # for max_lines0 in [None,3]:
                                            # for placeholder0 in ['[...]','...']:
                                                # print(f'width {width0}',f'expand_tabs {expand_tabs0}',f'tabsize {tabsize0}',f'replace_whitespace {replace_whitespace0}',f'drop_whitespace {drop_whitespace0}',f'initial_indent {initial_indent0}',f'subsequent_indent {subsequent_indent0}',f'fix_sentence_endings {fix_sentence_endings0}',f'break_long_words {break_long_words0}',f'break_on_hyphens {break_on_hyphens0}',f'max_lines {max_lines0}',f'placeholder {placeholder0}',sep='\n')
                                                # textWrapper0=textwrap.TextWrapper(width=width0,expand_tabs=expand_tabs0,tabsize=tabsize0,replace_whitespace=replace_whitespace0,drop_whitespace=drop_whitespace0,initial_indent=initial_indent0,subsequent_indent=subsequent_indent0,fix_sentence_endings=fix_sentence_endings0,break_long_words=break_long_words0,break_on_hyphens=break_on_hyphens0,max_lines=max_lines0,placeholder=placeholder0)
                                                # for function00 in [textWrapper0.wrap,textWrapper0.fill]:
                                                    # print(f'function0 {function00}')
                                                    # try:
                                                        # print(function00(stringToWrap0))
                                                    # except Exception as e:
                                                        # print(e)
                                                    # statusCounter0+=1
                                                    # print(f'percentageComplete0 {statusCounter0/8192}; currentCounterValue {statusCounter0}')
                                                    # if statusCounter0==4416:
                                                        # break
# print(textwrap.wrap(stringToWrap0))
# print(textwrap.fill(stringToWrap0))
# print(textwrap.shorten(stringToWrap0,10))
# print(textwrap.dedent(stringToWrap0))
# print(textwrap.indent(stringToWrap0,'prefixIsMandatory0'))
# stringToWrap1=''' word0\n \n  \n word1 \n word2'''
# print(textwrap.dedent(stringToWrap1))
# print(textwrap.indent(stringToWrap1,'    '))
# print(textwrap.indent(stringToWrap1,'    ',(lambda line0: True)))

# stringToWrap0='''robot-assisted sesquicentennial celebrations are   what Dr. Feld loves to see as she exclaims "Oh the joy!" as   she \n walked by. \v Remote-robot-assisted technologies are the future \t\t as they \t can reduce costs significantly. pneumonoultramicroscopicsilicovolcanoconiosis    is the longest English word?'''
# stringToWrap1=''' word0\n \n  \n word1 \n word2'''
# s0=pandas.Series([stringToWrap0,stringToWrap1,'line to be wrapped', 'another line to be wrapped'],dtype=pandas.StringDtype())
# print(s0)
# for width0 in [70,10]:
    # for expand_tabs0 in [True,False]:
        # for replace_whitespace0 in [True,False]:
            # for drop_whitespace0 in [True,False]:
                # for break_long_words0 in [True,False]:
                    # for break_on_hyphens0 in [True,False]:
                        # print(f'width {width0}',f'expand_tabs {expand_tabs0}',f'replace_whitespace {replace_whitespace0}',f'drop_whitespace {drop_whitespace0}',f'break_long_words {break_long_words0}',f'break_on_hyphens {break_on_hyphens0}',sep='\n')
                        # print(s0.str.wrap(width=width0,expand_tabs=expand_tabs0,replace_whitespace=replace_whitespace0,drop_whitespace=drop_whitespace0,break_long_words=break_long_words0,break_on_hyphens=break_on_hyphens0))

# # # s0 = pandas.Series(['line to be wrapped', 'another line to be wrapped'],dtype=pandas.StringDtype())
# # # s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])
# # # s3 = pd.Series(['23', 'Â³', 'â…•', ''])
# # # s4 = pd.Series([' ', '\t\r\n ', ''])
# # # s2 = pd.Series(['A B', '1.5', '3,000'])
# # # s1 = pd.Series(['one', 'one1', '1', ''])

# s0=pandas.Series(['line to be wrapped', 'another line to be wrapped','leopard', 'Golden Eagle', 'SNAKE','23', 'Â³', 'â…•',' ', '\t\r\n ','A B', '1.5', '3,000','one', 'one1', '1', ''],dtype=pandas.StringDtype())
# print(s0)
# for function00 in [s0.str.isalnum,s0.str.isalpha,s0.str.islower,s0.str.isupper,s0.str.istitle,s0.str.isdecimal,s0.str.isdigit,s0.str.isnumeric,s0.str.isspace]:
    # print(f'function0 {function00}')
    # try:
        # print(function00())
    # except Exception as e:
        # print(e)


# s0=pandas.Series(['cat0|cat1','cat0|cat2','cat0|cat3','cat1|cat2|cat3',numpy.nan,pandas.NA,None],dtype=pandas.StringDtype())
# print(s0)
# for sep0 in ['|',' ','']:
    # print(f'sep {sep0}')
    # print(s0.str.get_dummies(sep=sep0))

# i0=pandas.Index(['cat0|cat1','cat0|cat2','cat0|cat3','cat1|cat2|cat3',numpy.nan,pandas.NA,None],dtype=pandas.StringDtype())
# print(i0)
# for sep0 in ['|',' ','']:
    # print(f'sep {sep0}')
    # print(i0.str.get_dummies(sep=sep0))


# print(pandas.Series(['cat0|cat1','cat0|cat2','cat0|cat3','cat1|cat2|cat3',numpy.nan,pandas.NA,None],dtype=pandas.StringDtype()))
# print(pandas.Series(['cat0|cat1','cat0|cat2','cat0|cat3','cat1|cat2|cat3',numpy.nan,pandas.NA,None],dtype="string"))
# print(pandas.Series(['cat0|cat1','cat0|cat2','cat0|cat3','cat1|cat2|cat3']).astype("string"))

# print(pandas.Series(pandas.Categorical(['c','b','a','c','c','b','c','b','a','d'])))
# print(pandas.Series(pandas.Categorical(['c','b','a','c','c','b','c','b','a','d'])).cat)
# print(pandas.Series(pandas.Categorical(['c','b','a','c','c','b','c','b','a','d'])).cat.categories)
# print(pandas.Series(pandas.Categorical(['c','b','a','c','c','b','c','b','a','d'])).cat.ordered)
# print(pandas.Series(pandas.Categorical(['c','b','a','c','c','b','c','b','a','d'],categories=['a','d','c''b','e'])).cat.categories)
# print(pandas.Series(pandas.Categorical(['c','b','a','c','c','b','c','b','a','d'],categories=['a','d','c''b','e'])).cat.ordered)
# print(pandas.Series(pandas.Categorical(['c','b','a','c','c','b','c','b','a','d'],categories=['a','d','c','b','e'])).cat.ordered)
# print(pandas.Series(pandas.Categorical(['c','b','a','c','c','b','c','b','a','d'],ordered=True,categories=['a','d','c','b','e'])).cat.categories)
# print(pandas.Series(pandas.Categorical(['c','b','a','c','c','b','c','b','a','d'],ordered=True,categories=['a','d','c','b','e'])).cat.ordered)

# try:
    # s0=pandas.Series(pandas.Categorical(['c','b','a','c','c','b','c','b','a','d',['a','f']]))
# except Exception as e:
    # print(e)
# s0=pandas.Series(pandas.Categorical(['c','b','a','c','c','b','c','b','a','d']))
# s1=pandas.Series(['c','b','a','c','c','b','c','b','a','d',['a','f']],dtype="string")
# s1=pandas.Series(['c','b','a','c','c','b','c','b','a','d'],dtype="string")
# try:
    # print(s0+s0)
# except Exception as e:
    # print(e)
# print(s1+s1)
# try:
    # print(s1.str.len())
# except Exception as e:
    # print(e)
# print(s0.str.len())


# s3 = pd.Series(
    # ["A", "B", "C", "Aaba", "Baca", "", np.nan, "CABA", "dog", "cat", ".Here", ".There"],
    # dtype="string",
# )
# print(s3)
# print(s3.str.replace(".", "replacedDot", case=False, regex=True))#only replaces literal '.'
# print(s3.str.replace(".", "replacedDot", case=True, regex=True))#only replaces literal '.'

# df=pandas.DataFrame([numpy.arange(0,4,1),numpy.arange(3,7,1),numpy.arange(6,10,1),numpy.arange(9,13,1)],columns=['x_lowest','x_low','y_lowest','y_low'])
# print(df)
# print(df.columns.str.removeprefix('x_').str.removeprefix('y_'))
# df.columns=df.columns.str.removeprefix('x_').str.removeprefix('y_')
# print(df)
# print(df.columns.str.removesuffix('ow'))
# df.columns=df.columns.str.removesuffix('ow')
# print(df)

# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)
# # print(df)
# s0=df['comp_name_2']
# print(s0)
# # for repeats0 in [3,numpy.arange(s0.shape[0])]:
    # # print(f'repeats {repeats0}')
    # # print(s0.str.repeat(repeats0))
# print(s0.str.slice(start=4,stop=11,step=2))
# print(s0.str[4:11:2])
# print(s0.str.slice_replace(start=4,stop=11,repl='Redacted0'))
# print(s0.str.slice(start=-4))
# print(s0.str[-4::])

# print(pandas.Series([pandas.Series(['t0','t1','t2','t3'],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),numpy.array(['t5','t6','t7','t8'])]))
# print(pandas.Series([pandas.Series(['t0','t1','t2',['t30','t3']],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),numpy.array(['t5','t6','t7','t8'])]))
# print(pandas.Series([pandas.Series(['t0','t1','t2','t3'],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),numpy.array(['t5','t6','t7','t8'])]).str.count('t3'))
# print(pandas.Series([pandas.Series(['t0','t1','t2',['t30','t3']],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),numpy.array(['t5','t6','t7','t8'])]).str.count('t3'))
# print(pandas.Series([pandas.Series(['t0','t1','t2','t3'],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),numpy.array(['t5','t6','t7','t8'])]).str.contains('t3'))
# print(pandas.Series([pandas.Series(['t0','t1','t2',['t30','t3']],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),pandas.Series(['t0','t1','t2','t3'],dtype="string"),numpy.array(['t5','t6','t7','t8'])]).str.contains('t3'))#all these str.methods are returning NaN because pandas.Series canNOT take dtype="string" and have nested lists..


# s0 = pd.Series(["a1", "b2", "c3"], ["A11", "B22", "C33"], dtype="string")
# print(s0)
# print(s0.str.extract('(?P<named0>[a-zA-Z]+)'))
# print(s0.str.extract('(?P<named0>[a-zA-Z]+)',expand=False))
# print(s0.index.str.extract('(?P<named0>[a-zA-Z]+)'))
# print(s0.index.str.extract('(?P<named0>[a-zA-Z]+)',expand=False))

# i0=pandas.Index(["A11", "B22", "C33"],dtype="string")
# s0 = pd.Series(["a1", "b2", "c3"], i0, dtype="string")
# print(s0)
# print(s0.str.extract('(?P<named0>[a-zA-Z]+)'))
# print(s0.str.extract('(?P<named0>[a-zA-Z]+)',expand=False))
# print(s0.index.str.extract('(?P<named0>[a-zA-Z]+)'))
# print(s0.index.str.extract('(?P<named0>[a-zA-Z]+)',expand=False))


# s0 = pd.Series(["a1", "b2", "c3"], ["A11", "B22", "C33"], dtype="string")
# print(s0)
# print(s0.str.extract('(?P<named0>[a-zA-Z]+)(?P<named1>[0-9]+)'))
# print(s0.str.extract('(?P<named0>[a-zA-Z]+)(?P<named1>[0-9]+)',expand=False))
# print(s0.index.str.extract('(?P<named0>[a-zA-Z]+)(?P<named1>[0-9]+)'))
# try:
    # print(s0.index.str.extract('(?P<named0>[a-zA-Z]+)(?P<named1>[0-9]+)',expand=False))
# except Exception as e:
    # print(e)


# s0 = pd.Series(["a1", "b2", "c3",'c4',numpy.nan,pandas.NA,None], dtype="string")
# print(s0)
# print(s0.str.contains('c'))
# print(s0.str.contains('c',na=False))
# print(s0.str.contains('c',na=True))#not sure when you'd ever do this..

# print(pandas.Series([numpy.inf]))
# print(pandas.options.mode.use_inf_as_na)
# pandas.options.mode.use_inf_as_na=True
# print(pandas.options.mode.use_inf_as_na)
# print(pandas.Series([numpy.inf]))

# # date_range0=pandas.date_range('2023-01-01','2023-01-05',freq='D')
# # print(date_range0)
# # date_range0.iloc[[0,5]]=numpy.nan
# # print(date_range0)

# s0=pandas.Series(pandas.date_range('2023-01-01','2023-01-05',freq='D'))
# print(s0)
# s0.iloc[[0,4]]=numpy.nan
# print(s0)

# print(numpy.equal(numpy.array([None]),numpy.array([None])))
# print(numpy.equal(numpy.array([numpy.nan]),numpy.array([numpy.nan])))

# print(pandas.Series([None,numpy.nan,pandas.NA,'a']))

# for lag0 in [1,0,2,3,4,5,6,7,8,9]:
    # print(f'lag {lag0}')
    # # print(pandas.Series(numpy.arange(10)).autocorr(lag=lag0))
    # print(pandas.Series(numpy.arange(10,0,-1)).autocorr(lag=lag0))
    # print(pandas.Series(numpy.arange(10,0,-1)))
    # print(pandas.Series(numpy.arange(10,0,-1)).shift(lag0))


# with open(r'C:\Users\pdumas\Downloads\tsla.InceptionToDateStockPrices.20230219.pickle','rb') as f0:
    # r=pickle.load(f0)
# data = r.json()
# # print(data)
# # print(pandas.DataFrame(data['Time Series (Daily)']))
# # print(pandas.DataFrame(data['Time Series (Daily)']).T)
# # print(pandas.DataFrame(data['Time Series (Daily)']).T.columns)
# # print(pandas.DataFrame(data['Time Series (Daily)']).T.index)
# df0=pandas.DataFrame(data['Time Series (Daily)']).T
# df0.index=pandas.DatetimeIndex(df0.index)
# df0=df0.applymap(float)
# # print(df0['4. close'])
# print(df0['4. close'].count())
# list0=[]
# for lag0 in list(range(df0['4. close'].count())):
    # print(f'lag {lag0}')
    # print(df0['4. close'].autocorr(lag=lag0))
    # list0.append(df0['4. close'].autocorr(lag=lag0))
# # matplotlib.pyplot.plot(list(range(len(list0))),list0)
# matplotlib.pyplot.plot(df0['4. close'].index,list0)
# matplotlib.pyplot.show()

# cat0=pandas.Categorical(['c','b','a','c','c','b','c','b','a','d',numpy.nan,pandas.NA,None])
# s0=pandas.Series(['c','b','a','c','c','b','c','b','a','d',numpy.nan,pandas.NA,None],dtype="string")
# na0=numpy.array(['c','b','a','c','c','b','c','b','a','d',numpy.nan,None])
# # for values0 in [cat0,s0,na0]:
# for values0 in [s0]:
    # for sort0 in [False,True]:
        # for use_na_sentinel0 in [True,False]:
            # for size_hint0 in [None,1,11]:
                # print(f'values {values0}',f'sort {sort0}',f'use_na_sentinel {use_na_sentinel0}',f'size_hint {size_hint0}',sep='\n')
                # print(pandas.factorize(values0,sort=sort0,use_na_sentinel=use_na_sentinel0,size_hint=size_hint0),end='\n\n')
                # print(s0.factorize(sort=sort0,use_na_sentinel=use_na_sentinel0))

# print(timeit.repeat('''pandas.factorize(s0,size_hint=4)''',number=100,globals=globals()))
# print(timeit.repeat('''pandas.factorize(s0,size_hint=None)''',number=100,globals=globals()))


# df1=pandas.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},
                   # 'B': {0: 1, 1: 3, 2: 5},
                   # 'C': {0: 2, 1: 4, 2: 6}})
# df1.columns = [list('ABC'), list('DEF')]
# df0 = pandas.DataFrame({'studentId': ['0', '3', '27'],
                   # 'Name': ['John', 'Mike', 'Sarah'],
                   # 'Maths': [90, 80, 75],
                   # 'Engineering': [92, 82, 73],
                   # 'Science': [85, 70, 80],
                   # 'English': [86, 71, 83]})
# df0.columns=[['student0','student0','courseStem0','courseStem0','courseStem0','courseArts0'],[c for c in df0]]
# for frame0 in [df0]:
    # for id_vars0 in [None,['Name'],['studentId','Name']]:
        # for value_vars0 in [None,['Science','English'],['Maths','Engineering','Science','English']]:
            # for var_name0 in [None,'variableNamestudent0']:
                # for value_name0 in ['value','variableNamecourseGrade0']:
                    # for col_level0 in [None,1]:
                        # for ignore_index0 in [True,False]:
                            # print(f'frame {frame0}',f'id_vars {id_vars0}',f'value_vars {value_vars0}',f'var_name {var_name0}',f'value_name {value_name0}',f'col_level {col_level0}',f'ignore_index {ignore_index0}',sep='\n')
                            # try:
                                # print(pandas.melt(frame0,id_vars=id_vars0,value_vars=value_vars0,var_name=var_name0,value_name=value_name0,col_level=col_level0,ignore_index=ignore_index0))
                                # print(frame0.melt(id_vars=id_vars0,value_vars=value_vars0,var_name=var_name0,value_name=value_name0,col_level=col_level0,ignore_index=ignore_index0))
                            # except Exception as e:
                                # print(e)


# for start0 in [0,pandas.Timestamp('2023-01-01')]:#can't just use string as date (must wrap in pandas.Timestamp or else interprets as actual string!)
    # for end0 in [10,pandas.Timestamp('2023-06-01')]:
        # for periods0 in [None,5]:
            # for freq0 in [None,'2D','1M']:
                # for name0 in [None,'intervalIndexName0',]:
                    # for closed0 in ['right','left','both','neither']:
                        # print(f'start {start0}',f'end {end0}',f'periods {periods0}',f'freq {freq0}',f'name {name0}',f'closed {closed0}',sep='\n')
                        # try:
                            # print(pandas.interval_range(start=start0,end=end0,periods=periods0,freq=freq0,name=name0,closed=closed0))
                            # print(pandas.IntervalIndex(pandas.interval_range(start=start0,end=end0,periods=periods0,freq=freq0,name=name0,closed=closed0).to_numpy(),name=name0,closed=closed0,dtype=None,copy=True,verify_integrity=True))
                        # except Exception as e:
                            # print(e)


# import platform,psutil
# from datetime import datetime

# def get_size(bytes, suffix="B"):
    # """
    # Scale bytes to its proper format
    # e.g:
        # 1253656 => '1.20MB'
        # 1253656678 => '1.17GB'
    # """
    # factor = 1024
    # for unit in ["", "K", "M", "G", "T", "P"]:
        # if bytes < factor:
            # return f"{bytes:.2f}{unit}{suffix}"
        # bytes /= factor

# #basic system info
# print("="*40, "System Information", "="*40)
# uname = platform.uname()
# print(f"System: {uname.system}")
# print(f"Node Name: {uname.node}")
# print(f"Release: {uname.release}")
# print(f"Version: {uname.version}")
# print(f"Machine: {uname.machine}")
# print(f"Processor: {uname.processor}")

# # Boot Time
# print("="*40, "Boot Time", "="*40)
# boot_time_timestamp = psutil.boot_time()
# bt = datetime.fromtimestamp(boot_time_timestamp)
# print(f"Boot Time: {bt.year}/{bt.month}/{bt.day} {bt.hour}:{bt.minute}:{bt.second}")

# # let's print CPU information
# print("="*40, "CPU Info", "="*40)
# # number of cores
# print("Physical cores:", psutil.cpu_count(logical=False))
# print("Total cores:", psutil.cpu_count(logical=True))
# # CPU frequencies
# cpufreq = psutil.cpu_freq()
# print(f"Max Frequency: {cpufreq.max:.2f}Mhz")
# print(f"Min Frequency: {cpufreq.min:.2f}Mhz")
# print(f"Current Frequency: {cpufreq.current:.2f}Mhz")
# # CPU usage
# print("CPU Usage Per Core:")
# for i, percentage in enumerate(psutil.cpu_percent(percpu=True, interval=1)):
    # print(f"Core {i}: {percentage}%")
# print(f"Total CPU Usage: {psutil.cpu_percent()}%")

# # Memory Information
# print("="*40, "Memory Information", "="*40)
# # get the memory details
# svmem = psutil.virtual_memory()
# print(f"Total: {get_size(svmem.total)}")
# print(f"Available: {get_size(svmem.available)}")
# print(f"Used: {get_size(svmem.used)}")
# print(f"Percentage: {svmem.percent}%")
# print("="*20, "SWAP", "="*20)
# # get the swap memory details (if exists)
# swap = psutil.swap_memory()
# print(f"Total: {get_size(swap.total)}")
# print(f"Free: {get_size(swap.free)}")
# print(f"Used: {get_size(swap.used)}")
# print(f"Percentage: {swap.percent}%")


# import numerapi
# d0={'Public ID':' 7RIMYG27S6JKCSROKFOGPGNBI6BL57LN','Secret':'CP2F5ZFPJW5ACW44LERXEBAHMCYJEBL5YIG74CYAW246MB6CAE2S2CNCE42H75ZQ'}
# numerapi0=numerapi.NumerAPI(verbosity='info')
# numerapi0.download_dataset('v2/numerai_datasets.zip','numerai_datasets20230317.zip')
# !unzip numerai_datasets20230317.zip
# import pandas
# tabularPredictor1=pandas.read_csv('numerai_tournament_data.csv',nrows=100000)

# !pip install autogluon
# from autogluon.tabular import TabularDataset,TabularPredictor
# tabularDataset0=TabularDataset('numerai_training_data.csv')
# tabularDataset1=TabularDataset(tabularPredictor1)
# tabularPredictor0=TabularPredictor(label='target').fit(train_data=tabularDataset0)
# tabularPredictor0.predict(tabularDataset1.drop(columns=['target']))

# print(pandas.IntervalIndex.from_arrays([0,5,9],[4,8,12],name='n0',copy=True,dtype=None,closed='right'))
# print(pandas.IntervalIndex.from_tuples([(0,4),(5,8),(9,12)],name='n1',copy=True,dtype=None,closed='right'))
# print(pandas.IntervalIndex.from_breaks([0,4,8,12],name='n2',copy=True,dtype=None,closed='right'))
# for value0 in [2,7,11]:
    # print(pandas.IntervalIndex.from_breaks([0,4,8,12],name='n2',copy=True,dtype=None,closed='right').contains(value0))
# try:
    # print(pandas.IntervalIndex.from_breaks([0,4,8,12],name='n2',copy=True,dtype=None,closed='right').overlaps(pandas.IntervalIndex.from_breaks([4,9,11],closed='right')))
# except Exception as e:
    # print(e,sys.exc_info())
# print(pandas.arrays.IntervalArray.from_tuples([(1,4),(4,8)]))
# print(pandas.arrays.IntervalArray.from_tuples([(1,4),(4,8)]).overlaps(pandas.Interval(0,1)))
# print(pandas.arrays.IntervalArray.from_tuples([(1,4),(4,8)]).overlaps(pandas.Interval(0,2)))
# print(pandas.IntervalIndex.from_breaks([0,4,8,12],name='n2',copy=True,dtype=None,closed='right').set_closed(closed='both'))
# print(pandas.IntervalIndex.from_breaks([0,4,8,12],name='n2',copy=True,dtype=None,closed='right').to_tuples(na_tuple=False))
# print(pandas.IntervalIndex.from_breaks([0,4,8,12],name='n2',copy=True,dtype=None,closed='right').to_tuples(na_tuple=True))
# print(pandas.IntervalIndex.from_tuples([(numpy.nan,numpy.nan),(0,1),(2,3)],name='n2',copy=True,dtype=None,closed='right').to_tuples(na_tuple=False))
# print(pandas.IntervalIndex.from_tuples([(numpy.nan,numpy.nan),(0,1),(2,3)],name='n2',copy=True,dtype=None,closed='right').to_tuples(na_tuple=True))


# object0=pandas.IntervalIndex.from_arrays([0,5,9],[4,8,12],name='n0',copy=True,dtype=None,closed='right')
# for a0 in dir(object0):
    # try:
        # print(a0,'    ',getattr(object0,a0))
    # except Exception as e:
        # print(e,sys.exc_info())
# listOfAttributes0=[]
# for a0 in dir(object0):
    # try:
        # listOfAttributes0.append(getattr(object0,a0))
    # except Exception as e:
        # print(e,sys.exc_info())
# listOfMethods0=filter(callable,listOfAttributes0)
# print('methods0',end='\n\n\n\n\n')
# for method0 in listOfMethods0:
    # try:
        # # print(method0,method0(),method0.__doc__,sep='\n',end='\n\n\n\n')
        # print(method0,method0(),sep='\n',end='\n\n')
    # except Exception as e:
        # print(e,sys.exc_info())


# for x0 in [numpy.arange(0,11,2),[0,5,7,8,9.5,9.5]]:
    # for bins0 in [5,[0,4,8],pandas.interval_range(0,10,2)]:
        # for right0 in [True,False]:
            # for labels0 in [None,['bin0','bin1','bin2','bin3','bin4'],False]:
                # for precision0 in [3,6]:
                    # for retbins0 in [False,True]:
                        # for include_lowest0 in [False,True]:
                            # for duplicates0 in ['raise','drop']:
                                # for ordered0 in [True,False]:
                                    # print(f'x {x0}',f'bins {bins0}',f'right {right0}',f'labels {labels0}',f'precision {precision0}',f'retbins {retbins0}',f'include_lowest {include_lowest0}',f'duplicates {duplicates0}',f'ordered {ordered0}',sep='\n')
                                    # try:
                                        # print(pandas.cut(x0,bins0,right=right0,labels=labels0,precision=precision0,retbins=retbins0,include_lowest=include_lowest0,duplicates=duplicates0,ordered=ordered0))
                                    # except Exception as e:
                                        # print(e)

# print(pandas.cut(np.array([1, 7, 5, 4, 6, 3]),3, labels=["extreme0", "leastExtreme0", "extreme0"],ordered=False))
# try:
    # print(pandas.cut(np.array([1, 7, 5, 4, 6, 3]),3, labels=["extreme0", "leastExtreme0", "extreme0"],ordered=True))
# except Exception as e:
    # print(e)
# print(pandas.cut(np.array([1, 7, 5, 4, 6, 3]),3, labels=["extreme0", "leastExtreme0", "lessExtreme0"],ordered=True))
# print(pandas.cut(np.array([1, 7, 5, 4, 6, 3]),3, labels=["bad", "medium", "good"],ordered=True))
# try:
    # print(pandas.cut(['b','a','b','a'],2,ordered=True))
    # print(pandas.cut(['b','a','b','a'],2,ordered=False))
# except Exception as e:
    # print(e)
    
# for x0 in [numpy.arange(0,11,2),[2.6, 2.85, 2.9, 2.91, 2.95, 3.0, 3.0, 3.022, 3.1, 3.1, 3.1, 3.1, 3.1, 3.125, 3.15, 3.15, 3.15, 3.16, 3.2, 3.2, 3.2, 3.2, 3.2, 3.2, 3.2, 3.2, 3.25, 3.25, 3.294, 3.3, 3.3, 3.3, 3.3, 3.3, 3.3, 3.3, 3.3, 3.3, 3.3, 3.3, 3.35, 3.35, 3.35, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.41, 3.425, 3.45, 3.45, 3.46, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.52, 3.55, 3.55, 3.55, 3.559, 3.56, 3.566, 3.567, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.61, 3.62, 3.63, 3.65, 3.65, 3.65, 3.66, 3.67, 3.675, 3.675, 3.68, 3.68, 3.69, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.733, 3.75, 3.75, 3.75, 3.75, 3.75, 3.75, 3.76, 3.785, 3.79, 3.795, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.82, 3.82, 3.825, 3.825, 3.825, 3.83, 3.83, 3.84, 3.84, 3.84, 3.85, 3.85, 3.86, 3.86, 3.866, 3.868, 3.875, 3.89, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.92, 3.925, 3.925, 3.925, 3.925, 3.925, 3.93, 3.97, 3.97, 3.97, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.3]]:
    # for q0 in [5,[0.,.8,.9,.95,.99,1.]]:
        # for labels0 in [None,['bin0','bin1','bin2','bin3','bin4'],False]:
            # for precision0 in [3,6]:
                # for retbins0 in [False,True]:
                    # for duplicates0 in ['raise','drop']:
                        # print(f'x {x0}',f'q {q0}',f'labels {labels0}',f'precision {precision0}',f'retbins {retbins0}',f'duplicates {duplicates0}',sep='\n')
                        # try:
                            # print(pandas.qcut(x=x0,q=q0,labels=labels0,precision=precision0,retbins=retbins0,duplicates=duplicates0))
                        # except Exception as e:
                            # print(e)
# # x,q,labels,precision,retbins,duplicates,

# print(pandas.Series([numpy.nan,pandas.NA,None],dtype="Int64").prod())
# print(pandas.Series([numpy.nan],dtype="Int64").prod())
# print(pandas.Series([],dtype="Int64").prod())
# print(pandas.Series([numpy.nan,pandas.NA,None],dtype="Int64").sum())
# print(pandas.Series([numpy.nan],dtype="Int64").sum())
# print(pandas.Series([],dtype="Int64").sum())

# print(pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5)),columns=list(string.ascii_lowercase[:5])))
# df0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5)),columns=list(string.ascii_lowercase[:5]))
# df0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(5,5)),dtype="Int32",columns=list(string.ascii_lowercase[:5]))
# print(df0)
# # df0.iloc[[0,3],[0,1]]=numpy.nan
# # print(df0)
# df0.iloc[[0,3],[0,1]]=pandas.NA
# print(df0)
# print(df0.groupby('a').count())
# print(df0.groupby('a').sum())
# print(df0.groupby('a').groups)

# for dtype0 in ["bool","boolean","int64","Int64","float64","object"]:
    # print(f'dtype {dtype0}',end='\n')
    # try:
        # s0=pandas.Series([0,1,0,1],dtype=dtype0)
    # except Exception as e:
        # print(e)
    # print(s0)
    # print(s0.reindex(numpy.arange(6)))
    # print(s0.reindex(numpy.arange(6)).dtype)
    # # s0=s0.reindex(numpy.arange(6))
    # # print(s0.fillna(True)

# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)
# s0=df['emp_ft_cnt']
# # print(df['emp_ft_cnt'])
# # print(df)
# # print(df['emp_ft_cnt'].dtype)
# # print(df['emp_ft_cnt'].convert_dtypes().dtype)
# # print(df.dtypes)
# # print(df.convert_dtypes().dtypes)
# print(df.dtypes)
# print(s0.dtype)
# for infer_objects0 in [True,False]:
    # for convert_string0 in [True,False]:
        # for convert_boolean0 in [True,False]:
            # for convert_integer0 in [True,False]:
                # for convert_floating0 in [True,False]:
                    # print(f'infer_objects {infer_objects0}',f'convert_string {convert_string0}',f'convert_boolean {convert_boolean0}',f'convert_integer {convert_integer0}',f'convert_floating {convert_floating0}',sep='\n')
                    # print(df.convert_dtypes(infer_objects=infer_objects0,convert_string=convert_string0,convert_boolean=convert_boolean0,convert_integer=convert_integer0,convert_floating=convert_floating0).dtypes)
                    # print(s0.convert_dtypes(infer_objects=infer_objects0,convert_string=convert_string0,convert_boolean=convert_boolean0,convert_integer=convert_integer0,convert_floating=convert_floating0).dtype)

# df = pd.DataFrame(
    # {
        # "a": pd.Series([1, 2, 3], dtype=np.dtype("int32")),
        # "b": pd.Series(["x", "y", "z"], dtype=np.dtype("O")),
        # "c": pd.Series([True, False, np.nan], dtype=np.dtype("O")),
        # "d": pd.Series(["h", "i", np.nan], dtype=np.dtype("O")),
        # "e": pd.Series([10, np.nan, 20], dtype=np.dtype("float")),
        # "f": pd.Series([np.nan, 100.5, 200], dtype=np.dtype("float")),
    # }
# )
# print(df.dtypes)
# for infer_objects0 in [True,False]:
    # for convert_string0 in [True,False]:
        # for convert_boolean0 in [True,False]:
            # for convert_integer0 in [True,False]:
                # for convert_floating0 in [True,False]:
                    # print(f'infer_objects {infer_objects0}',f'convert_string {convert_string0}',f'convert_boolean {convert_boolean0}',f'convert_integer {convert_integer0}',f'convert_floating {convert_floating0}',sep='\n')
                    # print(df.convert_dtypes(infer_objects=infer_objects0,convert_string=convert_string0,convert_boolean=convert_boolean0,convert_integer=convert_integer0,convert_floating=convert_floating0).dtypes)
                    # print(df.convert_dtypes())
                    # print(df.convert_dtypes(convert_string=True))
                    # print(df.convert_dtypes(infer_objects=True,convert_string=True))
                    # print(df.convert_dtypes(infer_objects=True,convert_string=True,convert_boolean=True))
                    # print(df.convert_dtypes(infer_objects=True,convert_string=True,convert_boolean=True,convert_integer=True))
                    # print(df.convert_dtypes(infer_objects=True,convert_string=True,convert_boolean=True,convert_integer=True,convert_floating=True))
                    # print(df)
                    # print(df.iloc[[1],[4]]==pandas.NA)
                    # print(df.iloc[[1],[4]].isna())
                    # print(df.iloc[[1],[4]]==numpy.nan)
                    # print(df.iloc[1,4]==numpy.nan)
                    # df.iloc[[1],[4]]=pandas.NA
                    # print(df.iloc[[1],[4]]==pandas.NA)
                    # print(df)

# print(pandas.NA+2)
# print(pandas.NA+'b')
# print(pandas.NA=='b')
# print(pandas.NA==pandas.NA)
# print(pandas.NA>=pandas.NA)
# print(pandas.NA!=pandas.NA)
# print(pandas.NA*1)
# print('pandas.NA*1')
# print(1**pandas.NA)
# print(pandas.NA**0)
# print('pandas.NA**0')

# print(pandas.Series([pandas.NA,pandas.NA,pandas.NA],dtype="Int32"))
# try:
    # print(pandas.Series([pandas.NA,pandas.NA,pandas.NA],dtype="Int32").fillna())
# except Exception as e:
    # print(e)
# print(pandas.Series([pandas.NA,pandas.NA,pandas.NA],dtype="boolean").fillna(True))
# try:
    # print(bool(pandas.NA))
# except Exception as e:
    # print(e)

# if pandas.Series([True,True]).all():
    # print('all0')
# if pandas.Series([False,True]).any():
    # print('any0')
# try:
    # if pandas.Series([]).empty():
        # print('empty0')
# except Exception as e:
    # print(e)
# if pandas.Series([]).empty:
    # print('empty0')
# if pandas.Series([True]).bool():
    # print('True0')
# if not pandas.Series([False]).bool():
    # print('False0')
# print(pandas.DataFrame([True,True]))
# print(pd.DataFrame([True,True]))
# print(pd.DataFrame([True,True]).all())
# print(pd.DataFrame([True,True]).all().item())
# try:
    # if pandas.DataFrame([True,True]).all():
        # print('all0')
# except Exception as e:
    # print(e)
# try:
    # if pandas.DataFrame([False,True]).any():
        # print('any0')
# except Exception as e:
    # print(e)
# try:
    # if pandas.DataFrame([]).empty:
        # print('empty0')
# except Exception as e:
    # print(e)
# if pandas.DataFrame([True]).bool():
    # print('True0')
# if not pandas.DataFrame([False]).bool():
    # print('False0')

# print('boolean0')
# if pandas.Series([True,True],dtype='boolean').all():
    # print('all0')
# if pandas.Series([False,True],dtype='boolean').any():
    # print('any0')
# try:
    # if pandas.Series([],dtype='boolean').empty:
        # print('empty0')
# except Exception as e:
    # print(e)
# if pandas.Series([True],dtype='boolean').bool():
    # print('True0')
# if not pandas.Series([False],dtype='boolean').bool():
    # print('False0')
# try:
    # if pandas.DataFrame([True,True],dtype='boolean').all():
        # print('all0')
# except Exception as e:
    # print(e)
# try:
    # if pandas.DataFrame([False,True],dtype='boolean').any():
        # print('any0')
# except Exception as e:
    # print(e)
# try:
    # if pandas.DataFrame([],dtype='boolean').empty:
        # print('empty0')
# except Exception as e:
    # print(e)
# if pandas.DataFrame([True],dtype='boolean').bool():
    # print('True0')
# if not pandas.DataFrame([False],dtype='boolean').bool():
    # print('False0')

# print('boolean1')
# try:
    # if pandas.DataFrame([[True,True],[True,True]],dtype='boolean').all():
        # print('all0')
# except Exception as e:
    # print(e)
# try:
    # if pandas.DataFrame([[False,True],[True,True]],dtype='boolean').any():
        # print('any0')
# except Exception as e:
    # print(e)
# try:
    # if pandas.DataFrame([],dtype='boolean').empty:
        # print('empty0')
# except Exception as e:
    # print(e)
# try:
    # if pandas.DataFrame([[True],[True]],dtype='boolean').bool():
        # print('True0')
# except Exception as e:
    # print(e)
# try:
    # if not pandas.DataFrame([[False],[True]],dtype='boolean').bool():
        # print('False0')
# except Exception as e:
    # print(e)


# print('allAsIntended')
# if pandas.Series([True,True]).all():
    # print('all0')
# if pandas.Series([False,True]).any():
    # print('any0')
# if pandas.Series([]).empty:
    # print('empty0')
# if pandas.Series([True]).bool():
    # print('True0')
# if not pandas.Series([False]).bool():
    # print('False0')
# if pandas.DataFrame([True,True]).all().item():
    # print('all0')
# if pandas.DataFrame([False,True]).any().item():
    # print('any0')
# if pandas.DataFrame([]).empty:
    # print('empty0')
# if pandas.DataFrame([True]).bool():
    # print('True0')
# if not pandas.DataFrame([False]).bool():
    # print('False0')
# if pandas.DataFrame([[True,True],[True,True]],dtype='boolean').all().all():
    # print('all0')
# if pandas.DataFrame([[False,True],[True,True]],dtype='boolean').any().any():
    # print('any0')

# print(numpy.remainder(5,5))
# print(numpy.remainder(5,4))
# print(numpy.remainder(5,3))
# print(numpy.remainder(5,2))
# print(numpy.remainder(5,1))
# print(numpy.remainder(5,5))
# print(numpy.remainder(4,5))
# print(numpy.remainder(3,5))
# print(numpy.remainder(2,5))
# print(numpy.remainder(1,5))
# s0=pandas.Series(numpy.arange(5))
# print(numpy.exp(s0))
# df0=pandas.DataFrame([numpy.arange(5),numpy.arange(5)])
# print(numpy.exp(df0))#autobroadcast so cool
# s1=pandas.Series([1,2,3])
# i1=pandas.Index([1,2,3])
# s2=pandas.Series([1,2,3],index=[4,3,2])
# print(s1+s2)
# # sparse0=pandas.arrays.SparseArray([1,pandas.NA,pandas.NA,pandas.NA,pandas.NA,3])
# sparse0=pandas.arrays.SparseArray([1,pandas.NA,3])
# print('numpy0',numpy.add(numpy.arange(6,9,1),pandas.Series(sparse0.to_dense(),dtype='Int32')))
# print(type(s1+i1))
# print(type(i1+s1))
# print(type(s1+sparse0+s1))
# print(type(sparse0+s1+s1))
# print(sparse0)
# try:
    # sparse0=pandas.arrays.SparseArray([1,pandas.NA,3],fill_value=-42)
# except Exception as e:
    # print(e)
# sparse0=pandas.arrays.SparseArray([1,False,3],fill_value=-42)
# print(sparse0)
# print(sparse0.to_dense())
# print(numpy.abs(sparse0))
# print(numpy.abs(sparse0).to_dense())
# print(numpy.power(sparse0,2).to_dense())
# sparse0=pandas.arrays.SparseArray([1,numpy.nan,3],fill_value=-42)
# print(sparse0)
# print(sparse0.to_dense())
# print(numpy.abs(sparse0))
# print(numpy.abs(sparse0).to_dense())
# print(numpy.power(sparse0,2).to_dense())
# sparse0=pandas.arrays.SparseArray([1,numpy.nan,-3],fill_value=numpy.nan)
# print(sparse0)
# print(sparse0.to_dense())
# print(numpy.abs(sparse0))
# print(numpy.abs(sparse0).to_dense())
# print(numpy.power(sparse0,2).to_dense())

# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)
# print(df.info())
# print(df.describe())
# print(pandas.options.display.max_info_rows,pandas.options.display.max_info_columns,pandas.options.display.memory_usage,sep='\n')
# # pandas.options.display.max_info_columns=500
# # with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # # df=pickle.load(f0)
# # print(df.info())
# # print(df.convert_dtypes().info())
# # print(df.info(memory_usage='deep'))
# # print(df.convert_dtypes().info(memory_usage='deep'))

# dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']
# data = dict([(t, np.ones(shape=5000, dtype=int).astype(t)) for t in dtypes])
# df = pd.DataFrame(data)
# print(df)
# s0=df['object']
# # infer_objects,convert_string,convert_boolean,convert_integer,convert_floating,
# for index0 in [True,False]:
    # for deep0 in [False,True]:
        # print(f'index {index0}',f'deep {deep0}',sep='\n')
        # print(df.memory_usage(index=index0,deep=deep0))
        # try:
            # print(df.convert_dtypes().memory_usage(index=index0,deep=deep0))
        # except Exception as e:
            # print(e)
        # print(s0.memory_usage(index=index0,deep=deep0))
        # print(pandas.Series(pandas.Categorical(s0)).memory_usage(index=index0,deep=deep0))
        # print(s0.astype('string').convert_dtypes().memory_usage(index=index0,deep=deep0))
        # print(s0.astype('Float64').convert_dtypes().memory_usage(index=index0,deep=deep0))
# df.iloc[0,3]=2
# print(df)
# s0=df['object']
# for index0 in [True,False]:
    # for deep0 in [False,True]:
        # print(f'index {index0}',f'deep {deep0}',sep='\n')
        # print(df.memory_usage(index=index0,deep=deep0))
        # try:
            # print(df.convert_dtypes().memory_usage(index=index0,deep=deep0))
        # except Exception as e:
            # print(e)
        # print(s0.memory_usage(index=index0,deep=deep0))
        # print(pandas.Series(pandas.Categorical(s0)).memory_usage(index=index0,deep=deep0))
        # print(s0.astype('string').convert_dtypes().memory_usage(index=index0,deep=deep0))
        # print(s0.astype('Float64').convert_dtypes().memory_usage(index=index0,deep=deep0))

# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)
# s0=df.iloc[:,[0]]#returns df
# s0=df['m_ticker']
# print(s0)
# print(type(s0))
# for verbose0 in [None,True,False]:
    # for buf0 in [sys.stdout,sys.stderr]:
        # for max_cols0 in [100,300]:
            # for memory_usage0 in [True,'deep',False]:
                # for show_counts0 in [True,False]:
                    # print(f'verbose {verbose0}',f'buf {buf0}',f'max_cols {max_cols0}',f'memory_usage {memory_usage0}',f'show_counts {show_counts0}',sep='\n')
                    # print(df.info(verbose=verbose0,buf=buf0,max_cols=max_cols0,memory_usage=memory_usage0,show_counts=show_counts0))
                    # print(s0.info(verbose=verbose0,buf=buf0,memory_usage=memory_usage0,show_counts=show_counts0))

# with open(r'C:\Users\pdumas\Downloads\zacks.fc.sampleDataFrom2018Only.20230219.pickle','rb') as f0:
    # df=pickle.load(f0)
# print(df)
# # print(df.info(verbose=True))
# # s0=df['m_ticker']
# # print(s0)
# # pandas.pivot(index='comp_name_2',columns='auditor',values='m_ticker')
# # print(pandas.pivot(df,index='comp_name_2',columns='auditor',values='tot_revnu'))
# df9=pandas.concat([df['comp_name_2'],df['auditor'],df['tot_revnu']],axis=1)
# print(df9)
# df9['auditor']=df9.auditor.apply(str)
# print(df9)
# df9=df9.replace('None',pandas.NA)
# print(df9)
# df9=df9.dropna()
# print(df9)
# print(df9.sort_values('tot_revnu',ascending=False).drop_duplicates(subset=['comp_name_2','auditor'],keep='first'))
# # print(df9.sort_values('tot_revnu',ascending=False))
# # df9=df9.drop_duplicates(subset='auditor',keep='last')
# # print(df9)
# # print(pandas.melt(df9))
# try:
    # print(pandas.pivot(df,index='comp_name_2',columns='auditor',values=None))#won't work since index and columns SAME index index different columns columsn different
# except Exception as e:
    # print(e)
# df = pd.DataFrame({'foo': ['one', 'two', 'three', 'one', 'two',
                           # 'three'],
                   # 'bar': ['A', 'B', 'C', 'A', 'B', 'C'],
                   # 'baz': [1, 2, 3, 4, 5, 6]})
# print(df)
# print(pandas.pivot(df,index='foo',columns='bar',values=None))#won't work since index and columns SAME index index repeating,different columns columsn repeating,different
                
# df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',
                           # 'two'],
                   # 'bar': ['A', 'B', 'C', 'A', 'B', 'C'],
                   # 'baz': [1, 2, 3, 4, 5, 6],
                   # 'zoo': ['x', 'y', 'z', 'q', 'w', 't']})
# print(df)
# print(pandas.pivot(df,index='foo',columns='bar',values='zoo'))

# import pandas._testing as tm

# def unpivot(frame):
    # N, K = frame.shape
    # data = {
        # "value": frame.to_numpy().ravel("F"),
        # "variable": np.asarray(frame.columns).repeat(N),
        # "date": np.tile(np.asarray(frame.index), K),
    # }
    # return pd.DataFrame(data, columns=["date", "variable", "value"])

# print(tm.makeTimeDataFrame(3))
# df = unpivot(tm.makeTimeDataFrame(3))

# print(df)
# print(pandas.pivot(df,index='date',columns='variable',values='value'))

# df['value1']=df['value']*2
# df['value2']=df['value']*3
# print(pandas.pivot(df,index='date',columns='variable',values='value'))
# print(pandas.pivot(df,index='date',columns='variable'))
# print(pandas.pivot(df,index='date',columns='variable')['value1'])

# df = pd.DataFrame({
       # "lev1": [1, 1, 1, 2, 2, 2],
       # "lev2": [1, 1, 2, 1, 1, 2],
       # "lev3": [1, 2, 1, 2, 1, 2],
       # "lev4": [1, 2, 3, 4, 5, 6],
       # "values": [0, 1, 2, 3, 4, 5]})
# print(df)
# print(df.pivot(index=['lev3','lev4'],columns=['lev1','lev2']))

# s9 = pd.Series([1, 2, 3, 4],
              # index=pd.MultiIndex.from_product([['one', 'two'],
                                                # ['a', 'b']]))
# print(s9)
# print(s9.unstack(level=0))
# print(s9.unstack(level=1))
# print(s9.unstack(level=-1))
# print(s9.reset_index(level=-1))


# index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),
                                   # ('two', 'a'), ('two', 'b')])
# df8 = pd.DataFrame([np.arange(1.0, 5.0),np.arange(4.0, 8.0),np.arange(4.0, 8.0),np.arange(4.0, 8.0)], index=index)
# print(df8)
# print(df8.unstack(level=0))
# print(df8.unstack(level=1))
# print(df8.unstack(level=-1))
# print(df8.unstack(level=-1).index)
# print(df8.unstack(level=-1).columns)
# print(df8.unstack(level=-1).unstack(level=-1))
# print(df8.unstack(level=-1).unstack(level=-1).index)
# try:
    # print(df8.unstack(level=-1).unstack(level=-1).columns)
# except Exception as e:
    # print(e)


# df = pd.DataFrame({
    # 'A': ['foo', 'foo', 'bar', 'bar'],
    # 'B': ['one', 'two', 'one', 'two'],
    # 'C': [1.0, 2.0, None, 4.0]
# })

# print(df)
# print(df.set_index(['A', 'B']))
# print(df.set_index(['A', 'B']).unstack([0,1],fill_value=42))
# # df1=df.set_index(['A', 'B']).iloc[[0,1,2],:].unstack(
# print(df.set_index(['A', 'B']).iloc[[0,1,2],:].unstack([-1],fill_value=42))
# try:
    # print(df.set_index(['A', 'B']).unstack([0,1],fill_value=42).columns)
# except Exception as e:
    # print(e)
# print(df.set_index(['A', 'B']).unstack([0,1],fill_value=42).index)

# multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),
                                       # ('height', 'm')],names=['english0','unitOfMeasure0'])
# df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]],
                                    # index=['cat', 'dog'],
                                    # columns=multicol2)
                                    
# print(df_multi_level_cols3)
# print(df_multi_level_cols3.stack())
# print(df_multi_level_cols3.stack(-1))
# print(df_multi_level_cols3.stack(1))
# print(df_multi_level_cols3.stack(0))
# print('english0')
# print(df_multi_level_cols3.stack('english0'))
# print(df_multi_level_cols3.stack(level=[0,1]))
# print(df_multi_level_cols3.stack(level=[0,1],dropna=False))
# try:
    # print(df_multi_level_cols3.stack(level=[0,1],dropna=False).unstack())
# except Exception as e:
    # print(e)
# print(df_multi_level_cols3.stack().unstack())#given broadcast on forward and broadcast on back, not going to give original


# index = pd.MultiIndex.from_product([[2, 1], ["a", "b"]])

# df = pd.DataFrame(np.random.randn(4), index=index, columns=["A"])

# print(df)
# print(df.unstack())
# print(df.unstack().stack())
# print(df.sort_index())
# print(all(df.unstack().stack() == df.sort_index()))


# cheese = pd.DataFrame(
    # {
        # "first": ["John", "Mary"],
        # "last": ["Doe", "Bo"],
        # "height": [5.5, 6.0],
        # "weight": [130, 150],
    # }
# )
# print(cheese)
# print(cheese.melt(id_vars=["first", "last"]))
# print(cheese.melt(id_vars=["first", "last"], var_name="quantity"))

# cheese = pd.DataFrame(
    # {
        # "first": ["John", "Mary"],
        # "last": ["Doe", "Bo"],
        # "height": [5.5, 6.0],
        # "weight": [130, 150],
        # "length": [10, 12],
    # }
# )
# print(cheese)
# print(cheese.melt(id_vars=["first", "last"]))
# print(cheese.melt(id_vars=["first", "last"], var_name="quantity"))
# print(cheese.melt(id_vars=["first", "last"], value_vars=['weight'], var_name="quantity"))

# cheese = pd.DataFrame(
    # {
        # "first": ["John", "Mary"],
        # "middle": ["K", "C"],
        # "last": ["Doe", "Bo"],
        # "height": [5.5, 6.0],
        # "weight": [130, 150],
        # "length": [10, 12],
    # }
# )
# print(cheese)
# print(cheese.melt(id_vars=["first", "last"]))
# print(cheese.melt(id_vars=["first", "last"], var_name="quantity"))
# print(cheese.melt(id_vars=["first", "middle","last"], var_name="quantity"))


# df = pd.DataFrame({
    # 'famid': [1, 1, 1, 2, 2, 2, 3, 3, 3],
    # 'birth': [1, 2, 3, 1, 2, 3, 1, 2, 3],
    # 'ht1': [2.8, 2.9, 2.2, 2, 1.8, 1.9, 2.2, 2.3, 2.1],
    # 'ht2': [3.4, 3.8, 2.9, 3.2, 2.8, 2.4, 3.3, 3.4, 2.9]
# })
# df


# l = pd.wide_to_long(df, stubnames='ht', i=['famid', 'birth'], j='age')
# print(df)
# print(l)
# print(l.index)
# print(l.unstack())
# print(l.unstack().columns)
# print('\n\n')
# print(l.unstack().columns.map('{0[0]}{0[1]}'.format))
# w=l.unstack()
# w.columns=l.unstack().columns.map('{0[0]}{0[1]}'.format)
# print(w)
# print(w.reset_index())

# df = pd.DataFrame({
    # 'famid': [1, 1, 1, 2, 2, 2, 3, 3, 3],
    # 'birth': [1, 2, 3, 1, 2, 3, 1, 2, 3],
    # 'ht_one': [2.8, 2.9, 2.2, 2, 1.8, 1.9, 2.2, 2.3, 2.1],
    # 'ht_two': [3.4, 3.8, 2.9, 3.2, 2.8, 2.4, 3.3, 3.4, 2.9]
# })
# print(df)
# print(pandas.wide_to_long(df,'ht',i=['famid','birth'],j='category0',sep='_',suffix=r'\w+'))



# # create the index levels
# index = pd.MultiIndex.from_product([['bar', 'baz', 'foo', 'qux'], ['one', 'two']], names=['first', 'second'])

# # create the column levels
# columns = pd.MultiIndex.from_product([['A', 'B'], ['cat', 'dog']], names=['exp','animal'])
# # columns = pd.MultiIndex.from_tuples([('A', 'cat'), ('B', 'dog'),('A','cat'),('B','dog')], names=['exp','animal'])
# # columns = pd.MultiIndex.from_tuples([('A', 'cat'), ('B', 'dog'),('','cat'),('A','dog')], names=['exp','animal'])

# # create the data values
# data = np.array([[0.895717, 0.805244, -1.206412, 2.565646],
                 # [1.431256, 1.340309, -1.170299, -0.226169],
                 # [0.410835, 0.813850, 0.132003, -0.827317],
                 # [-0.076467, -1.187678, 1.130127, -1.436737],
                 # [-1.413681, 1.607920, 1.024180, 0.569605],
                 # [0.875906, -2.211372, 0.974466, -2.006747],
                 # [-0.410001, -0.078638, 0.545952, -1.219217],
                 # [-1.226825, 0.769804, -1.281247, -0.727707]])

# # create the DataFrame
# df = pd.DataFrame(data, index=index, columns=columns)

# # display the DataFrame
# print(df)
# print(df.stack())
# print(df.stack().mean(1))
# print(df.stack().mean(1).unstack())
# print(df.groupby(level=1,axis=1).groups)
# print(df.groupby(level=1,axis=1).mean())
# print(df.mean())
# print(df.mean().unstack(0))


# df = pd.DataFrame({"A": ["foo", "foo", "foo", "foo", "foo",
                         # "bar", "bar", "bar", "bar"],
                   # "B": ["one", "one", "one", "two", "two",
                         # "one", "one", "two", "two"],
                   # "C": ["small", "large", "large", "small",
                         # "small", "large", "small", "small",
                         # "large"],
                   # "D": [1, 2, 2, 3, 3, 4, 5, 6, 7],
                   # "E": [2, 4, 5, 5, 6, 6, 8, 9, 9]})
# df1 = pd.DataFrame({"A": ["foo", "foo", "foo", "foo", "foo",
                         # "bar", "bar", "bar", "bar"],
                   # "B": ["one", "one", "one", "two", "two",
                         # "one", "one", "two", "two"],
                   # "C": ["small", "large", "large", "small",
                         # "small", "large", "small", "small",
                         # "large"],
                   # "D": pandas.Categorical([1, 2, 2, 3, 3, 2, 1, 2, 2]),
                   # "E": pandas.Categorical([4, 5, 5, 4, 5, 5, 4, 6, pandas.NA])})

# #verbose,buf,max_cols,memory_usage,show_counts,
# # for data0 in [df,df1]:
# for data0 in [df1]:
    # for values0 in [None,'E',['D','E']]:
        # for index0 in [None,'A',['A','B']]:
            # for columns0 in [None,data0.groupby('C'),'C',numpy.array(['B','C'])]:
                # for aggfunc0 in [None,numpy.sum,[numpy.mean,numpy.sum,numpy.amin,numpy.amax,numpy.ptp]]:
                    # for fill_value0 in [None,[42]]:
                        # for dropna0 in [True,False]:
                            # for margins0 in [False,True]:
                                # for margins_name0 in ['All','total0']:
                                    # for sort0 in [True,False]:
                                        # for observed0 in [False,True]:
                                            # print(f'data {data0}',f'values {values0}',f'index {index0}',f'columns {columns0}',f'aggfunc {aggfunc0}',f'fill_value {fill_value0}',f'dropna {dropna0}',f'margins {margins0}',f'margins_name {margins_name0}',f'sort {sort0}',f'observed {observed0}',sep='\n')
                                            # try:
                                                # print(pandas.pivot_table(data=data0,values=values0,index=index0,columns=columns0,aggfunc=aggfunc0,fill_value=fill_value0,dropna=dropna0,margins=margins0,margins_name=margins_name0,sort=sort0,observed=observed0))
                                            # except Exception as e:
                                                # print(e)




#dropna,observed,fill_value
# df = pd.DataFrame({"A": ["foo", "foo", "foo", "foo", "foo",
                         # "bar", "bar", "bar", "bar"],
                   # "B": ["one", "one", "one", "two", "two",
                         # "one", "one", "two", "two"],
                   # "C": ["small", "large", "large", "small",
                         # "small", "large", "small", "small",
                         # "large"],
                   # "D": [1, 2, 2, 3, 3, 4, 5, 6, 7],
                   # "E": [pandas.NA, pandas.NA, pandas.NA, pandas.NA, pandas.NA, 6, 8, 9, 9]})
# print(df.pivot_table(index=['A','B'],columns='C'))
# print(df.pivot_table(index=['A','B'],columns='C',dropna=False))
# print(df.pivot_table(index=['A','B'],columns='C',dropna=False,fill_value=42))





# # Create a sample dataset
# df = pd.DataFrame({
    # 'color': ['red', 'blue', 'green', 'red', 'red', 'green', 'blue', 'red'],
    # 'size': ['small', 'large', 'large', 'medium', 'small', 'medium', 'small', 'large'],
    # 'count': [10, 5, 3, 8, 2, 6, 7, 1]
# })

# # Convert the "color" column to a categorical data type
# df['color'] = pd.Categorical(df['color'], categories=['red', 'blue', 'green', 'yellow'])

# # Pivot the table with observed=False (default)
# pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size')
# print(pivot_table_all)
# pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',observed=False)
# print(pivot_table_all)
# pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',observed=True)
# print(pivot_table_all)

# # Create a sample dataset
# df = pd.DataFrame({
    # 'color': ['red', 'blue', 'green', 'red', 'red', 'green', 'blue', 'red'],
    # 'size': ['small', 'large', 'large', 'medium', 'small', 'medium', 'small', 'large'],
    # 'count': ['a', 'a', 'a', 'a', 'a', 'b', 'b', 'b']
# })

# # Convert the "color" column to a categorical data type
# df['color'] = pd.Categorical(df['color'], categories=['red', 'blue', 'green', 'yellow'])
# df['size'] = pd.Categorical(df['size'], categories=['large', 'medium', 'small'])

# # Pivot the table with observed=False (default)
# pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count')
# print(pivot_table_all)
# pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count',observed=False)
# print(pivot_table_all)
# pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count',observed=True)
# print(pivot_table_all,'\n\n')



# # Create a sample dataset
# df = pd.DataFrame({
    # 'color': ['red', 'blue', 'green', 'red', 'red', 'green', 'blue', 'red'],
    # 'size': ['small', 'large', 'large', 'medium', 'small', 'medium', 'small', 'large'],
    # 'count': ['a', 'a', 'a', 'a', 'a', 'b', 'b', 'b']
# })

# # Convert the "color" column to a categorical data type
# df['color'] = pd.Categorical(df['color'], categories=['red', 'blue', 'green', 'yellow'])

# # Pivot the table with observed=False (default)
# pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count')
# print(pivot_table_all)
# pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count',observed=False)
# print(pivot_table_all)
# pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count',observed=True)
# print(pivot_table_all,'\n\n')



# # Create a sample dataset
# df = pd.DataFrame({
    # 'color': ['red', 'blue', 'green', 'red', 'red', 'green', 'blue', 'red'],
    # 'size': ['small', 'large', 'large', 'medium', 'small', 'medium', 'small', 'large'],
    # 'count': ['a', 'a', 'a', 'a', 'a', 'b', 'b', 'b']
# })

# # Convert the "color" column to a categorical data type #if this step doesn't happen, then observed is no-op since there's not at least 1 categorical variable in the mix!

# # Pivot the table with observed=False (default)
# pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count')
# print(pivot_table_all)
# pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count',observed=False)
# print(pivot_table_all)
# pivot_table_all = pd.pivot_table(df, values='count', index='color', columns='size',aggfunc='count',observed=True)
# print(pivot_table_all,'\n\n')


# import datetime
# df = pd.DataFrame(
    # {
        # "Branch": "A A A A A B B B".split(),
        # "Buyer": "Carl Mark Carl Carl Joe Joe Joe Carl".split(),
        # "Quantity": [1, 3, 5, 1, 8, 1, 9, 3],
        # "Date": [
            # datetime.datetime(2013, 1, 1, 13, 0),
            # datetime.datetime(2013, 1, 1, 13, 5),
            # datetime.datetime(2013, 10, 1, 20, 0),
            # datetime.datetime(2013, 10, 2, 10, 0),
            # datetime.datetime(2013, 10, 1, 20, 0),
            # datetime.datetime(2013, 10, 2, 10, 0),
            # datetime.datetime(2013, 12, 2, 12, 0),
            # datetime.datetime(2013, 12, 2, 14, 0),
        # ],
    # }
# )
# print(df)
# print(df.groupby([pandas.Grouper(freq='6M',key='Date'),'Branch'])[['Quantity']].sum())
# df1=df.set_index('Date')
# df1['Date']=df1.index+pandas.tseries.offsets.MonthEnd(2)
# print(df1)
# print(df1.groupby([pandas.Grouper(freq='6M',key='Date'),'Branch'])[['Quantity']].sum())
# print(df1.groupby([pandas.Grouper(freq='6M',level='Date'),'Branch'])[['Quantity']].sum())
# print(df.groupby([pandas.Grouper(freq='1M',key='Date'),'Branch'])[['Quantity']].sum())
# print(df1.groupby([pandas.Grouper(freq='1M',key='Date'),'Branch'])[['Quantity']].sum())
# print(df1.groupby([pandas.Grouper(freq='1M',level='Date'),'Branch'])[['Quantity']].sum())
# print(df1.groupby([pandas.Grouper(freq='1M',level='Date'),'Branch'],as_index=False)[['Quantity']].sum())#Grouper not included in result
# print(df1.groupby([pandas.Grouper(freq='1M',key='Date'),'Branch'],as_index=False)[['Quantity']].sum())#Grouper not included in result
# print(df1.groupby('Branch',as_index=False)[['Quantity']].sum())
# print(df1.groupby('Buyer',as_index=False)[['Quantity']].sum())
# print(df1.groupby('Branch',as_index=False).nth(0))
# print(df1.groupby('Buyer',as_index=False).nth(0))
# print(df1.groupby('Buyer',as_index=False)[['Quantity']].nth(0))

# business_dates = pd.date_range(start="4/1/2014", end="6/30/2014", freq="B")
# # df = pd.DataFrame(numpy.repeat(numpy.arange(business_dates.shape[0]),2).reshape((business_dates.shape[0],2)), index=business_dates, columns=["a", "b"])
# df = pd.DataFrame(numpy.repeat(business_dates.to_numpy(),2).reshape((business_dates.shape[0],2)), index=business_dates, columns=["a", "b"])
# print(df)
# print(df.groupby([df.index.year, df.index.month]).nth([0, 3, -1]))
# print(df.groupby([df.index.year, df.index.week]).nth([0, 3, -1]))


# np.random.seed(1234)

# df_box = pd.DataFrame(np.random.randn(50, 2))
# print(df_box)
# df_box["g"] = np.random.choice(["A", "B"], size=50)
# print(df_box)
# df_box.loc[df_box["g"] == "B", 1] += 3
# print(df_box)
# bp = df_box.boxplot(by="g")
# print(bp)


# n = 1000
# df = pd.DataFrame(
    # {
        # "Store": np.random.choice(["Store_1", "Store_2"], n),
        # "Product": np.random.choice(["Product_1", "Product_2"], n),
        # "Revenue": (np.random.random(n) * 50 + 10).round(2),
        # "Quantity": np.random.randint(1, 10, size=n),
    # }
# )
# print(df.head(10))
# print(df.groupby(["Store", "Product"]))
# print(df.groupby(["Store", "Product"]).pipe(lambda grp: grp.Revenue.sum() / grp.Quantity.sum()))
# print(df.groupby(["Store", "Product"]).pipe(lambda grp: grp.Revenue.sum() / grp.Quantity.sum()).unstack())
# print(df.groupby(["Store", "Product"]).pipe(lambda grp: grp.Revenue.sum() / grp.Quantity.sum()).unstack().round(2))

# def f0(kwarg0='stringPrintMe0',kwarg1df0=pandas.DataFrame(numpy.arange(4))):
    # print(kwarg0)
    # return kwarg1df0.sum()

# df0=pandas.DataFrame(numpy.arange(10,20,1))
# print(df0)
# print(df0.pipe(f0))
# print(df0.count().pipe((f0)))
# print(df0.count().pipe((f0,'kwarg1df0')))

# df = pd.DataFrame({'temp_c': [17.0, 25.0]},index=['Portland', 'Berkeley'])
# print(df)
# print(df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32))
# print(df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,temp_k=lambda x: (x['temp_f'] +  459.67) * 5 / 9))

# df=pandas.DataFrame(numpy.arange(4))
# print(df)
# df[1]=df[0]*2
# print(df)
# # print(df.assign(c2=df[0]*3))
# # df=df.assign(c2=df[0]*3)
# # df=df.assign(c3=df['c2']*2)
# # print(df)
# try:
    # print(df.assign(c2=df[0]*3).assign(c3=df['c2']*2))#changing input DataFrame is a no-no! one must take (e.g. in a lambda function) input DataFrame, calculate what you need, and return a Series.
# except Exception as e:
    # print(e)
# print(df.assign(c2=(lambda df: df[0]*3),c3=(lambda df: df['c2']*3)))
# # print(df.assign(c2=(lambda df: type(df[0]*3))))#it is a Series!

# #data,values,index,columns,aggfunc,fill_value,dropna,margins,margins_name,sort,observed,

# i0=pandas.date_range('2023-01-01',periods=10,freq='1M',name='i0')
# i1=pandas.date_range('2023-01-01',periods=10,freq='1D',name='i1')
# i0=pandas.period_range('2023-01-01',periods=10,freq='1M',name='i0')
# i1=pandas.period_range('2023-01-01',periods=10,freq='1D',name='i1')
# mi0=pandas.MultiIndex.from_arrays([i0,i1])
# df0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10)),columns=mi0,index=mi0)
# print(df0)
# df1=pandas.DataFrame(numpy.random.default_rng(8).integers(0,10,(10,10)),columns=i0,index=i1)
# print(df1)
# for key0 in [None,'2023-01-02']:
    # for level0 in [None,1]:#can't specify level and key at the same time
        # for axis0 in [0,1]:#1 still resamples 0 but to span the entire axis=1 (whereas 0 resamples 0 to span entire axis=0)
            # for sort0 in [False,True]:
                # for freq0 in [None,'5D']:
                    # for closed0 in ['left','right']:#if passed and not freq, errors (same for all that must go with 'freq' per docs)
                        # for label0 in ['left','right']:
                            # for convention0 in ['s','e']:
                                # for origin0 in ['start_day','epoch']:
                                    # for offset0 in [None,'16D']:
                                        # for dropna0 in [True,False]:
                                            # print(f'key {key0}',f'level {level0}',f'axis {axis0}',f'sort {sort0}',f'freq {freq0}',f'closed {closed0}',f'label {label0}',f'convention {convention0}',f'origin {origin0}',f'offset {offset0}',f'dropna {dropna0}',sep='\n')
                                            # try:
                                                # print(df0.groupby(pandas.Grouper(key=key0,level=level0,axis=axis0,sort=sort0,freq=freq0,closed=closed0,label=label0,convention=convention0,origin=origin0,offset=offset0,dropna=dropna0)).sum())
                                            # except Exception as e:
                                                # print(e)
                                                # try:
                                                    # print(df1.groupby(pandas.Grouper(key=key0,level=level0,axis=axis0,sort=sort0,freq=freq0,closed=closed0,label=label0,convention=convention0,origin=origin0,offset=offset0,dropna=dropna0)).sum())
                                                # except Exception as e:
                                                    # print(e)


# #closed,label example (different values giving different results)
# # Create a DataFrame with a datetime column
# dates = pd.date_range(start='2022-01-01', end='2022-12-31', freq='D')
# df = pd.DataFrame({'date': dates, 'value': np.random.default_rng(8).random(len(dates))})
# # Group the DataFrame by month, with the left endpoint closed and labeling the left boundary
# grouped = df.groupby(pd.Grouper(key='date', freq='M', closed='left', label='left'))
# # Calculate the mean of each group
# grouped_mean = grouped.mean()
# # Print the resulting DataFrame
# print(grouped_mean)
# grouped = df.groupby(pd.Grouper(key='date', freq='M', closed='right', label='right'))
# # Calculate the mean of each group
# grouped_mean = grouped.mean()
# # Print the resulting DataFrame
# print(grouped_mean)
# grouped = df.groupby(pd.Grouper(key='date', freq='M', closed='left', label='right'))#typically you don't want to do this because it would label (using the right labels) but have the values of the left labels, whicih isn't accurate!
# # Calculate the mean of each group
# grouped_mean = grouped.mean()
# # Print the resulting DataFrame
# print(grouped_mean)




# # # Create a DataFrame with a PeriodIndex column
# # dates = pd.date_range(start='2022-01-01', end='2022-12-31', freq='D')
# # df = pd.DataFrame({'value': np.random.default_rng(8).random(len(dates))}, index=pd.PeriodIndex(dates, freq='D'))

# # # Group the DataFrame by quarter, with the convention set to 'end'
# # grouped = df.groupby(pd.Grouper(key=df.index.name, freq='Q', convention='end'))

# # # Calculate the mean of each group
# # grouped_mean = grouped.mean()

# # # Print the resulting DataFrame
# # print(grouped_mean)

# # # Group the DataFrame by quarter, with the convention set to 'end'
# # grouped = df.groupby(pd.Grouper(key=df.index.name, freq='Q', convention='s'))
# # grouped = df.groupby(pd.Grouper(key=df.index.name, freq='Q', convention='start'))

# # # Calculate the mean of each group
# # grouped_mean = grouped.mean()

# # # Print the resulting DataFrame
# # print(grouped_mean)



# # Create a DataFrame with an hourly DatetimeIndex
# dates = pd.date_range(start='2022-01-01', end='2022-01-01 23:00:00', freq='H')
# df = pd.DataFrame({'value': np.random.default_rng(8).random(len(dates))}, index=dates)

# # Group the DataFrame by 6-hour periods starting at the beginning of each hour
# grouped_start = df.groupby(pd.Grouper(freq='6H', convention='start'))

# # Calculate the mean of each group
# grouped_mean_start = grouped_start.mean()

# # Print the resulting DataFrame
# print(grouped_mean_start)

# grouped_start = df.groupby(pd.Grouper(freq='6H',  convention='end'))

# # Calculate the mean of each group
# grouped_mean_start = grouped_start.mean()

# # Print the resulting DataFrame
# print(grouped_mean_start)


# # Create a DataFrame with an hourly DatetimeIndex
# dates = pd.date_range(start='2022-01-01', end='2022-01-01 23:00:00', freq='H')
# df = pd.DataFrame({'value': np.random.default_rng(8).random(len(dates))}, index=dates[::-1])

# # Group the DataFrame by 6-hour periods starting at the beginning of each hour
# grouped_start = df.groupby(pd.Grouper(freq='6H', convention='start'))

# # Calculate the mean of each group
# grouped_mean_start = grouped_start.mean()

# # Print the resulting DataFrame
# print(grouped_mean_start)

# grouped_start = df.groupby(pd.Grouper(freq='6H',  convention='end',sort=True))

# # Calculate the mean of each group
# grouped_mean_start = grouped_start.mean()

# # Print the resulting DataFrame
# print(grouped_mean_start)


# #sort example (different values giving different results)
# # Create a DataFrame with an hourly DatetimeIndex
# dates = pd.date_range(start='2022-01-01', end='2022-01-01 23:00:00', freq='H')
# df = pd.DataFrame({'value': np.random.default_rng(8).random(len(dates)),'value1': numpy.repeat(numpy.arange(len(dates)/2)[::-1],2)})
# grouped_start = df.groupby(pd.Grouper(key='value1',sort=False))
# grouped_start = df.groupby(pd.Grouper(key='value1'))
# # Calculate the mean of each group
# grouped_mean_start = grouped_start.mean()
# # Print the resulting DataFrame
# print(grouped_mean_start)
# grouped_start = df.groupby(pd.Grouper(key='value1',sort=True))
# # Calculate the mean of each group
# grouped_mean_start = grouped_start.mean()
# # Print the resulting DataFrame
# print(grouped_mean_start)

# key,level,axis,sort,freq,closed,label,convention,origin,offset,dropna,
# s0=pandas.Series(numpy.random.default_rng(8).integers(0,5,(10,)))
# s1=pandas.Series(numpy.random.default_rng(8).integers(0,5,(10,)))
# s2=pandas.Series(numpy.random.default_rng(8).integers(0,5,(10,)))
# s3=pandas.Series(numpy.random.default_rng(8).integers(0,5,(10,)))
# print(s0,s1,s2,s3,sep='\n')
# for index0 in [None,s0,[s0,s1]]:#if None but columns is something, then will just show empty df basically
    # for columns0 in [None,s2,[s2,s3]]:#if None but index is something, then will just show empty df basically; can't BOTH be None otherwise errors
        # for values0 in [None,s3]:#must have aggfunc otherwise errors
            # for rownames0 in [None,['rowNames0','rowNames1']]:
                # for colnames0 in [None,['colNames0','colNames1']]:
                    # for aggfunc0 in [None,numpy.mean]:
                        # for margins0 in [False,True]:
                            # for margins_name0 in ['All','total0']:
                                # for dropna0 in [False,True]:#renders NaN values
                                    # for normalize0 in [False,True,'all','index','columns']:#with margins=True AND normalize='index', shows ONLY 'All' margins at bottom (makes sense since we have to have this to normalize across that index); with margins=True AND normalize='columns', shows ONLY 'All' margins at right (makes sense since we have to have this to normalize down that column); with margins=True AND normalize=<anythingElseNotMentionedPreviously>, shows 'All' margins at bottom AND right (makes sense since we have to have this to normalize/total all)
                                        # print(f'index {index0}',f'columns {columns0}',f'values {values0}',f'rownames {rownames0}',f'colnames {colnames0}',f'aggfunc {aggfunc0}',f'margins {margins0}',f'margins_name {margins_name0}',f'dropna {dropna0}',f'normalize {normalize0}',sep='\n')
                                        # try:
                                            # print(pandas.crosstab(index0,columns0,values=values0,rownames=rownames0,colnames=colnames0,aggfunc=aggfunc0,margins=margins0,margins_name=margins_name0,dropna=dropna0,normalize=normalize0))
                                            # print('validHit0')
                                        # except Exception as e:
                                            # print(e)

# s0=pandas.Series(numpy.random.default_rng(8).integers(0,5,(50,)))
# s1=pandas.Series(numpy.random.default_rng(7).integers(0,5,(50,)))
# s2=pandas.Series(numpy.random.default_rng(6).integers(0,5,(50,)))
# s3=pandas.Series(numpy.random.default_rng(5).integers(0,5,(50,)))
# print(s0,s1,s2,s3,sep='\n')
# for index0 in [None,s0,[s0,s1]]:#if None but columns is something, then will just show empty df basically
    # for columns0 in [None,s2,[s2,s3]]:#if None but index is something, then will just show empty df basically; can't BOTH be None otherwise errors
        # for values0 in [None,s3]:#must have aggfunc otherwise errors
            # for rownames0 in [None,['rowNames0','rowNames1']]:
                # for colnames0 in [None,['colNames0','colNames1']]:
                    # for aggfunc0 in [None,numpy.mean]:#must have values otherwise errors
                        # for margins0 in [False,True]:
                            # for margins_name0 in ['All','total0']:
                                # for dropna0 in [False,True]:#renders NaN values
                                    # for normalize0 in [False,True,'all','index','columns']:#with margins=True AND normalize='index', shows ONLY 'All' margins at bottom (makes sense since we have to have this to normalize across that index); with margins=True AND normalize='columns', shows ONLY 'All' margins at right (makes sense since we have to have this to normalize down that column); with margins=True AND normalize=<anythingElseNotMentionedPreviously>, shows 'All' margins at bottom AND right (makes sense since we have to have this to normalize/total all)
                                        # print(f'index {index0}',f'columns {columns0}',f'values {values0}',f'rownames {rownames0}',f'colnames {colnames0}',f'aggfunc {aggfunc0}',f'margins {margins0}',f'margins_name {margins_name0}',f'dropna {dropna0}',f'normalize {normalize0}',sep='\n')
                                        # try:
                                            # print(pandas.crosstab(index0,columns0,values=values0,rownames=rownames0,colnames=colnames0,aggfunc=aggfunc0,margins=margins0,margins_name=margins_name0,dropna=dropna0,normalize=normalize0))
                                            # print('validHit0')
                                        # except Exception as e:
                                            # print(e)

# c0=pandas.Categorical(list(string.ascii_lowercase[:3]+'c'),categories=list(string.ascii_lowercase[:5]))
# c1=pandas.Categorical(list(string.ascii_lowercase[10:13]+'m'),categories=list(string.ascii_lowercase[10:16]))
# a2=[42,1,2,-300]
# # # a2=[42,1,2,-300,301]
# print(c0,c1,sep='\n')
# print(pandas.crosstab(c0,c1))
# print(pandas.crosstab(c0,c1,dropna=True))
# print(pandas.crosstab(c0,c1,dropna=False))
# print(pandas.crosstab(c0,c1,a2,aggfunc=numpy.sum,dropna=False))
# print(pandas.crosstab(c0,c1,a2,aggfunc=numpy.mean,dropna=False))
# print(pandas.crosstab(c0,c1,a2,aggfunc=numpy.ptp,dropna=False))

# c0=pandas.Categorical(list(string.ascii_lowercase[:3]+'c'),categories=list(string.ascii_lowercase[:5]))
# c1=pandas.Categorical(list(string.ascii_lowercase[10:13]+'m'),categories=list(string.ascii_lowercase[10:16]))
# a2=[42,1,3,-300]
# print(c0,c1,sep='\n')
# print(pandas.crosstab(c0,c1))
# print(pandas.crosstab(c0,c1,dropna=True))
# print(pandas.crosstab(c0,c1,dropna=False))
# print(pandas.crosstab(c0,c1,a2,aggfunc=numpy.sum,dropna=False))
# print(pandas.crosstab(c0,c1,a2,aggfunc=numpy.mean,dropna=False))
# print(pandas.crosstab(c0,c1,a2,aggfunc=numpy.ptp,dropna=False))

# c0=pandas.Categorical(list(string.ascii_lowercase[:3]+'c'*2),categories=list(string.ascii_lowercase[:5]))
# c1=pandas.Categorical(list(string.ascii_lowercase[10:13]+'m'*2),categories=list(string.ascii_lowercase[10:16]))
# a2=[42,1,3,-300,0]
# print(c0,c1,sep='\n')
# print(pandas.crosstab(c0,c1))
# print(pandas.crosstab(c0,c1,dropna=True))
# print(pandas.crosstab(c0,c1,dropna=False))
# print(pandas.crosstab(c0,c1,a2,aggfunc=numpy.sum,dropna=False))
# print(pandas.crosstab(c0,c1,a2,aggfunc=numpy.mean,dropna=False))
# print(pandas.crosstab(c0,c1,a2,aggfunc=numpy.ptp,dropna=False))

# c0=pandas.Categorical(list(string.ascii_lowercase[:3]+'c'*2),categories=list(string.ascii_lowercase[:5]))
# c1=pandas.Categorical(list(string.ascii_lowercase[10:13]+'m'*2),categories=list(string.ascii_lowercase[10:16]))
# a2=[42,1,3,-300,50]
# print(c0,c1,sep='\n')
# print(pandas.crosstab(c0,c1))
# print(pandas.crosstab(c0,c1,dropna=True))
# print(pandas.crosstab(c0,c1,dropna=False))
# print(pandas.crosstab(c0,c1,a2,aggfunc=numpy.sum,dropna=False))
# print(pandas.crosstab(c0,c1,a2,aggfunc=numpy.mean,dropna=False))
# print(pandas.crosstab(c0,c1,a2,aggfunc=numpy.ptp,dropna=False))

# s0=pandas.Series(numpy.random.default_rng(8).integers(0,10,(50,)))
# print(s0)
# print(pandas.cut(s0,5))
# print(pandas.cut(s0,5).get_dummies()

# index,columns,values,rownames,colnames,aggfunc,margins,margins_name,dropna,normalize,
# s0 = pd.Series(['cat0','cat1','cat2'])
# df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'], 'C': [1, 2, 3]})
# for data0 in [s0,df]:
    # for prefix0 in [None,'','prefix0',['prefix0','prefix1'],{'A':'prefix0','B':'prefix1'}]:#if prefix=None, uses each columnName as prefix (e.g. columnName(asPrefix)category0,columnName(asPrefix)category1,columnName(asPrefix)category2,columnName1(asPrefix)category0,...)
        # for prefix_sep0 in ['_','']:
            # for columns0 in [None,['A','C']]:#any columns not in 'columns'=thisList are still included in output but NOT as get_dummies (i.e. they are not split out but simply passed as is)
                # for dummy_na0 in [False,True]:#if dummy_na=True then 1 columnNamenan created for each columnName in DataFrame
                    # for sparse0 in [False,True]:
                        # for drop_first0 in [False,True]:
                            # for dtype0 in [numpy.uint8,numpy.float_]:
                                # print(f'data {data0}',f'prefix {prefix0}',f'prefix_sep {prefix_sep0}',f'columns {columns0}',f'dummy_na {dummy_na0}',f'sparse {sparse0}',f'drop_first {drop_first0}',f'dtype {dtype0}',sep='\n')
                                # try:
                                    # print(pandas.get_dummies(data0,prefix=prefix0,prefix_sep=prefix_sep0,columns=columns0,dummy_na=dummy_na0,sparse=sparse0,drop_first=drop_first0,dtype=dtype0))
                                # except Exception as e:
                                    # print(e)

# # c0=pandas.Categorical(string.ascii_lowercase[:13]*3+'x'*2+'y'*5,categories=list(string.ascii_lowercase[:13]+'xyz'))
# c0=pandas.Categorical(string.ascii_lowercase[:13],categories=list(string.ascii_lowercase[:13]+'xyz'))
# print(c0)
# print(pandas.get_dummies(c0,sparse=False))
# print(pandas.get_dummies(c0,sparse=True))

# print(pandas.get_dummies(pandas.cut(pandas.Series(numpy.random.default_rng(8).integers(0,10,(50,))),5)))
# print(pandas.get_dummies(pandas.cut(pandas.Series(numpy.random.default_rng(8).integers(0,10,(50,))),5),dtype=numpy.bool_))

#data,prefix,prefix_sep,columns,dummy_na,sparse,drop_first,dtype,
# df = pd.DataFrame({"a": [1, 0, 0, 1], "b": [0, 1, 0, 0],"c": [0, 0, 1, 0]})
# df1 = pd.DataFrame({"col1_a": [1, 0, 1], "col1_b": [0, 1, 0],"col2_a": [0, 1, 0], "col2_b": [1, 0, 0],"col2_c": [0, 0, 1]})
# df2 = pd.DataFrame({"col1_a": [1, 0, 0], "col1_b": [0, 1, 0],"col2_a": [0, 1, 0], "col2_b": [1, 0, 0],"col2_c": [0, 0, 0]})
# for data0 in [df,df1,df2]:
    # for sep0 in [None,'','_']:#'' not same as None and will error if no sep in df
        # for default_category0 in [None,'default_category0',{'col1':42,'col2':13}]:#must be same length as data otherwise errors (e.g. '''Length of 'default_category' (2) did not match the length of the columns being encoded (1)''')
            # print(f'data {data0}',f'sep {sep0}',f'default_category {default_category0}',sep='\n')
            # try:
                # print(pandas.from_dummies(data0,sep=sep0,default_category=default_category0))
                # print('validHit0')
            # except Exception as e:
                # print(e)

# print(pandas.get_dummies(pandas.cut(pandas.Series(numpy.random.default_rng(8).integers(0,10,(50,))),5)))
# print(pandas.from_dummies(pandas.get_dummies(pandas.cut(pandas.Series(numpy.random.default_rng(8).integers(0,10,(50,))),5))))
# print(pandas.get_dummies(pandas.cut(pandas.Series(numpy.random.default_rng(8).integers(0,10,(50,))),5),drop_first=True))
# print(pandas.from_dummies(pandas.get_dummies(pandas.cut(pandas.Series(numpy.random.default_rng(8).integers(0,10,(50,))),5),drop_first=True),default_category='(-0.009, 1.8]'))


# # In [134]: ser = pd.Series(['A', 'A', np.nan, 'B', 3.14, np.inf])

# # In [135]: pd.factorize(ser, sort=True)
# # Out[135]: (array([ 2,  2, -1,  3,  0,  1]), Index([3.14, inf, 'A', 'B'], dtype='object'))

# # In [136]: np.unique(ser, return_inverse=True)[::-1]
# # ---------------------------------------------------------------------------
# # TypeError                                 Traceback (most recent call last)
# # Cell In[136], line 1
# # ----> 1 np.unique(ser, return_inverse=True)[::-1]

# # File <__array_function__ internals>:180, in unique(*args, **kwargs)

# # File ~/micromamba/envs/test/lib/python3.8/site-packages/numpy/lib/arraysetops.py:274, in unique(ar, return_index, return_inverse, return_counts, axis, equal_nan)
    # # 272 ar = np.asanyarray(ar)
    # # 273 if axis is None:
# # --> 274     ret = _unique1d(ar, return_index, return_inverse, return_counts, 
    # # 275                     equal_nan=equal_nan)
    # # 276     return _unpack_tuple(ret)
    # # 278 # axis was specified and not None

# # File ~/micromamba/envs/test/lib/python3.8/site-packages/numpy/lib/arraysetops.py:333, in _unique1d(ar, return_index, return_inverse, return_counts, equal_nan)
    # # 330 optional_indices = return_index or return_inverse
    # # 332 if optional_indices:
# # --> 333     perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
    # # 334     aux = ar[perm]
    # # 335 else:

# # TypeError: '<' not supported between instances of 'float' and 'str'



# np.random.seed([3, 1415])

# n = 20

# cols = np.array(["key", "row", "item", "col"])

# df = cols + pd.DataFrame(
    # (np.random.randint(5, size=(n, 4)) // [2, 1, 2, 1]).astype(str)
# )


# df.columns = cols

# df = df.join(pd.DataFrame(np.random.rand(n, 2).round(2)).add_prefix("val"))

# print(df)
# print(df.pivot_table(index='row',columns='col',values='val0',aggfunc='count'))
# print(df.pivot_table(index='row',columns='col',values='val0',aggfunc='size'))
# df=pandas.DataFrame(numpy.ones((20,)))
# df.iloc[3:5,:]=pandas.NA
# print(df)
# print(df.count())
# print(df.agg('count'))
# print(df.size)


# series0=pandas.Series([[],'scalar0',2,numpy.nan,pandas.NA,None,['l0','l1','l2'],('t0','t1','t2'),{'s0','s1','s2'},numpy.array([0,1,2]),pandas.Series([0,1,2])])
# dataFrame0=pandas.DataFrame([series0,series0,numpy.ones(series0.shape)]).T.rename((lambda c0: 'col'+str(c0)),axis=1)
# # print(series0)
# # print(dataFrame0)
# for object00 in [series0,dataFrame0]:
    # for column0 in ['col0',['col0','col1']]:
        # for ignore_index0 in [False,True]:
            # print(f'object0 {object00}',f'column {column0}',f'ignore_index {ignore_index0}',sep='\n')
            # try:
                # print(object00.explode(column=column0,ignore_index=ignore_index0))
                # print('validHit0')
            # except Exception as e:
                # print(e)
                # print(object00.explode(ignore_index=ignore_index0))
                # print('validHit1')
            # print('\n')


# try:
    # dataFrame0=pandas.DataFrame([[['a','b'],['c','d']],[['a','b','b1'],['c','d','d1']]]).T.rename((lambda c0: 'col'+str(c0)),axis=1).explode(['col0','col1'],False)
# except Exception as e:
    # print(e)
# dataFrame0=pandas.DataFrame([[['a','b'],['c','d']],[['a','b','b1'],['c','d','d1']]]).T.rename((lambda c0: 'col'+str(c0)),axis=1)
# print(dataFrame0)
# try:
    # print(dataFrame0.apply(pandas.explode))
# except Exception as e:
    # print(e)
# def explodeSeries0(s0):
    # return s0.explode(False)
# try:
    # print(dataFrame0.apply(explodeSeries0))#will not work since apply does a reindex, which errors given duplicate indices from explode
# except Exception as e:
    # print(e)
# def explodeSeries0(s0):
    # return s0.explode(True)
# print(dataFrame0.apply(explodeSeries0))
# dataFrame0=pandas.DataFrame([[['a','b'],['c','d']],[['a','b','b1'],['c','d','d1']]]).T.rename((lambda c0: 'col'+str(c0)),axis=1)#in the real-world, data often comes in the form of all-elements-in-list1 associated with all-elements-in-list2 e.g. in this example here, a is associated with a,b,b1; b1 is in turn associated with a,b; hence, explode needs to have functionality that loops through the columns and explodes each separately to make one all-columns-exploded-sequentially DataFrame (instead of erroring out with '''columns must have matching element counts''', which isn't very useful); this is achieved with the following code ('''dataFrame1=dataFrame0.copy()...print(dataFrame0)'''); let's add this and maybe a kwarg iter=False (meaning do what we've been doing and raise if number of elements not equal) vs iter=True (apply the below code or equivalent, returning the result)
# print(dataFrame0)
# dataFrame1=dataFrame0.copy()
# for c0 in dataFrame1:
    # dataFrame0=dataFrame0.explode(c0)
    # print(dataFrame0)
# # print(dataFrame0)



# d = {"a": 0.0, "b": 1.0, "c": 2.0}
# print(d)
# print(pd.Series(d))
# print(pd.Series(d, index=["c", "b", "d", "a"]))


# print(pandas.Series(1,index=numpy.arange(20)))
# print(pandas.Series(1,index=numpy.arange(20))[0])
# print(pandas.Series(1,index=numpy.arange(20))[:3])
# print(pandas.Series(1,index=numpy.arange(20))[[2,4]])

# s0=pd.Series(numpy.random.default_rng(8).random((5,)), index=["a", "b", "c", "d", "e"])
# print(s0)
# print(s0[0])
# print(s0[:3])
# print(s0[[2,4]])
# print(s0[[False,False,True,False,True]])
# print(s0[[1,4]])#if length doesn't match, then uses positional
# print(s0[[False,True,False,False,True]])#does automatically use bool if length matches (how cool!)

# from pandas.api.extensions import register_dataframe_accessor
# # class dfAccessorGeo0(pandas.api.extensions.ExtensionDtype)
# @register_dataframe_accessor('geo0')
# class dfAccessorGeo0:
    # def __init__(self,object0):
        # self._object0=object0
    # @property
    # def center0(self):
        # _latitude0=self._object0.latitude0
        # _longitude0=self._object0.longitude0
        # return (float(numpy.mean(_longitude0)),float(numpy.mean(_latitude0)))
    
    # def plot0(self):
        # # self.plot()
        # pass

# df0=pandas.DataFrame({'longitude0':numpy.linspace(0,30),'latitude0':numpy.linspace(0,20)})
# print(df0)
# print(df0.geo0.center0)
# # print(df0.geo0.plot0())



# from pandas.api.extensions import register_series_accessor
# @register_series_accessor('geo1')#only lat
# class sAccessorGeo1:
    # def __init__(self,object1):
        # self.validate1(object1)
        # self._object1=object1
    # @staticmethod
    # def validate1(object1):
        # print(object1.dtype)
        # if object1.dtype != numpy.float_:
            # raise AttributeError('wrongDtypeForAccessor!')
    # @property
    # def center1(self):
        # _latitude1=self._object1.latitude1
        # return (float(numpy.mean(_latitude1)))
    # def plot1(self):
        # # self.plot()
        # pass

# s1=pandas.Series({'latitude1':['a','b','c']})
# print(s1)
# try:
    # print(s1.geo1.center1)
# except Exception as e:
    # print(e)
# # print(s1.geo1.plot1())



# from pandas.api.extensions import register_series_accessor
# @register_series_accessor('geo1')#only lat
# class sAccessorGeo1:
    # def __init__(self,object1):
        # self._object1=object1
    # @property
    # def center1(self):
        # _latitude1=self._object1.latitude1
        # return (float(numpy.mean(_latitude1)))
    # def plot1(self):
        # # self.plot()
        # pass

# # s1=pandas.Series({'latitude1':numpy.linspace(1,21,dtype=float)}).convert_dtypes()
# # s1=pandas.Series(numpy.linspace(1,21),name='latitude1')
# s1=pandas.Series({'latitude1':numpy.linspace(1,21)})
# print(s1)
# print(s1.geo1.center1)
# # print(s1.geo1.plot1())


# from pandas.api.extensions import register_index_accessor
# @register_index_accessor('geo2')#only lat
# class iAccessorGeo2:
    # def __init__(self,object2):
        # self._object2=object2
    # @property
    # def center2(self):
        # _latitude2=self._object2.values
        # return (float(numpy.mean(_latitude2)))
    
    # def plot2(self):
        # # self.plot()
        # pass

# i2=pandas.Index(numpy.linspace(2,22))
# print(i2)
# print(i2.geo2.center2)
# # print(i2.geo2.plot2())

# print(pandas.Index(['data0','data1','data2','data3'],dtype='string'))
# print(pandas.Index(['data0','data1','data2','data3'],dtype='string').repeat(0))
# print(pandas.Index(['data0','data1','data2','data3'],dtype='string').repeat(3))
# print(pandas.Index(['data0','data1','data2','data3'],dtype='string').repeat([3,3,7,7]))
# print(pandas.Series(['data0','data1','data2','data3'],dtype='string'))
# print(pandas.Series(['data0','data1','data2','data3'],dtype='string').repeat(0))#when would you ever do this..
# print(pandas.Series(['data0','data1','data2','data3'],dtype='string').repeat(3))
# print(pandas.Series(['data0','data1','data2','data3'],dtype='string').repeat([3,3,7,7]))

# i0= pandas.Index([1,2,3])
# df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
# v0=42
# l0=[42,43]
# s0=pandas.Series([42,43],index=[2,0])
# #object0,column,ignore_index,
# for loc0 in [0,1]:
    # for column0 in [420,'col420']:
        # for value0 in [v0,l0,s0]:
            # for allow_duplicates0 in [False,True]:
                # print(f'loc {loc0}',f'column {column0}',f'value {value0}',f'allow_duplicates {allow_duplicates0}',sep='\n')
                # try:
                    # print(df.insert(loc0,column0,value0,allow_duplicates=allow_duplicates0))
                    # print(df)
                # except Exception as e:
                    # print(e)
                # try:
                    # print(i0.insert(loc0,value0))
                # except Exception as e:
                    # print(e)

# loc,column,value,allow_duplicates,
# object0=AngleArray([1,2.2,5.6,2.3,1.2],unit='rad',copy=True)
# print(object0.repeat(4))
# for value0 in [5,2.2]:
    # for side0 in ['left','right']:
        # for sorter0 in [None,numpy.argsort(object0)]:
            # print(f'value {value0}',f'side {side0}',f'sorter {sorter0}',sep='\n')
            # print(object0.searchsorted(value0,side=side0,sorter=sorter0))

#value,side,sorter,
# object0=AngleArray([1,2.2,5.6,2.3,1.2],unit='rad',copy=True)
# for indices0 in [[1,2],[-1,2]]:
    # for allow_fill0 in [False,True]:
        # for fill_value0 in [None,[42]]:
            # print(f'indices {indices0}',f'allow_fill {allow_fill0}',f'fill_value {fill_value0}',sep='\n')
            # try:
                # print(object0.take(indices0,allow_fill=allow_fill0,fill_value=fill_value0))
            # except Exception as e:
                # print(e)
# try:
    # print(object0.take([0,1,2,3,4,5,6,7],allow_fill=True))
# except Exception as e:
    # print(e)
# object0=AngleArray([1,2.2,5.6,2.3,1.2],unit='rad',copy=True)
# try:
    # print(object0.view(dtype=numpy.float_))
# except Exception as e:
    # print(e,sys.exc_info())
# try:
    # print(object0.view(dtype='Float64'))
# except Exception as e:
    # print(e,sys.exc_info())


# object0=AngleArray([1,2.2,5.6,2.3,1.2],unit='rad',copy=True)
# object1=AngleArray([1,2.2,5.6,2.3,1.3],unit='rad',copy=True)
# print(object0,object1,AngleArray._concat_same_type([object0,object1]),sep='\n')

# print(object0._formatter())
# print(object0._formatter(boxed=False))
# print(object0._formatter(boxed=True))
# object0=AngleArray([1,2.2,5.6,2.3,1.2],unit='rad',copy=True)#full implementation of AngleArray https://stackoverflow.com/questions/68893521/simple-example-of-pandas-extensionarray
# print(pandas.Series([1.0]).apply(object0._formatter()))
# print(pandas.Series([1.0]).apply(object0._formatter(boxed=True)))
# print(pandas.Series(1.0).apply(object0._formatter()))
# print(pandas.Series(1.0).apply(object0._formatter(boxed=True)))

# object0=AngleArray([1,1,2,2],unit='rad',copy=True)#full implementation of AngleArray https://stackoverflow.com/questions/68893521/simple-example-of-pandas-extensionarray
# print(object0.factorize())
# try:
    # print(object0._from_factorized(object0.factorize()))
# except Exception as e:
    # print(e)
# print(object0._from_factorized(object0.factorize()[0],object0))
# print('')
# print(object0._from_factorized(object0.factorize()[1],object0))
# print('')
# try:
    # print(object0._from_factorized(object0.factorize()[1],object0.factorize()[0]))
# except Exception as e:
    # print(e)
# print('')
# print(object0._from_factorized(object0.factorize()[0],object0.factorize()[1]))

# object0=pandas.array(['a','a','b','b'])
# print(object0.factorize())
# try:
    # print(object0._from_factorized(object0.factorize()))
# except Exception as e:
    # print(e)
# try:
    # print(object0._from_factorized(object0.factorize()[0],object0))
# except Exception as e:
    # print(e)
# print('')
# try:
    # print(object0._from_factorized(object0.factorize()[1],object0))
# except Exception as e:
    # print(e)
# print('')
# try:
    # print(object0._from_factorized(object0.factorize()[1],object0.factorize()[0]))
# except Exception as e:
    # print(e)
# print('')
# try:
    # print(object0._from_factorized(object0.factorize()[0],object0.factorize()[1]))
# except Exception as e:
    # print(e)


# object0=AngleArray([1,1,2,2,3],unit='rad',copy=True)#full implementation of AngleArray https://stackoverflow.com/questions/68893521/simple-example-of-pandas-extensionarray
# print(object0._from_sequence([1,1,2,2,3,4]))
# print(object0._from_sequence_of_strings([1,1,2,2,3,4]))
# print(object0._from_sequence_of_strings(['1','1','2','2','3','4']))

# object0=AngleArray([1,1,2,2,3,numpy.nan],unit='rad',copy=True)#full implementation of AngleArray https://stackoverflow.com/questions/68893521/simple-example-of-pandas-extensionarray
# try:
    # print(object0._reduce(numpy.mean,skipna=False))
# except Exception as e:
    # print(e)
# print(object0._reduce('mean',skipna=False))
# print(object0._reduce('mean',skipna=True))

# object0=AngleArray([1,1,2,2,3],unit='rad',copy=True)#full implementation of AngleArray https://stackoverflow.com/questions/68893521/simple-example-of-pandas-extensionarray
# try:
    # print(object0._reduce(numpy.mean,skipna=False))
# except Exception as e:
    # print(e)
# print(object0._reduce('mean',skipna=False))
# print(object0._reduce('mean',skipna=True))


# print(pandas.arrays.PandasArray(numpy.array([1,2,3]),copy=False))
# print(pandas.arrays.PandasArray(numpy.array([1,2,3]),copy=True))


# print(pandas.api.indexers.check_array_indexer(pandas.array([1,2,3]),pandas.array([1,2,3])))
# try:
    # print(pandas.api.indexers.check_array_indexer(pandas.array([1,2,3]),pandas.array([1,2,numpy.nan],dtype='Int64')))
# except Exception as e:
    # print(e)
# print(pandas.api.indexers.check_array_indexer(pandas.array([1,2,3]),pandas.array([1,2,3],dtype='Int64')))
# print(pandas.api.indexers.check_array_indexer(pandas.array([1,2,3]),pandas.array([True,False,numpy.nan],dtype='boolean')))
# print(pandas.api.indexers.check_array_indexer(pandas.array([1,2,3]),pandas.array([True,False,False],dtype='boolean')))
# try:
    # print(pandas.api.indexers.check_array_indexer(pandas.array([1,2,3]),pandas.array([True,False],dtype='boolean')))
# except Exception as e:
    # print(e)
# try:
    # print(pandas.api.indexers.check_array_indexer(pandas.array([1,2,3]),pandas.array([...],dtype='boolean')))
# except Exception as e:
    # print(e)
# try:
    # print(pandas.api.indexers.check_array_indexer(pandas.array([1,2,3]),pandas.array(...,dtype='boolean')))
# except Exception as e:
    # print(e)
# try:
    # print(pandas.api.indexers.check_array_indexer(pandas.array([1,2,3]),pandas.array(4,dtype='Int64')))
# except Exception as e:
    # print(e)
# try:
    # print(pandas.api.indexers.check_array_indexer(pandas.array([1,2,3]),1))
# except Exception as e:
    # print(e)


# s0=pandas.Series([f'{digit0}' for digit0 in range(200)])
# print(s0.nbytes)
# print(s0.astype('category').nbytes)

# s0=pandas.Series(numpy.ones(200))
# print(s0.nbytes)
# print(s0.astype('category').nbytes)

# s0=pandas.Series([4,5,3],dtype='category')
# print((type(s0)))
# print(s0.cat.as_ordered())
# print(s0.cat.as_unordered())
# # for s1 in [s0.cat.as_ordered(),s0.cat.as_unordered()]:
# for s1 in [pandas.Categorical([4,5,3],ordered=True),pandas.Categorical([4,5,3],ordered=False)]:
    # for function0 in [s1.min,s1.max,s1.sort_values]:
        # print(s1,function0,sep='\n')
        # try:
            # print(function0())
        # except Exception as e:
            # print(e)

# for s1 in [pandas.Categorical([4,5,3],categories=[4,5,3],ordered=True),pandas.Categorical([4,5,3],categories=[4,5,3],ordered=False)]:
    # for function0 in [s1.min,s1.max,s1.sort_values]:
        # print(s1,function0,sep='\n')
        # try:
            # print(function0())
        # except Exception as e:
            # print(e)

#indices,allow_fill,fill_value,
# pandas.Categorical([4,5,3],categories=[4,5,3],ordered=True).astype('category'

# for categories0 in [['b','a','c','d'],['b','a','c',numpy.nan]]:
    # for ordered0 in [False,None,True]:
        # print(f'categories {categories0}',f'ordered {ordered0}',sep='\n')
        # try:
            # print(pandas.Series(['c','b','a','a'],dtype=pandas.CategoricalDtype(categories=categories0,ordered=ordered0)))
            # print(pandas.CategoricalDtype(categories=categories0,ordered=ordered0).categories)
            # print(pandas.CategoricalDtype(categories=categories0,ordered=ordered0).ordered)
        # except Exception as e:
            # print(e)

# print(pandas.Series([1,2,3],dtype=pandas.CategoricalDtype(categories=[2,3,1],ordered=True)))
# print(pandas.Series([1,2,3],dtype=pandas.CategoricalDtype(categories=[2,3,1],ordered=True)).astype(pandas.CategoricalDtype(ordered=None)))#when would you ever use this instead of just plain copy.. maybe in combinations it's more useful (especially when you don't know whether e.g. the 89th Categorical Series is ordered=False or ordered=True)
# print(pandas.Series([1,2,3],dtype=pandas.CategoricalDtype(categories=[2,3,1],ordered=True)).astype(pandas.CategoricalDtype(ordered=False)))

#categories,ordered,


# for values0 in [[1,3,2],['a','c','b']]:
    # for categories0 in [None,[1,3,2]]:
        # for ordered0 in [None,False,True]:
            # for dtype0 in [None,pandas.CategoricalDtype(categories=[3,2,1],ordered=True)]:#overrides inferred when not None; also, raises error '''Cannot specify `categories` or `ordered` together with `dtype`.''' when trying to specify `categories` or `ordered` together with `dtype` 
                # for fastpath0 in [False,True]:#10x faster when True (skip some internal checks and memory inefficient but faster (e.g. timeit.repeat results when False [0.0020938999950885773, 0.001845099963247776, 0.0020455000922083855] vs timeit.repeat results when True [0.0001822998747229576, 0.00014039967209100723, 0.00013450020924210548]))
                    # for copy0 in [False,True]:#True seems to be faster per timeit.repeat runs (don't have to update same memory by allocating some tmp memory and updating back from there (e.g. timeit.repeat results when False [0.004346900153905153, 0.0036661000922322273, 0.0025372998788952827] vs timeit.repeat results when True [0.0023807003162801266, 0.002176800277084112, 0.002770999912172556]))
                        # print(f'values {values0}',f'categories {categories0}',f'ordered {ordered0}',f'dtype {dtype0}',f'fastpath {fastpath0}',f'copy {copy0}',sep='\n')
                        # try:
                            # print(pandas.Categorical(values0,categories=categories0,ordered=ordered0,dtype=dtype0,fastpath=fastpath0,copy=copy0))
                            # print(timeit.repeat('''pandas.Categorical(values0,categories=categories0,ordered=ordered0,dtype=dtype0,fastpath=fastpath0,copy=copy0)''',number=10,repeat=3,globals=globals()))
                            # c0=pandas.Categorical(values0,categories=categories0,ordered=ordered0,dtype=dtype0,fastpath=fastpath0,copy=copy0)
                            # print(c0.categories,c0.codes,c0.ordered,c0.dtype,sep='\n')
                        # except Exception as e:
                            # print(e)
                        # print('\n')

# values,categories,ordered,dtype,fastpath,copy,
# for codes0 in [[0,1,0,1],[1,1,1,0]]:
    # for categories0 in [None,['b','a']]:
        # for ordered0 in [None,False,True]:
            # for dtype0 in [None,pandas.CategoricalDtype(categories=['a','b'],ordered=False)]:
                # print(f'codes {codes0}',f'categories {categories0}',f'ordered {ordered0}',f'dtype {dtype0}',sep='\n')
                # try:
                    # print(pandas.Categorical.from_codes(codes0,categories=categories0,ordered=ordered0,dtype=dtype0))
                    # print(pandas.Categorical.from_codes(codes0,categories=categories0,ordered=ordered0,dtype=dtype0).__array__(dtype=None))
                    # print(pandas.Categorical.from_codes(codes0,categories=categories0,ordered=ordered0,dtype=dtype0).__array__(dtype=None).dtype)
                # except Exception as e:
                    # print(e)
                # try:
                    # print(pandas.Categorical.from_codes(codes0,categories=categories0,ordered=ordered0,dtype=dtype0).__array__(dtype=pandas.CategoricalDtype(ordered=False)))
                # except Exception as e:
                    # print(e)
                # try:
                    # print(pandas.Categorical.from_codes(codes0,categories=categories0,ordered=ordered0,dtype=dtype0).__array__(dtype=pandas.CategoricalDtype(categories=['a','b'],ordered=False)))
                # except Exception as e:
                    # print(e)
                # try:
                    # print(pandas.Categorical.from_codes(codes0,categories=categories0,ordered=ordered0,dtype=dtype0).__array__(dtype=numpy.object_))
                # except Exception as e:
                    # print(e)
                # print('\n')

# print(pandas.DataFrame(list('abc'),list('def'),dtype='category'))
# print(pandas.DataFrame(list('abc'),list('def'),dtype='category').dtypes)
# print(pandas.DataFrame({'col0':list('abc'),'col1':list('def')}))
# print(pandas.DataFrame({'col0':list('abc'),'col1':list('def')}).astype('category'))
# print(pandas.DataFrame({'col0':list('abc'),'col1':list('def')}).astype('category').dtypes)
# print(pandas.DataFrame({'col0':list('abc'),'col1':list('def')},dtype='category'))
# print(pandas.DataFrame({'col0':list('abc'),'col1':list('def')},dtype='category').dtypes)
# print(pandas.unique(pandas.DataFrame({'col0':list('abc'),'col1':list('def')},dtype='category').to_numpy().ravel()))

# cuo0=pandas.CategoricalDtype([1,2,3],ordered=False)
# co0=pandas.CategoricalDtype([1,2,3],ordered=True)
# cuo1=pandas.CategoricalDtype([3,2,1],ordered=False)
# co1=pandas.CategoricalDtype([3,2,1],ordered=True)
# for c0 in [cuo0,co0,cuo1,co1]:
    # for c1 in [cuo0,co0,cuo1,co1]:
        # print(c0.categories,c0.ordered,c1.categories,c1.ordered,sep='\n')
        # print('c0==c1Compare0',c0==c1)
        # print('\n')

# cat = pd.Categorical(["a", "c", "c", np.nan], categories=["b", "a", "c"])
# df = pd.DataFrame({"cat": cat, "s": ["a", "c", "c", np.nan]})
# print(df.describe())

# print(pandas.unique(pandas.Categorical(['b','a','c'],categories=['a','b','c','d'])))
# print((pandas.Categorical(['b','a','c'],categories=['a','b','c','d'])).categories)
# print((pandas.Categorical(['b','a','c'],categories=['a','b','c','d'])).rename_categories([1,2,3,4]))
# print((pandas.Categorical(['b','a','c'],categories=['a','b','c','d'])).rename_categories({'a':42,'e':43}))
# print((pandas.Categorical(['b','a','c'],categories=['a','b','c','d'])).rename_categories((lambda c0: c0.upper())))
# c0=pandas.Categorical(['b','a','c'],categories=['a','b','c','d'])
# print(c0)
# print(c0.rename_categories((lambda c0: c0.upper())))#returns array of dtype='category' with new categories but does NOT modify original in place
# print(c0)#original still returns same as 2 lines above
# print(c0.ordered)
# print(c0.reorder_categories(['d','c','b','a'],ordered=True))
# print(c0.as_ordered())
# print(c0.as_ordered().as_unordered())
# print(c0.set_categories(['d','c','b'],ordered=True))
# print(c0.remove_categories(['a']))
# print(c0.set_categories(['d','c','b','a','e'],ordered=True))
# print(c0.add_categories(['e']))
# print(c0.remove_unused_categories())
# print(c0.as_ordered())
# print(c0.as_ordered().min()+c0.as_ordered().min())
# try:
    # print(c0.as_ordered().min()-c0.as_ordered().min())
# except Exception as e:
    # print(e)
# c0=pandas.Categorical([2,1,3],categories=[1,2,3,4])
# print(c0)
# print(c0.as_ordered())
# print(c0.as_ordered().min())
# print(c0.as_ordered().max())
# print(c0.as_ordered().min()+c0.as_ordered().min())
# print(c0.as_ordered().min()-c0.as_ordered().min())
# print(c0.as_ordered().min()*c0.as_ordered().min())
# print(c0.as_ordered().min()/c0.as_ordered().min())
# try:
    # print(c0.as_ordered().median())
# except Exception as e:
    # print(e)
# print(c0.as_ordered().min()+c0.as_ordered().max())
# print(c0.as_ordered().min()-c0.as_ordered().max())
# print(c0.as_ordered().min()*c0.as_ordered().max())
# print(c0.as_ordered().min()/c0.as_ordered().max())

# list0=[1,2,3]
# list1=[3,2,1]
# co0=pandas.Categorical([1,2,3],categories=[1,2,3],ordered=True)
# co1=pandas.Categorical([3,2,1],categories=[1,2,3],ordered=True)
# cuo0=pandas.Categorical([1,2,3],categories=[1,2,3],ordered=False)
# cuo1=pandas.Categorical([3,2,1],categories=[1,2,3],ordered=False)
# scalar0=1
# scalar1=2
# for object0 in [list0,list1,co0,co1,cuo0,cuo1,scalar0,scalar1]:
    # for object1 in [list0,list1,co0,co1,cuo0,cuo1,scalar0,scalar1]:
        # print(object0,object1,sep='\n')
        # try:
            # print('object0>object1',object0>object1)
        # except Exception as e:
            # print(e)
        # try:
            # print('object0>=object1',object0>=object1)
        # except Exception as e:
            # print(e)
        # try:
            # print('object0<object1',object0<object1)
        # except Exception as e:
            # print(e)
        # try:
            # print('object0<=object1',object0<=object1)
        # except Exception as e:
            # print(e)
        # try:
            # print('object0==object1',object0==object1)
        # except Exception as e:
            # print(e)
        # try:
            # print('object0!=object1',object0!=object1)
        # except Exception as e:
            # print(e)
        # print('\n')

# print(pandas.Series(pandas.Categorical(['a','a','b','c'],categories=['a','b','c','d'],ordered=True)).mode())
# print(pandas.Series(pandas.Categorical(['a','a','b','c'],categories=['a','b','c','d'],ordered=True)).value_counts())

# columns = pd.Categorical(
    # ["One", "One", "Two"], categories=["One", "Two", "Three"], ordered=True
# )
# print(columns)
# df = pd.DataFrame(
    # data=[[1, 2, 3], [4, 5, 6]],
    # columns=pd.MultiIndex.from_arrays([["A", "B", "B"], columns]),
# )
# print(df)
# print(df.groupby(axis=1, level=0).sum())
# print(df.groupby(axis=1, level=1).sum())
# try:
    # print(df.groupby(axis=1).sum())
# except Exception as e:
    # print(e)

# df0=pandas.DataFrame(numpy.random.default_rng(8).integers(0,100,(100,100)))
# for accessor0 in [df0.loc,df0.iloc,df0.at,df0.iat]:
    # try:
        # print(accessor0,accessor0[42,42],timeit.repeat('''accessor0[42,42]''',repeat=5,number=1000,globals=globals()),sep='\n')#based on below results, 1. at and iat are faster versions of loc and iloc respectively (when accessing 1 element, of course) 2. at < loc < iat < iloc in terms of speed (less is faster; probably due to necessary integer conversion of i* counterparts)
    # except Exception as e:
        # print(e)
# #results:
# # <pandas.core.indexing._LocIndexer object at 0x000001DFA82C9260>
# # 66
# # [0.012458200100809336, 0.011787200346589088, 0.01323659997433424, 0.01086620008572936, 0.011760300025343895]
# # <pandas.core.indexing._iLocIndexer object at 0x000001DFA830BD30>
# # 66
# # [0.03606580011546612, 0.03956490010023117, 0.036243699956685305, 0.03244740003719926, 0.03638960001990199]
# # <pandas.core.indexing._AtIndexer object at 0x000001DFA86F9A30>
# # 66
# # [0.004322299733757973, 0.005972200073301792, 0.004386099986732006, 0.005179999861866236, 0.004408000037074089]
# # <pandas.core.indexing._iAtIndexer object at 0x000001DFA86FBBA0>
# # 66
# # [0.027216500137001276, 0.02658300008624792, 0.029891499783843756, 0.028673999942839146, 0.03217059979215264]

# networkDifficulty=23e12
# hashRate=2280e6
# # hashRate=9050e6
# mH0=hashRate
# pHFromMH=mH0/(10**9)
# daysToMine1Bitcoin=(1 / (pHFromMH * 0.0066))
# print(daysToMine1Bitcoin)
# # # mineTimeInDays=difficultyRate/hashRate
# # # print(mineTimeInDays)
# # # mineTimeInYears=mineTimeInDays/365
# # print(mineTimeInYears)
# yearsToMine1Bitcoin = ((networkDifficulty * (2**32)) / (hashRate * 60 * 60 * 24 * 365.25))
# print(yearsToMine1Bitcoin)
# # yearsToMine1Bitcoin=2.8
# monthsToMine1Bitcoin=yearsToMine1Bitcoin*12
# priceOf1Bitcoin=30000
# pricePerMonth=priceOf1Bitcoin/monthsToMine1Bitcoin
# print(pricePerMonth)


# idx = pd.Index(["h", "i", "j", "k", "l", "m", "n"])
# cats = pd.Series(["a", "b", "b", "b", "c", "c", "c"], dtype="category", index=idx)
# values = [1, 2, 2, 2, 3, 4, 5]
# df = pd.DataFrame({"cats": cats, "values": values}, index=idx)
# print(df.iloc[2:4,:].dtypes)
# print(df.iloc[2,:].dtypes)
# print(df.iloc[2,1])
# print(df.iloc[[2],[1]])
# df.iloc[2:4,:]=[['a',42],['a',42]]
# print(df)
# try:
    # df.iloc[2:4,:]=[['z',42],['a',42]]
# except Exception as e:
    # print(e)
# c9=pandas.Categorical(['a','b','c'],categories=['a','b','c'])
# df.loc['j':'l','cats']=c9
# print(df)
# c9=pandas.Categorical(['a','b','c'],categories=['a','b','c','d'])
# try:
    # df.loc['j':'l','cats']=c9
# except Exception as e:
    # print(e)
# # df.loc['j':'l','values']=pandas.Categorical([420,421,422])#this gives some crazy max recursion limit (977+ times recursed) error due to python int objects but converting to pandas Int64 (below) works..
# df.loc['j':'l','values']=pandas.Categorical(pandas.Series([420,421,422],dtype='Int64'))
# print(df)
# print(df.dtypes)

# print(pandas.Series(list(string.ascii_lowercase[:5])).astype('category').str.upper())
# print(pandas.Series(pandas.date_range('2023-01-01','2023-01-05',freq='1D')).astype('category').dt.year)

#codes,categories,ordered,dtype,

# #e0,e1,to_union,sort_categories,ignore_order,
# c0=pandas.Categorical([2,1,3])
# c1=pandas.Categorical([5,4,6])
# # c0=pandas.Categorical([2,1,3],ordered=True)
# # c1=pandas.Categorical([5,4,6],ordered=True)
# c2=pandas.Categorical(['a','b','c'])
# for e00 in [c0,c1,c2]:
    # for e10 in [c0,c1,c2]:
        # for to_union0 in [[e00,e10]]:
            # for sort_categories0 in [False,True]:#errors if used with ordered=True categoricals; seems to be no-op with ordered=False categoricals but seems to work in https://pandas.pydata.org/docs/user_guide/categorical.html#unioning simpler example (not sure what's going on)
                # for ignore_order0 in [False,True]:
                    # print(f'e0 {e00}',f'e1 {e10}',f'to_union {to_union0}',f'sort_categories {sort_categories0}',f'ignore_order {ignore_order0}',sep='\n')
                    # try:
                        # print(pandas.concat([pandas.Series(to_union0[0]),pandas.Series(to_union0[1])]).astype('category'))#pro: can be used with different dtypes so long as  con: must be in Series or DataFrame (e.g. Categorical not allowed)
                        # print(pandas.api.types.union_categoricals(to_union0,sort_categories=sort_categories0,ignore_order=ignore_order0))#con: cannot be used with different dtypes but pro: can be in Categorical, Series, any list-like
                    # except Exception as e:
                        # print(e)
                    # print('\n')

# from pandas.api.types import union_categoricals
# a = pd.Categorical(["b", "c"])
# b = pd.Categorical(["a", "b"])
# print(union_categoricals([a, b]))
# print(union_categoricals([a, b],sort_categories=True))

# dfcat0 = pd.DataFrame(
    # {"A": pd.Series(list("aabbcdba")).astype("category"), "B": np.random.randn(8)}
# )
# print(dfcat0)
# print(dfcat0.dtypes)
# cstore0=pandas.HDFStore('categories0.h5',mode='w')
# cstore0.append('dfcat',dfcat0,format='table',data_columns=['A'])
# queried0=cstore0.select('dfcat',where="A in ['c','d']")
# print(queried0)
# print(queried0.dtypes)

# import io
# csv0=io.StringIO()
# dfcat0.to_csv(csv0)
# csv0import0=pandas.read_csv(io.StringIO(csv0.getvalue()))
# print(csv0import0)
# print(csv0import0.dtypes)
# print(csv0import0.astype('category'))
# print(csv0import0.astype('category').dtypes)

# print(pd.Series(list("aabbcdba")+[numpy.nan]).astype("category"))
# print(pd.Series(list("aabbcdba")+[numpy.nan]).astype("category").cat.categories)
# print(pd.Series(list("aabbcdba")+[numpy.nan]).astype("category").cat.codes)

# print(pd.Series(list("aabbcdba")+[numpy.nan]).astype("category").dtype)
# print(hasattr(pd.Series(list("aabbcdba")+[numpy.nan]).astype("category"),'cat'))
# try:
    # print(pd.Series(list("aabbcdba")+[numpy.nan]).astype("category").upper())
# except Exception as e:
    # print(e)
# print(type(pd.Series(list("aabbcdba")+[numpy.nan]).astype("category")))
# print(type(type(pd.Series(list("aabbcdba")+[numpy.nan]).astype("category"))))
# print(type(pandas.CategoricalDtype(categories=list('abc'),ordered=True)))
# print(type(type(pandas.CategoricalDtype(categories=list('abc'),ordered=True))))
# print(pd.Series(list("aabbcdba")+[numpy.nan]).astype("category").dtype==numpy.str_)
# print(pandas.CategoricalDtype(categories=list('abc'),ordered=True)==numpy.str_)

# df = pd.DataFrame(
    # {
        # "a": [1, 2, 3, 4],
        # "b": ["a", "b", "c", "d"],
        # "cats": pd.Categorical([1, 2, 3, 2]),
    # }
# )
# print(df.apply((lambda row0: type(row0['cats'])),axis=1))
# print(df.apply((lambda col0: col0.dtype),axis=0))
# print(pandas.Series(numpy.arange(3),index=pandas.Categorical(['b','a','c'],categories=list('bac'),ordered=True)))
# print(pandas.Series(numpy.arange(3),index=pandas.Categorical(['b','a','c'],categories=list('bac'),ordered=True)).sort_values(ascending=False))
# print(pandas.Series(numpy.arange(4),index=pandas.Categorical(['b','a','c','c'],categories=list('bac'),ordered=True)))
# print(pandas.Series(numpy.arange(4),index=pandas.Categorical(['b','a','c','c'],categories=list('bac'),ordered=True)).sort_values(ascending=False))
# cat = pd.Categorical([1, 2, 3, 10], categories=[1, 2, 3, 4, 10])
# s = pd.Series(cat, name="cat", copy=True)
# print(pandas.Categorical([0,1,2,3],categories=[0,1,2,3]))
# c0=pandas.Categorical([0,1,2,3],categories=[0,1,2,3])
# print(pandas.Series(c0,copy=False))
# s0=pandas.Series(c0)
# try:
    # s0[0]=90
# except Exception as e:
    # print(e)
# s0[0]=3
# print(s0)
# print(c0)
# df0=pandas.DataFrame(s0,columns=['col0'],copy=False)
# df0['col0']=df0['col0'].cat.rename_categories([90,1,2,42])#this will properly rename/relabell categories AND values (e.g. 3 -> 42)
# # df0['col0']=df0['col0'].cat.set_categories([90,1,2,42])#this will completely remove and then add categories, setting underlying values (that change e.g. 3 -> 42) to NaN instead of 42
# print(df0['col0'].cat.categories)
# print(df0)
# print(c0)#not entirely sure why this was not updated if categories were updated in df with copy=False..

# print(pandas.Series([1,2,3.]))
# print(pandas.Series([1,2,3.]).array)


# df = pd.DataFrame(np.random.randn(10, 4), columns=["A", "B", "C", "D"])
# df2 = pd.DataFrame(np.random.randn(3, 3), columns=["A", "B", "C"],index=[2,4,6])
# print(df)
# print(df2)
# print(df + df2)

# df0=pandas.DataFrame(numpy.random.default_rng(8).random((4,4)),columns=['col0','col1','col2','col3'],index=pandas.MultiIndex.from_product([[0,1],list(string.ascii_lowercase[:2])]))
# print(df0)
# print(df0.sub(df0['col0'],axis=0,level=1))

# s0=pandas.Series(numpy.arange(6))
# s1,s2=numpy.divmod(s0,3)
# print(s0,s1,s2,sep='\n')
# s1,s2=numpy.divmod(s0,[0,1,2,0,1,2])
# print(s0,s1,s2,sep='\n')

# s3=pandas.Series(numpy.arange(6),index=numpy.arange(4,10,1))
# print(s0.add(s3))
# print(s0.add(s3,fill_value=0))
# print(s0.gt(s3))
# s3=pandas.Series(numpy.arange(3,9,1),index=numpy.arange(4,10,1))
# df0=pandas.DataFrame({'col0':s0,'col1':s3})
# print(df0)
# print(df0[df0['col0'] > 3])
# print(df0[(df0['col0'] > 3)|(df0['col1']<=5)])
# print(df0.loc[(df0['col0'] > 3)|(df0['col1']<=5),'col1'])
# print(df0.iloc[((df0['col0'] > 3)|(df0['col1']<=5)).values,1])

# print(5 in s3)
# print('col1' in df0)
# print(s3.isin([5]))
# print(df0.isin([5]))
# print(s3.isin([1,5]))
# print(df0.isin([1,5]))
# print(~s3.isin([1,5]))
# print(~df0.isin([1,5]))


# df = pd.DataFrame(
    # {
        # "one": pd.Series(np.random.randn(3), index=["a", "b", "c"]),
        # "two": pd.Series(np.random.randn(4), index=["a", "b", "c", "d"]),
        # "three": pd.Series(np.random.randn(3), index=["b", "c", "d"]),
    # }
# )
# print(df)
# print((df+df)==(df*2))
# print(((df+df)==(df*2)).all())
# df1=df+df
# df2=df*2
# print(df1.equals(df2))
# df1 = pd.DataFrame({"col": ["foo", 0, np.nan]})
# df2 = pd.DataFrame({"col": [np.nan, 0, "foo"]}, index=[2, 1, 0])
# print(df1.equals(df2))
# print(df1.equals(df2.sort_index()))
# print(df1.align(df2))
# print(df1.align(df2)[0].equals(df1.align(df2)[1]))

# print(pandas.Series([1,2,3])==pandas.Series([1,2,3]))
# print(pandas.Series([1,2,3])==pandas.Series([1,2,4]))
# try:
    # print(pandas.Series([1,2,3])==pandas.Series([1,2]))
# except Exception as e:
    # print(e)
# try:
    # print(pandas.Series([1,2,3])==pandas.Series([1]))
# except Exception as e:
    # print(e)
# print(numpy.array([1,2,3])==numpy.array([1,2,3]))
# print(numpy.array([1,2,3])==numpy.array([1,2,4]))
# print(numpy.array([1,2,3])==numpy.array([1,2]))#deprecated and will raise error in future to align with pandas
# print(numpy.array([1,2,3])==numpy.array([1]))#broadcast so no error; broadcast powerful so numpy keeping it this way (and don't have to worry about indices since not pandas)


# df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})
# df2 = pd.DataFrame({'B': [42, 3], 'C': [1, 1]}, index=[1, 2])
# print(df1,df2,df1.combine_first(df2),sep='\n')#if df2 has entirely new index (axis=0,1), then concats; otherwise, will fill iff index,column combination exists in df2 (if in df1 but not in df2, then no fill)

# s1 = pd.Series({'falcon': np.nan, 'eagle': 160.0})
# s2 = pd.Series({'eagle': 200.0, 'duck': 30.0})
# print(s1,s2,s1.combine_first(s2),sep='\n')


# # s1 = pd.Series({'falcon': 330.0, 'eagle': 160.0})
# # s2 = pd.Series({'falcon': 345.0, 'eagle': 200.0, 'duck': 30.0})
# def func0(scalar0,scalar1):
    # return scalar0
# # print(s1,s2,s1.combine(s2,func0))
# # print(s1,s2,s1.combine(s2,max,fill_value=0.))
# # print(s1,s2,s1.combine(s2,min,fill_value=0.))
# # print('\n')
# # print(s1,s2,s1.combine(s2,numpy.maximum,fill_value=0.))#sort is reversed (i.e. does not preserve original order) but gives right answer (maybe has to do with how system processes memory efficiently / the order ?)

# #e0,e1,to_union,sort_categories,ignore_order,
# df0=pandas.DataFrame({'a':numpy.random.default_rng(8).random((2,)),'b':numpy.random.default_rng(7).random((2,))})
# df1=pandas.DataFrame({'c':numpy.random.default_rng(6).random((2,)),'d':numpy.random.default_rng(5).random((2,))})
# df2=pandas.DataFrame({'b':numpy.random.default_rng(6).random((2,)),'c':numpy.random.default_rng(5).random((2,))})
# print(df0,df1,df0.combine(df1,func0))
# print(df0,df1,df0.combine(df1,numpy.minimum))
# print(df0,df1,df0.combine(df1,numpy.minimum,overwrite=False))
# print(df0,df1,df0.combine(df1,numpy.minimum,fill_value=42,overwrite=False))
# print(df0,df2,df0.combine(df2,func0))
# print(df0,df2,df0.combine(df2,numpy.minimum))
# print(df0,df2,df0.combine(df2,numpy.minimum,overwrite=False))
# print(df0,df2,df0.combine(df2,numpy.minimum,fill_value=42,overwrite=False))
# for other0 in [df1,df2]:
    # for func0 in [func0,numpy.minimum,numpy.maximum]:
        # for fill_value0 in [None,[42]]:
            # for overwrite0 in [False,True]:
                # print(f'df {df0}',f'other {other0}',f'func {func0}',f'fill_value {fill_value0}',f'overwrite {overwrite0}',sep='\n')
                # try:
                    # print(df0.combine(other0,func=func0,fill_value=fill_value0,overwrite=overwrite0))
                # except Exception as e:
                    # print(e)
                # print('\n')
# df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})
# df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])
# print(df1)
# print(df2)
# take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2
# print(df1.combine(df2, take_smaller))#overwrite=True wipes left-side operand if left-side operand (Series) not present; note that any not present / matching indices (axis=0,1) (regardless of whether left-side operand (Series) exists) are wiped
# print(df1.combine(df2, take_smaller,overwrite=False))
# print(df2.combine(df1, take_smaller, overwrite=False))
# print(df1.combine(df2, numpy.minimum))
# print(df2.combine(df1, numpy.minimum, overwrite=False))
# print(df2.combine(df1, numpy.minimum, overwrite=False,fill_value=42))#fill_value has weird semantic where (fill_value is applied first, calculation per func happens, and then output is result) if overwrite=False, fill_value persists in original NaNs whereas, if overwrite=True, fill_value does NOT persist in original NaNs (must have to do with double isna() / i.e. 'double-negative' English speaking)
# print(df2.combine(df1, numpy.minimum,fill_value=42))

# df = pd.DataFrame(
    # [
        # [24.3, 75.7, "high"],
        # [31, 87.8, "high"],
        # [22, 71.6, "medium"],
        # [35, 95, "medium"],
    # ],
    # columns=["temp_celsius", "temp_fahrenheit", "windspeed"],
    # index=pd.date_range(start="2014-02-12", end="2014-02-15", freq="D"),
# )
# print(df)
# print(df.get(['temp_celsius','temp_fahrenheit']))
# print(df.get(['temp_celsius','temp_kelvin'],'atLeast1KeyDoesntExist'))
# print(type(df.get(['temp_celsius'])))
# print(df['temp_celsius'].get(['2014-02-12']))
# print(df['temp_celsius'].get(['2014-04-12'],'atLeast1KeyDoesntExist'))


# df = pd.DataFrame(
    # [
        # [24.3, 75.7, "high"],
        # [31, 87.8, "high"],
        # [22, 71.6, "medium"],
        # [35, 95, "medium"],
    # ],
    # columns=["temp_celsius", "temp_fahrenheit", "windspeed"],
    # index=['a','b','c','d']
# )
# print(df.temp_celsius)
# print(df.temp_celsius.a)
# df.temp_celsius.a=42
# print(df.temp_celsius.a)
# df.iloc[2]={"temp_celsius":22.1, "temp_fahrenheit":71.7, "windspeed":'mediumMore'}
# print(df)
# df.attribute0='attributeValue0'
# print(df,df.attribute0,sep='\n')
# s0=df['temp_celsius']
# s1=s0.rename('temp_celsius0')
# print(s1)
# print(pandas.DataFrame(s1,index=['b','c','d','e']))

# d = {
    # "one": pd.Series([1.0, 2.0, 3.0], index=["a", "b", "f"]),
    # "two": pd.Series([1.0, 2.0, 3.0, 4.0], index=["a", "b", "c", "d"]),
# }
# df = pd.DataFrame(d)
# print(df)
# print(df.index)#union of each component's index
# print(df.columns)
# try:
    # df.index=['a','b']#cannot be overridden by post-construction assignment unless length matches
# except Exception as e:
    # print(e)
# try:
    # df.columns=['one','three','four']#cannot be overridden by post-construction assignment unless length matches
# except Exception as e:
    # print(e)
# df.columns=['one','three']
# print(df)
# print(df.index)
# print(df.columns)#renamed by post-construction assignment

# d = {
    # "one": pd.Series([1.0, 2.0, 3.0], index=["a", "b", "f"]),
    # "two": pd.Series([1.0, 2.0, 3.0, 4.0], index=["a", "b", "c", "d"]),
# }
# df = pd.DataFrame(d,index=['a','b','z'],columns=['one','three'])#only at creation time, can override index and columns
# print(df)
# print(df.index)
# print(df.columns)

# df = pd.DataFrame(d,columns=['two','one'])#only at creation time, can override index and columns; exists, reorders; no exists, nans
# print(df)
# print(df.index)
# print(df.columns)

# data = np.zeros((2,), dtype=[("A", "i4"), ("B", "f4"), ("C", "a10")])
# data[:] = [(1, 2.0, "Hello"), (2, 3.0, "World")]
# print(data)
# print(pd.DataFrame(data))
# print(pd.DataFrame(data, index=['f','s'], columns=["C", "A", "B"]))

# data = [{'a':1,'b':2},{'a':3,'b':4,'c':5}]
# print(data)
# print(pandas.DataFrame(data))
# print(pd.DataFrame(data, index=['f','s'], columns=["b", "a"]))

# dictOfTuples0={('c0','sc0'):{('i0','si0'):1,('i0','si1'):2},('c0','sc1'):{('i1','si0'):3,('i1','si1'):4}}
# print(dictOfTuples0)
# print(pandas.DataFrame(dictOfTuples0))

# print(pandas.Series([1,2,3],index=[1,2,3],name='1230'))
# print(pandas.DataFrame(pandas.Series([1,2,3],index=[1,2,3],name='1230')))

# from collections import namedtuple
# point3d0Class0=namedtuple('point3d0','x y z')
# print(pandas.DataFrame([point3d0Class0(1,2,3),point3d0Class0(4,5,6),(7,8)]))
# try:
    # print(pandas.DataFrame([point3d0Class0(1,2,3),point3d0Class0(4,5,6),(7,8),(7,8,9,10)]))
# except Exception as e:
    # print(e)

# from dataclasses import make_dataclass
# point3d0DataClass0=make_dataclass('point3d0',[('x',int),('y',int),('z',float)])
# print(pandas.DataFrame([point3d0DataClass0(1,2,3),point3d0DataClass0(4,5,6)]))
# try:
    # print(pandas.DataFrame([point3d0DataClass0(1,2,3),point3d0DataClass0(4,5,6),(7,8)]))
# except Exception as e:
    # print(e)

# data = {'data': [[1, 2, 3], [4, 5, 6, 7], [8, 9]]}
# print(pandas.DataFrame(data))
# data = {'data': [1, 2, 3], 'data1':[4, 5, 6, 7], 'data2':[8, 9]}#arrays must be of same length (contrary to from_dict orient='tight')
# try:
    # print(pandas.DataFrame(data))
# except Exception as e:
    # print(e)

# try:
    # print(pandas.DataFrame({'a':1,'b':2,'c':3}))
# except Exception as e:
    # print(e)
# print(pandas.DataFrame({'a':[1,2],'b':[2,3],'c':[3,4]}))
# print(pandas.DataFrame.from_dict({'a':[1,2],'b':[2,3],'c':[3,4]}))
# print(pandas.DataFrame.from_dict({'a':[1,2],'b':[2,3],'c':[3,4]},orient='columns'))
# print(pandas.DataFrame.from_dict({'a':[1,2],'b':[2,3],'c':[3,4]},orient='index',columns=['A','B']))
# print(pandas.DataFrame.from_dict({'a':[1,2],'b':[2,3],'c':[3,4]},orient='index',columns=['A','B'],dtype='Float64'))
# data = {'index': [('a', 'b'), ('a', 'c')],
        # 'columns': [('x', 1), ('y', 2)],
        # 'data': [[1, 3], [2, 4]],
        # 'index_names': ['n1', 'n2'],
        # 'column_names': ['z1', 'z2']}
# print(pd.DataFrame.from_dict(data, orient='tight'))
# print(pandas.DataFrame.from_dict({'columns':['A','B','C'],'index':['a','b'],'data':[[1,2,3],[4,5,6]],'column_names':['cA'],'index_names':['iA']},orient='tight'))
# print(pandas.DataFrame.from_dict({'columns':['A','B','C'],'index':['a','b'],'data':[[1,2,3],[4,5]],'column_names':['cA'],'index_names':['iA']},orient='tight'))#arrays can be of different length (e.g. sparse data)

#other,func,fill_value,overwrite,
# d0=[(1,'a'),(2,'b'),(3,'c')]
# # d1=numpy.array([(1,'a'),(2,'b'),(3,'c')],dtype=[('int0',numpy.int_),('unicode0',numpy.unicode_)])#numpy.unicode_ is 0 length so will give ''..
# d1=numpy.array([(1,'a'),(2,'b'),(3,'c')],dtype=[('int0',numpy.int_),('unicode0','U4')])
# d2=[{'int1':1,'unicode1':'a'},{'int1':2,'unicode1':'b'},{'int1':3,'unicode1':'c'}]
# d3=list(range(3))
# for data0 in [d0,d1,d2,d3]:
    # for index0 in [None,[0,1],[1,2,3]]:#must match length of incoming data else errors
        # for exclude0 in [None,['int1']]:#AFTER columns
            # for columns0 in [None,['int1','int2']]:#renames 0,1,... defaults; if not default, then picks (nans for new)
                # for coerce_float0 in [False,True]:#no-op (no float conversion)?
                    # for nrows0 in [None,2#no-op (all rows taken regardless)?
                        # print(f'data {data0}',f'index {index0}',f'exclude {exclude0}',f'columns {columns0}',f'coerce_float {coerce_float0}',f'nrows {nrows0}',sep='\n')
                        # try:
                            # print(pandas.DataFrame.from_records(data0,index=index0,exclude=exclude0,columns=columns0,coerce_float=coerce_float0,nrows=nrows0))
                        # except Exception as e:
                            # print(e)
# data = [{'col_1': 3, 'col_2': 'a'},
        # {'col_1': 2, 'col_2': 'b'},
        # {'col_1': 1, 'col_2': 'c'},
        # {'col_1': 0, 'col_2': 'd'}]
# print(pd.DataFrame.from_records(data,columns=['col_2','col_1']))

# df0=pandas.DataFrame.from_dict({'columns':['A','B','C'],'index':['a','b'],'data':[[1,2,3],[4,5,6]],'column_names':['cA'],'index_names':['iA']},orient='tight')
# print(df0)
# print(df0.pop('C'))#returns Series
# print(df0)
# del df0['B']
# print(df0)
# df0['D']=pandas.Series([1,2],index=['a','c'])#c is not added (so concat 2nd dim but not 1st dim if doesn't exist (makes sense since entirely new Series added is different than extending all Series by 1+))
# print(df0)



# df = pd.DataFrame({'A': range(1, 6),                   'B': range(10, 0, -2),                   'C C': range(10, 5, -1)})
# print(df)
# print(df.query('B > A'))
# print(df.query('B == `C C`'))
# print(df.eval('B > A'))
# print(df.eval('B > A'))
# # print(timeit.repeat('''df.eval('B == `C C`')''',number=1000,globals=globals()))
# # try:
    # # print(timeit.repeat('''eval(df['B'] == df['C C'])''',number=1000,globals=globals()))
# # except Exception as e:
    # # print(e)
# # print(timeit.repeat('''df.eval('B == `C C`',engine='python')''',number=1000,globals=globals()))
# df = pd.DataFrame({'B': range(10000, 0, -1),'C C': range(0, 10000, 1)})
# print(timeit.repeat('''df.eval('B == `C C`')''',number=100,globals=globals()))
# print(timeit.repeat('''df.eval('B == `C C`',engine='python')''',number=100,globals=globals()))
# df = pd.DataFrame({'B': range(100000, 0, -1),'C C': range(0, 100000, 1)})
# print(timeit.repeat('''df.eval('B == `C C`')''',number=100,globals=globals()))
# print(timeit.repeat('''df.eval('B == `C C`',engine='python')''',number=100,globals=globals()))

# df = pd.DataFrame({'A': range(1, 6),                   'B': range(10, 0, -2),                   'C C': range(10, 5, -1)})
# #data,index,exclude,columns,coerce_float,nrows,
# sqlVar0=2
# # for expr0 in [None,'@sqlVar0+A','A+B','sqlVar0+A']:
    # # for parser0 in ['pandas','python']:
        # # for engine0 in ['numexpr','python']:
            # # for local_dict0 in [None,locals(),{}]:
                # # for global_dict0 in [None,globals()]:
                    # # for resolvers0 in [None,[df.index,df.columns],[df]]:
                        # # for target0 in [None,df]:
                            # # for inplace0 in [False,True]:
                                # # for level0 in [0,1]:
                                    # # print(f'expr {expr0}',f'parser {parser0}',f'engine {engine0}',f'local_dict {local_dict0}',f'global_dict {global_dict0}',f'resolvers {resolvers0}',f'target {target0}',f'inplace {inplace0}',f'level {level0}',sep='\n')
                                    # # try:
                                        # # print(pandas.eval(expr0,parser=parser0,engine=engine0,local_dict=local_dict0,global_dict=global_dict0,resolvers=resolvers0,target=target0,inplace=inplace0,level=level0))
                                        # # print(timeit.timeit('''pandas.eval(expr0,parser=parser0,engine=engine0,local_dict=local_dict0,global_dict=global_dict0,resolvers=resolvers0,target=target0,inplace=inplace0,level=level0)''',number=3,globals=globals()))
                                        # # print('validHit0')
                                    # # except Exception as e:
                                        # # print(e)

# # print(df.query('''A<@sqlVar0'''))
# # try:
    # # print(pandas.eval('''A+B''',target=df))
# # except Exception as e:
    # # print(e)
# # print(df.eval('''A+B'''))
# # print(pandas.eval('''A+B''',resolvers=[df]))
# print(pandas.eval('''
    # D=A+B
    # E=B+B
    # F=B*B
    # ''',resolvers=[df],target=df))
# print(df)
    # # F=B*`C C`
# print(pandas.eval('''df.A+df.B'''))
# try:
    # print(pandas.eval('''df.C=df.A+df.B''',target=df))#assignment requires target AND must be single name (so requires resolvers as well!)
# except Exception as e:
    # print(e)
# print(pandas.eval('''C=A+B''',target=df,resolvers=[df]))
# print(pandas.eval('''A+B''',resolvers=[df]))#no fully-qualified name requires resolvers
# #combo of both above requires both above..
# print(df.eval('''@sqlVar0 + A'''))#df.eval and df.query allow @; pandas.eval does NOT
# print(df.eval('''A < B'''))#automatically passes resolvers=[df]
# print(df.eval('''A < B and B < `C C`'''))
# df=df.eval('''D=`C C`''')
# try:
    # print(df.eval('''(A < B) and (B < D)''',parser='python'))#` not valid in python, so spaced-out identifiers won't work; 'and','or','not' also dont work
# except Exception as e:
    # print(e)
# print(df.eval('''(A < B) & (B < D)''',parser='python'))

# df = pd.DataFrame(
    # {"strings": np.repeat(list("cba"), 3), "nums": np.repeat(range(3), 3)}
# )
# print(df)
# print(df.query("strings == 'a' and nums == 1"))
# print(df.query('''strings == 'a' and nums == 2'''))

# df = pd.DataFrame({'A': range(1, 6),                   'B': range(10, 0, -2),                   'C C': range(10, 5, -1)})
# print(df)
# print(df.reindex(index=[3,2,1],columns=['C C','B','A']))
# df1 = pd.DataFrame({'AA': range(1, 6),                   'B': range(10, 0, -2),                   'C': range(10, 5, -1)},index=numpy.arange(4,9,1))
# print(df1)
# print(df1.align(df))
# print(df1.align(df,axis=0))
# print(df1.align(df,axis=1))
# df1 = pd.DataFrame({"a": [1, 0, 1], "b": [0, 1, 1]}, dtype=bool)
# df2 = pd.DataFrame({"a": [0, 1, 1], "b": [1, 1, 0]}, dtype=bool)
# print(df1,df2,df1&df2,df1|df2,df1^df2,df1+df2+42,sep='\n')


# ser = pd.Series([1, 2, 3])
# idx = pd.Index([4, 5, 6])
# df = pd.DataFrame({'a':[7,8,9]})
# print(np.maximum(ser, idx))
# print(type(np.maximum(ser, idx)))
# print(df)
# print(df.shape)
# print(ser)
# print(ser.shape)
# # print(np.maximum(df, idx+numpy.newaxis))
# print(np.maximum(df.iloc[:,0],idx))#just gives Series vs Index
# # print(type(np.maximum(df, idx)))
# # print(np.maximum(df, ser))
# # print(type(np.maximum(df, ser)))
# print(pandas.concat([df,ser],axis=1))
# print(type(pandas.concat([df,ser],axis=1)))

#expr,parser,engine,local_dict,global_dict,resolvers,target,inplace,level,

#data,sparse_index,fill_value,kind,dtype,copy,

# for data0 in [[0,1,2,0],[[False,False,False,False],[False,False,True,True]]]:
    # for sparse_index0 in [None,[0,1],False,True]:#this is actually a SparseIndex that you must pass in (otherwise, stick with None and it'll create that SparseIndex for you)
        # for fill_value0 in [None,[42]]:#this is what value means sparse in the data / what value the system interprets as sparse/notAUsefulValue in the data (usually this is 0 for ints, etc. but can be whatever value you specify here)
            # for kind0 in ['integer','block']:#returns start and end block points (e.g. start at 1 and then ends at 4 means [1:4] are all contiguous data points / non-sparse)
                # for dtype0 in [int,bool]:
                    # for copy0 in [False,True]:
                        # print(f'data {data0}',f'sparse_index {sparse_index0}',f'fill_value {fill_value0}',f'kind {kind0}',f'dtype {dtype0}',f'copy {copy0}',sep='\n')
                        # try:
                            # print(pandas.arrays.SparseArray(data0,sparse_index=sparse_index0,fill_value=fill_value0,kind=kind0,dtype=dtype0,copy=copy0))
                        # except Exception as e:
                            # print(e)

# print(pandas.SparseDtype())
# print(pandas.SparseDtype(dtype=numpy.float64,fill_value=None))
# print(pandas.SparseDtype(dtype=numpy.bool_,fill_value=False))
# print(pandas.SparseDtype(dtype=numpy.bool_,fill_value=True))

# arr = np.random.randn(10)
# arr[2:-2] = np.nan
# print(arr)
# print(pandas.Series(pandas.arrays.SparseArray(arr)))

# arr = np.random.randn(100000)
# arr[2:-2] = np.nan
# print(pandas.Series(arr).memory_usage(deep=True))
# print(pandas.Series(pandas.arrays.SparseArray(arr)).memory_usage(deep=True))
# print(pandas.Series(pandas.arrays.SparseArray(arr)).sparse.density)
# print(pandas.Series(pandas.arrays.SparseArray(arr)).sparse.fill_value)
# print(pandas.arrays.SparseArray(arr).dtype)
# # print(numpy.asarray(pandas.arrays.SparseArray(arr)))
# print(pandas.array([1,0,0,3],dtype='Sparse[int]'))
# print(pandas.array([1,0,0,3],dtype='Sparse[bool]'))
# try:
    # print(pandas.array([1,0,0,3],dtype='Sparse[bool]').sparse.density)#docs '''This accessor is available only on data with SparseDtype, and on the Series class itself for creating a Series with sparse data from a scipy COO matrix with.''' needs to be updated to '''This accessor is available only on a Series with data of SparseDtype (e.g. for creating a Series with sparse data from a scipy COO matrix with).''', as this code line gives error ''''SparseArray' object has no attribute 'sparse''' even though it's of SparseDtype..
# except Exception as e:
    # print(e)
# # # print(pandas.array([1,0,0,3],dtype='Sparse[bool]').sparse.fill_value)

# print(pandas.DataFrame([[1,0],[0,4]],dtype='Sparse[int]'))
# print(pandas.DataFrame([[1,0],[0,4]],dtype='Sparse[int]').sparse.density)
# print(pandas.DataFrame([[1,0],[0,4]],dtype='Sparse[int]').sparse.to_dense())
# print(pandas.DataFrame([[1,0],[1,0]],dtype='Sparse[int]').sparse.to_dense())
# print(type(pandas.DataFrame([[1,0],[0,4]],dtype='Sparse[int]').sparse.to_dense()))
# print(type(pandas.DataFrame([[1,0],[1,0]],dtype='Sparse[int]').sparse.to_dense()))
# print(type(pandas.DataFrame([[1,0],[0,4]],dtype='Sparse[int]').sparse.to_coo()))
# print(pandas.DataFrame.sparse.from_spmatrix(pandas.DataFrame([[1,0],[0,4]],dtype='Sparse[int]').sparse.to_coo()))
# print(pandas.DataFrame.sparse.from_spmatrix(pandas.DataFrame([[1,0],[0,4]],dtype='Sparse[int]').sparse.to_coo(),index=['a','b'],columns=['A','B']))



# print(pandas.Series([0,0,0,4],dtype='Sparse[int]').sparse.fill_value)
# print(pandas.Series([0,0,0,4],dtype='Sparse[int]').sparse.npoints)
# print(pandas.Series([0,0,0,4],dtype='Sparse[int]').sparse.density)
# print(pandas.Series([0,0,0,4],dtype='Sparse[int]').sparse.sp_values)
# print(pandas.Series([0,0,0,4],dtype='Sparse[int]').sparse.to_dense())
# print(type(pandas.Series([0,0,0,4],dtype='Sparse[int]').sparse.to_dense()))
# print(type(pandas.Series([0,0,0,4],dtype='Sparse[int]').sparse.to_coo()))
# print(pandas.DataFrame.sparse.from_spmatrix(pandas.Series([0,0,0,4],dtype='Sparse[int]').sparse.to_coo()))
# print(pandas.DataFrame.sparse.from_spmatrix(pandas.Series([0,0,0,4],dtype='Sparse[int]').sparse.to_coo(),index=['a','b'],columns=['A','B']))

# from scipy import sparse
# ss0=sparse.coo_matrix(([3,2,1],([2,0,0],[0,3,2])),shape=(3,4))
# print(ss0)
# print(pandas.Series.sparse.from_coo(ss0))
# print(pandas.Series.sparse.from_coo(ss0,dense_index=True))
# print(pandas.Series.sparse.from_coo(ss0).sparse.to_coo())
# print(pandas.Series.sparse.from_coo(ss0).sparse.to_coo(sort_labels=True))
# print(pandas.Series.sparse.from_coo(ss0).sparse.to_coo(row_levels=(1,),column_levels=(0,),sort_labels=True))
# print(timeit.timeit('''pandas.Series.sparse.from_coo(ss0).sparse.to_coo(sort_labels=True)''',number=15,globals=globals()))
# print(timeit.timeit('''pandas.Series.sparse.from_coo(ss0).sparse.to_coo(sort_labels=False)''',number=15,globals=globals()))


# s = pd.Series([3.0, np.nan, 1.0, 3.0, np.nan, np.nan])
# s.index = pd.MultiIndex.from_tuples(
    # [
        # (1, 2, "a", 0),
        # (1, 2, "a", 1),
        # (1, 1, "b", 0),
        # (1, 1, "b", 1),
        # (2, 1, "b", 0),
        # (2, 1, "b", 1)
    # ],
    # names=["A", "B", "C", "D"],
# )
# print(s)
# ss = s.astype("Sparse")
# print(ss)
# A, rows, columns = ss.sparse.to_coo(row_levels=["A", "B"], column_levels=["C", "D"], sort_labels=True)
# print(A)
# print(A.todense())
# print(rows)
# print(columns)

# A, rows, columns = ss.sparse.to_coo(row_levels=["A", "B"], column_levels=["C", "D"], sort_labels=False)
# print(A)
# print(A.todense())
# print(rows)
# print(columns)

# print(timeit.timeit('''ss.sparse.to_coo(row_levels=["A", "B"], column_levels=["C", "D"], sort_labels=True)''',number=15,globals=globals()))#append '''When row_levels and/or column_levels refer to multiple levels, set to False for a faster execution.''' to '''Sort the row and column labels before forming the sparse matrix. When row_levels and/or column_levels refer to a single level, set to True for a faster execution.'''
# print(timeit.timeit('''ss.sparse.to_coo(row_levels=["A", "B"], column_levels=["C", "D"], sort_labels=False)''',number=15,globals=globals()))


# print(pandas.Series([0,0,0,4.],dtype='Sparse'))
# print(pandas.Series([0,0,0,4],dtype='Sparse'))
# print(pandas.Series([0,0,0,4]).astype('Sparse'))
# print(pandas.Series([0,0,0,4]).astype('Sparse[int]'))
# a=numpy.arange(1000)
# print(pandas.DataFrame([a,a]))
# print(pandas.options.display.expand_frame_repr)
# pandas.options.display.expand_frame_repr=True
# print(pandas.options.display.expand_frame_repr)
# print(pandas.DataFrame([a,a]))



# dates = pd.date_range("20130101", periods=6)
# print(dates)
# df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list("ABCD"))
# print(df)
# print(df.sort_index(axis=1,ascending=False))
# print(df.sort_index(axis=0,ascending=False))
# print(df.sort_values(by=['A'],axis=0,ascending=False))
# print(df.sort_values(by=pandas.Timestamp('20130101'),axis=1,ascending=False))
# df.iloc[:,0]=numpy.arange(6)
# print(df)


# def f0(str0: str):
    # print(str0)
# try:
    # eval('''f0(str0: str)''')
# except Exception as e:
    # print(e)

# def f0(str0):
    # print(str0)
# str0='iMStr0'
# f0(str0)

# import pymongo
# client=pymongo.MongoClient("mongodb+srv://pablodumas94:hHOCGZu1QuBj43Lv@testingmongodb20230401.osuw417.mongodb.net/?retryWrites=true&w=majority")
# print(client.list_database_names())
# # db=client.test
# db=client['newDb0']
# print(db.list_collection_names())
# collection0=db['posts']
# import bs4,requests
# url0=r'https://chat.openai.com/chat/a4307dda-b036-47b2-80dd-01b76ff26e0f'
# url0=r'https://www.postgresql.org/'
# response=requests.get(url0)
# htmlContent0=response.content
# print(response)
# print('\n\n\n\n')
# print(htmlContent0)
# print('\n\n\n\n')
# soup=bs4.BeautifulSoup(htmlContent0,'html.parser')
# print(soup)
# print('\n\n\n\n')
# collection0.insert_one({'title':soup.title.string,'body':soup.body.text})
# print(collection0.find())

# filePath0=r'C:\Users\pdumas\Downloads\csv0Test0.csv')
# with open (filePath0,'w+') as f0:
    # f0.write('col0}col1,col2\nv0|v1|v2\nv3333|v4444|v5555')
# # with open (filePath0,'r') as f0:
    # # read0=f0.read('col0}col1,col2\nv0|v1|v2\nv3333|v4444|v5555')
# import csv
# from io import StringIO
# st0=StringIO('col0|col1|col2\nv0|v1|v2\nv3333|v4444|v5555')
# print(st0)
# print(st0.getvalue())
# try:
    # dialect0=csv.Sniffer().sniff(st0.getvalue())
# except Exception as e:
    # print(e)
# try:
    # dialect0=csv.Sniffer().sniff(st0.getvalue(),delimiters=['|'])
# except Exception as e:
    # print(e)
# try:
    # dialect0=csv.Sniffer().sniff(st0.getvalue(),delimiters='|,')
# except Exception as e:
    # print(e)
# try:
    # dialect0=csv.Sniffer().sniff(st0.getvalue(),delimiters='|,')
# except Exception as e:
    # print(e)
# print(csv.Sniffer().has_header(st0.getvalue()))#has header but not very good at detecting..
# reader0=csv.reader(st0,dialect0)
# for row0 in reader0:
    # print(row0)
# st0=StringIO('col0,col1,col2\nv0,v1,v2\nv3333,v4444,v5555')
# dialect0=csv.Sniffer().sniff(st0.getvalue())
# print(st0)
# print(st0.getvalue())
# reader0=csv.reader(st0,dialect0)
# for row0 in reader0:
    # print(row0)
# st0=StringIO('col0,col1,col2\0,1,2\n3,4,5')
# try:
    # dialect0=csv.Sniffer().sniff(st0.getvalue(),delimiters=',')
# except Exception as e:
    # print(e)
# try:
    # dialect0=csv.Sniffer().sniff(st0.getvalue())#works above but not here..
# except Exception as e:
    # print(e)
# try:
    # print(csv.Sniffer().has_header(st0.getvalue()))
# except Exception as e:
    # print(e)
# print(csv.list_dialects())
# filePath0=r'C:\Users\pdumas\Downloads\csv0Test0.csv'
# for dialect0 in ['unix','excel','excel-tab']:
    # # filePath0=r'C:\Users\pdumas\Downloads\csv0Test'+str(hash(dialect0))+'.csv'
    # filePath0=r'C:\Users\pdumas\Downloads\csv0Test'+dialect0+'.csv'
    # with open(filePath0,'w+',newline='') as f0:
        # # writer0=csv.writer(f0,dialect='unix')
        # # writer0=csv.writer(f0,dialect='excel')
        # writer0=csv.writer(f0,dialect=dialect0)
        # # writer0.writerow('col0}col1,col2\nv0|v1|v2\nv3333|v4444|v5555')
        # writer0.writerow(['col0']+['col1'])
        # writer0.writerow(['val0']+['val1'])
        # # os.system(r'start "" "'+filePath0+'"')
        # os.system(r'C:\Users\pdumas\AppData\Local\Microsoft\WindowsApps\notepad++.exe '+filePath0+'')

# import csv,dis,inspect
# print(dis.dis(csv.Dialect))
# print(inspect.getsource(csv.Dialect))
# print(inspect.getsource(csv.excel_tab))
# class excel_tab_custom2TabsPd20230403(csv.excel):
    # """Describe the usual properties of Excel-generated TAB-delimited files."""
    # delimiter = '\t\t'
# print(csv.register_dialect('excel_tab_custom2TabsPd20230403',excel_tab_custom2TabsPd20230403,delimiter='|'))
# for dialectName0 in csv.list_dialects():
    # print('\n\n',dialectName0)
    # dialect0=csv.get_dialect(dialectName0)
    # object0=dialect0
    # for a0 in dir(object0):
        # try:
            # print(a0,'    ',getattr(object0,a0))
        # except Exception as e:
            # print(e,sys.exc_info())
    # print(csv.field_size_limit())
# print(csv.unregister_dialect('excel_tab_custom2TabsPd20230403'))
# print(csv.list_dialects())
# print(csv.field_size_limit(1024))
# print(csv.field_size_limit())

# import requests

# # url = 'https://www.example.com/'
# # url = 'https://www.wikipedia.org/'
# url = 'https://en.wikipedia.org/'

# # make a GET request to the website's root directory
# response = requests.get(url)

# # check if the website has a robots.txt file
# print(response.text)
# if response.status_code == 200 and 'robots.txt' in response.text:
    # robots_url = url + 'robots.txt'
    # robots_response = requests.get(robots_url)
    # # print the contents of the robots.txt file
    # print(robots_response.text)
# else:
    # print('This website does not have a robots.txt file.')


# import requests
# from bs4 import BeautifulSoup

# # url = 'https://en.wikipedia.org/wiki/Main_Page'
# url = 'https://en.wikipedia.org/'

# # make a GET request to the parent URL
# response = requests.get(url)

# print(response)
# # create a BeautifulSoup object from the response content
# soup = BeautifulSoup(response.content, 'html.parser')

# # find all <a> tags that have an 'href' attribute starting with 'https://en.wikipedia.org/'
# links = soup.find_all('a', href=lambda x: x.startswith('https://en.wikipedia.org/'))
# print(links)

# # loop through the links and print the URLs of the files
# for link in links:
    # print(link['href'])

# import csv
# filePath0=r'C:\Users\pdumas\Downloads\csv0Test0.csv'
# for dialect0 in ['excel']:
    # filePath0=r'C:\Users\pdumas\Downloads\csv0Test1'+dialect0+'.csv'
    # with open(filePath0,'w+',newline='') as f0:
        # writer0=csv.writer(f0,dialect=dialect0)
        # writer0.writerows([['col0','col1','col2'],['val0','val1','val2'],['val0','val1'],['val0','val1','val3','val31','val32'],['val0','val1','val4','val5']])
# with open(filePath0,'r',newline='') as f0:
    # # dictReader0=csv.DictReader(filePath0,fieldnames=['cols','vals0','vals1'],restkey='restkey0',restval='restval0',dialect='excel')#fieldnames are col names not row names.. this is probably used by pandas read_csv
    # dictReader0=csv.DictReader(f0,fieldnames=['col00','col11','col22'],restkey='restkey0',restval='restval0',dialect='excel')
    # for row0 in dictReader0:
        # print(row0['col00'],row0['col22'])
# with open(filePath0,'r',newline='') as f0:
    # dictReader0=csv.DictReader(f0,fieldnames=None,restkey='restkey0',restval='restval0',dialect='excel')
    # for row0 in dictReader0:
        # try:
            # print(row0['col0'],row0['col2'])
        # except Exception as e:
            # print(e)
# with open(filePath0,'r',newline='') as f0:
    # dictReader0=csv.DictReader(f0,fieldnames=None,restkey='restkey0',restval='restval0',dialect='excel')
    # for row0 in dictReader0:
        # print(row0)
    # os.system(r'C:\Users\pdumas\AppData\Local\Microsoft\WindowsApps\notepad++.exe '+filePath0+'')
# filePath1=r'C:\Users\pdumas\Downloads\csv0Test1.csv'
# with open(filePath1,'w',newline='') as f0:
    # dW0=csv.DictWriter(f0,fieldnames=['first0','mid0','last0'],restval='Doe',extrasaction='ignore',dialect='excel')
    # print(dW0.writeheader(),'writeheader0')
    # dW0.writerow({'first0':'John','mid0':'D','last0':'Wayne'})
    # dW0.writerow({'first0':'John','mid0':'D'})
    # dW0.writerow({'first0':'John','mid0':'D','last0':2+3j,'oneTooMany':'oneTooManyVal0'})
    # object0=dW0
    # for a0 in dir(object0):
        # try:
            # print(a0,'    ',getattr(object0,a0))
        # except Exception as e:
            # print(e,sys.exc_info())
    # object0=csv.writer(f0,dialect='excel')
    # for a0 in dir(object0):
        # try:
            # print(a0,'    ',getattr(object0,a0))
        # except Exception as e:
            # print(e,sys.exc_info())
# with open(filePath1,'r',newline='') as f0:
    # dictReader0=csv.DictReader(f0,fieldnames=None,restkey='restkey0',restval='restval0',dialect='excel')
    # object0=dictReader0
    # for a0 in dir(object0):
        # try:
            # print(a0,'    ',getattr(object0,a0))
        # except Exception as e:
            # print(e,sys.exc_info())
    # for row0 in dictReader0:
        # print(row0)
    # os.system(r'C:\Users\pdumas\AppData\Local\Microsoft\WindowsApps\notepad++.exe '+filePath1+'')
# print('one|two}three')
# for row0 in csv.reader(['one|two}three'],delimiter='|'):
    # print(row0)
# object0=csv
# for a0 in dir(object0):
    # try:
        # print(a0,'    ',getattr(object0,a0))
    # except Exception as e:
        # print(e,sys.exc_info())

# import fsspec
# fO0=fsspec.open("github://dask:fastparquet@main/test-data/nation.csv","rt")
# with fO0 as f0:
    # for line0 in f0:
        # print(line0)
# from fsspec.implementations.local import LocalFileSystem
# lFS0=LocalFileSystem()
# print(lFS0)
# fSFile0=fsspec.filesystem('file')
# print(fSFile0)
# import socket
# try:
    # # fSFtp0=fsspec.filesystem('ftp',host=socket.gethostname())
    # print(fSFtp0)
    # pass
# except Exception as e:
    # print(e)
# with lFS0.open(r'C:\Users\pdumas\Downloads\fsspec0test0.txt','w') as f0:
    # print(f0.write('test000'))
# with lFS0.open(r'C:\Users\pdumas\Downloads\fsspec0test0.txt','r') as f0:
    # print(f0.read())
# print(fsspec.available_protocols())

# # # pd2023-04-06 from numpy0.feedback0.txt pd2023-04-06 starting here moving forward, all commentary will be in original source code (#...) and will merge with github for efficiency 

# # import zstandard
# # samples0='sampleText0sampleText0111110,sampleText0sampleText0111110,sampleText0sampleText0111110\nval0,val1,val2'.encode()
# # # train_dictionary0=zstandard.train_dictionary(bytes(16384),bytes(list(samples0)),k=20,d=6,f=20,split_point=.8,accel=8,dict_id=424242,steps=200,threads=-1,level=2,notifications=4)#keeps erroring since arg 2 has to be bytes, but then list, but then bytes, etc. ..
# # train_dictionary0=zstandard.train_dictionary(16384,samples0,k=20,d=6,f=20,split_point=.8,accel=8,dict_id=424242,steps=200,threads=-1,level=2,notifications=4)
# # compress0=zstandard.ZstdCompressor(dict_data=train_dictionary0).compress(samples0)
# # df0=pandas.read_csv(compress0,compression={'method':'zstd','dict_data':train_dictionary0})
# # print(samples0,train_dictionary0,compress0,df0,sep='\n')

# listOfFilesToMatch0
# listOfFiles0
# tupleOfFiles1
# files2

# def on_bad_lines0func0(listOfStringsPreviouslySplitBySep0):#passed-in arg is extra-fields row, truncated to match length of other rows (i.e. removing extra fields); only passed in if extra fields
    # if 'val2' in listOfStringsPreviouslySplitBySep0:#given above '''only passed in if extra fields''', this will not work unless extra fields (e.g. won't remove 1st row since 1st row has no extra fields)
        # return None
    # else:
        # return listOfStringsPreviouslySplitBySep0#this will just return the extra-fields row, truncated 

# import csv
# ##filepath_or_buffer,sep,delimiter,header,names,index_col,usecols,dtype,engine,converters,true_values,false_values,skipinitialspace,skiprows,skipfooter,nrows,na_values,keep_default_na,na_filter,verbose,skip_blank_lines,parse_dates,infer_datetime_format,keep_date_col,date_parser,dayfirst,cache_dates,iterator,chunksize,compression,thousands,decimal,lineterminator,quotechar,quoting,doublequote,escapechar,comment,encoding,encoding_errors,dialect,on_bad_lines,delim_whitespace,low_memory,memory_map,float_precision,storage_options,
# #can't run below given combinatorics too much compute (at least 281474976710656 (2**48; 48 'for' loops with at least 2 values) resulting outputs is too much)
# # for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv',r'company_ipo.csv']:
    # # for sep0 in [',','|']:
        # # for delimiter0 in [None,'|']:
            # # for header0 in ['infer',0,[0,1],None]:
                # # for names0 in [['col00','col11','col22']]:#_NoDefault.no_default
                    # # for index_col0 in [None,False,0,[0,1],'col5']:
                        # # for usecols0 in [None,['col0','col2'],(lambda c0:c0.upper() in ['COL0','COL1'])]:
                            # # for dtype0 in [None,'string',{'col0':str,'col3':bool}]:
                                # # for engine0 in [None,'c','python','pyarrow']:
                                    # # for converters0 in [None,{'col0':(lambda v0:v0+'Z'),'col3':(lambda v0:v0+42)}]:
                                        # # for true_values0 in [None,[42]]:
                                            # # for false_values0 in [None,[42]]:
                                                # # for skipinitialspace0 in [False,True]:
                                                    # # for skiprows0 in [None,2,[0,2],(lambda rowNumber0: (rowNumber0%2)==0)]:
                                                        # # for skipfooter0 in [0,2]:
                                                            # # for nrows0 in [None,4]:
                                                                # # for na_values0 in [None,'42',['42','43'],{'col2':'val2'}]:
                                                                    # # for keep_default_na0 in [True,False]:
                                                                        # # for na_filter0 in [True,False]:
                                                                            # # for verbose0 in [False,True]:
                                                                                # # for skip_blank_lines0 in [True,False]:
                                                                                    # # for parse_dates0 in [None,True,['col5','col6'],{'dateTime0':['col5','col6']},False]:
                                                                                        # # for infer_datetime_format0 in [False,True]:
                                                                                            # # for keep_date_col0 in [False,True]:
                                                                                                # # for date_parser0 in [None,(lambda v0:None if (v0=='2023-01-01') else 42)]:#None is dateutil.parser.parser
                                                                                                    # # for dayfirst0 in [False,True]:
                                                                                                        # # for cache_dates0 in [True,False]:
                                                                                                            # # for iterator0 in [False,True]:
                                                                                                                # # for chunksize0 in [None,4]:
                                                                                                                    # # for compression0 in ['infer',{'method':'zstd','dict_data':train_dictionary0}},None]:
                                                                                                                        # # for thousands0 in [None,',','.']:
                                                                                                                            # # for decimal0 in ['.',',']:
                                                                                                                                # # for lineterminator0 in [None,'2','\n']:#length of 1 only (escaped newline works but not as intended as, on Windwos, will leave last float64 dummy value with trailing '\r' e.g. 41.792.083,032\r)
                                                                                                                                    # # for quotechar0 in ['"',"'"]:
                                                                                                                                        # # for quoting0 in [csv.QUOTE_MINIMAL,csv.QUOTE_ALL,csv.QUOTE_NONNUMERIC,csv.QUOTE_NONE]:
                                                                                                                                            # # for doublequote0 in [True,False]:
                                                                                                                                                # # for escapechar0 in [None,'\\','l']:
                                                                                                                                                    # # for comment0 in [None,'#']:
                                                                                                                                                        # # for encoding0 in [None,'iso-8859-1']:
                                                                                                                                                            # # for encoding_errors0 in ['strict','backslashreplace','ignore']:
                                                                                                                                                                # # for dialect0 in [None,'unix','excel']:
                                                                                                                                                                    # # for on_bad_lines0 in ['error','warn','skip',on_bad_lines0func0]:
                                                                                                                                                                        # # for delim_whitespace0 in [False,True]:
                                                                                                                                                                            # # for low_memory0 in [True,False]:
                                                                                                                                                                                # # for memory_map0 in [False,True]:
                                                                                                                                                                                    # # for float_precision0 in [None,'high','round_trip','legacy']:
                                                                                                                                                                                        # # for storage_options0 in [None,{'s3':{'anon':True}}]:
                                                                                                                                                                                            # # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                                                                                                                                                                                            # # try:
                                                                                                                                                                                                # # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                                                                                                                                                                                            # # except Exception as e:
                                                                                                                                                                                                # # print(e)

# sep0=','
# delimiter0=None
# header0='infer'
# names0=None#not actual default but need some value so don't get error on uninitialized variable
# index_col0=None
# usecols0=None
# dtype0=None
# engine0=None
# converters0=None
# true_values0=None
# false_values0=None
# skipinitialspace0=False
# skiprows0=None
# skipfooter0=0
# nrows0=None
# na_values0=None
# keep_default_na0=True
# na_filter0=True
# verbose0=False
# skip_blank_lines0=False
# parse_dates0=None
# infer_datetime_format0=False
# keep_date_col0=False
# date_parser0=None
# dayfirst0=False
# cache_dates0=True
# iterator0=False
# chunksize0=None
# compression0='infer'
# thousands0=None
# decimal0='.'
# lineterminator0=None
# quotechar0='"'
# quoting0=csv.QUOTE_MINIMAL
# doublequote0=True
# escapechar0=None
# comment0=None
# encoding0=None
# encoding_errors0='strict'
# dialect0=None
# on_bad_lines0='error'
# delim_whitespace0=False
# low_memory0=True
# memory_map0=False
# float_precision0=None
# storage_options0=None
# import csv
#filepath_or_buffer,sep,delimiter,header,names,index_col,usecols,dtype,engine,converters,true_values,false_values,skipinitialspace,skiprows,skipfooter,nrows,na_values,keep_default_na,na_filter,verbose,skip_blank_lines,parse_dates,infer_datetime_format,keep_date_col,date_parser,dayfirst,cache_dates,iterator,chunksize,compression,thousands,decimal,lineterminator,quotechar,quoting,doublequote,escapechar,comment,encoding,encoding_errors,dialect,on_bad_lines,delim_whitespace,low_memory,memory_map,float_precision,storage_options,
#below is still too large; program hangs and can't even pause-break or ctrl+c to get out..
# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv',r'company_ipo.csv']:
    # for sep0 in [',','|']:
        # for delimiter0 in [None,'|']:
            # for header0 in ['infer',0,[0,1],None]:
                # for names0 in [['col00','col11','col22']]:#_NoDefault.no_default
                    # for index_col0 in [None,False,0,[0,1],'col5']:
                        # for usecols0 in [None,['col0','col2'],(lambda c0:c0.upper() in ['COL0','COL1'])]:
                            # for dtype0 in [None,'string',{'col0':str,'col3':bool}]:
                                # for engine0 in [None,'c','python','pyarrow']:
                                    # for converters0 in [None,{'col0':(lambda v0:v0+'Z'),'col3':(lambda v0:v0+42)}]:
                                        # for true_values0 in [None,[42]]:
                                            # for false_values0 in [None,[42]]:
                                                # for skipinitialspace0 in [False,True]:
                                                    # for skiprows0 in [None,2,[0,2],(lambda rowNumber0: (rowNumber0%2)==0)]:
                                                        # for skipfooter0 in [0,2]:
                                                            # for nrows0 in [None,4]:
                                                                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                                                                # try:
                                                                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0))
                                                                # except Exception as e:
                                                                    # print(e)


                                                                # for na_values0 in [None,'42',['42','43'],{'col2':'val2'}]:
                                                                    # for keep_default_na0 in [True,False]:
                                                                        # for na_filter0 in [True,False]:
                                                                            # for verbose0 in [False,True]:
                                                                                # for skip_blank_lines0 in [True,False]:
                                                                                    # for parse_dates0 in [None,True,['col5','col6'],{'dateTime0':['col5','col6']},False]:
                                                                                        # for infer_datetime_format0 in [False,True]:
                                                                                            # for keep_date_col0 in [False,True]:
                                                                                                # for date_parser0 in [None,(lambda v0:None if (v0=='2023-01-01') else 42)]:#None is dateutil.parser.parser
                                                                                                    # for dayfirst0 in [False,True]:
                                                                                                        # for cache_dates0 in [True,False]:
                                                                                                            # for iterator0 in [False,True]:
                                                                                                                # for chunksize0 in [None,4]:
                                                                                                                    # for compression0 in ['infer',{'method':'zstd','dict_data':train_dictionary0}},None]:
                                                                                                                        # for thousands0 in [None,',','.']:
                                                                                                                            # for decimal0 in ['.',',']:
                                                                                                                                # for lineterminator0 in [None,'2','\n']:#length of 1 only (escaped newline works but not as intended as, on Windwos, will leave last float64 dummy value with trailing '\r' e.g. 41.792.083,032\r)
                                                                                                                                    # for quotechar0 in ['"',"'"]:
                                                                                                                                        # for quoting0 in [csv.QUOTE_MINIMAL,csv.QUOTE_ALL,csv.QUOTE_NONNUMERIC,csv.QUOTE_NONE]:
                                                                                                                                            # for doublequote0 in [True,False]:
                                                                                                                                                # for escapechar0 in [None,'\\','l']:
                                                                                                                                                    # for comment0 in [None,'#']:
                                                                                                                                                        # for encoding0 in [None,'iso-8859-1']:
                                                                                                                                                            # for encoding_errors0 in ['strict','backslashreplace','ignore']:
                                                                                                                                                                # for dialect0 in [None,'unix','excel']:
                                                                                                                                                                    # for on_bad_lines0 in ['error','warn','skip',on_bad_lines0func0]:
                                                                                                                                                                        # for delim_whitespace0 in [False,True]:
                                                                                                                                                                            # for low_memory0 in [True,False]:
                                                                                                                                                                                # for memory_map0 in [False,True]:
                                                                                                                                                                                    # for float_precision0 in [None,'high','round_trip','legacy']:
                                                                                                                                                                                        # for storage_options0 in [None,{'s3':{'anon':True}}]:
                                                                                                                                                                                            # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                                                                                                                                                                                            # try:
                                                                                                                                                                                                # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                                                                                                                                                                                            # except Exception as e:
                                                                                                                                                                                                # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in [',','|']:
        # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
        # try:
            # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
        # except Exception as e:
            # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for delimiter0 in [None,'|']:
        # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
        # try:
            # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
        # except Exception as e:
            # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for header0 in ['infer',0,[0,1],[1,2],None]:#infer takes 1st row (almost always ?); 0 takes 1st non-commented row always; if [0,1], then 0,1 must have same number of fields (makes sense); if None, then applies 0,1,...,n-1 as headers (similar to creating a table WITHOUT headers in Excel (Excel will give headers for you e.g. Column1	Column2 ...))
            # for comment0 in [None,'#']:
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for header0 in ['infer',0,[0,1],[1,2],None]:#infer takes 1st row (almost always ?); 0 takes 1st non-commented row always; if [0,1], then 0,1 must have same number of fields (makes sense); if None, then applies 0,1,...,n-1 as headers (similar to creating a table WITHOUT headers in Excel (Excel will give headers for you e.g. Column1	Column2 ...))
            # for comment0 in [None,'#']:
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for names0 in [['col00','col11','col22'],['column'+str(x) for x in range(8)]]:#if names has fewer elements than fields in csv then will group 1st x fields with name0 and then 1 y field with name1, 1 z field with name2, 1 a field with name3, etc. (probably not what you want); if names without header, acts as if header=None, then applies 0,1,...,n-1 as headers (similar to creating a table WITHOUT headers in Excel (Excel will give headers for you e.g. Column1	Column2 ...)) and renames them (in other words, 1st non-commented column stays as is below these headers)
            # for comment0 in [None,'#']:
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0).columns)
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0)['col00'])
                # except Exception as e:
                    # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for index_col0 in [None,False,0,[0,1],'col5']:
            # for comment0 in [None,'#']:
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for usecols0 in [None,['col0','col2'],(lambda c0:c0.upper() in ['COL0','COL1'])]:
            # for comment0 in [None,'#']:
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # # for dtype0 in [None,'string',{'col0':str,'col3':bool}]:
        # for dtype0 in [None,'string',{'col0':str,'col8':'boolean'}]:
            # for comment0 in [None,'#']:
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0).dtypes)
                # except Exception as e:
                    # print(e)

# import site,inspect
# print(site.getuserbase())
# print(sys.exec_prefix)
# print(inspect.getsourcefile(None))
# import inspect
# df0=pandas.DataFrame([str(inspect.getsource())])
# print(df0)

# import inspect

# # Get the source code of the current script
# with open(inspect.getsourcefile(lambda: None)) as f:
    # script_source_code = f.read()

# print(script_source_code)

# import inspect; print(inspect.getsourcefile(lambda: None))
# print(pandas.DataFrame([import inspect]))
# import inspect
# with open(inspect.getsourcefile(lambda: None)) as f: print(f.read())
# import inspect; print(open(inspect.getsourcefile(lambda: 0), 'r').read())
# import inspect
# print(pandas.DataFrame([inspect:=__import__('inspect')]))
# print(pandas.DataFrame([open(inspect.getsourcefile(lambda: 0), 'r').read()]))
# print(pandas.DataFrame([open(inspect.getsourcefile(lambda: 0), 'r').read()])[0].str.len())
# print(pandas.read_excel(r'C:\Users\pdumas\Downloads\testSourceCodeFromExcelInput0.xlsx'))#still wrapped in str so won't get the source code if you pass in an Excel file with this (it'll still be just the commands in str form not the result..))

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv',r'C:\Users\pdumas\Downloads\read_csv0test1.csv']:
    # for sep0 in ['|']:
        # for engine0 in [None,'c','python','pyarrow']:#pyarrow best on larger files (small files fastest in python (closely tied with c in 2nd if a lot of objects?; c must be faster if only ints and floats) seems like?)
            # for comment0 in [None,'#']:
                # # for skipfooter0 in [0,4]:
                # # for lineterminator0 in [0,4]:
                    # # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                    # print(f'engine {engine0}')
                    # try:
                        # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                        # print(timeit.timeit('''pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0)''',number=10,globals=globals()))
                    # except Exception as e:
                        # print(e)
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test0.csv',skipfooter=4))#default engine (None) is 'c' but falls back to 'python' (without user having to do anything) if skipfooter (or others?), not supported by 'c' but supported by 'python', is specified

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for converters0 in [None,{'col0':(lambda v0:v0+'Z'),'col3':(lambda v0:v0+42)}]:#for some reason doesn't work in this loop but works just below ok with same params.. (must be something with explicit passes on all vs not explicit pass)
            # for comment0 in [None,'#']:
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test0.csv',sep='|',comment='#',converters={'col0':(lambda v0:v0+'Z'),'col3':(lambda v0:v0+str(42))}))

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for true_values0 in [None,[b'42']]:#these must be encoded in bytes
            # for false_values0 in [None,[b'1']]:
                # for comment0 in [None,'#']:
                    # for dtype0 in [{'col8':'boolean'}]:
                        # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                        # try:
                            # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                        # except Exception as e:
                            # print(e)
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test0.csv',sep='|',comment='#',true_values=['0','val0'],false_values=['1'],dtype={'col8':'string'}))#true_values,false_values must originally be string in csv AND string in passed-in value (e.g. ['T'],['True'],etc.) (not even dtype to string works since (maybe?) true_values,false_values applies before [2nd round of?] dtype?

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for skipinitialspace0 in [False,True]:
            # for comment0 in [None,'#']:
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for skiprows0 in [None,2,[0,2],(lambda rowNumber0: (rowNumber0%2)==0)]:
            # for comment0 in [None,'#']:
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for skipfooter0 in [0,2]:
            # for comment0 in [None,'#']:
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for nrows0 in [None,4]:
            # for comment0 in [None,'#']:
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for na_values0 in [None,'42',['42','43'],{'col2':'val2'}]:
            # for comment0 in [None,'#']:
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)


# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for keep_default_na0 in [True,False]:#note that #N/A (if not '''"#N/A"''') will actually get picked up as comment per the below comment kwarg and will show up blank (as expected) if keep_default_na=False
            # for comment0 in [None,'#']:
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for na_values0 in [None,'42',['42','43'],{'col2':'val2'}]:
            # for na_filter0 in [True,False]:
                # for comment0 in [None,'#']:
                    # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                    # try:
                        # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                    # except Exception as e:
                        # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for na_values0 in [None,'42',['42','43'],{'col2':'val2'}]:
            # for verbose0 in [False,True]:#verbose has very little if anything to do with what is said in pandas docs: docs should say '''Prints how long tokenization, type conversion, and parser memory cleanup (each) took in milliseconds to load data. Printing occurs as data is being loaded and to sys.stdout.''' 
                # for comment0 in [None,'#']:
                    # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                    # try:
                        # # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                        # df0=pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0)
                    # except Exception as e:
                        # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for skip_blank_lines0 in [True,False]:
            # for comment0 in [None,'#']:
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for index_col0 in [None,'col5']:
            # for parse_dates0 in [None,True,['col5','col6'],{'dateTime0':['col5','col6']},False]:
                # for comment0 in [None,'#']:
                    # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                    # try:
                        # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                    # except Exception as e:
                        # print(e)


# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test2.csv']:
    # for sep0 in ['|']:
        # for index_col0 in [None,'col5']:
            # for parse_dates0 in [None,True,['col5','col6'],{'dateTime0':['col5','col6']},False]:#for 'combining columns into 1 column and parsing', doesn't seem to work (e.g. '''1/2|/2023''' (where '|' is 'sep') gives '''1/2 /2023''', and yes, that extra space in results in a no-parse! no matter what you'll get that extra space, so probably better just to do the ol' concat 2 converted-to-str columns and then parse that as date..
                # for keep_date_col0 in [False,True]:
                    # for comment0 in [None,'#']:
                        # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                        # try:
                            # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                        # except Exception as e:
                            # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test2.csv']:
    # for sep0 in ['|']:
        # for index_col0 in [None,'col5']:
            # for parse_dates0 in [None,True,['col5','col6'],{'dateTime0':['col5','col6']},False]:#for 'combining columns into 1 column and parsing', doesn't seem to work (e.g. '''1/2|/2023''' (where '|' is 'sep') gives '''1/2 /2023''', and yes, that extra space in results in a no-parse! no matter what you'll get that extra space, so probably better just to do the ol' concat 2 converted-to-str columns and then parse that as date..; docs has parse_dates=None as default and then below says 'default False' (confirming if you pass None, then behaves as if you passed False)
                # for keep_date_col0 in [False,True]:
                    # for comment0 in [None,'#']:
                        # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                        # try:
                            # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                        # except Exception as e:
                            # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test2.csv']:
    # for sep0 in ['|']:
        # for infer_datetime_format0 in [False,True]:#True faster than False for Index (e.g. parse_dates=True; 0.03702639997936785 vs 0.028106900048442185), slower for rest (probably because only a few rows; True must be faster for 1e6+ rows)
            # for parse_dates0 in [True,['col4'],['col5','col6'],{'dateTime0':['col5','col6']}]:
                # for comment0 in ['#']:
                    # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                    # # print(f'infer_datetime_format {infer_datetime_format0}')
                    # try:
                        # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                        # # print(timeit.timeit('''pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0)''',number=10,globals=globals()))
                    # except Exception as e:
                        # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test2.csv']:
    # for sep0 in ['|']:
        # for date_parser0 in [None,(lambda v0:None if (v0=='2023-01-01') else 42)]:
            # for parse_dates0 in [['col4']]:
                # for comment0 in ['#']:
                    # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                    # # print(f'infer_datetime_format {infer_datetime_format0}')
                    # try:
                        # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                        # # print(timeit.timeit('''pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0)''',number=10,globals=globals()))
                    # except Exception as e:
                        # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test2.csv']:
    # for sep0 in ['|']:
        # for dayfirst0 in [False,True]:
            # for parse_dates0 in [['col4']]:
                # for comment0 in ['#']:
                    # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                    # # print(f'infer_datetime_format {infer_datetime_format0}')
                    # try:
                        # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                        # # print(timeit.timeit('''pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0)''',number=10,globals=globals()))
                    # except Exception as e:
                        # print(e)

# print(pandas.DataFrame([pandas.Timestamp('2023-01-01').strftime('%d/%m/%Y')]*3))
# path0=r'C:\Users\pdumas\Downloads\read_csv0test3.csv'
# pandas.DataFrame([pandas.Timestamp('2023-01-01').strftime('%d/%m/%Y')]*100000).to_csv(path0)
# for filepath_or_buffer0 in [path0]:
    # for parse_dates0 in [[0]]:
        # for cache_dates0 in [True,False]:#True is faster (0.6148367000278085 vs 0.6964176999172196)
            # # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
            # print(f'cache_dates {cache_dates0}')
            # try:
                # # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # print(timeit.timeit('''pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0)''',number=10,globals=globals()))
            # except Exception as e:
                # print(e)

# path0=r'C:\Users\pdumas\Downloads\read_csv0test4.csv'
# pandas.DataFrame(pandas.date_range(start=pandas.Timestamp('2023-01-01'),freq='1H',periods=100000)).to_csv(path0)
# with pandas.read_csv(path0,iterator=True,chunksize=4) as read_csv0:#chunksize is number of rows per chunk (e.g. '''read_csv0.get_chunk()''' call returns the default chunksize rows (e.g. 4 rows); you can also specify read_csv0.get_chunk(<chunkSizeYouWantHere>) to get more than chunksize, but that's probably inefficient memory-,performance-wise given you read the iterator in with specific chunksize=4 (anything less or more than that would be inefficient!))
    # print(read_csv0.get_chunk(3))
    # print(read_csv0.get_chunk(2))
    # print(read_csv0.get_chunk(700))
    # print(read_csv0.get_chunk())
    # print(read_csv0.get_chunk())
    # # for x in range(chunksize0:=4):
        # # print(read_csv0.get_chunk(x))

# for filepath_or_buffer0 in [r'ftp://ftp.fec.gov/FEC/2016/cn16.zip',r'https://github.com/fivethirtyeight/data/blob/master/nba-elo/nbaallelo.csv.gz']:
# for filepath_or_buffer0 in [r"C:\Users\pdumas\Downloads\relationshipsFastCompress.csv.gz"]:
    # for compression0 in ['infer','zip','gzip',None]:#if wrong, it'll just error, stating wrong file type OR can't decode byte...
        # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
        # try:
            # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
        # except Exception as e:
            # print(e)


# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for comment0 in ['#']:
            # for thousands0 in [None,',','.']:#for this and below row to work as intended, can't have number with multiple decimals (e.g. 123.456.789 with decimal='.' will result in object dtype, i.e. interpreted as string..); also, if thousands,decimal have same value/compete, thousands takes precedence / overrides decimal (e.g. 123,456,789 with decimal=',' and thousands=',' will result in float64 123456789.0)
                # for decimal0 in ['.',',']:
                    # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                    # try:
                        # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                        # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0).dtypes)
                    # except Exception as e:
                        # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for comment0 in ['#']:
            # for lineterminator0 in [None,'2','\n']:#length of 1 only (escaped newline works but not as intended as, on Windwos, will leave last float64 dummy value with trailing '\r' e.g. 41.792.083,032\r)
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for comment0 in ['#']:
            # for quotechar0 in ['"',"'"]:
                # for doublequote0 in [True,False]:
                    # for escapechar0 in [None,'\\','l']:#escape chars go away in output, as expected
                        # for quoting0 in [csv.QUOTE_MINIMAL,csv.QUOTE_ALL,csv.QUOTE_NONNUMERIC,csv.QUOTE_NONE]:#csv.QUOTE_NONE works (will literally override most quote settings (not escapechar though) and NOT quote, as expected); csv.QUOTE_MINIMAL,csv.QUOTE_ALL,csv.QUOTE_NONNUMERIC all seems to do the same thing..
                            # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                            # try:
                                # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                            # except Exception as e:
                                # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
    # for sep0 in ['|']:
        # for comment0 in ['#']:
            # for encoding0 in [None,'ascii','iso-8859-1']:
                # for encoding_errors0 in ['strict','backslashreplace','ignore']:
                    # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                    # try:
                        # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                    # except Exception as e:
                        # print(e)


# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv']:
# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\csv0Testunix.csv',r'C:\Users\pdumas\Downloads\csv0Testexcel.csv',r'C:\Users\pdumas\Downloads\csv0Testexcel-tab.csv']:
    # for sep0 in ['|']:
        # for comment0 in ['#']:
            # for dialect0 in [None,'unix','excel','excel-tab']:#unix and excel very similar (and will give same results on LOADING for unix-,excel-written-(using those Dialects)-to-csv files) 
                # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test5.csv']:
    # for sep0 in ['|']:
        # for comment0 in ['#']:
            # for engine0 in ['python']:
                # for on_bad_lines0 in ['error','warn','warn','skip',on_bad_lines0func0]:#see above '''def on_bad_lines0func0''' for comments
                    # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                    # try:
                        # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                    # except Exception as e:
                        # print(e)

# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv',r'C:\Users\pdumas\Downloads\read_csv0test6.csv']:
    # for comment0 in ['#']:
        # for delim_whitespace0 in [False,True]:
            # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
            # try:
                # # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # print(pandas.read_csv(filepath_or_buffer0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
            # except Exception as e:
                # print(e)

# # for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test0.csv',r'C:\Users\pdumas\Downloads\relationships.csv']:
# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\relationships.csv']:
    # for sep0 in [',']:
        # for comment0 in ['#']:
            # for low_memory0 in [True,False]:#True is overall much faster (685.12 ms vs. 1281.34 ms for 'Type conversion', which was biggest difference; probably due to parallelization) than False (although specific,individual parts may be slower)
                # for memory_map0 in [False,True]:#True is overall faster (1082.80 ms vs. 1281.34 ms for 'Type conversion', which was around same %-wise as 'Tokenization'; also, 0 ms 'Parser memory cleanup' when memory_map=True, which further speedens)
                    # for verbose0 in [True]:
                        # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
                        # try:
                            # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                        # except Exception as e:
                            # print(e)

# print(pandas.options.display.max_colwidth)
# pandas.options.display.max_colwidth=1000
# print(pandas.options.display.max_colwidth)
# for filepath_or_buffer0 in [r'C:\Users\pdumas\Downloads\read_csv0test7.csv']:
    # for float_precision0 in [None,'high','round_trip','legacy']:#docs not fully accurate / seems like if number passed in is larger than what system can hold, then just stringifies it.. (e.g. '123456789123456789' works and is auto float64  but '123456789123456789123456789123456789123456789' doesnt and is auto object (string)..)
        # for dtype0 in [None,'float64']:
            # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
            # try:
                # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
                # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0).dtypes)
                # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0).convert_dtypes().dtypes)
                # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine='c',converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
            # except Exception as e:
                # print(e)


# for filepath_or_buffer0 in [r'https://drive.google.com/file/d/1DfcnkcHj__PLTKyNDT0N19K_u5lSyyin/view?usp=share_link']:#doesn't work
    # for storage_options0 in [None,{'s3':{'anon':True}}]:
        # print(f'filepath_or_buffer {filepath_or_buffer0}',f'sep {sep0}',f'delimiter {delimiter0}',f'header {header0}',f'names {names0}',f'index_col {index_col0}',f'usecols {usecols0}',f'dtype {dtype0}',f'engine {engine0}',f'converters {converters0}',f'true_values {true_values0}',f'false_values {false_values0}',f'skipinitialspace {skipinitialspace0}',f'skiprows {skiprows0}',f'skipfooter {skipfooter0}',f'nrows {nrows0}',f'na_values {na_values0}',f'keep_default_na {keep_default_na0}',f'na_filter {na_filter0}',f'verbose {verbose0}',f'skip_blank_lines {skip_blank_lines0}',f'parse_dates {parse_dates0}',f'infer_datetime_format {infer_datetime_format0}',f'keep_date_col {keep_date_col0}',f'date_parser {date_parser0}',f'dayfirst {dayfirst0}',f'cache_dates {cache_dates0}',f'iterator {iterator0}',f'chunksize {chunksize0}',f'compression {compression0}',f'thousands {thousands0}',f'decimal {decimal0}',f'lineterminator {lineterminator0}',f'quotechar {quotechar0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'escapechar {escapechar0}',f'comment {comment0}',f'encoding {encoding0}',f'encoding_errors {encoding_errors0}',f'dialect {dialect0}',f'on_bad_lines {on_bad_lines0}',f'delim_whitespace {delim_whitespace0}',f'low_memory {low_memory0}',f'memory_map {memory_map0}',f'float_precision {float_precision0}',f'storage_options {storage_options0}',sep='\n')
        # try:
            # print(pandas.read_csv(filepath_or_buffer0,sep=sep0,delimiter=delimiter0,header=header0,names=names0,index_col=index_col0,usecols=usecols0,dtype=dtype0,engine=engine0,converters=converters0,true_values=true_values0,false_values=false_values0,skipinitialspace=skipinitialspace0,skiprows=skiprows0,skipfooter=skipfooter0,nrows=nrows0,na_values=na_values0,keep_default_na=keep_default_na0,na_filter=na_filter0,verbose=verbose0,skip_blank_lines=skip_blank_lines0,parse_dates=parse_dates0,infer_datetime_format=infer_datetime_format0,keep_date_col=keep_date_col0,date_parser=date_parser0,dayfirst=dayfirst0,cache_dates=cache_dates0,iterator=iterator0,chunksize=chunksize0,compression=compression0,thousands=thousands0,decimal=decimal0,lineterminator=lineterminator0,quotechar=quotechar0,quoting=quoting0,doublequote=doublequote0,escapechar=escapechar0,comment=comment0,encoding=encoding0,encoding_errors=encoding_errors0,dialect=dialect0,on_bad_lines=on_bad_lines0,delim_whitespace=delim_whitespace0,low_memory=low_memory0,memory_map=memory_map0,float_precision=float_precision0,storage_options=storage_options0))
        # except Exception as e:
            # print(e)
            
# # see below as still doesnt work even with s3 protocol path and installing s3fs
# # >>> pd.read_csv(
# # ...     "s3://ncei-wcsd-archive/data/processed/SH1305/18kHz/SaKe2013"
# # ...     "-D20130523-T080854_to_SaKe2013-D20130523-T085643.csv",
# # ...     storage_options={"anon": True},
# # ... )
# # Traceback (most recent call last):
  # # File "<stdin>", line 1, in <module>
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    # # return func(*args, **kwargs)
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\util\_decorators.py", line 331, in wrapper
    # # return func(*args, **kwargs)
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\io\parsers\readers.py", line 950, in read_csv
    # # return _read(filepath_or_buffer, kwds)
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\io\parsers\readers.py", line 605, in _read
    # # parser = TextFileReader(filepath_or_buffer, **kwds)
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\io\parsers\readers.py", line 1442, in __init__
    # # self._engine = self._make_engine(f, self.engine)
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\io\parsers\readers.py", line 1735, in _make_engine
    # # self.handles = get_handle(
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\io\common.py", line 713, in get_handle
    # # ioargs = _get_filepath_or_buffer(
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\pandas\io\common.py", line 409, in _get_filepath_or_buffer
    # # file_obj = fsspec.open(
  # # File "C:\Users\pdumas\AppData\Roaming\Python\Python310\site-packages\fsspec\core.py", line 419, in open
    # # return open_files(
  # # File "C:\Users\pdumas\AppData\Roaming\Python\Python310\site-packages\fsspec\core.py", line 272, in open_files
    # # fs, fs_token, paths = get_fs_token_paths(
  # # File "C:\Users\pdumas\AppData\Roaming\Python\Python310\site-packages\fsspec\core.py", line 574, in get_fs_token_paths
    # # chain = _un_chain(urlpath0, storage_options or {})
  # # File "C:\Users\pdumas\AppData\Roaming\Python\Python310\site-packages\fsspec\core.py", line 315, in _un_chain
    # # cls = get_filesystem_class(protocol)
  # # File "C:\Users\pdumas\AppData\Roaming\Python\Python310\site-packages\fsspec\registry.py", line 212, in get_filesystem_class
    # # register_implementation(protocol, _import_class(bit["class"]))
  # # File "C:\Users\pdumas\AppData\Roaming\Python\Python310\site-packages\fsspec\registry.py", line 235, in _import_class
    # # mod = importlib.import_module(mod)
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\importlib\__init__.py", line 126, in import_module
    # # return _bootstrap._gcd_import(name[level:], package, level)
  # # File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  # # File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  # # File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  # # File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  # # File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  # # File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\s3fs\__init__.py", line 1, in <module>
    # # from .core import S3FileSystem, S3File
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\s3fs\core.py", line 28, in <module>
    # # import aiobotocore.session
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\aiobotocore\session.py", line 12, in <module>
    # # from .client import AioBaseClient, AioClientCreator
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\aiobotocore\client.py", line 20, in <module>
    # # from .args import AioClientArgsCreator
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\aiobotocore\args.py", line 8, in <module>
    # # from .endpoint import AioEndpointCreator
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\aiobotocore\endpoint.py", line 19, in <module>
    # # from aiobotocore.httpsession import AIOHTTPSession
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\aiobotocore\httpsession.py", line 42, in <module>
    # # from aiobotocore._endpoint_helpers import _IOBaseWrapper, _text
  # # File "C:\Users\pdumas\Anaconda3\envs\env0\lib\site-packages\aiobotocore\_endpoint_helpers.py", line 13, in <module>
    # # aiohttp.http_exceptions.HttpProcessingError,
# # AttributeError: module 'aiohttp' has no attribute 'http_exceptions'

#filepath_or_buffer,sep,delimiter,header,names,index_col,usecols,dtype,engine,converters,true_values,false_values,skipinitialspace,skiprows,skipfooter,nrows,na_values,keep_default_na,na_filter,verbose,skip_blank_lines,parse_dates,infer_datetime_format,keep_date_col,date_parser,dayfirst,cache_dates,iterator,chunksize,compression,thousands,decimal,lineterminator,quotechar,quoting,doublequote,escapechar,comment,encoding,encoding_errors,dialect,on_bad_lines,delim_whitespace,low_memory,memory_map,float_precision,storage_options,

# # # pd2023-04-07 13:59:21 switch to pandas2.0.0

# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test6.csv',sep=None))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test6.csv',sep='\t\t'))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test1.csv',sep='|',index_col=None))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test8.csv',sep='|',index_col=None))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test8.csv',sep='|',index_col=None,dtype={'defaultdict':'float64'}))
# from collections import defaultdict
# defaultdict0=defaultdict(lambda: numpy.float64)
# # defaultdict0=defaultdict(lambda x: numpy.float64 if type(x) is int else numpy.object_)
# defaultdict0['col1']='int'
# print(defaultdict0)
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test8.csv',sep='|',index_col=None,dtype=defaultdict0))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test9.csv',sep='|',index_col=None,dtype=defaultdict0))#works but works on all columsn without specified dtype, meaning that the dtype you choose as default has to work for all such columns (e.g. cannot specify 'boolean' for default where columns are string..)
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test9.csv',sep='|',index_col=None))#'''dtype_backend=_NoDefault.no_default''' (i.e. not passing kwarg dtype_backend) backs with pure numpy (i.e. doesnt have pandas <NA> null; e.g. 'int64')
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test9.csv',sep='|',index_col=None)._data)
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test9.csv',sep='|',index_col=None).values)
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test9.csv',sep='|',index_col=None,dtype_backend='numpy_nullable'))#this backs with numpy but nullable, meaning pandas <NA> and pandas dtypes (e.g. 'boolean','Int64')
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test9.csv',sep='|',index_col=None,dtype_backend='numpy_nullable')._data)
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test9.csv',sep='|',index_col=None,dtype_backend='numpy_nullable').values)
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test9.csv',sep='|',index_col=None,dtype_backend='pyarrow'))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test9.csv',sep='|',index_col=None,dtype_backend='pyarrow')._data)
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test9.csv',sep='|',index_col=None,dtype_backend='pyarrow').values)
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test10.csv',sep='|',index_col=None,parse_dates=['col2']))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test10.csv',sep='|',index_col=None,parse_dates=['col2'],date_format='%d.%m.%Y'))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test11.csv',sep='|',index_col=None,parse_dates=['col2']))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test11.csv',sep='|',index_col=None,parse_dates=['col2'],date_format='%d.%m.%Y'))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test11.csv',sep='|',index_col=None,parse_dates=['col2'],dayfirst=True))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test12.csv'))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test12.csv').dtypes)

# # arg,errors,downcast,dtype_backend,
# for arg0 in [pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test12.csv')['col3'],pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test12.csv')['col4'],pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test12.csv')['col5']]:
    # for errors0 in ['raise','coerce','ignore']:
        # for downcast0 in [None,'integer','signed','unsigned','float']:#if cannot downcast to passed-in value, will just not downcast at all (e.g. 'integer' on inf will remain Float64 (since inf is Float64..) but 'float' on inf will go down to 'Float32' (since downcast is successful))
            # for dtype_backend0 in ['numpy_nullable','pyarrow']:
                # print(f'arg {arg0}',f'errors {errors0}',f'downcast {downcast0}',f'dtype_backend {dtype_backend0}',sep='\n')
                # try:
                    # print(pandas.to_numeric(arg0,errors=errors0,downcast=downcast0,dtype_backend=dtype_backend0))
                # except Exception as e:
                    # print(e)
                # print('\n')

# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test13.csv',sep='|',dtype='category'))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test13.csv',sep='|',dtype='category').dtypes)
# dtype0=pandas.CategoricalDtype(categories=['b','a'],ordered=True)
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test13.csv',sep='|',dtype=dtype0))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test13.csv',sep='|',dtype=dtype0).dtypes)
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test14.csv',sep='|',header=0))

# data = (
    # "# empty\n"
    # "# second empty line\n"
    # "# third emptyline\n"
    # "X,Y,Z\n"
    # "1,2,3\n"
    # "A,B,C# comment in metadata\n"
    # "1,2.,4.# super cool\n"
    # "5.,NaN,10.0# not cool\n"
# )
# print(data)
# import io
# print(pandas.read_csv(io.StringIO(data),comment='#',header=1,skiprows=1))#if skiprows < header  and  header(relativeToSkiprows) is in a sea of comments, then goes to next row (out of sea) as position 0, next row after that as position 1, etc.; all rows after header will be pulled of course!
# print(pandas.read_csv(io.StringIO(data),comment='#',header=1,skiprows=5))

# import io
# data = "a,b,c\n4,apple,bat,\n8,orange,cow,"
# print(data)
# print(pd.read_csv(io.StringIO(data)))
# print(pd.read_csv(io.StringIO(data), index_col=False))
# data = "a,b,c\naa,apple,bat,\nbb,orange,cow,"
# print(data)
# print(pd.read_csv(io.StringIO(data)))
# print(pd.read_csv(io.StringIO(data), index_col=False))

# import io
# data = "a,b,c\n4,apple,bat,e\n8,orange,cow,e"
# print(data)
# print(pd.read_csv(io.StringIO(data)))
# print(pd.read_csv(io.StringIO(data), index_col=False))
# data = "a,b,c\naa,apple,bat,e\nbb,orange,cow,e"
# print(data)
# print(pd.read_csv(io.StringIO(data)))
# print(pd.read_csv(io.StringIO(data), index_col=False))#False just discards the last,extra column and creates a regular 0,1,...,n-1 index
# print(pd.read_csv(io.StringIO(data),usecols=['a','c'], index_col=0))#False just discards the last,extra column and creates a regular 0,1,...,n-1 index

# data = (
    # "KORD,19990127, 19:00:00, 18:56:00, 0.8100\n"
    # "KORD,19990127, 20:00:00, 19:56:00, 0.0100\n"
    # "KORD,19990127, 21:00:00, 20:56:00, -0.5900\n"
    # "KORD,19990127, 21:00:00, 21:18:00, -0.9900\n"
    # "KORD,19990127, 22:00:00, 21:56:00, -0.5900\n"
    # "KORD,19990127, 23:00:00, 22:56:00, -0.5900"
# )

# import io
# print(pd.read_csv(io.StringIO(data), header=None))
# print(pd.read_csv(io.StringIO(data), header=None, parse_dates=[[1, 2], [1, 3]]))#not sure why something like this wasnt working in the grid-search loop before..

# path0=r'C:\Users\pdumas\Downloads\read_csv0test15.csv'
# pandas.DataFrame(pandas.date_range(start=pandas.Timestamp('2023-01-01'),freq='1H',periods=100000))[0].dt.strftime('%d/%m%Y %H:%m.%s').to_csv(path0)
# print(timeit.timeit('''pandas.read_csv(path0)''',number=20,globals=globals()))

# path0=r'C:\Users\pdumas\Downloads\read_csv0test15.csv'
# pandas.DataFrame(pandas.date_range(start=pandas.Timestamp('2023-01-01T00:00:00'),freq='1H',periods=100000)).to_csv(path0)
# print(timeit.timeit('''pandas.read_csv(path0)''',number=20,globals=globals()))

# path0=r'C:\Users\pdumas\Downloads\read_csv0test16.csv'
# pandas.DataFrame([pandas.Timestamp('2023-01-01')]*100000)[0].dt.strftime('%d/%m%Y %H:%m.%s').to_csv(path0)
# print(timeit.timeit('''pandas.read_csv(path0)''',number=20,globals=globals()))

# path0=r'C:\Users\pdumas\Downloads\read_csv0test16.csv'
# pandas.DataFrame([pandas.Timestamp('2023-01-01')]*100000).to_csv(path0)
# print(timeit.timeit('''pandas.read_csv(path0)''',number=20,globals=globals()))#per docs '''read_csv has a fast_path for parsing datetime strings in iso8601 format''', very true for when all dates (or most) are similar; true for the most part even when all dates are different (e.g. pandas.date_range); 2.1x speed-up is fastest experienced here though (not 20x!)

# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test17.csv'))
# read_csv17=pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test17.csv')
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test17.csv',parse_dates=['col2']))
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test17.csv',parse_dates=['col2']).dtypes)
# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test17.csv',parse_dates=['col2']).assign(col2=pandas.to_datetime(read_csv17['col2'],format='mixed',errors='coerce')))
# from pandas import to_datetime
# try:
    # print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test17.csv',parse_dates=['col2']).eval('''col2=to_datetime(col2,format='mixed',errors='coerce')'''))
# except Exception as e:
    # print(e)

# import pandas as pd
# df = pd.DataFrame({'date': ['2022-01-01', '2022-01-02', '2022-01-03'], 'value': [1, 2, 3]})
# df.eval("date = pd.to_datetime(date)", inplace=True)
# print(df)

# import pandas as pd
# df = pd.DataFrame({'date': ['2022-01-01', '2022-01-02', '2022-01-03'], 'value': [1, 2, 3]})
# df.eval("date = pd.to_datetime(date)",local_dict={'pd': pd}, inplace=True)
# print(df)

# import io
# data = io.StringIO("date\n2020-01-01\n2020-01-01 03:00\n")
# df = pd.read_csv(data)
# try:
    # df1['date'] = pd.to_datetime(df['date'])
# except Exception as e:
    # print(e)
# df['date'] = pd.to_datetime(df['date'],format='ISO8601')
# print(df)
# print(timeit.timeit('''df['date'] = pd.to_datetime(df['date'],format='ISO8601')''',number=100,globals=globals()))
# print(timeit.timeit('''df['date'] = pd.to_datetime(df['date'],format='mixed')''',number=100,globals=globals()))#format='mixed' is not THAT much slower (e.g. 0.029113100026734173 vs 0.03062500001396984)
# data = io.StringIO("date\n2020-01-01\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n2020-01-01 03:00\n")
# df = pd.read_csv(data)
# print(timeit.timeit('''df['date'] = pd.to_datetime(df['date'],format='ISO8601')''',number=100,globals=globals()))
# print(timeit.timeit('''df['date'] = pd.to_datetime(df['date'],format='mixed')''',number=100,globals=globals()))#format='mixed' is not THAT much slower (e.g. 0.029113100026734173 vs 0.03062500001396984)

# print(pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test18.csv',comment='#',sep='|'))
# df0=pandas.read_csv(r'C:\Users\pdumas\Downloads\read_csv0test18.csv',comment='#',sep='|')
# df0.index=pandas.MultiIndex.from_product([[0,1,2,3],[0,1]],names=['index0','index1'])
# df0['col15']=pandas.Timestamp('2023-04-08T05:00:00+01:00')
# print(df0)

# # # def my_function(x):
    # # # return x + 1
# # # def my_function_str(self):
    # # # return "This is my custom string representation of the function"
# # # my_function.__str__ = my_function_str
# # # print(str(my_function))  # output: This is my custom string representation of the function

# # def my_function(x):
    # # return x + 1
# # def my_function_repr(self):
    # # return "This is my custom string representation of the function"
# # my_function.__repr__ = my_function_repr
# # print(my_function)  # output: This is my custom string representation of the function
# # print(repr(my_function))  # output: This is my custom string representation of the function

# def float_format00(float0):
    # return 'f{float0:.4f}'
# def float_format00str0(self):
    # return '''float_format00'''
# float_format00.__str__=float_format00str0
# float_format00.__str__='float_format00'
# print(str(float_format00))
# import csv,os
# # # # path_or_buf,sep,float_format,date_format,na_rep,columns,header,index,index_label,lineterminator,mode,chunksize,quoting,doublequote,quotechar,escapechar,compression,encoding,errors,decimal,storage_options,
# # # # can't run below given combinatorics too much compute (at least 8388608 (2**23; 23 'for' loops with at least 2 values) resulting outputs is too much)
# # for path_or_buf0 in [r'C:\Users\pdumas\Downloads\to_csv0test0.csv']:
    # # for sep0 in [',','|']:
        # # for float_format0 in [None,'%.4f','{:0.4f}',float_format00]:
            # # for date_format0 in [None,'%m/%d/%Y %H:%M:%S %Z']:
                # # for na_rep0 in ['','nan']:
                    # # for columns0 in [None,['col0']]:
                        # # for header0 in [True,['col0renamed0'],False]:
                            # # for index0 in [True,False]:
                                # # for index_label0 in [None,['index0renamed0','index1renamed0'],False]:
                                    # # for lineterminator0 in [None,'\r\n\r\n']:
                                        # # for mode0 in ['w','wb']:
                                            # # for chunksize0 in [None,4]:
                                                # # for quoting0 in [csv.QUOTE_MINIMAL,csv.QUOTE_ALL,csv.QUOTE_NONNUMERIC,csv.QUOTE_NONE]:
                                                    # # for doublequote0 in [True,False]:
                                                        # # for quotechar0 in ['"',"'"]:
                                                            # # for escapechar0 in [None,'\\','l']:
                                                                # # for compression0 in ['infer','zstd',{'method':'zstd','compressionlevel':3,'mtime':1}]:
                                                                    # # for encoding0 in [None,'ascii','iso-8859-1']:
                                                                        # # for errors0 in ['strict','backslashreplace','ignore']:
                                                                            # # for decimal0 in ['.',',']:
                                                                                # # for storage_options0 in [None,{'s3':{'anon':True}}]:
                                                                                    # # print(f'path_or_buf {path_or_buf0}',f'sep {sep0}',f'float_format {float_format0}',f'date_format {date_format0}',f'na_rep {na_rep0}',f'columns {columns0}',f'header {header0}',f'index {index0}',f'index_label {index_label0}',f'lineterminator {lineterminator0}',f'mode {mode0}',f'chunksize {chunksize0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'quotechar {quotechar0}',f'escapechar {escapechar0}',f'compression {compression0}',f'encoding {encoding0}',f'errors {errors0}',f'decimal {decimal0}',f'storage_options {storage_options0}',sep='\n')
                                                                                    # # try:
                                                                                        # # print(df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
                                                                                    # # except Exception as e:
                                                                                        # # print(e)

# # path_or_buf0=r'C:\Users\pdumas\Downloads\to_csv0test0.csv'
# path_or_buf0=None
# sep0=','
# float_format0=None
# date_format0=None
# na_rep0=''
# columns0=None
# header0=True
# index0=True
# index_label0=None
# lineterminator0=None
# mode0='w'
# chunksize0=None
# quoting0=csv.QUOTE_MINIMAL
# doublequote0=True
# quotechar0='"'
# escapechar0=None
# compression0='infer'
# encoding0=None
# errors0='strict'
# decimal0='.'
# storage_options0=None

# for sep0 in [',','.']:#'can't use '|' as can't be in Windows filename otherwise error..
    # # for path_or_buf0 in [r'C:\Users\pdumas\Downloads\to_csv0test0'+str(sep0)+str(float_format0)+str(date_format0)+str(na_rep0)+str(columns0)+str(header0)+str(index0)+str(index_label0)+str(lineterminator0)+str(mode0)+str(chunksize0)+str(quoting0)+str(doublequote0)+str(quotechar0)+str(escapechar0)+str(compression0)+str(encoding0)+str(errors0)+str(decimal0)+str(storage_options0)+'.csv']:#filepath too long to create and read (appears as empty file with truncated file name..)
    # for path_or_buf0 in [r'C:\Users\pdumas\Downloads\to_csv0test0'+str(sep0)+'.csv']:
        # print(f'path_or_buf {path_or_buf0}',f'sep {sep0}',f'float_format {float_format0}',f'date_format {date_format0}',f'na_rep {na_rep0}',f'columns {columns0}',f'header {header0}',f'index {index0}',f'index_label {index_label0}',f'lineterminator {lineterminator0}',f'mode {mode0}',f'chunksize {chunksize0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'quotechar {quotechar0}',f'escapechar {escapechar0}',f'compression {compression0}',f'encoding {encoding0}',f'errors {errors0}',f'decimal {decimal0}',f'storage_options {storage_options0}',sep='\n')
        # try:
            # print(df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
            # os.system(r'C:\Users\pdumas\AppData\Local\Microsoft\WindowsApps\notepad++.exe '+path_or_buf0+'')
        # except Exception as e:
            # print(e)

# for float_format0 in [None,'%.4f','{:0.4f}','{value0:0.4f}',float_format00]:#docs need to specify that float_formatting like python3.6 or higher (e.g. '{:0.4f}','{value0:0.4f}') but the ol' python2 way (e.g. '%.4f') does; also passing function doesn't work here in loop but works below (outside of loop..; not sure why)
    # for path_or_buf0 in [r'C:\Users\pdumas\Downloads\to_csv0test0'+str(float_format0)+'.csv']:
        # print(f'path_or_buf {path_or_buf0}',f'sep {sep0}',f'float_format {float_format0}',f'date_format {date_format0}',f'na_rep {na_rep0}',f'columns {columns0}',f'header {header0}',f'index {index0}',f'index_label {index_label0}',f'lineterminator {lineterminator0}',f'mode {mode0}',f'chunksize {chunksize0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'quotechar {quotechar0}',f'escapechar {escapechar0}',f'compression {compression0}',f'encoding {encoding0}',f'errors {errors0}',f'decimal {decimal0}',f'storage_options {storage_options0}',sep='\n')
        # try:
            # print(df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
            # os.system(r'C:\Users\pdumas\AppData\Local\Microsoft\WindowsApps\notepad++.exe '+path_or_buf0+'')
        # except Exception as e:
            # print(e)
            # print(df0.to_csv(r'C:\Users\pdumas\Downloads\to_csv0test0float_format0.csv',sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
            # os.system(r'C:\Users\pdumas\AppData\Local\Microsoft\WindowsApps\notepad++.exe C:\Users\pdumas\Downloads\to_csv0test0float_format0.csv')

# import pandas as pd

# df = pd.DataFrame({'A': [0.12345, 1.2345, 12.345, 123.45]})

# # Using a format string to specify 4 decimal places
# csv_string = df.to_csv(float_format='{:0.4f}')

# print(csv_string)#this is wrong.. actual output is 0,{:.4f}...
# # Output:
# # ,A
# # 0,0.1235
# # 1,1.2345
# # 2,12.3450
# # 3,123.4500


# def my_float_format(x):
    # return f'{x:.4f}'

# df = pd.DataFrame({'A': [0.12345, 1.2345, 12.345, 123.45]})

# # Using a callable function to format the floating point numbers
# csv_string = df.to_csv(float_format=my_float_format)

# print(csv_string)
# # Output:
# # ,A
# # 0,0.1235
# # 1,1.2345
# # 2,12.3450
# # 3,123.4500



# for date_format0 in [None,'%m/%d/%Y %H:%M:%S %Z']:
    # for path_or_buf0 in [r'C:\Users\pdumas\Downloads\to_csv0test0'+str(date_format0)+'.csv']:
        # print(f'path_or_buf {path_or_buf0}',f'sep {sep0}',f'float_format {float_format0}',f'date_format {date_format0}',f'na_rep {na_rep0}',f'columns {columns0}',f'header {header0}',f'index {index0}',f'index_label {index_label0}',f'lineterminator {lineterminator0}',f'mode {mode0}',f'chunksize {chunksize0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'quotechar {quotechar0}',f'escapechar {escapechar0}',f'compression {compression0}',f'encoding {encoding0}',f'errors {errors0}',f'decimal {decimal0}',f'storage_options {storage_options0}',sep='\n')
        # try:
            # print(df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
            # os.system(r'C:\Users\pdumas\AppData\Local\Microsoft\WindowsApps\notepad++.exe '+path_or_buf0+'')
        # except Exception as e:
            # print(e)
            # print(df0.to_csv(r'C:\Users\pdumas\Downloads\to_csv0test0date_format0.csv',sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
            # os.system(r'C:\Users\pdumas\AppData\Local\Microsoft\WindowsApps\notepad++.exe C:\Users\pdumas\Downloads\to_csv0test0date_format0.csv')

# for na_rep0 in ['','nan']:
    # for path_or_buf0 in [r'C:\Users\pdumas\Downloads\to_csv0test0'+str(na_rep0)+'.csv']:
        # print(f'path_or_buf {path_or_buf0}',f'sep {sep0}',f'float_format {float_format0}',f'date_format {date_format0}',f'na_rep {na_rep0}',f'columns {columns0}',f'header {header0}',f'index {index0}',f'index_label {index_label0}',f'lineterminator {lineterminator0}',f'mode {mode0}',f'chunksize {chunksize0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'quotechar {quotechar0}',f'escapechar {escapechar0}',f'compression {compression0}',f'encoding {encoding0}',f'errors {errors0}',f'decimal {decimal0}',f'storage_options {storage_options0}',sep='\n')
        # try:
            # print(df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
            # os.system(r'C:\Users\pdumas\AppData\Local\Microsoft\WindowsApps\notepad++.exe '+path_or_buf0+'')
        # except Exception as e:
            # print(e)

# for na_rep0 in ['','nan']:
    # print(f'path_or_buf {path_or_buf0}',f'sep {sep0}',f'float_format {float_format0}',f'date_format {date_format0}',f'na_rep {na_rep0}',f'columns {columns0}',f'header {header0}',f'index {index0}',f'index_label {index_label0}',f'lineterminator {lineterminator0}',f'mode {mode0}',f'chunksize {chunksize0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'quotechar {quotechar0}',f'escapechar {escapechar0}',f'compression {compression0}',f'encoding {encoding0}',f'errors {errors0}',f'decimal {decimal0}',f'storage_options {storage_options0}',sep='\n')
    # try:
        # print(df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
    # except Exception as e:
        # print(e)

# for columns0 in [None,['col0']]:
    # for header0 in [True,['col0renamed0'],False]:
        # for index0 in [True,False]:
            # for index_label0 in [None,['index0renamed0','index1renamed0'],False]:
                    # print(f'path_or_buf {path_or_buf0}',f'sep {sep0}',f'float_format {float_format0}',f'date_format {date_format0}',f'na_rep {na_rep0}',f'columns {columns0}',f'header {header0}',f'index {index0}',f'index_label {index_label0}',f'lineterminator {lineterminator0}',f'mode {mode0}',f'chunksize {chunksize0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'quotechar {quotechar0}',f'escapechar {escapechar0}',f'compression {compression0}',f'encoding {encoding0}',f'errors {errors0}',f'decimal {decimal0}',f'storage_options {storage_options0}',sep='\n')
                    # try:
                        # print(df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
                    # except Exception as e:
                        # print(e)

# for lineterminator0 in [None,'\r\n\r\n']:
    # for mode0 in ['w','wb']:#'wb' must have file to write to to automatically assume bytes (if path_or_buf is None, then is string output, which is not compatible with bytes and will error)
        # print(f'path_or_buf {path_or_buf0}',f'sep {sep0}',f'float_format {float_format0}',f'date_format {date_format0}',f'na_rep {na_rep0}',f'columns {columns0}',f'header {header0}',f'index {index0}',f'index_label {index_label0}',f'lineterminator {lineterminator0}',f'mode {mode0}',f'chunksize {chunksize0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'quotechar {quotechar0}',f'escapechar {escapechar0}',f'compression {compression0}',f'encoding {encoding0}',f'errors {errors0}',f'decimal {decimal0}',f'storage_options {storage_options0}',sep='\n')
        # try:
            # print(df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
        # except Exception as e:
            # print(e)

# df0.to_csv(r'C:\Users\pdumas\Downloads\to_csv0test0wb.csv',mode='wb')
# os.system(r'C:\Users\pdumas\AppData\Local\Microsoft\WindowsApps\notepad++.exe C:\Users\pdumas\Downloads\to_csv0test0wb.csv')

# for chunksize0 in [None,4]:#all in 1 go (chunksize=None) is faster (e.g. 0.023780399933457375 vs 0.03888950007967651) at least on small files (8 rows); larger will have memory benefits if chunksize=<notAllRows>
    # print(f'path_or_buf {path_or_buf0}',f'sep {sep0}',f'float_format {float_format0}',f'date_format {date_format0}',f'na_rep {na_rep0}',f'columns {columns0}',f'header {header0}',f'index {index0}',f'index_label {index_label0}',f'lineterminator {lineterminator0}',f'mode {mode0}',f'chunksize {chunksize0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'quotechar {quotechar0}',f'escapechar {escapechar0}',f'compression {compression0}',f'encoding {encoding0}',f'errors {errors0}',f'decimal {decimal0}',f'storage_options {storage_options0}',sep='\n')
    # try:
        # print(df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
        # print(timeit.timeit('''df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0)''',number=20,globals=globals()))
    # except Exception as e:
        # print(e)

# for quoting0 in [csv.QUOTE_MINIMAL,csv.QUOTE_ALL,csv.QUOTE_NONNUMERIC,csv.QUOTE_NONE]:#much more predictable (besides csv.QUOTE_MINIMAL comment 2 rows below), as 'csv.QUOTE_MINIMAL,csv.QUOTE_ALL,csv.QUOTE_NONNUMERIC,csv.QUOTE_NONE' will wrap onlyFieldsWithCommentsInThem?(toDistinguish),everyDtype,prettyMuchOnlyStr,noFields, respectively
    # for doublequote0 in [True,False]:
        # for quotechar0 in ['"',"'"]:#anything other than '"' will wrap the quoted field (e.g. usually str fields) in the quotechar? (relates to how only csv.QUOTE_MINIMAL acts ?)
            # for escapechar0 in [None,'\\','l']:#escapechar is applied to all places in data to preserve original (e.g. if 'l' than 'val0' will become 'vall0' given 2 escapechars just means the escapechar literal; e.g. '\' with 'val0' will just result in 'val0')
                # print(f'path_or_buf {path_or_buf0}',f'sep {sep0}',f'float_format {float_format0}',f'date_format {date_format0}',f'na_rep {na_rep0}',f'columns {columns0}',f'header {header0}',f'index {index0}',f'index_label {index_label0}',f'lineterminator {lineterminator0}',f'mode {mode0}',f'chunksize {chunksize0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'quotechar {quotechar0}',f'escapechar {escapechar0}',f'compression {compression0}',f'encoding {encoding0}',f'errors {errors0}',f'decimal {decimal0}',f'storage_options {storage_options0}',sep='\n')
                # try:
                    # print(df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
                # except Exception as e:
                    # print(e)

# for compression0 in ['infer','zstd',{'method':'zstd','compressionlevel':3,'mtime':1},{'method':'zstd','level':3}]:#docs needs update since ''compressionlevel' is an invalid keyword argument for ZstdCompressor()' (same thing applies to mtime; the following works '''{'method':'zstd','level':3}'''); will still compress even though extension is .csv and resulting file is .csv (but will be compressed; probably better to use proper extension and 'infer' of course); zstd uses optional dependency package 'zstandard' so must install before usings
    # for path_or_buf0 in [r'C:\Users\pdumas\Downloads\to_csv0test0'+str(compression0)+'.csv']:
        # print(f'path_or_buf {path_or_buf0}',f'sep {sep0}',f'float_format {float_format0}',f'date_format {date_format0}',f'na_rep {na_rep0}',f'columns {columns0}',f'header {header0}',f'index {index0}',f'index_label {index_label0}',f'lineterminator {lineterminator0}',f'mode {mode0}',f'chunksize {chunksize0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'quotechar {quotechar0}',f'escapechar {escapechar0}',f'compression {compression0}',f'encoding {encoding0}',f'errors {errors0}',f'decimal {decimal0}',f'storage_options {storage_options0}',sep='\n')
        # try:
            # print(df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
            # os.system(r'C:\Users\pdumas\AppData\Local\Microsoft\WindowsApps\notepad++.exe '+path_or_buf0+'')
        # except Exception as e:
            # print(e)
            # try:
                # print(df0.to_csv(r'C:\Users\pdumas\Downloads\to_csv0test0compression0.csv',sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
                # os.system(r'C:\Users\pdumas\AppData\Local\Microsoft\WindowsApps\notepad++.exe C:\Users\pdumas\Downloads\to_csv0test0compression0.csv')
            # except Exception as e:
                # print(e)


# for encoding0 in [None,'ascii','iso-8859-1']:#all print in python .txt file given set encoding at very top of this file; actual .csvs will be different
    # for errors0 in ['strict','backslashreplace','ignore']:
        # for decimal0 in ['.',',']:#what result will look like in .csv (NOT what is read from [since it's a..] DataFrame)
            # print(f'path_or_buf {path_or_buf0}',f'sep {sep0}',f'float_format {float_format0}',f'date_format {date_format0}',f'na_rep {na_rep0}',f'columns {columns0}',f'header {header0}',f'index {index0}',f'index_label {index_label0}',f'lineterminator {lineterminator0}',f'mode {mode0}',f'chunksize {chunksize0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'quotechar {quotechar0}',f'escapechar {escapechar0}',f'compression {compression0}',f'encoding {encoding0}',f'errors {errors0}',f'decimal {decimal0}',f'storage_options {storage_options0}',sep='\n')
            # try:
                # print(df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
            # except Exception as e:
                # print(e)

# for encoding0 in [None,'ascii','iso-8859-1']:
    # for errors0 in ['strict','backslashreplace','ignore']:
        # for path_or_buf0 in [r'C:\Users\pdumas\Downloads\to_csv0test0encoding'+str(encoding0)+str(errors0)+'.csv']:
            # print(f'path_or_buf {path_or_buf0}',f'sep {sep0}',f'float_format {float_format0}',f'date_format {date_format0}',f'na_rep {na_rep0}',f'columns {columns0}',f'header {header0}',f'index {index0}',f'index_label {index_label0}',f'lineterminator {lineterminator0}',f'mode {mode0}',f'chunksize {chunksize0}',f'quoting {quoting0}',f'doublequote {doublequote0}',f'quotechar {quotechar0}',f'escapechar {escapechar0}',f'compression {compression0}',f'encoding {encoding0}',f'errors {errors0}',f'decimal {decimal0}',f'storage_options {storage_options0}',sep='\n')
            # try:
                # print(df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
                # os.system(r'C:\Users\pdumas\AppData\Local\Microsoft\WindowsApps\notepad++.exe '+path_or_buf0+'')
            # except Exception as e:
                # print(e)

# for storage_options0 in [None,{'s3':{'anon':True}}]:#storage options must be used with storage-option output (e.g. 's3' has to go to Amazon S3 output .csv file (starting with 's3://'))
    # try:
        # print(df0.to_csv(path_or_buf0,sep=sep0,float_format=float_format0,date_format=date_format0,na_rep=na_rep0,columns=columns0,header=header0,index=index0,index_label=index_label0,lineterminator=lineterminator0,mode=mode0,chunksize=chunksize0,quoting=quoting0,doublequote=doublequote0,quotechar=quotechar0,escapechar=escapechar0,compression=compression0,encoding=encoding0,errors=errors0,decimal=decimal0,storage_options=storage_options0))
    # except Exception as e:
        # print(e)
# # os.system(r'C:\Users\pdumas\AppData\Local\Microsoft\WindowsApps\notepad++.exe '+path_or_buf0+'')


#not sure why below didn't work in loop when reading from actual .csvs but works here!
from io import StringIO
val = "0.3066101993807095471566981359501369297504425048828125"
data = "a,b,c\n1,2,{0}".format(val)
print(abs(
    pd.read_csv(
        StringIO(data),
        engine="c",
        float_precision=None,
    )["c"][0] - float(val)
))
print(abs(
    pd.read_csv(
        StringIO(data),
        engine="c",
        float_precision="high",
    )["c"][0] - float(val)
))
print(abs(
    pd.read_csv(StringIO(data), engine="c", float_precision="legacy")["c"][0]#least precise (1.1102230246251565e-16 difference)
    - float(val)
))
print(abs(
    pd.read_csv(StringIO(data), engine="c", float_precision="round_trip")["c"][0]
    - float(val)
))


sys.stdout.close()
os.system(r'start "" "C:\Users\pdumas\Documents\SAP\SAP GUI\numpy0output1.txt"')
# time.sleep(10)
#python "C:\Users\pdumas\Documents\SAP\SAP GUI\numpy1.py"